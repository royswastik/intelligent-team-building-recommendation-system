Effects of Related Term Extraction in Transliteration into Chinese
HaiXiang Huang Atsushi Fujii
Graduate School of Library, Information and Media Studies
University of Tsukuba
1-2 Kasuga, Tsukuba, 305-8550, Japan
{lectas21,fujii}@slis.tsukuba.ac.jp
Abstract
To transliterate foreign words, in Japanese
and Korean, phonograms, such as Katakana
and Hangul, are used. In Chinese, the
pronunciation of a source word is spelled
out using Kanji characters. Because Kanji
is ideogrammatic representation, different
Kanji characters are associated with the
same pronunciation, but can potentially con-
vey different meanings and impressions. To
select appropriate Kanji characters, an ex-
isting method requests the user to provide
one or more related terms for a source word,
which is time-consuming and expensive. In
this paper, to reduce this human effort, we
use the World Wide Web to extract related
terms for source words. We show the effec-
tiveness of our method experimentally.
1 Introduction
Reflecting the rapid growth of science, technology,
and economies, new technical terms and product
names have progressively been created. These new
words have also been imported into different lan-
guages. There are two fundamental methods for im-
porting foreign words into a language.
In the first method?translation?the meaning of
the source word in question is represented by an ex-
isting or new word in the target language.
In the second method?transliteration?the pronun-
ciation of the source word is represented by using
the phonetic alphabet of the target language, such as
Katakana in Japanese and Hangul in Korean. Tech-
nical terms and proper nouns are often transliterated.
In Chinese, Kanji is used to spell out both conven-
tional Chinese words and foreign words. Because
Kanji is ideogrammatic, an individual pronunciation
can be represented by more than one character. If
several Kanji strings are related to the same pronun-
ciation of the source word, their meanings will be
different and convey different impressions.
For example, ?Coca-Cola? can be represented by
different Kanji strings in Chinese with similar pro-
nunciations, such as ?????? and ??????.
The official transliteration is ??????, which
comprises ??? (tasty)? and ??? (pleasant)?, and
is therefore associated with a positive connotation.
However, ?????? is associated with a nega-
tive connotation because this word includes ??? ?,
which is associated with ?choking?.
For another example, the official transliteration of
the musician Chopin?s name in Chinese is ????,
where ??? is commonly used for Chinese family
names. Other Kanji characters with the same pro-
nunciation as ??? include ???. However, ???,
which means ?to disappear?, is not ideal for a per-
son?s name.
Thus, Kanji characters must be selected carefully
during transliteration into Chinese. This is espe-
cially important when foreign companies intend to
introduce their names and products into China.
In a broad sense, the term ?transliteration? has
been used to refer to two tasks. The first task is
transliteration in the strict sense, which creates new
words in a target language (Haizhou et al, 2004;
Wan and Verspoor, 1998; Xu et al, 2006). The sec-
ond task is back-transliteration (Knight and Graehl,
1998), which identifies the source word correspond-
643
ing to an existing transliterated word. Both tasks
require methods that model pronunciation in the
source and target languages.
However, by definition, in back-transliteration,
the word in question has already been transliter-
ated and the meaning or impression of the source
word does not have to be considered. Thus, back-
transliteration is outside the scope of this paper. In
the following, we use the term ?transliteration? to
refer to transliteration in the strict sense.
Existing transliteration methods for Chi-
nese (Haizhou et al, 2004; Wan and Verspoor,
1998), which aim to spell out foreign names of
people and places, do not model the impression the
transliterated word might have on the reader.
Xu et al (2006) proposed a method to model both
the impression and the pronunciation for transliter-
ation into Chinese. In this method, impression key-
words that are related to the source word are used.
However, a user must provide impression keywords,
which is time-consuming and expensive.
In this paper, to reduce the amount of human ef-
fort, we propose a method that uses the World Wide
Web to extract related terms for source words.
2 Overview
Figure 1 shows our transliteration method, which
models pronunciation, impression, and target lan-
guage when transliterating foreign words into Chi-
nese. Figure 1 is an extension of the method pro-
posed by Xu et al (2006) and the part surrounded by
a dotted line is the scheme we propose in this paper.
We will explain the entire process using Figure 1.
There are two parts to the input for our method.
First, a source word to be transliterated into Chi-
nese is requested. Second, the category of the source
word, such as ?company? or ?person?, is requested.
The output is one or more Kanji strings.
Using the pronunciation model, the source word
is converted into a set of Kanji strings whose pro-
nunciation is similar to that of the source word. Each
of these Kanji strings is a transliteration candidate.
Currently, we use Japanese Katakana words as
source words, because Katakana words can be easily
converted into pronunciations using the Latin alpha-
bet. In Figure 1, the Katakana word ?epuson (EP-
SON)? is used as an example source word. How-
Source word
Related term(s)
Transliteration candidates Kanji characters
Category of source word
Ranked list of transliteration candidates
pronunciation model impression model
ranking candidates
language model
????(epuson)
??(like)??(popularize)??(general)?(good)
???(company)
????????? ...
?????? ??????????
World Wide Web
Kanji characters
Figure 1: Overview of our transliteration method.
ever, in principle, any language that uses a phonetic
script can be a source language for our method.
Using the impression model, one or more related
terms are converted into a set of Kanji characters.
In Xu et al (2006), one or more words that de-
scribe the impression of the source word are used as
related terms (i.e., impression keywords). Because
impression keywords are given manually, users must
have a good command of Chinese. In addition, the
task of providing impression keywords is expensive.
We solve these problems by automatically extracting
terms related to the source word from the Web.
Unlike Xu at al. (2006), the language model for
the category of the source word is used. For ex-
ample, if the category is ?person?, Kanji characters
that are often used for personal names in Chinese are
preferably used for the transliteration.
Because of the potentially large number of se-
lected candidates, we need to rank the candidates.
We model pronunciation, impression, and target lan-
guage in a probabilistic framework, so that candi-
dates are sorted according to their probability score.
In practice, the Kanji characters derived via the im-
pression and language models are used to re-rank the
candidates derived via the pronunciation model.
3 Probabilistic Transliteration Model
Given a romanized source word R, a set of related
terms W , and the category of the source word C,
our purpose is to select the Kanji string K that max-
imizes P (K|R,W,C), which is evaluated as shown
in Equation (1), using Bayes?s theorem.
644
P (K|R,W,C)
= P (R,W,C|K)?P (K)
P (R,W,C)
? P (R|K)?P (W |K)?P (C|K)?P (K)
P (R,W,C)
? P (R|K)?P (W |K)?P (C|K)?P (K)
= P (R|K)?P (W |K)?P (C,K)
(1)
Xu et al (2006) did not consider the category of the
source word and computed P (K|R,W ).
In the third line of Equation (1), we assume the
conditional independence of R, W , and C given K.
In the fourth line, we omit P (R,W,C), which is
independent of K. This does not affect the rela-
tive rank of Kanji strings, when ranked in terms of
P (K|R,W,C). If a user intends to select more than
one Kanji string, those Ks associated with higher
probabilities should be selected. In Figure 1, R, W ,
and C are ?epuson?, ?????????? and ??
???, respectively, and a K is ?????.
In Equation (1), P (K|R,W,C) can be approx-
imated by the product of P (R|K), P (W |K), and
P (C,K). We call these three factors the pronuncia-
tion, impression, and language models, respectively.
The implementation of P (R|K) and P (W |K) is
the same as in Xu et al (2006). While P (R|K) has
commonly been used in the literature, the basis of
P (W |K) should perhaps be explained. P (W |K) is
computed using co-occurrence frequencies of each
word in W and each character in K, for which we
extracted co-occurrences of a word and a Kanji char-
acter from a dictionary of Kanji in Chinese. Please
see Xu et al (2006) for details. However, unlike Xu
et al (2006), in which W was provided manually,
we automatically extract W from the Web.
While Xu et al (2006) did not use the language
model, we compute P (C,K) by Equation (2).
P (C,K) = P (C)?P (K|C) ? P (K|C) (2)
We omit P (C), which is independent of K. Thus,
we compute P (K|C), which is the probability that
a Kanji string K is selected given category C.
To compute P (K|C), we decompose K into sin-
gle Kanji characters. We used a character unigram
model and produced the following three language
models.
? general model: one month of newspaper arti-
cles in the PFR corpus1 were used. In this
model, 4 540 character types (12 229 563 to-
kens) are modeled.
? company model: a list of 22 569 company
names in CNLP (Chinese Natural Language
Processing)2 was used. In this model, 2 167
character types (78 432 tokens) are modeled.
? person model: a list of 38 406 personal names
in CNLP was used. In this model, 2 318 char-
acter types (104 443 tokens) are modeled.
To extract Kanji characters from the above corpus
and lists, we performed morphological analysis by
SuperMorpho3 and removed functional words and
symbols. While the general model is not adapted to
any specific category, the other models are adapted
to the company and person categories, respectively.
Although the effect of adapting language models has
been explored in spoken language processing, no at-
tempt has been made for transliteration.
4 Extracting Related Terms
To extract related terms for a source word, we used
Wikipedia4, which is a free encyclopedia on the Web
and includes general words, persons, places, compa-
nies, and products, as headwords. We extracted re-
lated term candidates for a source word as follows.
1. We consulted the Japanese Wikipedia for the
source word and obtained the result page.
2. We deleted HTML tags from the result page
and performed morphological analysis by
ChaSen5.
3. We extracted nouns and adjectives as related
term candidates.
We used mutual information (Turney, 2001) to
measure the degree of relation between the source
word and a related term candidate by Equation (3).
I(X,Y ) = log P (X,Y )
P (X) ? P (Y )
(3)
1http://icl.pky.edu.cn/
2http://www.nlp.org.cn/
3http://www.omronsoft.com/
4http://ja.wikipedia.org/wiki/
5http://chasen.naist.jp/hiki/ChaSen/
645
X and Y denote the source word and a related term
candidate, respectively. P (X) and P (Y ) denote
probabilities of X and Y , respectively. P (X,Y ) de-
notes the joint probability of X and Y .
To estimate the above three probabilities, we fol-
lowed the method proposed by Turney (2001). We
used the Yahoo!JAPAN6 search engine and replaced
P (A) in Equation (3) with the number of pages re-
trieved by the query A. Here, ?A? can be ?X?, ?Y ?,
or ?X and Y ?. Then, we selected up to 10 Y s with
the greatest I(X,Y ) and translated them into Chi-
nese using the Yahoo!JAPAN machine translation
system.
Table 1 shows examples of related terms for the
source word ??? (mass)?, such as ??? (cere-
mony)? and ? ?? (dedication)?. Irrelevant candi-
dates, such as ? ? (meeting)? and ??? (thing)?,
were discarded successfully.
Table 1: Example of related terms for ??? (mass)?.
Extracted related terms Discarded candidates
Japanese English Japanese English
?? ceremony ? meeting
?? dedication ?? thing
?? bishop ?? meeting
?? church ?? join
5 Experiments
5.1 Method
To evaluate the effectiveness of the related term ex-
traction in the transliteration, we compared the ac-
curacy of the following three methods.
? A combination of the pronunciation and lan-
guage models that does not use the impression
model, P (W |K), in Equation (1),
? Our method, which uses Equation (1) and uses
automatically extracted related terms as W ,
? Equation (1), in which manually provided im-
pression keywords are used as W .
To make the difference between the second and
third methods clear, we use the terms ?related term
(RT)? and ?impression keyword (IK)? to refer to
6http://www.yahoo.co.jp/
words provided automatically and manually, respec-
tively. Then, we call the above three methods
?PL?, ?PL+RT?, and ?PL+IK?, respectively. PL and
PL+IK are the lower bound and the upper bound of
the expected accuracy, respectively. PL+IK is the
same as in Xu et al (2006), but the language model
is adapted to the category of source words.
To produce test words for the transliteration, we
first collected 210 Katakana words from a Japanese?
Chinese dictionary. These 210 words were also used
by Xu et al (2006) for experiments. We then con-
sulted Wikipedia for each of the 210 words and se-
lected 128 words that were headwords in Wikipedia,
as test words. Details of the 128 test words are
shown in Table 2.
Table 2: Categories of test words.
Category #Words
Example word
Japanese Chinese English
General 24 ????? ??? angel
Company 35 ???? ??? Intel
Product 27 ???? ?? Audi
Person 13 ???? ?? Chopin
Place 29 ???? ??? Ohio
We selectively used the three language models ex-
plained in Section 3. We used the general model
for general words. We used the company model for
company and product names, and used the person
model for person and place names. A preliminary
study showed that the language model adaptation
was generally effective for transliteration. However,
because the focus of this paper is the related term
extraction, we do not describe the evaluation of the
language model adaptation.
Two Chinese graduate students who had a good
command of Japanese served as assessors and pro-
duced reference data, which consisted of impression
keywords used for PL+IK and correct answers for
the transliteration. Neither of the assessors was an
author of this paper. The assessors performed the
same task for the 128 test words independently, to
enhance the objectivity of the evaluation.
We produced the reference data via the following
procedure that is the same as that of Xu et al (2006).
First, for each test word, each assessor pro-
vided one or more impression keywords in Chinese.
We did not restrict the number of impression key-
646
words per test word; the number was determined
by each assessor. We provided the assessors with
the descriptions for the test words from the source
Japanese?Chinese dictionary, so that the assessors
could understand the meaning of each test word.
Second, for each test word, we applied the three
methods (PL, PL+RT, and PL+IK) independently,
which produced three lists of ranked candidates.
Third, for each test word, each assessor identi-
fied one or more correct transliterations, according
to their impression of the test word. It was impor-
tant not to reveal to the assessors which method pro-
duced which candidates. By these means, we se-
lected the top 100 transliteration candidates from the
three ranked lists. We merged these candidates, re-
moved duplications, and sorted the remaining can-
didates by character code. The assessors judged
the correctness of up to 300 candidates for each
test word. The average number of candidates was
36 976.
The resultant reference data were used to evaluate
the accuracy of each method in ranking translitera-
tion candidates. We used the average rank of correct
answers in the list as the evaluation measure. If more
than one correct answer was found for a single test
word, we first averaged the ranks of these answers
and then averaged the ranks over the test words.
For each test word, there was more than one type
of ?correct answer?, as follows:
(a) transliteration candidates judged as correct by
either of the assessors independently,
(b) transliteration candidates judged as correct by
both assessors,
(c) transliteration defined in the source Japanese?
Chinese dictionary.
In (a), the coverage of correct answers is the largest,
whereas the objectivity of the judgment is the low-
est. In (c), the objectivity of the judgment is the
largest, whereas the coverage of correct answers is
the lowest. In (b), where the assessors did not dis-
agree about the correctness, the coverage of the cor-
rectness and the objectivity are in between.
The number of test words was 128 for both (a) and
(c), but 76 for (b). The average numbers of correct
answers were 1.65, 1.04, and 1 for (a), (b), and (c),
respectively.
5.2 Results and Analyses
Table 3 shows the average rank of correct answers
for different cases. Looking at Table 3, for certain
categories, such as ?Place?, when the impression
model was used, the average rank was low. How-
ever, on average, the average rank for PL+RT was
lower than that for PL+IK, but was higher than that
for PL, irrespective of the answer type.
Figures 2 and 3 show the distribution of correct
answers for different ranges of ranks, using answer
types (a) and (c) in Table 3, respectively. Because
the results for types (a) and (b) were similar, we
show only the results of type (a), for the sake of con-
ciseness. In Figure 2, the number of correct answers
in the top 10 for PL+RT was smaller than that for
PL+IK, but was greater than that for PL.
In Figure 3, the number of correct answers in the
top 10 for PL+RT was greater than those for PL and
PL+IK. Because in Figure 3, the correct answers
were defined in the dictionary and were independent
of the assessor judgments, PL+IK was not as effec-
tive as in Figure 2.
In summary, the use of automatically extracted re-
lated terms was more effective than the method that
does not use the impression model. We also reduced
the manual cost of providing impression keywords,
while maintaining the transliteration accuracy.
Table 4 shows examples of related terms or im-
pression keywords for answer type (c). In Table
4, the column ?Rank? denotes the average rank
of correct answers for PL+RT and PL+IK, respec-
tively. For ??? (mass)?, the rank for PL+RT was
higher than that for PL+IK. However, for ????
? (the State of Qatar)?, the rank for PL+RT was
lower than that for PL+IK. One reason for this is
that most related terms for PL+RT were names of
countries that border Qatar, which do not describe
Qatar well, compared with impression keywords for
PL+IK, such as ??? (desert)? and ? ?? (oil)?.
This example indicates room for improvement in the
related term extraction algorithm.
6 Conclusion
For transliterating foreign words into Chinese, the
pronunciation of a source word is spelled out with
Kanji characters. Because Kanji is an ideogram-
matic script, different Kanji characters are associ-
647
Table 3: Average rank of correct answers for different methods in different cases.
Category
Answer type (a) Answer type (b) Answer type (c)
PL PL+RT PL+IK PL PL+RT PL+IK PL PL+RT PL+IK
General 189 165 167 44 49 52 84 61 65
Company 232 208 203 33 29 27 317 391 325
Product 197 175 166 34 27 21 313 198 198
Person 98 69 44 4 4 4 114 154 75
Place 85 133 95 13 14 16 76 98 89
Avg. 160 150 135 26 25 24 181 160 150
?
??
??
??
???
???
???? ????? ?????? ??????? ???????
?
???????
?? ?????????
????????
????????
???? PL PL?RT PL?IK
Figure 2: Rank for correct answer type (a).
???
????
?????
???
???? ????? ?????? ??????? ???????? ????????
? ?????????
????????
????????
???? PL PL?RT PL?IK
Figure 3: Rank for correct answer type (c).
Table 4: Examples of related terms and impression keywords used for experiments.
Source word Answer Method Rank Examples of related terms or impression keywords
??
??
PL+RT 8 ?? (ceremony),?? (bishop),?? (dedication),?? (church)
(mass) PL+IK 10 ?? (ceremony),?? (bishop),?? (belief),?? (church)
????
???
PL+RT 103 ??? (State of Kuwait),?? (Republic of Yemen)
(State of Qatar) PL+IK 61 ??? (Arab),?? (desert),?? (oil),?? (dryness)
ated with the same pronunciation, but can poten-
tially convey different meanings and impressions.
In this paper, to select appropriate characters for
transliterating into Chinese, we automatically ex-
tracted related terms for source words using the
Web. We showed the effectiveness of our method
experimentally.
References
Li Haizhou, Zhang Min, and Su Jian. 2004. A joint
source-channel model for machine transliteration. In
Proceedings of the 42nd Annual Meeting of the Asso-
ciation for Computational Linguistics, pages 160?167.
Kevin Knight and Jonathan Graehl. 1998. Machine
transliteration. Computational Linguistics, 24(4):599?
612.
Peter D. Turney. 2001. Mining the Web for Synonyms:
PMI-IR versus LSA on TOEFL. In Proceedings of the
Twelfth European Conference on Machine Learning,
pages 419?502.
Stephen Wan and Cornelia Maria Verspoor. 1998. Auto-
matic English-Chinese name transliteration for devel-
opment of multilingual resources. In Proceedings of
the 36th Annual Meeting of the Association for Com-
putational Linguistics and the 17th International Con-
ference on Computational Linguistics, pages 1352?
1356.
LiLi Xu, Atsushi Fujii, and Tetsuya Ishikawa. 2006.
Modeling Impression in Probabilistic Transliteration
into Chinese. Proceedings of the 2006 Conference on
Empirical Methods in Natural Language Processing,
pages 242?249.
648
