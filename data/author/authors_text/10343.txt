Proceedings of the ACL-08: HLT Demo Session (Companion Volume), pages 28?31,
Columbus, June 2008. c?2008 Association for Computational Linguistics
ModelTalker Voice Recorder ? An Interface System for Recording a 
Corpus of Speech for Synthesis 
 
 
Debra Yarrington, John Gray,  
Chris Pennington  
 
H. Timothy Bunnell, Allegra Cornaglia, 
Jason Lilley, Kyoko Nagao,  
James Polikoff,  
AgoraNet, Inc. Speech Research Laboratory 
Newark, DE  19711 A.I. DuPont Hospital for Children 
USA Wilmington, DE  19803, USA 
{yarringt, gray, penningt} 
@agora-net.com 
{bunnell, cornagli, lilley,  
nagao, polikoff}@asel.udel.edu 
 
 
 
 
Abstract 
We will demonstrate the ModelTalker Voice 
Recorder (MT Voice Recorder) ? an interface 
system that lets individuals record and bank a 
speech database for the creation of a synthetic 
voice. The system guides users through an au-
tomatic calibration process that sets pitch, 
amplitude, and silence. The system then 
prompts users with both visual (text-based) 
and auditory prompts. Each recording is 
screened for pitch, amplitude and pronuncia-
tion and users are given immediate feedback 
on the acceptability of each recording. Users 
can then rerecord an unacceptable utterance. 
Recordings are automatically labeled and 
saved and a speech database is created from 
these recordings. The system?s intention is to 
make the process of recording a corpus of ut-
terances relatively easy for those inexpe-
rienced in linguistic analysis. Ultimately, the 
recorded corpus and the resulting speech da-
tabase is used for concatenative synthetic 
speech, thus allowing individuals at home or 
in clinics to create a synthetic voice in their 
own voice. The interface may prove useful  
for other purposes as well. The system facili-
tates the recording and labeling of large cor-
pora of speech, making it useful for speech 
and linguistic research, and it provides imme-
diate feedback on pronunciation, thus making 
it useful as a clinical learning tool.  
 
1 Demonstration 
1.1 MT Voice Recorder Background 
While most of us are familiar with the highly intel-
ligible but somewhat robotic sound of synthetic 
speech, for the approximately 2 million people in 
the United States with a limited ability to commu-
nicate vocally (Matas et al, 1985), these synthetic 
voices are inadequate. The restricted number of 
available voices lack the personalization they de-
sire. While intelligibility is a priority for these in-
dividuals, almost equally important is the 
naturalness and individuality one associates with 
one?s own voice. Individuals with difficulty speak-
ing can be any age, gender, and from any part of 
the country, with regional dialects and idiosyncrat-
ic variations. Each individual deserves to speak 
with a voice that is not only intelligible, but uni-
quely his or her own. For those with degenerative 
diseases such as Amyotrophic Lateral Sclerosis 
(ALS), knowing they will be losing the voice that 
has become intricately associated with their identi-
ty is not only traumatic to the individual but to 
family and friends as well.  
A form of synthesis that incorporates the quali-
ties of individual voices is concatenative synthesis. 
In this type of synthesis, units of recorded speech 
are appended. By using recorded speech, many of 
the voice qualities of the person recording the 
speech remain in the resulting synthetic voice. Dif-
ferent synthesis systems append different sized 
28
segments of speech. Appending larger the units of 
speech results in smoother, more natural sounding 
synthesis, but requires many hours of recording, 
often by a trained professional. The recording 
process is usually supervised, and the recordings 
are often hand-polished. Because appending small-
er units requires less recording on the part of the 
speaker, this is the approach the ModelTalker Syn-
thesizer has taken. However using smaller units 
may result in noticeable auditory glitches at conca-
tenative junctures that are a result of variations (in 
pitch, amplitude, pronunciation, etc.) between the 
speech units being appended. Thus the speech rec-
orded must be more uniform in pitch and ampli-
tude. In addition, the units cannot be 
mispronounced because each unit is crucial to the 
resulting synthetic speech. In a smaller database 
there may not be a second example of a specific 
phoneme sequence.  
MT Voice Recorder expects that the individuals 
recording will be untrained and unsupervised, and 
may lack strength and endurance because of the 
presence of a degenerative disease. Thus the sys-
tem is user-friendly enough for untrained, unsu-
pervised individuals to record a corpus of speech. 
The system provides the user with feedback on the 
quality of each utterance they record in terms of 
pronunciation accuracy, relative uniformity of 
pitch, and relative uniformity of amplitude. Confe-
rence attendees will be able to experience this in-
terface system and test all its different features. 
1.2 Feature Demonstration 
At the conference, attendees will be able to try out 
the different features of ModelTalker Voice Re-
corder. These features include automatic micro-
phone calibration, pitch, amplitude, and 
pronunciation detection and feedback, and auto-
matic phoneme labeling of speech recordings. 
 
1.2.1 Microphone calibration 
One important new feature of the MT Voice Re-
corder is the automatic microphone calibration 
procedure. In InvTool, a predecessor software of 
MT Voice Recorder, users had to set the micro-
phone?s amplitude. The system now calibrates the 
signal to noise ratio automatically through a step-
by-step process (see Figure 1, below). 
 
 
Using the automatic calibration procedure, the 
optimal signal to noise ratio is set for the recording 
session. These measurements are retained for fu-
ture recording sessions in cases in which an indi-
29
vidual is unable to record the entire corpus in one 
sitting. 
Once the user has completed the automatic cali-
bration procedure, he will be able to start recording 
a corpus of speech. The interface has been de-
signed with the assumption that individuals will be 
recording without supervision. Thus the interface 
incorporates a number of feedback mechanisms to 
aid individuals in making a high quality corpus for 
synthesis (see Figure 2, below). 
 
1.2.2 Recording Utterances 
The corpus was carefully chosen so that all fre-
quently used phoneme combinations are included 
at least once. Thus it is critical that users pro-
nounce prompted sentences in the manner in which 
the system expects. Alterations in pronunciation as 
small as saying /i/ versus /?/ for ?the,? for example, 
can negatively affect the resulting synthetic voice. 
To reduce the incidence of alternate pronunciation, 
the user is prompted with both a text and an audito-
ry version of the utterance.  
 
1.2.3 Recording Feedback 
Once an utterance has been recorded, the user rece-
ives feedback on the overall quality of the utter-
ance. Specifically, the user receives feedback on 
the pitch, the overall amplitude, and the pronuncia-
tion of the recording. 
Pitch: The user receives feedback on whether 
the utterance?s average pitch is within range of the 
user?s base pitch determined during the calibration 
process. Collecting all recordings within a relative-
ly small pitch range minimizes concatenation costs 
during the synthesis process. MT Voice Recorder 
determines the average pitch of each utterance and 
gives the user feedback on whether the pitch is 
within an acceptable range. This feedback mechan-
ism also helps to eliminate cases in which the sys-
tem is unable to accurately track the pitch of an 
utterance. In these cases, the utterance will be 
marked unacceptable and the user should rerecord, 
hopefully yielding an utterance with more accurate 
pitch tracking. 
 
 
Figure 2: MT Voice Recorder User Interface 
30
Amplitude: The user is also given feedback on 
the overall amplitude of an utterance. If the ampli-
tude is either too low or too high, the user must 
rerecord the utterance. 
Pronunciation: Each recorded utterance is eva-
luated for pronunciation. Each utterance within the 
corpus is associated with a string of phonemes 
representing its transcription. When an utterance is 
recorded, the phoneme string associated with the 
utterance is force-aligned with the recorded 
speech. If the alignment does not fall within an 
acceptable range, the user is given feedback that 
the recording?s pronunciation may not be accepta-
ble and the user is given the option of rerecording 
the utterance. 
 
1.2.4 Automatic Phoneme Labeling  
During the process of pronunciation evaluation, an 
associated phoneme transcription is aligned with 
the utterance. This alignment is retained so that 
each utterance is automatically labeled. Once the 
entire corpus has been recorded, alignments are 
automatically refined based on specific individual 
voice characteristics. 
 
1.2.5 Other Features 
The MT Voice Recorder also allows users to add 
utterances of their choice to the corpus of speech 
for the synthetic voice. These utterances are those 
the user wants to be synthesized clearly and will 
automatically be included in their entirety in the 
speech database. These utterances are also auto-
matically labeled before being stored. 
In addition, for those with more speech and lin-
guistic experience, the system has a number of 
other features that can be explored. For example, 
the MT Voice Recorder also allows one to change 
settings so that the phoneme string, peak ampli-
tude, RMS range, average F0, F0 range, and pro-
nunciation score can be viewed. Users may use this 
information to more precisely adjust their utter-
ances. 
1.3 Synthetic Voice Demonstration 
Those attending the demonstration will also be 
able to listen to a sampling of synthetic voices 
created using the ModelTalker system. While one 
of the synthetic voices was created by a profes-
sional speaker and manually polished, all other 
voices were created by untrained individuals, most 
of whom have ALS, in an untrained setting, with 
the recordings having no manual polishing. 
2 Other Applications 
Although the MTVR was designed specifically to 
record speech for the creation of a database that 
will be used in speech synthesis, it can also be used 
as a digital audio recording tool for speech re-
search. For example, the MT Voice Recorder of-
fers useful features for language documentation. 
An immediate warning about a poor quality re-
cording will alert a researcher to rerecord the utter-
ance. MT Voice Recorder employs file formats 
that are recommended for digital language docu-
mentation (e.g., XML, WAV, and TXT) (Bird & 
Simons, 2003). The recorded files are automatical-
ly stored with broad phonetic labels. The automatic 
saving function will reduce the time of recordings 
and the potential risk for miscataloging the files. 
Currently, the automatic phonetic labeling feature 
is only available for English, but it could be appli-
cable to different languages in the future.  
For more information about the ModelTalker 
System and to experience an interactive demo as 
well as listen to sample synthetic voices,  
visit http://www.modeltalker.com.  
Acknowledgments 
This work was supported by STTR grants 
R41/R42-DC006193 from NIH/NIDCD and from 
Nemours Biomedical Research. We are especially 
indebted to the many people with ALS, the AAC 
specialists in clinics, and other interested individu-
als who have invested a great deal of time and ef-
fort into this project and have provided valuable 
feedback. 
References  
Bird, S. and Simons, G.F. (2003). Seven dimensions of 
portability for language documentation and descrip-
tion. Language, 79(3): 557-582. 
Matas, J., Mathy-Laikko, P., Beaukelman, D. and Le-
gresley. K. (1985). Identifying the nonspeaking 
population: a demographic study, Augmentative & 
Alternative Communication, 1: 17-31. 
  
31
