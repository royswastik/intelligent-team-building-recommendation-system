Linguistic Interpretation of Emotions for Affect Sensing from Text 
Mostafa Al Masum Shaikh 
Dept. of Information and 
Communication Engineering 
University of Tokyo 
7-3-1 Hongo, Bunkyo-Ku 
113-8656 Tokyo, Japan 
almasum@gmail.com 
Helmut Prendinger 
Digital Contents and Media 
Sciences Research Division 
National Institute of Informatics
2-1-2 Hitotsubashi, Chiyoda Ku
101-8430 Tokyo, Japan 
helmut@nii.ac.jp 
Mitsuru Ishizuka 
Dept. of Information and 
Communication Engineering
University of Tokyo 
7-3-1 Hongo, Bunkyo-Ku 
113-8656 Tokyo, Japan 
ishizuka@ieee.org 
 
Abstract 
Several approaches have already been em-
ployed to ?sense? affective information from 
text, but none of those ever considered the 
cognitive and appraisal structure of individ-
ual emotions. Hence this paper aims at inter-
preting the cognitive theory of emotions 
known as the OCC emotion model, from a 
linguistic standpoint. The paper provides 
rules for the OCC emotion types for the task 
of sensing affective information from text. 
Since the OCC emotions are associated with 
several cognitive variables, we explain how 
the values could be assigned to those by ana-
lyzing and processing natural language com-
ponents. Empirical results indicate that our 
system outperforms another state-of-the-art 
system.   
1 Introduction and Motivation 
While various conceptual models, computational 
methods, techniques, and tools are reported in 
(Shanahan et. al., 2006), we argue that the current 
work for sensing the affect communicated by text 
is incomplete and often gives inaccurate results. It 
is true that the assessment of affective content is 
inevitably subjective and subject to considerable 
disagreement. Yet the interest in sentiment or af-
fect based text categorization is increasing with the 
large amount of text becoming available on the 
Internet. A brief discussion on available ap-
proaches is given in (Shaikh et. al., 2007a; Liu et. 
al., 2003). For example, keyword spotting, lexical 
affinity, statistical and hand crafted approaches 
target affective lexicons which are not sufficient to 
recognize affective information from text, because 
according to a linguistic survey (Pennebaker et. al., 
2003), only 4% of words used in written texts carry 
affective content. 
In this paper we consider the contextual-
valenced based approached (i.e., SenseNet) as dis-
cussed by Shaikh et. al., (2007a, 2007b) and con-
sider their SenseNet as the basis of our know-
ledgebase. For simplicity, we use the words ?sen-
timent? and ?opinion? synonymously and consider 
sentiment sensing as the prior task of ?affect? or 
?emotion? sensing. The SenseNet can sense either 
positive or negative ?sentiment?, but it cannot clas-
sify different emotions. Therefore, this paper ex-
plains how the SenseNet can be employed to sense 
emotions from text. So the primary focus of this 
paper is to provide a set of rules for emotions char-
acterized by the OCC (Ortony et. al., 1988) emo-
tion model and discuss how the rules are imple-
mented.  
2 Affect Sensing from Text 
2.1 Extending Valence Assignment Approach 
for Emotions Classification 
For the task of affect sensing from text we should 
incorporate both commonsense knowledge and 
cognitive structure of emotions along with the se-
mantic interpretation of the words used in a sen-
tence. We have chosen the OCC model of emo-
tions for this task. The rule-based definition of the 
OCC emotion types characterized by a rich set of 
linguistic tokens makes it appropriate to cope with 
the valence assignment approach for affect sensing 
from text.   
2.2 Characterization of OCC Emotions  
The OCC emotion types can be characterized by 
appropriate rules interplaying with several vari-
ables. There are two kinds of variables, namely, 
895
emotion inducing variables (event, agent and ob-
ject based variables) and emotion intensity vari-
ables. The event-based variables are calculated 
with respect to the event which is usually a verb-
object pair found in the sentence. For example, the 
sentence, John bought Mary an ice-cream, gives 
an event as ?buy, ice-cream?. The variables are 
enlisted in Table 1. In general we call them ?emo-
tion variables?. 
Type Variable Name 
agent_fondness (af) agent based 
cognitive_strength (cs) 
object_fondness (of) object based 
object_appealing (oa) 
self_reaction (sr) 
self_presumption (sp) 
other_presumption (op) 
prospect (pros) 
status (stat) 
unexpectedness (unexp) 
self_appraisal (sa) 
event based 
valenced_reaction (vr) 
event_deservingness (ed) 
effort_of_action (eoa) 
expected_deviation (edev) 
intensity  
event_familiarity (ef) 
        Table 1. OCC emotion variables 
 
The OCC emotion model specifies 22 emotion 
types and 2 cognitive states. For example, OCC 
model literally defines ?Happy-for? as ?Pleased 
about a Desirable event for a Liked agent?, and 
?Fear? as ?Displeased about Negative Prospect of 
an Undesirable Unconfirmed event?. Our goal is to 
represent these literal definitions by rules inter-
playing with the emotion variables so that the sys-
tem can evaluate and get either a ?true? or ?false? 
value. For example, we have an input text txt, that 
has an agent a, associated with an event e, and we 
have a program entity x that detects emotion from 
txt. We can now represent the rule for ?Happy-for? 
emotion as, x senses ?Happy-for? if the following 
condition holds. 
[Linguisitc_Token_found_for_HappyFor(txt) and 
No_Negation_Found (txt)] or [vr =True and sr (e, 
txt) = ?Pleased? and op(e, txt) = ?Desirable? and  
af (x, txt) = ?Liked? and cs (a,x) = ?Other?]    
 
3 Implementation of the Rules 
In this section, we first briefly discuss about the 
SenseNet and its different linguistic resources. 
Then we explain the ?emotion variables?, their 
enumerated values and how the values are assigned 
to the respective variables. 
3.1 SenseNet  
Semantic Parser. The SenseNet has imple-
mented a semantic parser using Machinese Syntax 
(Connexor Oy, 2005) that produces XML-
formatted syntactic output for an input text. For 
example, the sentence, ?My mother presented me a 
nice wrist watch on my birthday and made deli-
cious pancakes.?, the output of the semantic parser 
is shown in Table 2.  
 
Triplet Output of Semantic Parser 
Triplet 1 [['Subject Name:', 'mother', 'Subject 
Type:', 'Person', 'Subject Attrib:', 
['PRON PERS GEN SG1:i']], ['Action 
Name:', 'present', 'Action Status:', 
'Past ', 'Action Attrib:', ['time: my 
birthday', 'Dependency: and']], ['Ob-
ject Name:', 'watch', 'Object Type:', 'N 
NOM SG', 'Object Attrib:', ['Deter-
miner: a', 'A ABS: nice', 'N NOM SG: 
wrist', 'Goal: i']]] 
Triplet 2 [['Subject Name:', 'mother', 'Subject 
Type:', 'Person', 'Subject Attrib:', []], 
['Action Name:', 'make', 'Action 
Status:', 'Past ', 'Action Attrib:', []], 
['Object Name:', 'pancake', 'Object 
Type:', 'N NOM PL', 'Object Attrib:', 
['A ABS: delicious']]] 
Table2.  Semantic Verb-Frames outputted by Se-
mantic Parser 
  
Semantic parser outputs each semantic verb-frame 
of a sentence as a triplet of ?subject, verb, and ob-
ject?. Hence, one obtains multiple triplets if the 
parser encounters multiple verbs in a sentence. In 
our case, we consider each triplet to indicate an 
event encoding the information about ?who is do-
ing what and how?. Therefore, the output given in 
Table 2 has two events, which are dependent to 
each other as indicated by ?dependency? keyword 
in the action attribute of Triplet 1. 
Valenced Output. SenseNet is the implementa-
tion of contextual valence based approach that 
deals with semantic relationships of the words in a 
sentence and assign contextual-valence using a set 
of rules and prior-valence of the words. It outputs a 
numerical value ranging from -15 to +15 flagged 
as the ?sentence-valence? for each input sentence. 
896
For examples, SenseNet outputs -11.158 and 
+10.973 for the inputs, ?The attack killed three 
innocent civilians.? and ?It is difficult to take bad 
photo with this camera.?, respectively. These val-
ues indicate a numerical measure of negative or 
positive sentiments carried by the sentences.  
Scored-list of Action, Adjective, and Adverb. 
SenseNet has initially assigned prior-valence to 
928 verbs, 948 adjectives and 144 adverbs by 
manual investigations of eight judges where the 
inter-agreement among the judges are reported as 
reliable (i.e., the Kappa value is 0.914). The judges 
have manually counted the number of positive and 
negative senses of each word of a selected list ac-
cording to the contextual explanations of each 
sense found in WordNet 2.1. A database of words 
with prior-valence assigned using Equations (1) to 
(3) is developed and scores are stored in the scale 
of -5 to 5. 
Prior-Valence = Average (((Positive-Sense 
Count ? Negative-Sense Count)/Total Sense 
Count) * 5.0) 
(1)
Prospect Polarity = if (Positive-Sense Count > 
Negative-Sense Count) then 1 else -1  
Prospective Valence = Average(max(Positive-
Sense Count, Negative-Sense Count)/Total 
Sense Count) * 5.0*Prospect Polarity) 
(2)
Praiseworthy Valence = Average (Prior-
Valence + Prospective Valence) 
(3)
 
Scored-list of Nouns. SenseNet does an auto-
matic approach to assign prior-valence to nouns by 
employing ConceptNet (Liu and Singh, 2004). A 
value between -5 to 5 is assigned as the valence for 
an unrated noun or concept as follows. To assign a 
prior-valence to a concept, the system collects all 
semantically connected entities that ConceptNet 
returns for the input concept. For example, to get 
the prior-valence for the noun ?rocket?, the system 
failed to find it in the existing knowledgebase, but 
from the action list of the concept the system re-
turned the value 4.112 by averaging the scores of 
the verbs ?carry (4.438)?, ?contain (4.167)?, ?fly 
(3.036)?, ?launch (5.00)? and ?go (3.917)?. 
3.2 Assigning Values to the Emotion Variables 
According to the OCC model, the values for the 
variables self_presumption (sp) and self_reaction 
(sr) are ?Desirable? or ?Undesirable?, and 
?Pleased? or ?Displeased? respectively. For exam-
ple, for the events ?buy ice-cream?, ?present wrist 
watch?, ?kill innocent civilians? referred in the 
example sentences  SenseNet returns contextual 
valence as +7.832, +8.817 and -8.458, respec-
tively. According to SenseNet scoring system the 
valence range for an event (i.e., verb, object pair) 
is ?10. Thereby we decide that for an event if the 
valence is positive (i.e., ?buy ice-cream?), sp and 
sr are set as ?Desirable? and ?Pleased?, and in the 
case of negative valence (i.e., ?Kill innocent civil-
ian?) sp and sr are set to ?Undesirable? and ?Dis-
pleased?, respectively.  
The values for other_presumption (op) could be 
set ?Desirable? or ?Undesirable?. For the sentence 
?A terrorist escaped from the Jail?, the value for 
op (for the event ?escape from jail?) is presumably 
?Desirable? for the agent ?terrorist? but it gets 
?Undesirable? and ?Displeased? for sp and sr be-
cause of negative valence (i.e., -6.715) of the 
event. From SenseNet we get the valence for ter-
rorist as -3.620. Thus in this case we set op as ?De-
sirable? because of having a negative valenced 
event associated with a negative valenced agent. 
Similarly we have the following simple rules to 
assign the values to op. 
? If a positive valenced event is associated with 
a positive valenced agent, op is set ?Desir-
able?. e.g., the Teacher was awarded the best-
teacher award. [(teacher, +4.167) , (award 
best-teacher award, +8.741)]  
? If a negative valenced event is associated with 
a positive valenced agent, op is set ?Undesir-
able?. e.g., the employee was sacked from the 
job.  [(employee, +3.445), (sack from job, -
6.981)]   
? If a positive valenced event is associated with 
a negative valenced agent, op is set ?Undesir-
able?. e.g., the criminal was punished for the 
crime. [(criminal,-3.095), (punish for crime, 
+5.591)] 
In this context and in accordance to the OCC 
model, the value for cognitive_strength (cs) indi-
cates how closely the computer program considers 
selfness. This value is set as ?Self? if the agent de-
scribed in the text is a first person (i.e., I or We); 
otherwise it is set as ?Other?. For the sentence, ?I 
wish I could win the lottery.?, cs is set ?Self?, but 
for the sentence, ?Susan won the million dollar 
lottery.?, cs is set ?Other?. 
According to the OCC model, prospect of an 
event involves a conscious expectation that it will 
897
occur in the future, and the value for the variable 
prospect (pros) can be either ?Positive? or ?Nega-
tive?. In the aforementioned equation (2), Sense-
Net considers either the positive or negative sense-
count (whichever is the maximum for a verb) to 
calculate ?prospective valence? with the notion of 
semantic orientation towards optimistic-pessimistic 
scale. In order to assign pros value to an event we 
also consider the ?prospective valence? of the verb 
instead of ?prior-valence? of that verb. Thus ?posi-
tive? or ?negative? is assigned according to a cer-
tain threshold (i.e., ?3.5) for ?positive? or ?nega-
tive? valence obtained for that event. For example, 
the events ?admit into university?, ?kill innocent 
people?, ?do it?, SenseNet returns  +9.375, -8.728, 
+2.921, respectively and according to this valence, 
pros of the events is set to ?positive?, ?negative? 
and ?null?, respectively.  
The variable status (stat) has the values like: 
?Unconfirmed?, ?Confirmed? and ?Disconfirmed?. 
We decide if the tense of the verb is present or fu-
ture, the value is set to ?Unconfirmed? (e.g., I am 
trying to solve it.); and if it is past or modal with-
out a negation, stat is set ?Confirmed? (e.g., I suc-
ceeded.), but with a negation, stat is set ?Discon-
firmed? (e.g., I did not succeed.). 
If the valence of the agent/object is positive, 
?Liked? is set to the variables agent_fondness (af) 
and object_fondness (of) variables, otherwise 
?Not-liked? is set. For example, for the sentences, 
?The hero appeared to save the girl.?, and ?A ter-
rorist escaped from the Jail?, af for ?hero? and 
?terrorist? is set to ?Liked? and ?Not-Liked? be-
cause of positive and negative valence. Similarly, 
of is set ?Liked? and ?Not-Liked? for ?girl? and 
?Jail? respectively.  
The value for self_appraisal (sa) can be either 
?Praiseworthy? or ?Blameworthy?. In the afore-
mentioned equation (3) SenseNet takes the average 
of ?Prior Valence? and ?Prospective Valence? of a 
verb with the notion of average semantic orienta-
tion of the verb from both good-bad and optimis-
tic-pessimistic perspective. Like assigning pros 
value to an event we consider the ?praiseworthy 
valence? of the verb to assign value to sa. Thereby 
for the same events discussed above to explain 
pros assignment, the value for sa is set ?Praisewor-
thy?, ?Blameworthy? and ?null?, respectively. 
The value of object_appealing (oa) indicates 
whether an object is ?Attractive? or ?Unattractive?. 
In order to assign a value to oa, we deal with two 
scores (i.e., object valence, and familiarity valence) 
having the following heuristic. ?Attractive? is set if 
the object has a positive valence with a familiarity 
valence less than a certain threshold. Reversely 
?Unattractive? is set if the object has a negative 
valence with a familiarity valence above a certain 
threshold. The familiarity valence is obtained from 
the ConceptNet by calculating the percentage of 
nodes (out of 300,000 concept-nodes) linking to 
and from the given object/concept. For example, 
the familiarity valence for ?restaurant?, ?thief? and 
?diamond ring? is 0.242%, 0.120% and 0.013%, 
respectively. Heuristically we kept the threshold 
0.10% to signal familiarity and unfamiliarity of an 
object. Thus ?diamond ring? and ?thief? gets ?At-
tractive? and ?Unattractive? set for oa, but ?restau-
rant? gets ?null? accordingly. 
The value for valenced_reaction (vr) is set either 
?True? or ?False? in order to initiate further analy-
sis to sense emotions or decide the sentence(s) as 
expressing a neutral emotion. We consider vr to be 
?True? if the ?sentence-valence? returned by Sen-
seNet is either above than 3.5 or less than -3.5. For 
example, ?I go.?, doesn?t lead to further process-
ing (i.e., sentence-valence is +3.250) but ?I go to 
gym everyday.?, leads to classify emotion because 
of the sentence-valence +7.351 obtained from Sen-
seNet. The value to the variable unexpectedness 
(unexp) is set ?true? if there is a linguistic token to 
represent suddenness (e.g., abruptly, suddenly, 
swiftly etc.) in the input sentence, otherwise 
?false? is set. We have a list of such tokens to indi-
cate suddenness.  
OCC model has several variables to signify emo-
tional intensity. For example, the value for the in-
tensity variable event_deservingness (ed) is set 
?High? for an event having a higher positive va-
lence (i.e., above +7.0) or ?Low? for higher nega-
tive one (i.e., less than -7.0). If an action is quali-
fied with an adverb (e.g., He worked very hard) or 
target object qualified with an adjective (e.g., I am 
looking for a quiet place) without a negation, the 
value for effort_of_action (eoa) is set ?Obvious?, 
otherwise ?Not-Obvious?. Another variable called 
expected_deviation (edev) indicates the difference 
between the event and its actor. For example, in 
the sentence ?The police caught the criminal fi-
nally.?, the actor ?police? and the event ?catch 
criminal? don?t deviate because the action is pre-
sumably expected by the actor. We set the value 
for edev to ?Low? if ConceptNet can find any se-
898
mantic relationship between the actor and event; 
otherwise ?High? is set. For example, for sentence 
?the student invented the theory.?, edev is set 
?High? because ConceptNet doesn?t return any 
relationship between ?student? and ?invent?. The 
values ?Common? or ?Uncommon? are set for 
event_familiarity (ef) according to the familiarity 
valence obtained from ConceptNet for the input 
event as discussed before. 
4.3 The rules for the OCC Emotion Types 
In section 2.2 we briefly illustrated how a rule 
for the OCC defined emotion (e.g., happy-for) is 
characterized. Now using the same notion we enlist 
the rules for the OCC model defined emotion 
types. Although in txt there might be multiple e 
described and we also deal with such cases to get 
the resultant emotion types from txt, but we don?t 
discuss that in the scope of this paper and describe 
the simple cases. Thus, the rules for emotion types 
are given considering an event e, for example, the 
program x senses ?Joy? for e if following condition 
is true: 
 [Linguisitc_Token_found_for_Joy(txt) and 
No_Negation_Found (txt)] or [vr= true and sr= 
?Pleased? and sp= ?Desirable? and cs= ?Self?] 
(i.e., literally joy means being ?pleased about a de-
sirable event?.) Since we have the token words for 
each emotion types, we omit the first condition in 
the subsequent rules for space limitations. The 
rules for the emotion are listed as following and 
due to space limitations we are not providing the 
rules for all the emotions. 
? if (vr= true and sr= ?Pleased? and pros= ?Posi-
tive? and sp= ?Desirable? and status= ?Uncon-
firmed?), ?hope? is true. 
? if (vr= true and sr = ?Displeased? and pros= 
?Negative? and sp= ?Undesirable? and 
status=?Unconfirmed?), ?fear? is true. 
? if (vr= true and sr = ?Pleased? and pros= 
?Negative? and sp= ?Undesirable? and status= 
?Disconfirmed?), ?relief? is true. 
? if (vr= true and sr = ?Displeased? and pros= 
?Positive? and sp= ?Desirable? and status= 
?Disconfirmed?), ?disappointment? is true. 
? if (vr= true and sr= ?Displeased? and sa= 
?Blameworthy? and sp= ?Undesirable? and 
cs=?Self?), ?shame? is true. 
? if (vr= true and sp= ?Desirable? and sr= 
?Pleased? and of= ?Liked? and oa= ?Attrac-
tive?), ?love? is true. 
? if (vr= true and sp= ?Undesirable? and sr= 
?Displeased? and of= ?Not-Liked? and oa= 
?Unattractive?), ?hate? is true. 
The OCC model has four complex emotions 
namely, ?gratification?, ?remorse?, ?gratitude? and 
?anger?. For example: 
? If both ?joy? and ?pride? are true, ?gratifica-
tion? is also true. 
? If both ?distress? and ?reproach? are true, ?an-
ger? is also true. 
The cognitive states ?Shock? (i.e.; unpleasant sur-
prise) and ?Surprise? (i.e., pleasant surprise) are 
ruled as; If both ?distress? and unexp are true, 
?shock? is true. (e.g., The bad news came unex-
pectedly.). Similarly, if both ?joy? and unexp are 
true, ?surprise? is true. (e.g., I suddenly met my 
school friend in Tokyo.) 
Like Liu et al (2003), we also believe that a 
statement may contain more than one type of emo-
tions. In our case, the 22 emotion types and two 
cognitive states are grouped into seven groups, 
namely, well-being emotion, fortune of other emo-
tion, prospect based emotion, cognitive state, attri-
bution emotion, attraction emotion, and compound 
emotion. Hence an input sentence may contain one 
of the emotion types from each group. For exam-
ple, the sentence ?I suddenly got to know that my 
paper won the best paper award.?, outputs the fol-
lowing emotions: {Joy, Satisfaction, Surprise, 
Pride, Gratification}.The sentence ?She failed to 
pass the entrance examination.?, outputs {Dis-
tress, Sorry-for, Disappointment, Reproach, An-
ger} emotion types. In order to reduce the number 
of emotions, we consider the intensity variables. 
For the first set of emotions, we can reduce it to 
{Satisfaction, Surprise, Pride} because ?Joy? 
doesn?t have any intensity variables and the inten-
sity variables ed and edev are set to ?High? in this 
case. 
4 Test and Evaluation 
The similar system like ours is Liu?s system (Liu 
et. al., 2003). It is a rule based system, and it seems 
to be the best performing system for sentence-level 
affect sensing that senses happy, fearful, sad, an-
gry, disgust, and surprise emotions. On the practi-
cal side, it is freely available on the Internet. Ex-
899
ample input and output are enlisted to given an 
idea about the outputs of the two systems.   
Input: I avoided the accident luckily. 
Liu?s output: fearful(26%),happy (18%), angry 
(12%),sad(8%),surprised(7%),disgusted (0%) 
Ours output: valence: +11.453; [joy, pride, relief, 
surprise, gratification] 
Input: Susan bought a lottery ticket and she was 
lucky to win the million dollar lottery. 
Liu?s output: sad(21%), happy(18%), fearful 
(13%),angry(11%),disgusted(0%),surprised (0%) 
Ours: valence: +12.533; [happy-for, satisfaction, ad-
miration, love] 
We evaluated our system to assess the accuracy 
of sentence-level affect sensing when compared to 
human-ranked scores (as ?gold standard?) for 200 
sentences assessed by two systems. The sentences 
were collected from Internet based sources for re-
views of products, movies, and news. In order to 
conduct system?s performance and acceptance test 
we have two systems X (i.e., Liu?s System) and Y 
(i.e., our system). The judges were not told about 
the characteristics of any of the systems. Each 
judge receives the output from both X and Y for 
each input sentence and can accept either both out-
puts or anyone of the two or reject both. Thus %X 
means the percentage of the number of acceptances 
received by X in terms of accuracy of output. Simi-
larly %Y, %XY, and %!XY indicate the percent-
age of acceptances received by the system Y, both 
the systems and neither of the two systems respec-
tively. For example, for the input sentence ?She is 
extremely generous, but not very tolerant with peo-
ple who don't agree with her.?, among the 5 judges 
3 accepted the output of Y, 2 accepted the output 
of X. Since the majority of the judges accepted Y, 
vote for this sentence was counter for Y. Thus the 
vote for each sentence is counted. Outcome of our 
experiment is reported below while the valence 
range to classify a neutral sentence is considered 
?3.5 for the SenseNet upon which system Y is 
built.  
System Y received 16.069% more acceptances 
than that of X, which indicates that the output of Y 
is more acceptable and accurate than that of X. 
Though the test was conducted with a small group 
of judges with relatively small input size, but the 
experiment result (i.e., 82% accuracy with an aver-
age precision 76.49%, recall 81.04% and F-score 
78% for classifying positive, negative and neutral 
classes using the same dataset) for sentiment sens-
ing reported by SenseNet, provides an optimistic 
believe that the result would not vary even the sur-
vey is conducted with larger group of judges. Ta-
ble 3 summarizes the experimental result for 200 
sentences. 
Data-Set of 200 Sentences 
%X %Y %XY %!XY 
20.344 36.413 24.283 18.96 
 Table 3. Experimental Result 
5  Conclusion 
In order to perform more testing and usability 
study, we plan to implement a web-based user in-
terface where any user can input a chunk of text 
and get outputs from the both systems mentioned 
above. Thereby we can get user?s acceptance test 
in terms of accuracy of output. Next we plan to 
perform the task of affect sensing using online re-
sources (e.g., blogs, reviews, etc.).  
Reference 
Connexor Oy. 2005. Machinese Syntax, web-site: 
http://www.connexor.com/connexor/ 
Hugo Liu and Push Singh. 2004. ConceptNet: A Practi-
cal Commonsense Reasoning Toolkit, BT Technol-
ogy Journal, 22(4):211-226, Kluwer Academic Pub-
lishers. 
Hugo Liu, Henry Lieberman, and Ted Selker. 2003. A 
Model of Textual Affect Sensing using Real-World 
Knowledge, In Proc. IUI 03, pp. 125-132, Miami, 
USA, ACM. 
Opinmind, Discovering Bloggers, (2006), 
http://www.opinmind.com/ 
Andrew Ortony, Gerald L. Clore and Allan Collins. 
1988. The Cognitive Structure of Emotions, Cam-
bridge University Press. 
James W. Pennebaker, Martha E. Francis, and Roger J. 
Booth. 2001. Linguistic inquiry and word count: 
LIWC (2nd ed.) [Computer software]. Mahwah, NJ: 
Erlbaum. 
Mostafa A. M. Shaikh, Helmut Prendinger and Mitsuru 
Ishizuka. 2007a. SenseNet: A Linguistic Tool to 
Visualize Numerical-Valance Based Sentiment of 
Textual Data, In Proc. ICON-2007, pages 147-152. 
Mostafa A. M. Shaikh, Helmut Prendinger and Mitsuru 
Ishizuka. 2007b. Assessing Sentiment of Text by 
Semantic Dependency and Contextual Valence 
Analysis. In Proc. ACII 07, pp. 191-202. 
James G. Shanahan, Yan Qu and Janyce Wiebe (Eds.). 
2006. Computing Attitude and Affect in Text: The-
ory and Applications, Springer. 
900
