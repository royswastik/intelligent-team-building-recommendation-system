Interpreter for Highly Portable Spoken Dialogue System
Masamitsu Umeda
Department of Information and
Computer Science,
Toyohashi University of Technology
Aichi, JAPAN, 441-8580
umeda@slp.ics.tut.ac.jp
Satoru Kogure
Faculty of Education,
Aichi University of Education
Aichi, JAPAN, 448-8542
skogure@auecc.aichi-edu.ac.jp
Seiichi Nakagawa
Department of Information and
Computer Science,
Toyohashi University of Technology
Aichi, JAPAN, 441-8580
nakagawa@slp.ics.tut.ac.jp
Abstract
Recently the technology for speech recog-
nition and language processing for spoken
dialogue systems has been improved, and
speech recognition systems and dialogue
systems have been developed to the ex-
tent of practical usage. In order to become
more practical, not only those fundamen-
tal techniques but also the techniques of
portability and expansibility should be de-
veloped. In our previous research, we
demonstrated the portability of the speech
recognition module to a developed portal
spoken dialogue system. And we con-
structed a dialogue strategy design tool
of dialogue script for controlling the dia-
logue strategy.
In this paper, we report a highly portable
interpreter using a commercial electronic
dictionary. We apply this to three do-
mains/tasks and confirm the validity of the
interpreter for each domain/task.
Keywords: spoken dialogue system, robust inter-
preter, portability, dialogue script
1 Introduction
Recently, much research has been done on the ro-
bustness and reliability of spoken dialogue sys-
tems. We developed a ?Mt.Fuji sightseeing guid-
ance? system which uses touch screen input, speech
input/output and graphical output, and have im-
proved the sub-modules of a speech recognizer, nat-
ural language interpreter, response generator and
multi-modal interface (Kai and Nakagawa, 1995;
Itoh et al, 1995; Denda et al, 1996; Kogure et al,
1999; Nakagawa et al, 2000). General speaking, all
of these modules except for the speech recognition
module depended on a given task or domain.
As speech recognition systems are increasingly
being used in practical applications, spoken dialogue
systems will also become more widespread. How-
ever, the cost of developing a new spoken dialogue
system is enormous. The systems that have been de-
veloped so far can not be transferred to other do-
mains easily, and a highly-portable system that can
be easily adapted to another domain or task urgently
should be developed. There are several examples of
researches that focused on high portability and ex-
pansibility (Kaspar and Hoffmannn, 1998; Brond-
sted et al, 1998; Sutton et al, 1998; Sasajima et al,
1999; Abella and Gorin, 1999; Levin et al, 2000).
In (Kaspar and Hoffmannn, 1998), a prototype
could be simply constructed even in a complicated
speech dialogue system using the PIA system, which
was implemented using Visual Basic. This sys-
tem placed priority on achieving high robustness of
speech recognition and high naturalness of gener-
ated dialogue. However, the system limited the task
to the domain of knowledge search. E. Levin et
al. reported the design and implementation of the
AT&T Communicator mixed-initiative spoken dia-
logue system (Levin et al, 2000). The communica-
tor project sponsored by DARPA launched in 1999.
On the other hand, we have also considered the
portability of spoken dialogue system (Kogure and
Nakagawa, 2000). We showed from experience that
Figure 1: System overview.
it was difficult to transfer from the Mt. Fuji sight-
seeing guidance existing system to the East Mikawa
sightseeing guidance.
Therefore?we built portable spoken dialogue sys-
tem developing tools based on GUI (Kogure and
Nakagawa, 2000). Especially, we focused on the
developing tools of spoken dialogue system for
database retrieval.
Some spoken language systems focused on ro-
bust matching to handle ungrammatical utterances
and illegal sentences. The Template Matcher (TM)
at the Stanford Research Institute (Moore and Pod-
lozny, 1991) instantiates competing templates, each
of which seeks to fill its slots with appropriate words
and phrases from the utterance. The template with
the highest score yields the semantic representation.
R.Kuhn and R.De Mori suggest a method where the
system?s rules for semantic interpretation are learnt
automatically from training data (Kuhn and Mori,
1995). The rules are encoded in forest of special-
ized decision trees called as Semantic Classifica-
tion Trees (SCTs). The learned rules are robust to
ungrammatical sentences and misrecognition in the
input. Minker compared a rule-based case frame
grammar analysis and a stochastics based case frame
grammar analysis for understanding(Minker, 1998).
Globally speaking, the performances of the stochas-
tic and rule-based parsers were comparable for ATIS
(Air Travel Information Service). Y. Wang sug-
gests a robust chart parser which is the major Spo-
ken Language Understanding (SLU) engine compo-
nent behind MiPad(Wang, 2001). The robustness to
ungrammaticality and noise can be attributed to its
ability of skipping minimum unparsable segments in
the input. The robust parsing algorithm is an exten-
sion of the bottom-up chart-parsing algorithm.
In (Nakagawa et al, 2000), the dialogue system
understands spontaneous speech which has many
ambiguous phenomena such as interjections, el-
lipses, inversions, repairs, unknown words and so
on, and responds to the user?s utterance. But the sys-
tem fails to analyze some utterances. ?Incomplete-
ness? with the interpreter mainly causes the analy-
sis failure, and leads to domain/task dependent de-
velopment. Therefore, in this paper we focused on
improving the interpreter in order to make it a ro-
bust/portable one.
For this purpose, we used the EDR electronic dic-
tionary as a semantic dictionary and improved the
interpreter so that it had some new functions. Fi-
nally, we applied the system to three domains/tasks;
hotel retrieval, Mt.Fuji sightseeing guidance and lit-
erature retrieval.
2 Highly-portable System for Information
Retrieval from Database
The proposed system in the dialogue processing
parts consists of semantics interpreter, retrieval
module, response generator and dialogue man-
ager which integrates three modules. The system
overview is shown in Figure 1.
Each module has the following roles:
? Speech Recognizer: This module recognizes
a user utterance via speech input and generates
a recognized sentence. We used SPOJUS (Kai
and Nakagawa, 1995) for this.
? Semantic Interpreter: This module under-
stands a user utterance via recognized sentence
and generates semantic representation.
? Retrieval Module: This module that extracts
the word as retrieval key word/phrase from the
semantic representation.
? Response Generator: This module is acti-
vated by a dialogue manager, selects a kind
of response strategies and generates a response
sentence.
? Text-to-speech Module: This module gener-
ates a response sentence, synthesizes speech
signals and playbacks this audio files to user.
In this paper, we focused on three modules: Se-
mantic Interpreter, Retrieval Module and Re-
sponse Generator. We believe that the Speech
Recognizer except for the language models and the
Text-to-speech Module are domain and task inde-
pendent. A domain/task adaptation technique of the
language models for the speech recognizer was pre-
liminarily evaluated (Kogure and Nakagawa, 2000).
3 Improving the Semantic Interpreter
3.1 Adding New Functionality
Our purpose is to improve our previous inter-
preter (Kogure and Nakagawa, 2000) to make it
more robust and portable. In this study, we imple-
mented new functions into the interpreter as follows:
? Processing of Correction Utterance: The sys-
tem omits the word sequence as restatement
Figure 2: An example of processing of correction
utterance.
Figure 3: An example of removing recognition error
caused by logging error.
and word preceding this sequence. The omitted
word sequence is the word or word sequence
which the user uses when he/she tells the sys-
tem to repair the wrong word or word sequence.
Figure 2 shows this process.
? Removing Recognition Error by Logging
Error: The system ignores non-semantic
words at the head or the tail of the sentence
caused by detection errors of beginning/ending
speech and adopts the grammaticaly longest
candidate from plural candidates as the valid
Figure 4: An example of improving keyword re-
trieval.
Figure 5: An example of concept classification.
sentence. Speech segmentation errors in back-
ground noise environments yield non-semantic
words. Figure 3 shows this process.
? Improving Keyword Retrieval: If an input
sentence is inadequate for parsing, the system
creates a retrieval condition from the semantic
labels which are attached to the word used as
the keyword in a sentence. Figure 4 shows this
process.
3.2 EDR Electronic Dictionary for Semantic
Interpreter
In the study, we clearly separated domain/task in-
dependent parts and dependent parts. When an ap-
plication developer wants to change a domain or
task, he/she modifies or prepares only domain/task
dependent parts, such as semantic features, proper
nouns, and so on. In this section, we describe the do-
main/task dependent information obtained from the
EDR electronic dictionary, which is used to analyze
the utterance in the interpreter.
The EDR electronic dictionary1 has widely been
used for research and application development of
1http://www.jsa.co.jp/EDR/
? ?
search[3cec34] :::
agent 30f6b0;30f746 =GA,
object 3f97b1 =WO
? ?
Figure 6: An example of case frame.
Japanese language processing. We developed a high
portable semantic dictionary for the interpreter using
the EDR electronic dictionary.
3.2.1 Concept Dictionary
The EDR electronic dictionary is constructed by a
hierarchical tree structure with classification records
which are composed of 410,000 concepts.
Figure 5 shows a part of concept classification
from ?location.? ?30f751? denotes the concept clas-
sification for ?location.?
We assign the concept for domain/task dependent
words to the existing hierarchical structure. In Fig-
ure 5, ?G-PLACE? is a keyword which is used for
referencing to a place. Since the morphological
analysis assigns the concept to the word, the inter-
preter can use the concept information.
3.2.2 Dictionary of Selectional Restriction for
Japanese Verbs
The interpreter analyzes an input sentence us-
ing the dictionary of selectional restrictions or case
frames for Japanese verbs, which are attached as a
co-occurrence dictionary for the EDR electronic dic-
tionary. This dictionary contains information related
to the surface case and the deep case about main
verbs. The interpreter converts the input sentence
to the case frame format information using this dic-
tionary, which is formalized from the information on
a deep case and the conceptual classification infor-
mation for every verb using the technique of a selec-
tional restriction.
Figure 6 shows the case frame of the verb
?search?. It shows that ?3cec34? is the concept
classification of ?search.? When the deep case is
?agent? and the surface case is ?GA?, ?30f6b0? or
?30f746? is selected, and when the deep case is ?ob-
ject? and the surface case is ?WO?, ?3f97b1? is se-
lected. Where ?GA? and ?WO? are particle peculiars
(postpositions) in Japanese.
Figure 7: An example of semantic interpreter.
3.3 An Example
Figure 7 shows an example of the interpreter flow.
In Figure 7 , the user inputs a Japanese utterance
that means ?What hotels are there along Yamanote
Line?? in English. The interpreter executes the pro-
cesses of a morphological analysis and parsing, and
generates a parsing result that is represented by a
tree-structure in accordance to the prepared gram-
mar. This sentence?s verb is ?ARU?(There are, in
English), and the concept classification of ?ARU? is
?0e5a74?. The interpreter generates a semantic anal-
ysis result from the parsing result using this concept
classification information, that is, the case frame of
?ARU?. The system transfers the semantic analysis
result into a retrieval condition. This condition is
used to generate SQL language for the retrieval.
4 Domain/Task Independency and
Dependency
4.1 Domain/Task Independency/Dependency
In this section, we describe how to realize the high
portability which has the benefit of efficiency when
application developers design a new dialogue sys-
tem. That is, while the system performance is kept at
a certain level, we will shorten the period of develop-
ing the dialogue system as possible. Therefore, we
define the domain/task independency/dependency.
Domain independency means that application devel-
opers can use common data for all domains 2. Do-
main dependency means that applications are not do-
main independent. Task independency means that
application developers can use these common data
for all tasks 3 in a certain domain. Task dependency
means that is not task independent. Hereafter, four
data types are abbreviated as DI, DD, TI, TD, respec-
tively.
We clearly separated semantics, retrieval and re-
sponse modules into DI/DI, DD/TI, TI/TD, and TI/TI
parts, respectively. The system core was built whilst
keeping it completely domain and task independent
(DI/TI). We can divide data sets three types4 as
shown in Table 1; DI/TI, DD/TI and DD/TD. DI/TI
data sets served as information for a morphological
analysis except for nouns or verbs with respect to
the domain/task and so on. DD/TI data sets are used
as information for morphological analysis of nouns
or verbs with respect to the domain/task, informa-
tion for semantics analysis and so on. DD/TD data
sets are used as information for format that the sys-
tem responds the retrieval results and so on. In the
2Domain is a field or area of dialogue object.
3Task is the problem or process that the user wants to realize
in a particular domain.
4Since we define a domain and a task as the above, all do-
main independent data sets are surely task independent data
sets, therefore DI/TD data sets are none.
Table 1: Separation of domain/task dependent data sets and domain/task independent data sets.
types Data
DI/TI
syllable HMMs, morphological dictionary except
for noun and verb, syntactic grammar, noun and verb
semantic dictionary for dialogue processing ,seman-
tic dictionary, case frame
DD/TI morphological dictionary for noun and verb field in-formation of database, database
DD/TD convert rule from semantic representation to re-
trieval pattern, display format of retrieval result
DI: domain independent DD: domain dependent
TI: task independent TD: task dependent
Figure 8: Task adaptation.
next section, we describe how application develop-
ers prepare DD/TI and DD/TD data sets.
4.2 System Core
We used Chasen 5 as Japanese morphological analy-
sis and PostgreSQL 6 as a database retrieval man-
agement system. We have constructed Semantics
Modules based on the Mt. Fuji sightseeing guidance
system (Nakagawa et al, 2000) with separating task
dependent and independent parts. All parts of the
system core are clearly DI/TI.
5http://chasen.aist-nara.ac.jp/
6http://www.pgsql.com/
4.3 Data Sets
Data sets consist of DI/TI, DD/TI and DD/TD data
sets. The separated results are shown in Table 1.
5 Task Adaptation -Hotel Retrieval
System-
Figure 8 shows the flow chart of the task adaptation.
We consider what kind of data may be prepared as
task-dependent knowledge when a new task is ap-
plied. In the proposed framework, the application
developer prepares the following:
? A generally usable database (machine read-
able)
? The format information of each field of the
database
A generally usable database
------------------------------------------------------------
<name>GrandCentralHotel</name>
<address>2-2 Kandatsukasa-machi Chiyoda Tokyo</address>
<access>On foot-from JR line and subway line Kanda station 3 minutes</access>
<land>Tokyo Tower,TOKYO DOME</land>
<single>8900,7120</single>
:
------------------------------------------------------------
The format information of each field of the database
Database format information
------------------------------------------------------------
S|<name>|</name>|name
S|<address>|</address>|address
R|<access>|:|,|</access>|access
R|<land>|:|,|</land>|land
R|<single>|:|,|</single>|single
:
------------------------------------------------------------
Transfer format information
------------------------------------------------------------
DATABASE:::
hotel:$hotel_id{int},$name{varchar(200)},$address{varchar(200)},
$checkin{varchar(10)},$checkout{varchar(10)},$scale{varchar(20)},
$room{varchar(20)},$smoking{varchar(20)}
acc:$acc_id{int},$hotel_id{int},$access[]{varchar(200)}
land:$land_id{int},$hotel_id{int},$land[]{varchar(200)}
single:$single_id{int},$hotel_id{int},$single[]{varchar(200)}
double:$double_id{int},$hotel_id{int},$double[]{varchar(200)}
twin:$twin_id{int},$hotel_id{int},$twin[]{varchar(200)}
inside_hotel:$inside_hotel_id{int},$hotel_id{int},$inside_hotel[]{varchar(200)}
room:$room_id{int},$hotel_id{int},$room[]{varchar(200)}
service:$service_id{int},$hotel_id{int},$service[]{varchar(200)}
card:$card_id{int},$hotel_id{int},$card[]{varchar(200)}
DATABASE:::
Figure 9: An example of hotel information and the definition given by a developer.
? A corpus of user utterances (dialogue exam-
ples)
The database information retrieval system first re-
quires a database (generally, one that is open to the
public) as a retrieval target. The format information
of each field in the database should be given in order
to access the database. In addition, since the dictio-
nary and language model are adapted to the database
information retrieval system in the task, a corpus of
the user utterances is required.
For examples, Figure 9 shows a generally usable
database and the format information of each field
of the database in a hotel retrieval system.
We used the hotel data of Hornet7 of the hotel ref-
erence site in Japan. The web page of this site can
be automatically translated into a database. The data
obtained from the HTML source is translated into a
data format like the generally usable database in
Figure 9.
This is translated according to the rules of Fig-
ure 9. In Figure 9, hotel information consists of
7http://www.inn-info.co.jp/
the name of the hotel, address of the hotel, access
method to the hotel, and so on. Transfer format in-
formation describes how each item of hotel informa-
tion is processed.
In Figure 9, the landmarks, ?Tokyo Tower? and
?Tokyo Dome? are substituted into an array variable
?landmark? which represents a landmark.
From the description of this file, the construction
of a database and creation of the table for every cat-
egory can be performed automatically. And word
registration to an analysis dictionary can be auto-
matically performed using a morphological-analysis
dictionary tool and a semantic dictionary registra-
tion tool. In this way, the hotel retrieval system was
constructed in about 10 hours.
The sample of a dialogue is shown in Figure 10.
6 Other Task Adaptation
6.1 Application to Mt. Fuji Sightseeing
Guidance System
We applied the portable system to Mt. Fuji sight-
seeing guidance system as well as the hotel retrieval
===== Speech Input =====
Input :What hotels are there around Kanda Station?
<=== input utterance
:What hotels are there near in Kanda Station?
<=== recognized sentence
===== System Output =====
5 facilities were found.
===== Retrieval Result =====
No.1 Olympic in Kanda, single room:11000yen
No.2 Grand Central Hotel,single room:8900yen,double room:12200yen, twin room:142000yen
No.3 Sun Hotel Kanda,single room:8400yen,twin room:13600yen
No.4 Central Hotel,single room:6500yen,double room:9800yen,twin room:9300yen
No.5 New Central Hotel,single room:7000yen,double room:7500yen,twin room:9600yen
===== System Output =====
The retrieval result is the above.
===== Speech Input =====
Input :Please display the data of No.2.
<=== input utterance
:Please display the data of No.2.
<=== recognized sentence
===== System Output =====
The details of the data of No.2 are displayed.
===== Retrieval Result =====
*** Grand Central Hotel ***
2-2 Kandatsukasa-machi Chiyoda Tokyo
On foot-from JR line and subway line Kanda station 3 minutes
Landmark:
Room charge :: single:8900yen double:12200yen twin:14200yen
check in time is 15:00,check out time is 11:00
11 stories,157 rooms
No smoking room is Nothing
Inside-a-hotel equipment:conference room,vending
machine,laundromat,restaurant,banquet hall
indoor equipment:bath,toilet,air conditioning,lighting
desk,refrigerator,Japanese tea,drier,amenity
set,television,video broadcast,satellite broadcasting,telephone
service:Room service,copy,facsimile,word processor loan,iron
loan,trouser press loan,parcel delivery service
receptionist,cleaning receptionist,massage,mail servic
Usable credit card:DC,VISA,JCB,Master,UC,AMEX,Million,Dainers,NICOS
Figure 10: Dialogue example (hotel retrieval system).
===== Speech Input =====
Input :What is there in Kawaguchi Lake? <=== input utterance-1
===== System Output =====
29 facilities were found.
The reference conditions which can be used by addition are shown below.
action : reading(9) lodging(7) appreciation(2) resting(2) camping(2)
kind : hotel(4) museum(3) concert hall(2) pension(2) campsite(2)
===== Speech Input =====
Input :Campsite. <=== input utterance-2
===== System Output =====
(Facility-kind campsite) <=== retrieval condition
2 facilities were found.
===== Retrieval Result =====
Kitagishi no Myoukosan(campsite), Kawaguchi Lake, 0yen
Tozawa center(campsite), Kawaguchi Lake, 4000yen
===== Speech Input =====
The retrieval result is the above.
Figure 11: Dialogue example (Mt. Fuji sightseeing guidance system).
===== System Output =====
This is a document retrieval system. Please input retrieval conditions.
===== Speech Input =====
input: Is there a paper on the multi modal? <=== input utterance
Yet uh uh.. is there a paper on the multi modal such?
<=== recognized sentence
===== System Output =====
23 papers were found.
Please input additional retrieval conditions.
===== Speech Input =====
input: This is related to Internet. <=== input utterance
This is related to Internet. <=== recognized sentence
===== System Output =====
3 paper were found.
===== Retrieval Result =====
No.1 A. Nakashima, et al:"Intelligent network for personal move
communication",Institute of Electronics, Information and
Communication Engineers Journal of Japan, 1995)
No.2 K. Ono, et al:"Development of new generation communication
network",Institute of Electronics, Information and Communication
Engineers Journal of Japan, 1995)
No.3 H. Aiso, et al:"Future prospects of information highway",
Institute of Electronics, Information and Communication Engineers
Journal of Japan, 1995)
===== System Output =====
The retrieval result is the above.
Figure 12: Dialogue example (literature retrieval system).
system. An example of using the system is shown in
Figure 11.
The dialogue manager uses the dialogue script in
order to decide a dialogue strategy. This scripts have
the functions that if retrieval results are too numer-
ous, the system does not display all retrieval results
but inquires the user for additional retrieval condi-
tions. Of course, application developers can easily
change this dialogue strategy with the GUI tools.
For example, since input utterance-2 in
Figure 11 is not a sentence, the interpreter may fail
at the step of the semantic analysis. The interpreter
adapts Improved Keyword Retrieval described in
Section 3. The concept classification of campsite
is ?G-KIND?, so the interpreter directly changes
this word (see retrieval condition) to ?G-
KIND.?
6.2 Application to Literature Retrieval System
We also applied the system to a literature retrieval
system as well as the hotel retrieval system.
Figure 12 shows an example of using the system.
In this example the recognized sentence has
misrecognition and interjections. So the CFG gram-
mar cannot accept this sentence. Therefore, Re-
moving Recognition Error by Lodging Error
in Section 3 is used for this sentence. So yet,
uh, uh and such are omitted in the recognized
utterance.
If there are some related papers catalogues as
retrieved results and the user inputs an utterance
?Please display detailed information of the second
paper.?, the system displays detailed information
like the abstract of the second paper in the paper cat-
alogue.
6.3 Evaluation of Portability
We evaluated the portability of our dialogue sys-
tem and robustness of the interpreter through the
Mt.Fuji sightseeing system and literature retrieval
system, and we confirmed that the developing period
was shortened to the time of the hotel?s one, which
means a reduction to 10 hours from 15 hours in the
previous system (Kogure and Nakagawa, 2000).
7 Summary
We improved the portable semantic interpreter for
spoken dialogue systems. The highly portable se-
mantic interpreter was constructed using the EDR
electronic dictionary. By the example of the hotel
retrieval system, we explained the structure of a high
portable system.
We also constructed the Mt.Fuji sightseeing sys-
tem and literature retrieval system, and we con-
firmed that the developing effort/period was reduced
to the same as the hotel?s one, which means a re-
duction to 10 hours from 15 hours in the previous
system.
In the near future, we will construct a system that
can change a task during a dialogue.
References
A. Abella and A. L. Gorin. 1999. Construct algebra:
Analytical dialog management. In Proc. of ACL ?99,
pages 191?199.
T. Brondsted, B. Bai, and J. Olsen. 1998. The reward
service creation environment. an overview. In Proc. of
ICSLP ?98, pages 1175?1178.
A. Denda, T. Itoh, and S. Nakagawa. 1996. A robust
dialogue system with spontaneous speech and touch
screen. In Proc. of ICMI ?96, pages 144?151.
T. Itoh, M. Hidano, M. Yamamoto, and S. Nakagawa.
1995. Spontaneous speech understanding for a robust
dialogue system. In Proc. of NLPRS ?95, volume 2,
pages 538?543.
A. Kai and S. Nakagawa. 1995. Investigation on un-
known word processing and strategies for spontaneous
speech understanding. In Proc. of EUROSPEECH ?95,
pages 2095?2098.
S. Kaspar and A. Hoffmannn. 1998. Semi-automated
incremental prototyping of spoken dialog systems. In
Proc. of ICSLP ?98, pages 859?862.
S. Kogure and S. Nakagawa. 2000. A portable devel-
opment tool for spoken dialogue systems. In Proc. of
ICSLP ?2000, pages 238?241.
S. Kogure, T. Itoh, and S. Nakagawa. 1999. A seman-
tic interpreter for a robust spoken dialogue system. In
Proc. ICMI ?99, pages II 61?66.
R. Kuhn and R. De Mori. 1995. The application of se-
mantic classification trees to natural language under-
standing. In IEEE Trans. Pattern Analysis and Ma-
chine Intelligence, volume 17, pages 449?460.
E. Levin, S. Narayanan, R. Pieraccini, K. Biatov, E. Bia-
tov, E. Bocchieri, G. Di Fabbrizio, W. Eckert, S. Lee,
A. Pokrovsky, M. Rahim, P. Ruscitti, and M. Walker.
2000. The at&t-darpa communicator mixed-initiative
spoken dialog system. In Proc. of ICSLP ?2000, vol-
ume 2, pages 122?125.
W. Minker. 1998. Stochastic versus rule-based speech
understanding for information retrieval. In Speech
Communication, pages 223?147.
R. Moore and A. Podlozny. 1991. A template matcher
for robust nl interpretation. In Proc. Speech and
Natural Language Workshop, Morgan Kaufmann Inc.,
pages 190?194.
S. Nakagawa, S. Kogure, and T. Itoh. 2000. A semantic
interpreter and a cooperative response generator for a
robust spoken dialogue system. IJPRAI, 14(5):553?
569.
M. Sasajima, T. Yano, and Y. Kono. 1999. Europa:
generic framework for developing spoken dialogue
systes. In Proc. of EUROSPEECH ?99, pages 1163?
1166.
S. Sutton, R. Cole, J. de Villiers, J. Schalkwyk, P. Ver-
meulen, M. Macon, Y.Yan, E. Kaiser, B. Rundle,
K. Shobaki, P. Hosom, A. Kain, J. Wouters, D. Mas-
saro, and M. Cohen. 1998. Universal speech tools:the
cslu toolkit. In Proc. of ICSLP ?98, pages 3221?3224.
Y. Wang. 2001. Robust language understanding in mi-
pad. In Proc. of EUROSPEECH ?2001, pages 1555?
1558.
