Proceedings of the 8th International Conference on Computational Semantics, pages 260?263,
Tilburg, January 2009. c?2009 International Conference on Computational Semantics
Towards an Analysis of Opinions in News
Editorials: How positive was the year?
Bal Krishna Bal
Madan Puraskar Pustakalaya, Lalitpur, PatanDhoka, Nepal
and IRIT, 118 route de Narbonne, 31062 Toulouse, France
bal@mpp.org.np
1 Introduction
Editorials represent opinion articles written by the publisher, editors or
columnists of newspapers. From this perspective, editorials are ideal sources
for outlining views on events and analyzing how they are perceived, e.g.
whether they are positive or negative or the kind of feelings or analysis they
involve (uncertainty, worries, etc.). The proposed work aims at identifying
the linguistic criteria and at creating a model for the aforementioned pur-
pose, which makes use of an adequate set of semantic tags that we have
defined to annotate texts from which a detailed analysis can be carried out.
Currently, the work is in its preliminary stage, primarily focussed on
defining the tags required for the semantic-pragmatic analysis. In parallel
with the definition of tags and text annotation, we explore ways to construct
synthesis of opinions on a given event from various editorials. One of the
challenges is to organize the positive and the negative views, and the asso-
ciated arguments and their strength. We noted that opinions in editorials
are not so apparent, which makes synthesis construction a challenging task.
2 Opinion Mining as a problem
Although Opinion Mining has emerged only quite recently as a subdiscipline
under computational linguistics, a considerable amount of work has already
been done in this direction, which include but not limit to (Hearst,1992),
(Hatzivassiloglou and Wiebe,2000), (Wilson et al, 2005), (Esuli and Sebas-
tiani, 2006) and (Read et al, 2007). These works range from a variety of
task domains like mining the product reviews available on the web, sen-
timent classification of documents, opinion mining and summarization to
260
much more. Irrespective of the nature of different specific tasks, Opinion
Mining generally encompasses the following generic problems: (1) Determin-
ing the subjectivity or identifying the subjective and objective expressions
in texts, where subjective expressions are opinions whereas objective ones
denote facts; (2) Determining the orientation or polarity of the subjective
expressions. A first analysis may be just identifying whether an expression
is positive or negative, but in general other dimensions need to be inte-
grated since opinions are rarely so vivid; (3) Determining the strength of
the orientation of the subjective expressions.
Our problem of mining editorials falls under the larger task domain of
sentiment classification of documents and this essentially involves the prob-
lems 1 and 2 above. Problem 3 also may be partially applicable depending
upon the type of analysis we would like to have as an end result.
3 Linguistic framework and the distinction be-
tween facts and opinions
Since editorials are usually a mix of facts and opinions, there is a clear need
to make a distinction between them. Opinions often express an attitude
towards something. This can be a judgment, a view or a conclusion or even
an opinion about opinion(s). Different approaches have been suggested to
distinguish facts from opinions. Generally, facts are characteristic for the
presence of certain verbs like ?declare? and different tense and number forms
of the verb ?be? etc. Moreover, statements interpreted as facts are generally
accompanied by some reliable authority providing the evidence of the claim,
e.g.:
Fact: Both the two dates announced for the constituent assembly (CA) elec-
tions came and went without the vote taking place.
Reliable authority: Election Commission for CA elections 2007.
Fact: We have fewer people getting killed every day.
Reliable authority Nepal Police Department of Crime and Investigation.
(December 2007)
Opinions, on the other hand, are characterized by the evaluative expres-
sions of various sorts such as the following (Dunworth, 2008):
- Presence of evaluative adverbs and adjectives in sentences - ?ugly? and
?disgusting?.
- Expressions denoting doubt and probability - ?may be?, ?possibly?, ?prob-
ably?, ?perhaps?, ?may?, ?could? etc.
261
<expression expression type=?Fact? opinion type=?Null? opinion orientation=?Null? force=?Null? opin-
ion date=?Null? authority=?Yes?>
This was the year Nepal declared itself a Federal Democratic Republic
</expression>
<expression expression type=?Opinion? opinion type=?Assumptive? opinion orientation=?Positive?
force=?Low? opinion date=?2007-12-31? authority=?Null?>,
but the decision needs to be endorsed which will probably happen in 2008.
</expression> </input>
- Presence of epistemic expressions - ?I think?, ?I believe?, ?I feel?, ?In my
opinion? etc.
It is obvious that the distinction between the two is not always straight-
forward. Facts could well be opinions in disguise and, in such cases, the
intention of the author as well as the reliability of information needs to be
verified. In order to make a finer distinction between facts and opinions and
within opinions themselves, opinions are proposed for gradation as shown
below:
Opinion type Global definition
Hypothesis statements Explains an observation.
Theory statements Widely believed explanation
Assumptive statements Improvable predictions.
Value statements Claims based on personal beliefs.
Exaggerated statements Intended to sway readers.
Attitude statements Based on implied belief system.
4 Results
For the purpose of annotation, the following semantic tag set has been de-
veloped, subject to further extension or modification in the future. The
current annotation scheme can be represented as a list of five parameters
and their possible values as shown below:
Parameter Possible values
expression type Fact, Opinion, Undefined
opinion orientation Positive, Negative, Neutral
opinion date Date of the editorial publication
force Low, Average, High
authority Yes, Average, No
Here, ?force? refers to the strength of the orientation of the opinion. Any
textual expression subject to annotation would go within <expression>
</expression>. A non-applicable parameter for a particular type of ex-
pression would receive a ?Null? value. The annotation of text fragments has
been guided by the presence of evaluative expressions and other criteria as
explained in section III.
For annotation purposes, we have collected the editorials from two online
newspapers (http://ekantipur.com,http://kantipuronline.com/ktmpost.php)
of different dates of the year 2007, amounting to a total of 16 text files
and approximately 320 sentences with an average of 20 sentences per edi-
torial. Two annotators having a fairly good understanding of the English
262
language have been involved in the annotation work. The annotators have
been assigned the same texts to see how semantic annotations can differ
among annotators. Results have shown that the difficulties in the manual
annotation exist at two levels, the first one in determining an expression as
being a fact or an opinion and the other one in grading the opinion as one
of the types, i.e., assumptive or value etc. Wherever the annotators have
confusions about providing one particular value, they have been advised to
provide multiple values separated by commas. A sample of the annotated
text in XML format is given in Fig. 1. above.
5 Conclusion
The work that we have described is currently in the phase of manually
annotating samples of editorials being based on the semantic tag set and
methodology discussed in the document. Further, we plan to develop a
computational model which would suggest methods to automate the pro-
cess of analyzing and synthesizing opinions from editorials. The manually
annotated texts and collected editorials would serve as training data and
test data respectively for validating the proposed computational model.
Acknowledgements: This work was partly supported by the French Stic-
Asia programme.
References
[1] Hearst M. A., Direction-based text interpretation as an information access re-
finement, Text-based intelligent systems: current research and practice in infor-
mation extraction and retrieval, 1992, Erlbaum.
[2] Hatzivassiloglou V. and Wiebe J. M., Effects of adjective orientation and grad-
ability on sentence subjectivity, Proc. 18th Conference on Computational Lin-
guistics, 2000, Saarbru?cken.
[3] Wilson T. et al, Recognizing contextual polarity in phrase-level sentiment anal-
ysis, Proc. HLT/ EMNLP 2005, Vancouver.
[4] Esuli A. and Sebastiani F. , Determining term subjectivity and term orientation
for opinion mining, Proc. EACL-06, Trento.
[5] Read J.et al, Annotating Expressions of Appraisal in English, Proc. ACL 2007
Linguistic Annotation Workshop, Prague.
[6] Dunworth K., UniEnglish reading: distinguishing facts from opinions, World
Wide Web, 2008, http://unienglish.curtin.edu.au/local/docs/RW facts opinions.pdf
263
Proceedings of the 7th Workshop on Asian Language Resources, ACL-IJCNLP 2009, pages 165?170,
Suntec, Singapore, 6-7 August 2009. c?2009 ACL and AFNLP
Towards Building Advanced Natural Language Applications - An
Overview of the Existing Primary Resources and Applications in Nepali
Bal Krishna Bal
Madan Puraskar Pustakalaya
Lalitpur,Patan Dhoka,
Nepal
bal@mpp.org.np
Abstract
The paper gives an overview of some of
the major primary resources and appli-
cations developed in the field of Natural
Language Processing(NLP) for the Nepali
language and their prospective for build-
ing advanced NLP applications. The pa-
per also sheds light on the approaches fol-
lowed by the current applications and their
coverage as well as limitations.
1 Introduction
NLP is a relatively new area of involvement in
the context of Nepal.The first ever NLP works
in Nepal include the Nepali Spell Checker and
Thesaurus that got released in the year 2005.
The years after that saw an increasing amount
of Research and Development of NLP resources
and applications under different programs.This in-
cluded Dobhase1, an English to Nepali Machine
Translation System, Stemmer and Morphological
Analyzer, Parts-of-Speech(POS) Tagger, Chunker,
Parser, a corpus-based on-line Nepali monolin-
gual dictionary, Text-To-Speech etc. On the re-
sources front, by 2008, we have had developed a
Lexicon, Nepali Written Corpus,Parallel Corpus,
POS Tagset,Speech Recordings etc. In the sec-
tions that follow, we will be discussing over the
current achievements and the possible advanced
applications that can be developed on the basis of
the existing resources and applications.
2 Resources
2.1 Nepali Lexicon
The process of the development of the Nepali
Lexicon(Bista et al,2004-2007;2004-2007a) un-
derwent several changes as the purpose of the lex-
icon was not very clear in the beginning.No doubt,
1http://nlp.ku.edu.np/cgi-bin/dobhase
we were aware that the usage of a lexicon would
be basically a multi-purpose one, fitting to one or
more NLP applications but we were a bit unsure
about the actual format of the lexicon.As a result,
the entries of the lexicon were maintained in dif-
ferent file formats ranging from plain spreadsheets
to XML formatted data files. In the beginning, the
attributes of the lexicon were decided to be as:
? Rootword
? Headword
? Pronunciation
? Syllablebreak
? Meaning
? PartsofSpeech
? Synonym
? Idiom
But later on, owing to time constraints and also
taking into consideration the applicability of the
lexicon to some of the immediate NLP applica-
tions being developed like the Spell Checker and
the Stemmer/Morphological Analyzer, the entries
were just made for the attributes - Rootword and
PartsofSpeech. The file format was also fixed for
the plain spreadsheet one, keeping into considera-
tion the discomfort faced by the linguists and data
entry persons with the XML data format.The lat-
est size of the lexicon is 37,000 root words with
their parts of speech category specified. Wherever
more than one category is possible, multiple cat-
egories have been entered with the comma as the
separator.
2.2 Nepali POS Tagset
The Nepali POS Tagset designed in the begin-
ning consisted of 112 tags2. These tags were
2http://www.bhashasanchar.org/pdfs/nelralec-wp-
tagset.pdf
165
used to manually and semi-automatically anno-
tate the written corpus as well. Experiences, how-
ever, showed that error rates of annotation could
be much higher when the size of the tagset was a
big one, the reason primarily being the chances of
assigning incorrect tags to the words out of con-
fusion while manually annotating the the train-
ing data itself. It was with such motivations that
a smaller sized POS Tagset3 was later on devel-
oped that consists of just 43 tags. While develop-
ing the tagset, maximum care has been taken to
ensure that this minimalist approach does not un-
necessarily eliminate the unavoidable lexical cate-
gories of the language. The design of this Nepali
POS Tagset was inspired by the PENN Treebank
POS Tagset.Hence, whenever possible, the same
naming convention has been used as in the case of
the PENN Treebank Tagset. In Table 1, we pro-
vide the summary of the small sized POS Tagset.
Owing to space constraints, we have just provided
limited examples for each of the POS category.
2.3 Nepali Written Corpus
Different efforts have been put into developing the
Nepali Written Corpus. We try to provide a brief
overview on each of them below.
With an aim to facilitate linguistic and computa-
tional/corpus linguistic researches of the Nepali
language,the compilation of different text cor-
pora got initiated under the activity, Nepali Na-
tional Corpus4. The Nepali National Corpus ba-
sically consists of three different types of corpora,
namely, the Written Corpus(monolingual and par-
allel), the Spoken Corpus and the Speech Corpus.
The monolingual Nepali Written Corpus was fur-
ther sub-divided into two types - the Core Cor-
pus and the General Corpus. The Core Corpus
consists of 398 texts from about 15 different gen-
res and amounting to 1 million words, has been
collected from different books,journals,magazines
and newspapers. The texts belong to the time pe-
riod between 1990 and 1992. The Core Corpus
has been converted into XML file format. In ad-
dition, the text has been annotated using the 112
Tagset. The General Corpus,on the other hand, is
a collection of the written texts basically from the
3http://nepalinux.org/downloads/nlp/nepali pos
tagset.pdf
4The Nepali National Corpus was developed under the
Nepali Language Resources and Localization for Education
and Communication(NeLRaLEC)Project.For details, please
visit http://bhashasanchar.org
Table 1: Summary of the Nepali POS Tagset
Tag Description Example
NN Common Noun Ghar
NNP Proper Noun Ram
PP Personal Pronoun Ma
PP$ Possessive Pronoun Mero
PPR Reflexive Pronoun Afu
DM Marked Demonstrative Arko
DUM Unmarked Demonstra-
tive
Tyo
VBF Finite Verb Khayo
VBX Auxiliary Verb Thiyo
VBI Verb Infinitive Khana
VBNE Prospective Participle hidne manchhe
VBKO Aspectual Participle Thiyo
VBO Other Participle Verb Diyeko
JJ Normal Unmarked Ad-
jective
Asal
JJM Marked Adjective Ramro
JJD Degree Adjective Adhiktar
RBM Manner Adverb dhilo hidchha
RBO Other Adverb yaha basa
INTF Intensifier dherai chalaakh
PLE Le-Postposition Harile
PLAI Lai-Postposition Bhailai
KO KO-Postposition Ramko
POP Other PostPositions tabulmathi
CC Co-ordinating Con-
junction
ra
CS Subordinating Con-
junction
Kinabhane
UH Interjection Oho
CD Cardinal Number Ek
OD Ordinal Number Pahilo
HRU Plural Marker Haru
QW Question Word Ko
CL Classifier Dasjana
RP Particle Khai
DT Determiner Tyo keto
UNW Unknown Word Nekomprenas
FW Foreign Word good
YF Sentence Final ? ! etc.
YM Sentence Medieval , ; : etc.
YQ Quotation ?? ""
YB Brackets () {} []
FB Abbreviation Ma.Pu.Pu
ALPH Header List Ka.
SYM Symbol %
NULL <NULL>
166
internet. The collected texts amount to a size of 14
million words. Both the Core Corpus and the Gen-
eral Corpus above have been developed following
the internationally accepted FLOB and FROWN
framework for collecting text corpus.
Another set of collection under the Written Corpus
is the Parallel Corpus. The Parallel Corpus con-
sists of collections from two genres - computing
and national development. The one on comput-
ing sizes to be 3 million words of English-Nepali
parallel texts whereas the other one on national de-
velopment amounts to about 966,203 words.
In another bid, a Nepali Corpora parallel to
100,000 words of common English source from
PENN Treebank corpus, available through the
Linguistic Data Consortium(LDC)has been devel-
oped5.This Parallel Corpus has been also POS
Tagged with the 43 POS Tagset as presented in Ta-
ble 1.
2.4 Nepali Spoken Corpus
The Spoken Corpora has been designed on the
basis of the Goteborg Spoken Language Cor-
pus(GSLC). The Corpora have been collected
from 17 social activities and contain about
2,60,000 words. These texts are audio-video
recordings of the activities with their correspond-
ing transcriptions and annotations about the par-
ticipant?s information. Each activity is stored in
three separate files (.mpeg, .txt and .doc) respec-
tively for recording,transcription and recording in-
formation.
2.5 Nepali Speech Corpus
The Speech Corpus is a specialized recordings
of speech developed for the Nepali Text-To-
Speech(TTS) application for enabling the software
to speak Nepali from written texts.It consists of
1,880 sentences and 6053 words, extracted from
the Core Corpus and later recorded in male and
female voices. The recordings are approximately
of 3-4 hours.
3 Applications
3.1 Nepali Thesaurus
For developing the Nepali Thesaurus, we have
used the MyThes framework6 developed by Kevin
5This work has been developed with the support from the
Language Resource Association (GSK) of Japan and Inter-
national Development Research Center (IDRC) of Canada,
through the PAN Localization Project(www.PANL10n.net)
6http://lingucomponent.openoffice.org/MyThes-1.zip
Hendricks. MyThes is incorporated with the
OpenOffice.org suite.Originally, it did not sup-
port UTF-8 encoding but the support has been
enabled after OpenOffice.org 2.0.2 onwards.The
Nepali Thesaurus currently contains 5,500 entries
with the attributes - POS Tag, Meaning and Syn-
onym. This application has been released as an
inbuilt package with OpenOffice.org Writer local-
ized into Nepali for public usage since 2005.
3.2 Nepali Spell Checker
The Nepali Spell Checker follows the Hunspell
framework7. In essence, Hunspell is a spell
checker and morphological library.It is included
in OpenOffice.org suite 2.0 onwards by default.
Recently,it has also been adopted by the Google
Search Engine as it?s default Spell Checker. De-
pending upon the language specific terriotory,
HunSpell may be customized by using the con-
cerned locale file. HunSpell requires two files8,
respectively the dictionary file that contains the
words for the language and the affix file that
has rules associated to the words in the dictio-
nary by using flags serving as pointers. The
two files should be located in the folder openof-
ficefolder/share/dic/ooo/. Spell checking is done
using the affix file, locale and the dictionary
file.While the affix file consists of affix rules, the
dictionary file consists of root words. At the
moment,the size of the dictionary file is about
37,000 entries whereas we have about 1,800 af-
fix rules in the affix file. The word coverage
in terms of spell checking is 6.2 million Nepali
words. Random tests of the spell checker yielded
accuracies of 90%(43 words unhandled out of
450 words),94%(25 words unhandled out of 400
words),89% accuracy(100 words unhandled out of
923 words) etc. By saying unhandled, we refer to
the situation whereby the incorrect words are not
provided appropriate suggestions.
3.3 Dobhase - English to Nepali Machine
Translation System
With a view to aid to the majority of English un-
proficient Nepalis to some extent, this application
was developed under a joint collaboration between
Kathmandu University and Madan Puraskar Pus-
takalaya.The software currently is able to provide
gist translations to simple declarative sentences.It
7http://hunspell.sourceforge.net
8The two files for Nepali is available at
http://nepalinux.org/downloads/ne NP dict.zip
167
is a rule and transfer-based Machine Translation
System. More information on the software is
available at http://nlp.ku.edu.np/
3.4 The Online Nepali Dictionary
A Corpus based Online Nepali Dictionary has
been developed for Nepali and is available in the
following link http://nepalisabdakos.com
This dictionary differs from the existing ones(both
hard and soft copy versions) in that this dictionary
contains examples and meanings from the corpus
itself. The XIARA software has been used to look
for wordlists and concordances in due course of
compiling the dictionary. The dictionary currently
contains about 8,000 entries .
3.5 The Nepali Text-To-Speech
The Nepali Text-To-Speech Application has been
developed following the Festival Speech Synthe-
sis System.Currently, the Nepali Text-To-Speech
works just in the Linux environment and has the
basic capabilities of reading text from files.One
may opt to hear the texts either from a male
or a female voice.The application has been
deemed useful not only to visually impaired
but also to illiterates.Lately, there has been a
growing demand of the application for extend-
ing it to a screen reader and making it work in
cross-platforms.For more information, please visit
http://bhashasanchar.org/textspeech intro.php
3.6 Conversion Tools
Keeping into consideration that a lot of texts
both in the government and the general pub-
lic are still encoded in ASCII-based Nepali non-
unicode fonts,we have developed the Conver-
sion Tools both for converting non-unicode texts
to unicode and vice versa.For details,please visit
http://madanpuraskar.org/ Our efforts in the devel-
opment of the tool have been supplemented by
the Open Source Community as well.The latest
information on the extended work is available at
http://code.google.com/p/nepaliconverter/
3.7 The Nepali Stemmer and the
Morphological Analyzer
The Nepali Stemmer and the Morphological Ana-
lyzer combines the results of the Stemmer and the
Morphological Analyzer in the sense that besides
producing the stem or root of any word, the as-
sociated bound morphemes and their grammatical
category are also kept track of. The Nepali Stem-
mer and Morphological Analyzer is a rule-based
one and makes use of the following resources:
? Free morpheme based lexicon
? Affix file or bound morpheme list
? Database of word breaking rules
The free morpheme based lexicon consists
of free or unbound morphemes of the Nepali
language together with their respective parts-
of-speech information. Similarly, the affix file
or bound morpheme list contains the prefix
and the suffixes in Nepali.These affixes are
further associated with numbers which point to
the corresponding word breaking rules.Finally,
the word breaking rules database basically
represent the insertion and deletion rules appli-
cable once a word breaks down into the root
and the respective affixes. The application,
which is still at a prototypical stage, is available at
http://nepalinux.org/downloads/nlp/stemmer ma.zip
3.8 The Nepali Computational Grammar
Analyzer
The Nepali Computational Grammar Analyzer
is an attempt to develop a basic computational
framework for analyzing the correctness of a
given input sentence in the Nepali language.
While the primary objective remains in building
such a framework, the secondary objective lies in
developing intermediate standalone NLP modules
like the POS Tagger,chunker and the parser.In
Figure 1, we present the system architecture of
the Nepali Computational Grammar Analyzer.
Talking about the individual modules,for the POS
Tagger,we have used TNT9,a very efficient and
state-of-the-art statistical POS tagger and trained
it with around 82000 Nepali words.Currently
the accuracy of the trained TnT POS Tagger for
Nepali is 56% for unknown words and 97% for
known words.
Similarly,for the chunker module, we have devel-
oped a hand-crafted linguistic chunk rules and a
simple algorithm to process these rules.Currently,
we have around 30 chunk rules, which have
to be further optimized for better coverage and
output.The chunkset consists of 11 chunk tags at
the moment.
For the parser module, we have implemented
9http://coli.uni-saarland.de/ thorsten/tnt/
168
a constraint-based parser following the depen-
dency grammar formalism10 and in particular
the Paninian Grammar framework(Bharati et
al.,1993,1995;Pederson et al,2004).A depen-
dency parser gives us a framework to identify
the relations between the verb(s) and the other
constituents in a sentence. Such relations, which
basically occur between verb(s) and nominal
constituents are called Karaka relations.For
Nepali, we have identified altogether six different
Karaka relations, namely,Karta - K1, Karma -
K2, Karan-K3, Sampradan - K4, Apadaan-K5,
Others-KX.
The assumption is that if we can establish valid
Karaka relations between the chunks of the sen-
tence and the verb, then the given input sentence
is valid.For example, in the Nepali sentence
Ram le bhaat khaayo (meaning Ram ate rice),
there is a K1 relation between the verb khaayo
and the noun chunk Ram le, and similarly K2
relation between the verb khaayo and the noun
chunk bhaat. Next, the Karaka frame specifies
what karakas are mandatory or optional for the
verb and what vibhaktis(postpositions) they take
respectively. Each verb belongs to a specific verb
class (in our case, whether the verb is transitive
or intransitive)and each class has a basic karaka
frame. Each Tense,Aspect and Modality - TAM
of a verb specifies a transformation rule. Based
10http://w3.msi.vxu.se/nivre/papers/05133.pdf
Figure 1: System Architecture of the Nepali Com-
putational Grammar Analyzer
on the TAM of a verb, a transformation is made
on the verb frame taking reference of the TAM
frame. A detailed description of the Nepali
Computation Grammar Analyzer is available at
http://nepalinux.org/downloads/nlp/report on
nepali computational grammar.pdf
The Grammar Analyzer for Nepali currently
parses and analyzes simple declarative sentences
with just one verb candidate.We have developed
the karaka frame for around 700 Nepali verbs.An
agreement module if added to the analyzer could
further filter the parses returned by the parser
module, this time taking the feature agreements
like gender, number, person, tense, aspect and
modality. Hence,with the possible addition of the
agreement module, the robustness of the Grammar
Analyzer is believed to significantly increase.
4 Conclusion
In this paper, we discussed on the different efforts
put towards developing the basic NLP resources
and applications.We also talked about the ap-
proaches followed by the applications and shed
light on their current coverage and limitations.
From the discussions above, it is quite clear
that much work has been done in developing
a basic NLP foundation for Nepali both from
resource buiding and applications development
perspectives. The way ahead is undoubtedly in
refining the current achievements and building ad-
vanced NLP applications like Statistical Machine
Translation System, Name Entity Recognition
System, Question Answering System,Information
Retrieval System, Information Extraction System
etc. Another possibility is applying the expertise
and experiences gathered while working for
Nepali to other non-Nepali languages.
Acknowledgements
The works described in the paper have been
partly supported by the International Develop-
ment Research Center(IDRC), Canada through
the PAN Localization Project(http://panl10n.net)
and Asia IT & C Programme of the Euro-
pean Commission under the Bhasha Sanchar
Project(http://bhashasanchar.org).
169
References
A.Bharati, V. Chaitanya, and R. Sangal, Nat-
ural Language Processing - A Paninian Per-
spective. New Delhi: Easter Economy Edition
ed.Kantipur:Prentice Hall, 1995.
A.Bharati and R. Sangal, ?Parsing free word order lan-
guages in the Paninian framework.,? in Proceedings
of the 31?st Annual Meeting on Association For
Computational Linguistics (Columbus, Ohio, June
22, 1993).Annual Meeting of the ACL., Morristown,
NJ, 1993, pp. 105-111.
A.Bharati, R. Sangal, and T. Reddy, ?A Constraint
Based Parser Using Integer Programming,? in Pro-
ceedings of the ICON-2002, Mumbai, 2002, pp.
121-127.
B. K. Bal, B. Karki, and L. Khatiwada, ?Nepali
Spellchecker 1.1 and the Thesaurus, Research and
Development,? PAN Localization Working Papers
2004-2007.
B. K. Bal and P. Shrestha, ?Nepali Spellchecker,? PAN
Localization Working Papers 2004-2007.
S. Bista, L. Kathiwada, and B. Keshari, ?Nepali Lex-
icon,? PAN Localization, Working Papers 2004-
2007, pp.307-10.
S. Bista, L. Khatiwada, and B. Keshari, ?Nepali Lexi-
con Development.,? PAN Localization, Working Pa-
pers 2004-2007, pp.311-15.
M.Pederson, D. Eades, S. Amin, and L. Prakash, ?Rel-
ative clauses in Hindi and Arabic:A paninian de-
pendency grammar analysis. ,? in Proceedings of
the Twentiet International Conference on Computa-
tional Linguistics., Geneva, 2004, pp. 17-24.
170
