Proceedings of the 47th Annual Meeting of the ACL and the 4th IJCNLP of the AFNLP, pages 638?646,
Suntec, Singapore, 2-7 August 2009. c?2009 ACL and AFNLP
Quantitative modeling of the neural representation of adjective-noun 
phrases to account for fMRI activation 
 
 
Kai-min K. Chang1   Vladimir L. Cherkassky2   Tom M. Mitchell3   Marcel Adam Just2
Language Technologies Institute1
Center for Cognitive Brain Imaging2
Machine Learning Department3
Carnegie Mellon University 
Pittsburgh, PA 15213, U.S.A. 
{kkchang,cherkassky,tom.mitchell,just}@cmu.edu 
 
  
 
Abstract 
 
Recent advances in functional Magnetic 
Resonance Imaging (fMRI) offer a significant 
new approach to studying semantic represen-
tations in humans by making it possible to di-
rectly observe brain activity while people 
comprehend words and sentences. In this 
study, we investigate how humans compre-
hend adjective-noun phrases (e.g. strong dog) 
while their neural activity is recorded. Classi-
fication analysis shows that the distributed 
pattern of neural activity contains sufficient 
signal to decode differences among phrases. 
Furthermore, vector-based semantic models 
can explain a significant portion of system-
atic variance in the observed neural activity. 
Multiplicative composition models of the 
two-word phrase outperform additive models, 
consistent with the assumption that people 
use adjectives to modify the meaning of the 
noun, rather than conjoining the meaning of 
the adjective and noun. 
1 Introduction 
How humans represent meanings of individual 
words and how lexical semantic knowledge is 
combined to form complex concepts are issues 
fundamental to the study of human knowledge. 
There have been a variety of approaches from 
different scientific communities trying to charac-
terize semantic representations. Linguists have 
tried to characterize the meaning of a word with 
feature-based approaches, such as semantic roles 
(Kipper et al, 2006), as well as word-relation 
approaches, such as WordNet (Miller, 1995). 
Computational linguists have demonstrated that a 
word?s meaning is captured to some extent by 
the distribution of words and phrases with which 
it commonly co-occurs (Church & Hanks, 1990). 
Psychologists have studied word meaning 
through feature-norming studies (Cree & McRae, 
2003) in which human participants are asked to 
list the features they associate with various 
words. There are also efforts to recover the latent 
semantic structure from text corpora using tech-
niques such as LSA (Landauer & Dumais, 1997) 
and topic models (Blei et al, 2003). 
Recent advances in functional Magnetic 
Resonance Imaging (fMRI) provide a significant 
new approach to studying semantic 
representations in humans by making it possible 
to directly observe brain activity while people 
comprehend words and sentences. fMRI 
measures the hemodynamic response (changes in 
blood flow and blood oxygenation) related to 
neural activity in the human brain. Images can be 
acquired at good spatial resolution and reason-
able temporal resolution ? the activity level of 
15,000 - 20,000 brain volume elements (voxels) 
of about 50 mm3 each can be measured every 1 
second. Recent multivariate analyses of fMRI 
activity have shown that classifiers can be 
trained to decode which of several visually pre-
sented objects or object categories a person is 
contemplating, given the person?s fMRI-
measured neural activity (Cox and Savoy, 2003; 
O'Toole et al, 2005; Haynes and Rees, 2006; 
Mitchell et al, 2004). Furthermore, Mitchell et 
al. (2008) showed that word features computed 
from the occurrences of stimulus words (within a 
trillion-token Google text corpus that captures 
the typical use of words in English text) can 
predict the brain activity associated with the 
638
meaning of these words. They developed a 
generative model that is capable of predicting 
fMRI neural activity well enough that it can 
successfully match words it has not yet 
encountered to their previously unseen fMRI 
images with accuracies far above chance level. 
The distributed pattern of neural activity encodes 
the meanings of words, and the model?s success 
indicates some initial access to the encoding. 
Given these early succesess in using fMRI to 
discriminate categorial information and to model 
lexical semantic representations of individual 
words, it is interesting to ask whether a similar 
approach can be used to study the representation 
of adjective-noun phrases. In this study, we 
applied the vector-based models of semantic 
composition used in computational linguistics to 
model neural activation patterns obtained while 
subjects comprehended adjective-noun phrases. 
In an object-contemplation task, human partici-
pants were presented with 12 text labels of ob-
jects (e.g. dog) and were instructed to think of 
the same properties of the stimulus object consis-
tently during multiple presentations of each item. 
The participants were also shown adjective-noun 
phrases, where adjectives were used to modify 
the meaning of nouns (e.g. strong dog). 
Mitchell and Lapata (2008) presented a 
framework for representing the meaning of 
phrases and sentences in vector space. They 
discussed how an additive model, a 
multiplicative model, a weighted additive model, 
a Kintsch (2001) model, and a model which 
combines multiplicative and additive models can 
be used to model human behavior in similiarity 
judgements when human participants were 
presented with a reference containing a subject-
verb phrase (e.g., horse ran) and two landmarks 
(e.g., galloped and dissolved) and asked to 
choose which landmark was most similiar to the 
reference (in this case, galloped). They compared 
the composition models to human similarity 
ratings and found that all models were 
statistically significantly correlated with human 
judgements. Moreover, the multiplicative and 
combined model performed signficantlly better 
than the non-compositional models. Our 
approach is similar to that of Mitchell and Lapata 
(2008) in that we compared additive and 
multiplicative models to non-compositional 
models in terms of their ability to model human 
data. Our work differs from these efforts because 
we focus on modeling neural activity while 
people comprehend adjective-noun phrases. 
In section 2, we describe the experiment and 
how functional brain images were acquired. In 
section 3, we apply classifier analysis to see if 
the distributed pattern of neural activity contains 
sufficient signal to discriminate among phrases. 
In section 4, we discuss a vector-based approach 
to modeling the lexical semantic knowledge 
using word occurrence measures in a text corpus. 
Two composition models, namely the additive 
and the multiplicative models, along with two 
non-composition models, namely the adjective 
and the noun models, are used to explain the 
systematic variance in neural activation. Section 
5 distinguishes between two types of adjectives 
that are used in our stimuli: attribute-specifying 
adjectives and object-modifying adjectives. 
Classifier analysis suggests people interpret the 
two types of adjectives differently. Finally, we 
discuss some of the implications of our work and 
suggest some future studies. 
2 Brain Imaging Experiments on Adjec-
tive-Noun Comprehension 
2.1 Experimental Paradigm 
Nineteen right-handed adults (aged between 18 
and 32) from the Carnegie Mellon community 
participated and gave informed consent approved 
by the University of Pittsburgh and Carnegie 
Mellon Institutional Review Boards. Four addi-
tional participants were excluded from the analy-
sis due to head motion greater than 2.5 mm. 
The stimuli were text labels of 12 concrete 
nouns from 4 semantic categories with 3 
exemplars per category. The 12 nouns were bear, 
cat, dog (animal); bottle, cup, knife (utensil); 
carrot, corn, tomato (vegetable); airplane, train, 
and truck (vehicle; see Table 1). The fMRI 
neural signatures of these objects have been 
found in previous studies to elicit different neural 
activity. The participants were also shown each 
of the 12 nouns paired with an adjective, where 
the adjectives are expected to emphasize certain 
semantic properties of the nouns. For instance, in 
the case of strong dog, the adjective is used to 
emphasize the visual or physical aspect (e.g. 
muscular) of a dog, as opposed to the behavioral 
aspects (e.g. play, eat, petted) that people more 
often associate with the term. Notice that the last 
three adjectives in Table 1 are marked by aster-
isks to denote they are object-modifying adjec-
tives. These adjectives appear to behave differ-
ently from the ordinary attribute-specifying ad-
jectives. Section 5 is devoted to discussing the 
different adjective types in more detail. 
639
 
Adjective Noun Category 
Soft Bear Animal 
Large Cat Animal 
Strong Dog Animal 
Plastic Bottle Utensil 
Small Cup Utensil 
Sharp Knife Utensil 
Hard Carrot Vegetable 
Cut Corn Vegetable 
Firm Tomato Vegetable 
Paper* Airplane Vehicle 
Model* Train Vehicle 
Toy* Truck Vehicle 
Table 1. Word stimuli. Asterisks mark the ob-
ject-modifying adjectives, as opposed to the or-
dinary attribute-specifying adjectives. 
 
To ensure that participants had a consistent set 
of properties to think about, they were each 
asked to generate and write a set of properties for 
each exemplar in a session prior to the scanning 
session (such as ?4 legs, house pet, fed by me? 
for dog). However, nothing was done to elicit 
consistency across participants. The entire set of 
24 stimuli was presented 6 times during the 
scanning session, in a different random order 
each time. Participants silently viewed the 
stimuli and were asked to think of the same item 
properties consistently across the 6 presentations 
of the items. Each stimulus was presented for 3s, 
followed by a 7s rest period, during which the 
participants were instructed to fixate on an X 
displayed in the center of the screen. There were 
two additional presentations of fixation, 31s 
each, at the beginning and end of each session, to 
provide a baseline measure of activity. 
2.2 Data Acquisition and Processing 
Functional images were acquired on a Siemens 
Allegra 3.0T scanner (Siemens, Erlangen, 
Germany) at the Brain Imaging Research Center 
of Carnegie Mellon University and the 
University of Pittsburgh using a gradient echo 
EPI pulse sequence with TR = 1000 ms, TE = 30 
ms, and a 60? flip angle. Seventeen 5-mm thick 
oblique-axial slices were imaged with a gap of 1-
mm between slices. The acquisition matrix was 
64 x 64 with 3.125 x 3.125 x 5-mm voxels. Data 
processing were performed with Statistical 
Parametric Mapping software (SPM2, Wellcome 
Department of Cognitive Neurology, London, 
UK; Friston, 2005). The data were corrected for 
slice timing, motion, and linear trend, and were 
temporally smoothed with a high-pass filter 
using a 190s cutoff. The data were normalized to 
the MNI template brain image using a 12-
parameter affine transformation and resampled to 
3 x 3 x 6-mm3 voxels. 
The percent signal change (PSC) relative to 
the fixation condition was computed for each 
item presentation at each voxel. The mean of the 
four images (mean PSC) acquired within a 4s 
window, offset 4s from the stimulus onset (to 
account for the delay in hemodynamic response), 
provided the main input measure for subsequent 
analysis. The mean PSC data for each word 
presentation were further normalized to have 
mean zero and variance one to equate the 
variation between participants over exemplars. 
Due to the inherent limitations in the temporal 
properties of fMRI data, we consider here only 
the spatial distribution of the neural activity after 
the stimuli are comprehended and do not attempt 
to model the cogntive process of comprehension.  
3 Does the distribution of neural activ-
ity encode sufficient signal to classify 
adjective-noun phrases? 
3.1 Classifier Analysis 
We are interested in whether the distribution of 
neural activity encodes sufficient signal to de-
code both nouns and adjective-noun phrases. 
Given the observed neural activity when partici-
pants comprehended the adjective-noun phrases, 
Gaussian Na?ve Bayes classifiers were trained to 
identify cognitive states associated with viewing 
stimuli from the evoked patterns of functional 
activity (mean PSC). For instance, the classifier 
would predict which of the 24 exemplars the par-
ticipant was viewing and thinking about. Sepa-
rate classifiers were also trained for classifying 
the isolated nouns, the phrases, and the 4 seman-
tic categories. 
Since fMRI acquires the neural activity at 
15,000 ? 20,000 distinct voxel locations, many of 
which might not exhibit neural activity that en-
codes word or phrase meaning, the classifier 
analysis selected the voxels whose responses to 
the 24 different items were most stable across 
presentations. Voxel stability was computed as 
the average pairwise correlation between 24 item 
vectors across presentations. The focus on the 
most stable voxels effectively increased the 
signal-to-noise ratio in the data and facilitated 
further analysis by classifiers. Many of our 
previous analyses have indicated that 120 voxels 
is a set size suitable for our purposes. 
640
Classification results were evaluated using 6-
fold cross validation, where one of the 6 repeti-
tions was left out for each fold. The voxel selec-
tion procedure was performed separately inside 
each fold, using only the training data. Since 
multiple classes were involved, rank accuracy 
was used (Mitchell et al, 2004) to evaluate the 
classifier. Given a new fMRI image to classify, 
the classifier outputs a rank-ordered list of possi-
ble class labels from most to least likely. The 
rank accuracy is defined as the percentile rank of 
the correct class in this ordered output list. Rank 
accuracy ranges from 0 to 1. Classification 
analysis was performed separately for each par-
ticipant, and the mean rank accuracy was com-
puted over the participants. 
3.2 Results and Discussion 
Table 2 shows the results of the exemplar-level 
classification analysis. All classification accura-
cies were significantly higher than chance (p < 
0.05), where the chance level for each classifica-
tion is determined based on the empirical distri-
bution of rank accuracies for randomly generated 
null models. One hundred null models were gen-
erated by permuting the class labels. The classi-
fier was able to distinguish among the 24 exem-
plars with mean rank accuracies close to 70%. 
We also determined the classification accuracies 
separately for nouns only and phrases only. Dis-
tinct classifiers were trained. Classification accu-
racies were significantly higher (p < 0.05) for the 
nouns, calculated with a paired t-test. For 3 par-
ticipants, the classifier did not achieve reliable 
classification accuracies for the phrase stimuli. 
Moreover, we determined the classification accu-
racies separately for each semantic category of 
stimuli. There were no significant differences in 
accuracy across categories, except for the differ-
ence between vegetables and vehicles.  
 
Classifier Racc 
All 24 exemplars 0.69 
Nouns 0.71 
Phrases 0.64 
Animals 0.67 
Tools 0.66 
Vegetables 0.65 
Vehicles 0.69 
Table 2. Rank accuracies for classifiers. Distinct 
classifiers were trained to distinguish all 24 ex-
amples, nouns only, phrases only, and only 
words within each of the 4 semantic categories.  
 
High classification accuracies indicate that the 
distributed pattern of neural activity does encode 
sufficient signal to discriminate differences 
among stimuli. The classification accuracy for 
the nouns was on par with previous research, 
providing a replication of previous findings 
(Mitchell et al 2004). The classifiers performed 
better on the nouns than the phrases, consistent 
with our expectation that characterizing phrases 
is more difficult than characterizing nouns in 
isolation. It is easier for participants to recall 
properties associated with a familiar object than 
to comprehend a noun whose meaning is further 
modified by an adjective. The classification 
analysis also helps us to identify participants 
whose mental representations for phrases are 
consistent across phrase presentations. Subse-
quent regression analysis on phrase activation 
will be based on subjects who perform the phrase 
task well. 
4 Using vector-based models of seman-
tic representation to account for the 
systematic variances in neural activity 
4.1 Lexical Semantic Representation 
Computational linguists have demonstrated that a 
word?s meaning is captured to some extent by 
the distribution of words and phrases with which 
it commonly co-occurs (Church and Hanks, 
1990). Consequently, Mitchell et al (2008) en-
coded the meaning of a word as a vector of in-
termediate semantic features computed from the 
co-occurrences with stimulus words within the 
Google trillion-token text corpus that captures 
the typical use of words in English text. Moti-
vated by existing conjectures regarding the cen-
trality of sensory-motor features in neural repre-
sentations of objects (Caramazza and Shelton, 
1998), they selected a set of 25 semantic features 
defined by 25 verbs: see, hear, listen, taste, 
smell, eat, touch, rub, lift, manipulate, run, push, 
fill, move, ride, say, fear, open, approach, near, 
enter, drive, wear, break, and clean. These verbs 
generally correspond to basic sensory and motor 
activities, actions performed on objects, and ac-
tions involving changes in spatial relationships. 
Because there are only 12 stimuli in our ex-
periment, we consider only 5 sensory verbs (see 
hear, smell, eat and touch) to avoid overfitting 
with the full set of 25 verbs. Following the work 
of Bullinaria and Levy (2007), we consider the 
?basic semantic vector? which normalizes n(c,t), 
the count of times context word c occurs within a 
window of 5 words around the target word t. The 
641
basic semantic vector is thus the vector of condi-
tional probabilities, 
 
( ) ( )( )
( )
( )?==
c
tcn
tcn
tp
tcp
tcp
,
,,
|  
 
where all components are positive and sum to 
one. Table 3 shows the semantic representation 
for strong and dog. Notice that strong is heavily 
loaded on see and smell, whereas dog is heavily 
loaded on eat and see, consistent with the intui-
tive interpretation of these two words. 
 
 See Hear Smell Eat Touch 
Strong 0.63 0.06 0.26 0.03 0.03 
Dog 0.34 0.06 0.05 0.54 0.02 
Table 3. The lexical semantic representation for 
strong and dog. 
4.2 Semantic Composition 
We adopt the vector-based semantic composition 
models discussed in Mitchell and Lapata (2008). 
Let u and v denote the meaning of the adjective 
and noun, respectively, and let p denote the com-
position of the two words in vector space. We 
consider two non-composition models, the 
adjective model and the noun model, as well as 
two composition models, the additive model and 
the multplicative model. 
The adjective model assumes that the meaning 
of the composition is the same as the adjective: 
 
up =  
 
The noun model assumes that the meaning of 
the composition is the same as the noun: 
 
vp =  
 
The adjective model and the noun model cor-
respond to the assumption that when people 
comprehend phrases, they focus exclusively on 
one of the two words. This serves as a baseline 
for comparison to other models. 
The additive model assumes the meaning of 
the composition is a linear combination of the 
adjective and noun vector: 
 
vBuAp ?+?=  
 
where A and B are vectors of weighting coeffi-
cients. 
The multiplicative model assumes the mean-
ing of the composition is the element-wise prod-
uct of the two vectors: 
 
vuCp ??=  
 
Mitchell and Lapata (2008) fitted the parame-
ters of the weighting vectors A, B, and C, though 
we assume A = B = C = 1, since we are interested 
in the model comparison. Also, there are no 
model complexity issues, since the number of 
parameters in the four models is the same. 
More critically, the additive model and multi-
plicative model correspond to different cognitive 
processes. On the one hand, the additive model 
assumes that people concatenate the meanings of 
the two words when comprehending phrases. On 
the other hand, the multiplicative model assumes 
that the contribution of u is scaled to its rele-
vance to v, or vice versa. Notice that the former 
assumption of the multiplicative model corre-
sponds to the modifier-head interpretation where 
adjectives are used to modify the meaning of 
nouns. To foreshadow our results, we found the 
modifier-head interpretation of the multiplicative 
model to best account for the neural activity ob-
served in adjective-noun phrase data.
Table 4 shows the semantic representation for 
strong dog under each of the four models. Al-
though the multiplicative model appears to have 
small loadings on all features, the relative distri-
bution of loadings still encodes sufficient infor-
mation, as our later analysis will show. Notice 
how the additive model concatenates the mean-
ing of two words and is heavily loaded on see, 
eat, and smell, whereas the multiplicative model 
zeros out unshared features like eat and smell. As 
a result, the multiplicative model predicts that the 
visual aspects will be emphasized when a par-
ticipant is thinking about strong dog, while the 
additive model predicts that, in addition, the be-
havioral aspects (e.g., eat, smell, and hear) of 
dog will be emphasized. 
 
 See Hear Smell Eat Touch
Adj 0.63 0.06 0.26 0.03 0.03 
Noun 0.34 0.06 0.05 0.54 0.02 
Add 0.96 0.12 0.31 0.57 0.04
Multi 0.21 0.00 0.01 0.01 0.00
Table 4. The semantic representation for strong 
dog under the adjective, noun, additive, and 
multiplicative models. 
 
642
Notice that these 4 vector-based semantic 
composition models ignore word order. This cor-
responds to the bag-of-words assumption, such 
that the representation for strong dog will be the 
same as that of dog strong. The bag-of-words 
model is used as a simplifying assumption in 
several semantic models, including LSA (Lan-
dauer & Dumais, 1997) and topic models (Blei et 
al., 2003). 
There were two main hypotheses that we 
tested. First, people usually regard the noun in 
the adjective-noun pair as the linguistic head. 
Therefore, meaning associated with the noun 
should be more evoked. Thus, we predicted that 
the noun model would outperform the adjective 
model. Second, people make more interpreta-
tions that use adjectives to modify the meaning 
of the noun, rather than disjunctive interpreta-
tions that add together or take the union of the 
semantic features of the two words. Thus, we 
predicted that the multiplicative model would 
outperform the additive model. 
4.3 Regression Fit 
In this analysis, we train a regression model to fit 
the activation profile for the 12 phrase stimuli. 
We focused on subjects for whom the classifier 
established reliable classification accuracies for 
the phrase stimuli. The regression model exam-
ined to what extent the semantic feature vectors 
(explanatory variables) can account for the varia-
tion in neural activity (response variable) across 
the 12 stimuli. All explanatory variables were 
entered into the regression model simultane-
ously. More precisely, the predicted activity av at 
voxel v in the brain for word w is given by 
 
( )?
=
+=
n
i
viviv wfa
1
??  
 
where fi(w) is the value of the ith intermediate 
semantic feature for word w, ?vi is the regression 
coefficient that specifies the degree to which the 
ith intermediate semantic feature activates voxel 
v, and ?v is the model?s error term that represents 
the unexplained variation in the response vari-
able. Least squares estimates of ?vi were obtained 
to minimize the sum of squared errors in recon-
structing the training fMRI images. An L2 regu-
larization with lambda = 1.0 was added to pre-
vent overfitting given the high parameter-to-
data-points ratios. A regression model was 
trained for each of the 120 voxels and the re-
ported R2 is the average across the 120 voxels. 
R2 measures the amount of systematic variance 
explained by the model. Regression results were 
evaluated using 6-fold cross validation, where 
one of the 6 repetitions was left out for each fold.  
Linear regression assumes a linear dependency 
among the variables and compares the variance 
due to the independent variables against the vari-
ance due to the residual errors. While the linear-
ity assumption may be overly simplistic, it re-
flects the assumption that fMRI activity often 
reflects a superimposition of contributions from 
different sources, and has provided a useful first 
order approximation in the field (Mitchell et al, 
2008). 
4.4 Results and Discussion 
The second column of Table 5 shows the R2 re-
gression fit (averaged across 120 voxels) of the 
adjective, noun, additive, and multiplicative 
model to the neural activity observed in adjec-
tive-noun phrase data. The noun model signifi-
cantly (p < 0.05) outperformed the adjective 
model, estimated with a paired t-test. Moreover, 
the difference between the additive and adjective 
models was not significant, whereas the differ-
ence between the additive and noun models was 
significant (p < 0.05). The multiplicative model 
significantly (p < 0.05) outperformed both of the 
non-compositional models, as well as the addi-
tive model. 
More importantly, the two hypotheses that we 
were testing were both verified. Notice Table 5 
supports our hypothesis that the noun model 
should outperform the adjective model based on 
the assumption that the noun is generally more 
central to the phrase meaning than is the adjec-
tive. Table 5 also supports our hypothesis that 
the multiplicative model should outperform the 
additive model, based on the assumption that 
adjectives are used to emphasize particular se-
mantic features that will already be represented 
in the semantic feature vector of the noun. Our 
findings here are largely consistent with Mitchell 
and Lapata (2008). 
 
 R2 Racc 
Adjective 0.34 0.57 
Noun 0.36 0.61 
Additive 0.35 0.60 
Multiplicative 0.42 0.62 
Table 5. Regression fit and regression-based 
classification rank accuracy of the adjective, 
noun, additive, and multiplicative models for 
phrase stimuli. 
 
643
Following Mitchell et al (2008), the regres-
sion model can be used to decode mental states. 
Specifically, for each regression model, the esti-
mated regression weights can be used to generate 
the predicted activity for each word. Then, a pre-
viously unseen neural activation vector is identi-
fied with the class of the predicted activation that 
had the highest correlation with the given ob-
served neural activation vector. Notice that, 
unlike Mitchell et al (2008), where the regres-
sion model was used to make predictions for 
items outside the training set, here we are just 
showing that the regression model can be used 
for classification purposes. 
The third column of Table 5 shows the rank 
accuracies classifying mental concepts using the 
predicted activation from the adjective, noun, 
additive, and multiplicative models. All rank ac-
curacies were significantly higher (p < 0.05) than 
chance, where the chance level for each classifi-
cation is again determined by permutation test-
ing. More importantly, here we observe a rank-
ing of these four models similar to that observed 
for the regression analysis. Namely, the noun 
model performs significantly better (p < 0.05) 
than the adjective model, and the multiplicative 
model performs significantly better (p < 0.05) 
than the additive model. However, the difference 
between the multiplicative model and the noun 
model is not statistically significant in this case. 
5 Comparing the attribute-specifying 
adjectives with the object-modifying 
adjectives 
Some of the phrases contained adjectives that 
changed the meaning of the noun. In the case of 
vehicle nouns, adjectives were chosen to modify 
the manipulability of the nouns (e.g., to make an 
airplane more manipulable, paper was chosen as 
the modifier). This type of modifier raises two 
issues. First, these modifiers (e.g. paper, model, 
toy) more typically assume the part of speech 
(POS) tag of nouns, unlike our other modifiers 
(e.g., soft, large, strong) whose typical POS tag 
is adjective. Second, these modifiers combine 
with the noun to denote a very different object 
from the noun in isolation (paper airplane, 
model train, toy truck), in comparison to other 
cases where the adjective simply specifies an 
attribute of the noun (soft bear, large cat, strong 
dog, etc.). In order to study this difference, we 
performed classification analysis separately for 
the attribute-specifying adjectives and the object-
modifying adjectives. 
Our hypothesis is that the phrases with attrib-
ute-specifying adjectives will be much more dif-
ficult to distinguish from the original nouns than 
the adjectives that change the referent. For in-
stance, we hypothesize that it is much more dif-
ficult to distinguish the neural representation for 
strong dog versus dog than it is to distinguish the 
neural representation for paper airplane versus 
airplane. To verify this, Gaussian Na?ve Bayes 
classifiers were trained to discriminate between 
each of the 12 pairs of nouns and adjective-noun 
phrases. The average classification for phrases 
with object-modifying adjectives is 0.76, 
whereas classification accuracies for phrases 
with attribute-specifying adjectives are 0.68. The 
difference is statistically significant at p < 0.05. 
This result supports our hypothesis. 
Furthermore, we performed regression-based 
classification separately for the two types of ad-
jectives. Notice that the number of phrases with 
object-modifying adjectives is much less than the 
number of phrases with attribute-specifying ad-
jectives (3 vs. 9). This affects the parameter-to-
data-points ratio in our regression model. Conse-
quently, an L2 regularization with lambda = 10.0 
was used to prevent overfitting. Table 6 shows a 
pattern similar to that seen in section 4 is ob-
served for the attribute-specifying adjectives. 
That is, the noun model outperformed the adjec-
tive model and the multiplicative model outper-
formed the additive model when using attribute-
specifying adjectives. However, for the object-
modifying adjectives, the noun model no longer 
outperformed the adjective model. Moreover, the 
additive model performed better than the noun 
model. Although neither difference is statistically 
significant, this clearly shows a pattern different 
from the attribute-specifying adjectives. This 
result suggests that when interpreting phrases 
like paper airplane, it is more important to con-
sider contributions from the adjectives, compared 
to when interpreting phrases like strong dog, 
where the contribution from the adjective is sim-
ply to specify a property of the item typically 
referred to by the noun in isolation. 
  
 Attribute-
specifying 
Object-
modifying 
Adjective 0.57 0.65 
Noun 0.62 0.64 
Additive 0.61 0.65 
Multiplicative 0.63 0.67 
Table 6. Separate regression-based classification 
rank accuracy for phrases with attribute-
specifying or object-modifying adjectives. 
644
In light of this observation, we plan to extend 
our analysis of adjective-nouns phrases to noun-
noun phrases, where participants will be shown 
noun phrases (e.g. carrot knife) and instructed to 
think of a likely meaning for the phrases. Unlike 
adjective-noun phrases, where a single interpre-
tation often dominates, noun-noun combinations 
allow multiple interpretations (e.g., carrot knife 
can be interpreted as a knife that is specifically 
used to cut carrots or a knife carved out of car-
rots). There exists an extensive literature on the 
conceptual combination of noun-noun phrases. 
Costello and Keane (1997) provide extensive 
studies on the polysemy of conceptual combina-
tion. More importantly, they outline different 
rules of combination, including property map-
ping, relational mapping, hybrid mapping, etc. It 
will be interesting to see if different composition 
models better account for neural activation when 
different kinds of combination rules are used. 
6 Contribution and Conclusion 
Experimental results have shown that the distrib-
uted pattern of neural activity while people are 
comprehending adjective-noun phrases does con-
tain sufficient information to decode the stimuli 
with accuracies significantly above chance. Fur-
thermore, vector-based semantic models can ex-
plain a significant portion of systematic variance 
in observed neural activity. Multiplicative com-
position models outperform additive models, a 
trend that is consistent with the assumption that 
people use adjectives to modify the meaning of 
the noun, rather than conjoining the meaning of 
the adjective and noun. 
In this study, we represented the meaning of 
both adjectives and nouns in terms of their co-
occurrences with 5 sensory verbs. While this 
type of representation might be justified for con-
crete nouns (hypothesizing that their neural rep-
resentations are largely grounded in sensory-
motor features), it might be that a different repre-
sentation is needed for adjectives. Further re-
search is needed to investigate alternative repre-
sentations for both nouns and adjectives. More-
over, the composition models that we presented 
here are overly simplistic in a number of ways. 
We look forward to future research to extend the 
intermediate representation and to experiment 
with different modeling methodologies. An al-
ternative approach is to model the semantic rep-
resentation as a hidden variable using a genera-
tive probabilistic model that describes how neu-
ral activity is generated from some latent seman-
tic representation. We are currently exploring the 
infinite latent semantic feature model (ILFM; 
Griffiths & Ghahramani, 2005), which assumes a 
non-parametric Indian Buffet prior to the binary 
feature vector and models neural activation with 
a linear Gaussian model. The basic proposition 
of the model is that the human semantic knowl-
edge system is capable of storing an infinite list 
of features (or semantic components) associated 
with a concept; however, only a subset is ac-
tively recalled during any given task (context-
dependent). Thus, a set of latent indicator vari-
ables is introduced to indicate whether a feature 
is actively recalled at any given task. We are in-
vestigating if the compositional models also op-
erate in the learned latent semantic space.  
The premise of our research relies on ad-
vancements in the fields of computational lin-
guistics and cognitive neuroimaging. Indeed, we 
are at an especially opportune time in the history 
of the study of language, when linguistic corpora 
allow word meanings to be computed from the 
distribution of word co-occurrence in a trillion-
token text corpus, and brain imaging technology 
allows us to directly observe and model neural 
activity associated with the conceptual combina-
tion of lexical items. An improved understanding 
of language processing in the brain could yield a 
more biologically-informed model of semantic 
representation of lexical knowledge. We there-
fore look forward to further brain imaging stud-
ies shedding new light on the nature of human 
representation of semantic knowledge. 
Acknowledgements 
This research was supported by the National Sci-
ence Foundation, Grant No. IIS-0835797, and by 
the W. M. Keck Foundation. We would like to 
thank Jennifer Moore for help in preparation of 
the manuscript. 
References  
Blei, D. M., Ng, A. Y., Jordan, and M. I.. 2003. La-
tent dirichlet alocation. Journal of Machine Learn-
ing Research 3, 993-1022. 
Bullinaria, J., and Levy, J. 2007. Extracting semantic 
representations from word co-occurrence statistics: 
A computational study. Behavioral Research 
Methods, 39:510-526. 
Caramazza, A., and Shelton, J. R. 1998. Domain-
specific knowledge systems in the brain the ani-
mate inanimate distinction. Journal of Cognitive 
Neuroscience 10(1), 1-34. 
645
Church, K. W., and Hanks, P. 1990. Word association 
norms, mutual information, and lexicography. 
Computational Linguistics, 16, 22-29. 
Cree, G. S., and McRae, K. 2003. Analyzing the fac-
tors underlying the structure and computation of 
the meaning of chipmunk, cherry, chisel, cheese, 
and cello (and many other such concrete nouns). 
Journal of Experimental Psychology: General 
132(2), 163-201. 
Costello, F., and Keane, M. 2001. Testing two theo-
ries of conceptual combination: Alignment versus 
diagnosticity in the comprehension and production 
of combined concepts. Journal of Experimental 
Psychology: Learning, Memory & Cognition, 
27(1): 255-271. 
Cox, D. D., and Savoy, R. L. 2003. Functioning mag-
netic resonance imaging (fMRI) "brain reading": 
Detecting and classifying distributed patterns of 
fMRI activity in human visual cortex. NeuroImage 
19, 261-270. 
Friston, K. J. 2005. Models of brain function in neuro-
imaging. Annual Review of Psychology 56, 57-87. 
Griffiths, T. L., and Ghahramani, Z. 2005. Infinite 
latent feature models and the Indian buffet process. 
Gatsby Unit Technical Report GCNU-TR-2005-
001. 
Haynes, J. D., and Rees, G. 2006. Decoding mental 
states from brain activity in humans. Nature Re-
views Neuroscience 7(7), 523-534. 
Kintsch, W. 2001. Prediction. Cognitive Science, 
25(2):173-202. 
Landauer, T.K., and Dumais, S. T. 1997. A solution to 
Plato?s problem: The latent semantic analysis the-
ory of acquisition, induction, and representation of 
knowledge. Psychological Review, 104(2), 211-
240. 
Miller, G. A. 1995. WordNet: A lexical database for 
English. Communications of the ACM 38, 39-41. 
Mitchell, J., and Lapata, M. 2008. Vector-based mod-
els of semantic composition. Proceedings of ACL-
08: HLT, 236-244. 
Mitchell, T., Hutchinson, R., Niculescu, R. S., 
Pereira, F., Wang, X., Just, M. A., and Newman, S. 
D. 2004. Learning to decode cognitive states from 
brain images. Machine Learning 57, 145-175. 
Mitchell, T., Shinkareva, S.V., Carlson, A., Chang, 
K.M., Malave, V.L., Mason, R.A., and Just, M.A. 
2008. Predicting human brain activity associated 
with the meanings of nouns. Science 320, 1191-
1195. 
O'Toole, A. J., Jiang, F., Abdi, H., and Haxby, J. V. 
2005. Partially distributed representations of ob-
jects and faces in ventral temporal cortex. Journal 
of Cognitive Neuroscience, 17, 580-590. 
 
646
