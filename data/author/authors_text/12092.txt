  
The Hindi Discourse Relation Bank 
Umangi Oza*, Rashmi Prasad?, Sudheer Kolachina*, Dipti Misra Sharma* and 
Aravind Joshi? 
*Language Technologies Research Centre 
IIIT Hyderabad, Gachibowli, Hyderabad, Andhra Pradesh, India 500032 
oza.umangi,sudheer.kpg08@gmail.com,dipti@iiit.ac.in 
 
?Institute for Research in Cognitive Science/Computer and Information Science 
3401 Walnut Street, Suite 400A 
Philadelphia, PA USA 19104 
rjprasad,joshi@seas.upenn.edu 
 
  
Abstract 
We describe the Hindi Discourse Relation 
Bank project, aimed at developing a large 
corpus annotated with discourse relations. 
We adopt the lexically grounded approach of 
the Penn Discourse Treebank, and describe 
our classification of Hindi discourse connec-
tives, our modifications to the sense classifi-
cation of discourse relations, and some cross-
linguistic comparisons based on some initial 
annotations carried out so far. 
1 Introduction 
To enable NLP research and applications beyond 
the sentence-level, corpora annotated with dis-
course level information have been developed. 
The recently developed Penn Discourse Tree-
bank (PDTB) (Prasad et al, 2008), for example, 
provides annotations of discourse relations (e.g., 
causal, contrastive, temporal, and elaboration 
relations) in the Penn Treebank Corpus. Recent 
interest in cross-linguistic studies of discourse 
relations has led to the initiation of similar dis-
course annotation projects in other languages as 
well, such as Chinese (Xue, 2005), Czech (Mla-
dov? et al, 2008), and Turkish (Deniz and Web-
ber, 2008). In this paper, we describe our ongo-
ing work on the creation of a Hindi Discourse 
Relation Bank (HDRB), broadly following the 
approach of the PDTB.1 The size of the HDRB 
corpus is 200K words and it is drawn from a 
400K word corpus on which Hindi syntactic de-
pendency annotation is being independently con-
ducted (Begum et al, 2008). Source corpus texts 
are taken from the Hindi newspaper Amar Ujala, 
and comprise news articles from several do-
mains, such as politics, sports, films, etc. We 
                                                 
1 An earlier study of Hindi discourse connectives towards 
the creation of HDRB is presented in Prasad et al (2008). 
present our characterization of discourse connec-
tives and their arguments in Hindi (Section 2), 
our proposals for modifying the sense classifica-
tion scheme (Section 3), and present some cross-
linguistics comparisons based on annotations 
done so far (Section 4). Section 5 concludes with 
a summary and future work.  
2 Discourse Relations and Arguments 
Following the PDTB approach, we take dis-
course relations to be realized in one of three 
ways: (a) as explicit connectives, which are 
?closed class? expressions drawn from well-
defined grammatical classes; (b) as alternative 
lexicalizations (AltLex), which are non-
connective expressions that cannot be defined as 
explicit connectives; and (c) as implicit connec-
tives, which are implicit discourse relations ?in-
ferred? between adjacent sentences not related by 
an explicit connective. When no discourse rela-
tion can be inferred between adjacent sentences, 
either an entity-based coherence relation (called 
EntRel) or the absence of a relation (called No-
Rel) is marked between the sentences. The two 
abstract object relata of a discourse relation are 
called the relation?s arguments (named Arg1 and 
Arg2), and argument annotation follows the ?mi-
nimality principle? in that only as much is se-
lected as the argument text span as is minimally 
necessary to interpret the relation. Finally, each 
discourse relation is assigned a sense label based 
on a hierarchical sense classification. 
2.1 Explicit Connectives 
In addition to the three major grammatical 
classes of Explicit connectives in the PDTB ? 
subordinating conjunctions, coordinating con-
junctions, and adverbials ? we recognize three 
other classes, described below. 
 
  
Sentential Relatives: These are relative pro-
nouns that conjoin a relative clause with its ma-
trix clause. As the name suggests, only relatives 
that modify verb phrases are treated as discourse 
connectives, and not those that modify noun 
phrases. Some examples are ????? (so that), 
????? ???? (because of which). 
 
1) [???? ??? ?????? ?? ?? ??????? ?? ????? ??? 
?? ?? ?? ????] ????? {???? ??? ???? ???? 
?? ???} 
?[Dropping all his work, he picked up the bird 
and ran towards the dispensary], so that {it 
could be given proper treatment}.? 
Subordinators: These include postpositions (Ex. 
2), verbal participles, and suffixes that introduce 
non-finite clauses with an abstract object inter-
pretation.2 
2) [?? ?? ????? ???]?? {??-??-?? ???????? ???? 
????? ???}? 
?Upon [hearing Baa?s words], {Gandhiji felt very 
ashamed}.? 
Particles: Particles such as ??, ?? act as dis-
course connectives. ?? is an emphatic inclusive 
particle used to suggest the inclusion of verbs, 
entities, adverbs, and adjectives. Instances of 
such particles which indicate the inclusion of 
verbs are taken as discourse connectives (Ex. 3) 
while others are not. 
3) ??? ?? ? ????? ????? ?? ??? ??? ? ???? ? ?? 
?????? ?? ??? ??? ??? ??? ???]?{?????? ??? 
??? ??? ???????? ???} ?? {?? ??? ???}? 
?[People see this as a consequence of the improv-
ing relation between the two countries]. {The 
Kashmiris are} also {learning an political lesson 
from this}.? 
2.2 Arguments of Discourse Relations 
In the PDTB, the assignment of the Arg1 and 
Arg2 labels to a discourse relation?s arguments is 
syntactically driven, in that the Arg2 label is as-
                                                 
2 Subordinators that denote the manner of an action are not 
discourse connectives, but since such disambiguation is a 
difficult task, we have decided to annotate subordinators in 
a later phase of the project.  
 
signed to the argument with which the connec-
tive was syntactically associated, while the Arg1 
label is assigned to the ?other? argument. In 
HDRB, however, the Arg1/Arg2 label assign-
ment is semantically driven, in that it is based on 
the ?sense? of the relation to which the argu-
ments belong.  Thus, each sense definition for a 
relation specifies the sense-specific semantic role 
of each of its arguments, and stipulates one of the 
two roles to be Arg1, and the other, Arg2.   For 
example, the ?cause? sense definition, which in-
volves a causal relation between two eventuali-
ties, specifies that one of its arguments is the 
cause, while the other is the effect, and further 
stipulates that the cause will be assigned the label 
Arg2, while the effect will be assigned the label 
Arg1.  Apart from giving meaning to the argu-
ment labels, our semantics-based convention has 
the added advantage simplifying the sense classi-
fication scheme. This is discussed further in Sec-
tion 3.  
2.3 Implicit Discourse Relations 
The HDRB annotation of implicit discourse rela-
tions largely follows the PDTB scheme. The only 
difference is that while implicit relations in 
PDTB are annotated only between paragraph-
internal adjacent sentences, we also annotate 
such relations across paragraph boundaries.  
3 Senses of Discourse Relations  
Broadly, we follow the PDTB sense classifica-
tion in that we take it to be a hierarchical classi-
fication, with the four top level sense classes of 
?Temporal?, ?Contingency?, ?Comparison?, and 
?Expansion?. Further refinements to the top class 
level are provided at the second type level and 
the third subtype level. Here, we describe our 
points of departure from the PDTB classification. 
The changes are partly motivated by general 
considerations for capturing additional senses, 
and partly by language-specific considerations. 
Figure 1 reflects the modifications we have made 
to the sense scheme. These are described below. 
 
Eliminating argument-specific labels: In the 
PDTB sense hierarchy, the tags at the type level 
are meant to express further refinements of the 
relations? semantics, while the tags at the subtype 
level are meant to reflect different orderings of 
the arguments (see Section 2.2). In HDRB, we 
eliminate these argument-ordering labels from 
the subtype level, since these labels don?t direct-
ly pertain to the meaning of discourse relations. 
  
All levels in the sense hierarchy thus have the 
purpose of specifying the semantics of the rela-
tion to different degrees of granularity. The rela-
tive ordering of the arguments is instead speci-
fied in the definition of the type-level senses, and 
is inherited by the more refined senses at the sub-
type level.   
 
 
 
     
 
Figure 1: HDRB (Modified) Sense Classification 
 
 
Uniform treatment of pragmatic relations: As 
in PDTB, discourse relations in HDRB are 
pragmatic when their relations have to be in-
ferred from the propositional content of the ar-
guments. However, we replace the PDTB prag-
matic senses with a uniform three-way classifica-
tion. Each pragmatic sense at the type level is 
further distinguished into three subtypes: ?epis-
temic? (Sweetser 1990), ?speech-act? (Sweetser 
1990), and ?propositional?. The propositional 
subtype involves the inference of a complete 
proposition. The relation is then taken to hold 
between this inferred proposition and the propo-
sitional content of one of the arguments. 
 
The ?Goal? sense: Under the ?Contingency? 
class, we have added a new type ?Goal?, which 
applies to relations where the situation described 
in one of the arguments is the goal of the situa- 
tion described in the other argument (which 
enables the achievement of the goal).   
4 Initial Annotation Experiments 
Based on the guidelines as described in this pa-
per, we annotated both explicit and implicit rela-
tions in 35 texts (averaging approx. 250 
words/text) from the HDRB corpus. A total of 
602 relation tokens were annotated. Here we 
present some useful distributions we were able to 
derive from our initial annotation, and discuss 
them in light of cross-linguistic comparisons of 
discourse relations.  
 
Types and Tokens of Discourse Relations: Ta-
ble 1 shows the overall distribution of the differ-
ent relation types, i.e., Explicit, AltLex, Implicit, 
EntRel, and NoRel. The second column reports 
the number of unique expressions used to realize 
the relation ? Explicit, Implicit and AltLex ? 
while the third column reports the total number 
of tokens and relative frequencies.  
 
Relations Types Tokens (%) 
Explicit 49 189 (31.4%) 
Implicit 35 185 (30.7%) 
AltLex 25 37 (6.14%) 
EntRel NA 140 (23.25%) 
NoRel NA 51 (8.5%) 
TOTAL 109 602 
Table 1: Distribution of Discourse Relations 
 
These distributions show some interesting simi-
larities and differences with the PDTB distribu-
tions (cf. Prasad et al, 2008). First, given that 
Hindi has a much richer morphological paradigm 
than English; one would have expected that it 
would have fewer explicit connectives. That is, 
one might expect Hindi to realize discourse rela-
tions morphologically more often than not, just 
as it realizes other syntactic relations.  However, 
even in the small data set of 602 tokens that we 
have annotated so far, we have found 49 unique 
explicit connectives, which is roughly half the 
number reported for the 1 million words anno-
tated in English texts in PDTB. It is expected that 
we will find more unique types as we annotate 
additional data. The relation type distribution 
  
thus seems to suggest that the availability of 
richer morphology in a language doesn?t affect 
connective usage. Second, the percentage of Alt-
Lex relations is higher in HDRB ? 6.14% com-
pared to 1.5% in PDTB, suggesting that Hindi 
makes greater usage of non-connective cohesive 
links with the prior discourse. Further studies are 
needed to characterize the forms and functions of 
AltLex expressions in both English and Hindi. 
 
Senses of Discourse Relations: We also ex-
amined the distributions for each sense class in 
HDRB and computed the relative frequency of 
the relations realized explicitly and implicitly. 
Cross-linguistically, one would expect languages 
to be similar in whether or not a relation with a 
particular sense is realized explicitly or implicit-
ly, since this choice lies in the domain of seman-
tics and inference, rather than syntax. Thus, we 
were interested in comparing the sense distribu-
tions in HDRB and PDTB. Table 2 shows these 
distributions for the top class level senses. (Here 
we counted the AltLex relations together with 
explicit connectives.) 
 
Sense Class Explicit (%) Implicit (%) 
Contingency 57 (58.2%) 41 (41.8%) 
Comparison 68 (76.5%) 21 (23.5%) 
Temporal 43 (65.2%) 23 (34.8%) 
Expansion 64(40%) 94(60%) 
Table 2: Distribution of Class Level Senses 
 
The table shows that sense distributions in 
HDRB are indeed similar to those reported in the 
PDTB (cf. Prasad et al, 2008). That is, the 
chances of ?Expansion? and ?Contingency? rela-
tions being explicit are lower compared to 
?Comparison? and ?Temporal? relations.    
5 Summary and Future Work 
This paper has reported on the Hindi Discourse 
Relation Bank (HDRB) project, in which dis-
course relations, their arguments, and their 
senses are being annotated. A major goal of our 
work was to investigate how well the Penn Dis-
course Treebank (PDTB) and its guidelines could 
be adapted for discourse annotation of Hindi 
texts. To a large extent, we have successfully 
adapted the PDTB scheme. Proposed changes 
have to do with identification of some new syn-
tactic categories for explicit connectives, and 
some general and language-driven modifications 
to the sense classification. From our initial anno-
tations, we found that (a) there doesn?t seem to 
be an inverse correlation between the usage fre-
quency of explicit connectives and the morpho-
logical richness of a language, although there 
does seem to be an increased use of cohesive 
devices in such a language; and (b) sense distri-
butions confirm the lack of expectation of cross-
linguistic ?semantic? differences. Our future goal 
is to complete the discourse annotation of a 200K 
word corpus, which will account for half of the 
400K word corpus being also annotated for syn-
tactic dependencies. We also plan to extend the 
annotation scheme to include attributions.   
 
Acknowledgements 
This work was partially supported by NSF grants 
EIA-02-24417, EIA-05-63063, and IIS-07-
05671.  
References 
Rafiya Begum, Samar Husain, Arun Dhwaj, Dipti 
Misra Sharma, Lakshmi Bai, and Rajeev Sangal. 
2008. Dependency annotation scheme for Indian 
languages. Proc. of IJCNLP-2008.  
Lucie Mladov?, ??rka Zik?nov? and Eva Haji?ov?. 
2008. From Sentence to Discourse: Building an 
Annotation Scheme for Discourse Based on Prague 
Dependency Treebank. Proc. of LREC-2008. 
Rashmi Prasad, Nikhil Dinesh, Alan Lee, Eleni Milt-
sakaki, Livio Robaldo, Aravind Joshi, and Bonnie 
Webber. 2008. The Penn Discourse TreeBank 2.0. 
Proc. of LREC-2008.  
Rashmi Prasad, Samar Husain, Dipti Mishra Sharma, 
and Aravind Joshi. 2008. Towards an Annotated 
Corpus of Discourse Relations in Hindi. Proc. of 
IJCNLP-2008. 
 Eve Sweetser.1990. From etymology to pragmat-
ics: Metaphorical and cultural aspects of se-
mantic structure .   Cambridge University Press. 
Nianwen Xue. 2005. Annotating Discourse Connec-
tives in the Chinese Treebank. Proc. of the ACL 
Workshop on Frontiers in Corpus Annotation 
II: Pie in the Sky.  
Deniz Zeyrek and Bonnie Webber. 2008. A Discourse 
Resource for Turkish: Annotating Discourse Con-
nectives in the METU Corpus. Proc. of IJCNLP-
2008.  
INLG 2012 Proceedings of the 7th International Natural Language Generation Conference, pages 125?127,
Utica, May 2012. c?2012 Association for Computational Linguistics
Natural Language Generation for a Smart Biology Textbook
Eva Banik1, Eric Kow1, Vinay Chaudhri2, Nikhil Dinesh2, and Umangi Oza3
1{ebanik,kowey}@comp-ling.co.uk, Computational Linguistics Ltd, London, UK
2 {chaudhri,dinesh}@ai.sri.com, SRI International, Menlo Park, CA
3umangi.oza@evalueserve.com, Evaluserve, New Delhi, India
1 Application Context
In this demo paper we describe the natural lan-
guage generation component of an electronic
textbook application, called Inquire1. Inquire
interacts with a knowledge base which encodes
information from a biology textbook. The
application includes a question-understanding
module which allows students to ask questions
about the contents of the book, and a question-
answering module which retrieves the corre-
sponding answer from the knowledge base. The
task of the natural language generation mod-
ule is to present specific parts of the answer in
English. Our current generation pipeline han-
dles inputs that describe the biological func-
tions of entities, the steps of biological processes,
and the spatial relations between parts of enti-
ties. Our ultimate goal is to generate paragraph-
length texts from arbitrary paths in the knowl-
edge base. We describe here the natural lan-
guage generation pipeline and demonstrate the
inputs and generated texts. In the demo pre-
sentation we will show the textbook application
and the knowledge base authoring environment,
and provide an opportunity to interact with the
system.
2 The Knowledge Base
The knowledge base contains information from
a college-level biology textbook2, encoded by bi-
1The work described in this paper and presented in
the demo is funded by Vulcan Inc.
2 Reece et al 2010. Campbell biology. Pearson
Publishing.
ologists as part of project HALO at SRI3. The
core of the knowledge base is the CLIB ontol-
ogy4, which is extended with biology-specific in-
formation. The knowledge base encodes entity-
to-event relations (similar to thematic roles in
linguistics), event-to-event relations (discourse
relations), various property values and relations
between properties, spatial relations, cardinality
constraints, and roles that participants play in
events. The input to the generation pipeline is a
set of triples extracted from the biology knowl-
edge base. Currently our content selection in-
cludes either an event and the entities that par-
ticipate in the event, or a set of entities and
spatial relations between them.
3 Generation Grammar and Lexicon
Our generation grammar consists of a set of Tree
Adjoining Grammar (TAG) elementary trees.
Each tree is associated with either a single rela-
tion, or a set of relations in the knowledge base.
As an example, Fig 1 illustrates the mapping
between elementary trees and event participant
relations in the KB for the above input. We
currently associate up to three different elemen-
tary trees with each event and the connected
set of participant relations: an active senten-
tial tree, a passive sentential tree and a complex
noun phrase.
The knowledge base provides concept-to-word
3 Gunning Et al, 2010. Project halo update
progress toward digital aristotle. AI Magazine Fall:33-
58. See also http://www.projecthalo.com/
4http://www.cs.utexas.edu/users/mfkb/RKF/clib.html
125
Figure 1: The grammar of the surface realizer
mappings (a list of synonyms) for every concept,
and the words are used in the generation lexi-
con to anchor elementary TAG trees. Our gen-
eration grammar consists of a set of TAG tree
templates, which are defined as combinations of
tree fragments and are compiled using the XMG
metgrammar toolkit5.
These underspecified elementary trees are fur-
ther specified in the generation lexicon, which
maps concepts onto elementary tree templates,
and associates a word (an anchor) with the
tree, along with other idiosynchratic information
(e.g., preposition choice). We create a genera-
tion lexicon dynamically at run-time, by map-
ping tree templates onto concepts based on the
number and types of participants, and the lexi-
cal information associated with the event (e.g.,
the preposition requirements of the verb).
Concept names for entities are included in
the elementary trees as features on the corre-
sponding NP nodes. These features form part
of the input to the referring expression genera-
tion module, which looks up the concept name
5https://sourcesup.renater.fr/xmg/
in the concept-to-word mapping to obtain a list
of possible noun phrases.
4 Realization
Our natural language generation pipeline is cen-
tered around the GenI surface realizer6,7. The
set of triples yielded by content selection are first
aggregated and converted to GenI?s input for-
mat, a set of flat semantic literals. We then feed
this input to GenI to produce an underspecified
surface form in which referring expressions are
still underspecified:
NP is detach from NP resulting in NP at NP
NP detach from NP resulting in NP at NP
Detachment of NP from NP resulting in NP at NP
A post-processing module carries out refer-
ring expression generation and morphological re-
alization to produce the fully specified output.
6 Kow, Eric. 2007. Surface realisation: ambiguity
and determinism. Doctoral Dissertation, Universite de
Henri Poincare - Nancy 1.
7 Banik, Eva 2010. A minimalist approach to gen-
erating coherent texts. Phd thesis, Department of Com-
puting, The Open University
126
Question Answering & Reasoning Algorithms
Event Instance 
Content Selection
Set of triples
Input aggregation and conversion +Stylistic control
Knowledge Base
Realization with GenI
Morphology &referring expression generation
Semantic literals +input parameters
Ranking
Underspecified realizations
Linguistic Resources
Generation Lexicon
Grammar: Description of TAG tree templates
Concept-to-Wordmappings
Mapping of KB relationsto TAG tree templates
Morphological lexicon
Verb frames (preposition choice)
NLG Pipeline
Figure 2: Linguistic resources and the generation pipeline
Our referring expression realization algorithm
performs further semantic aggregation where
necessary to produce cardinals (?two chromo-
somes?), and decides on a suitable determiner
based on previous mentions of instance names
and subclasses in the discourse context (def-
inite/indefinite determiner, ?another? or ?the
same?). For the input shown in Fig 1, our sys-
tem will produce the following three realizations:
1. A sister chromatid detaches from another sister chro-
matid resulting in two chromosomes at a kinetochore.
2. A sister chromatid is detached from another sister
chromatid resulting in two chromosomes at a kinetochore.
3. Detachment of a sister chromatid from another sister
chromatid resulting in two chromosomes at a kinetochore
We rank the generated outputs based on their
linguistic properties using optimality theoretic
constraints (e.g., active sentences are ranked
above passive sentences), where each constraint
corresponds to a (set of) tree fragments that
contributed to building the tree that appears in
the output. Our system also allows for extra in-
put parameters to be sent to GenI to restrict the
set of generated outputs to fit a specific context
(e.g., syntactic type or focused discourse entity).
Our full natural language generation pipeline is
illustrated in Fig 2.
5 Future Work
We are currently working on extending the sys-
tem to handle more relations and other data
types in the knowledge base. This involves ex-
tending the grammar to new sentence types and
other linguistic constructions, and extending the
content selection module to return more triples
from the knowledge base. Our ultimate goal is
to be able to generate arbitrary ? but in some
sense well-formed ? paths from the knowledge
base as coherent paragraphs of text.
127
