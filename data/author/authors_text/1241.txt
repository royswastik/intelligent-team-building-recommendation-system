Automatic construction of parallel English-Chinese corpus for 
cross-language information retrieval 
J i ang  Chen and  J ian -Yun  N ie  
D~partement d ' In format ique et Recherche Op~rationnel le 
Universit~ de Montreal  
C.P. 6128, succursale CENTRE-V ILLE  
Montreal  (Quebec), Canada  H3C 3J7 
{chen, nie} @iro. umontreal, ca 
Abst rac t  
A major obstacle to the construction ofa probabilis- 
tic translation model is the lack of large parallel cor- 
pora. In this paper we first describe a parallel text 
mining system that finds parallel texts automatically 
on the Web. The generated Chinese-English paral- 
lel corpus is used to train a probabilistic translation 
model which translates queries for Chinese-English 
cross-language information retrieval (CLIR). We will 
discuss ome problems in translation model training 
and show the preliminary CUR results. 
1 In t roduct ion  
Parallel texts have been used in a number of studies 
in computational linguistics. Brown et al (1993) 
defined a series of probabilistic translation models 
for MT purposes. While people may question the 
effectiveness of using these models for a full-blown 
MT system, the models are certainly valuable for de- 
veloping translation assistance tools. For example, 
we can use such a translation model to help com- 
plete target ext being drafted by a human transla- 
tor (Langlais et al, 2000). 
Another utilization is in cross-language informa- 
tion retrieval (CLIR) where queries have to be trans- 
lated from one language to another language in 
which the documents are written. In CLIR, the qual- 
ity requirement for translation is relatively low. For 
example, the syntactic aspect is irrelevant. Even if 
the translated word is not a true translation but is 
strongly related to the original query, it is still help- 
ful. Therefore, CLIR is a suitable application for 
such a translation model. 
However, a major obstacle to this approach is the 
lack of parallel corpora for model training. Only 
a few such corpora exist, including the Hansard 
English-French corpus and the HKUST English- 
Chinese corpus (Wu, 1994). In this paper, we will 
describe a method which automatically searches for 
parallel texts on the Web. We will discuss the text 
mining algorithm we adopted, some issues in trans- 
lation model training using the generated parallel 
corpus, and finally the translation model's perfor- 
mance in CLIR. 
2 Para l le l  Text  M in ing  A lgor i thm 
The PTMiner system is an intelligent Web agent 
that is designed to search for large amounts of paral- 
lel text on the Web. The mining algorithm is largely 
language independent. It can thus be adapted to 
other language pairs with only minor modifications. 
Taking advantage ofWeb search engines as much 
as possible, PTMiner implements he following steps 
(illustrated in Fig. 1): 
1 Search for candidate sites - Using existing Web 
search engines, search for the candidate sites 
that may contain parallel pages; 
2 File name fetching - For each candidate site, 
fetch the URLs of Web pages that are indexed 
by the search engines; 
3 Host crawling - Starting from the URLs col- 
lected in the previous tep, search through each 
candidate site separately for more URLs; 
4 Pair scan - From the obtained URLs of each 
site, scan for possible parallel pairs; 
5 Download and verifying - Download the parallel 
pages, determine file size, language, and charac- 
ter set of each page, and filter out non-parallel 
pairs. 
2.1 Search for candidate Sites 
We take advantage of the huge number of Web sites 
indexed by existing search engines in determining 
candidate sites. This is done by submitting some 
particular equests to the search engines. The re- 
quests are determined according to the following ob- 
servations. In the sites where parallel text exists, 
there are normally some pages in one language con- 
taining links to the parallel version in the other lan- 
guage. These are usually indicated by those links' 
anchor texts 1. For example, on some English page 
there may be a link to its Chinese version with 
the anchor text "Chinese Version" or "in Chinese". 
1An anchor text  is a piece of text on a Web page which, 
when clicked on, will take you to another linked page. To 
be helpful, it usual ly  contains the key information about the 
l inked page. 
21 
Figure 1: The workflow of the mining process. 
The same phenomenon can be observed on Chinese 
pages. Chances are that a site with parallel texts 
will contain such links in some of its documents. 
This fact is used as the criterion in searching for 
candidate sites. 
Therefore, to determine possible sites for English- 
Chinese parallel texts, we can request an English 
document containing the following anchor: 
anchor : "engl ish version H \["in english", ...\]. 
Similar requests are sent for Chinese documents. 
From the two sets of pages obtained by the above 
queries we extract wo sets of Web sites. The union 
of these two sets constitutes then the candidate sites. 
That  is to say, a site is a candidate site when it 
is found to have either an English page linking to 
its Chinese version or a Chinese page linking to its 
English version. 
2.2 File Name Fetching 
We now assume that a pair of parallel texts exists on 
the same site. To search for parallel pairs on a site, 
PTMiner first has to obtain all (or at least part of) 
the HTML file names on the site. From these names 
pairs are scanned. It is possible to use a Web crawler 
to explore the candidate sites completely. However, 
we can take advantage of the search engines again to 
accelerate the process. As the first step, we submit 
the following query to the search engines: 
host : hostname 
to fetch the Web pages that they indexed from this 
site. If we only require a small amount of parallel 
texts, this result may be sufficient. For our purpose, 
however, we need to explore the sites more thor- 
oughly using a host crawler. Therefore, we continue 
our search for files with a host crawler which uses 
the documents found by the search engines as the 
starting point. 
2.3 Host Crawling 
A host crawler is slightly different from a Web 
crawler. Web crawlers go through innumerable 
pages and hosts on the Web. A host crawler is a 
Web crawler that crawls through documents on a 
given host only. A breadth-first crawling algorithm 
is applied in PTMiner as host crawler. The principle 
is that when a link to an unexplored ocument on 
the same site is found in a document, it is added to 
a list that will be explored later. In this way, most 
file names from the candidate sites are obtained. 
2.4 Pair Scan 
After collecting file names for each candidate site, 
the next task is to determine the parallel pairs. 
Again, we try to use some heuristic rules to guess 
which files may be parallel texts before downloading 
them. The rules are based on external features of 
the documents. By external feature, we mean those 
features which may be known without analyzing the 
contents of the file, such as its URL, size, and date. 
This is in contrast with the internal features, such as 
language, character set, and HTML structure, which 
cannot be known until we have downloaded the page 
and analyzed its contents. 
The heuristic criterion comes from the following 
observation: We observe that parallel text pairs usu- 
ally have similar name patterns. The difference be- 
tween the names of two parailel pages usually lies 
in a segment which indicates the language. For ex- 
ample, "file-ch.html" (in Chinese) vs. "file-en.html" 
(in English). The difference may also appear in the 
path, such as ".../chinese/.../fi le.html" vs. ".../en- 
glish/.../f i le.html'. The name patterns described 
above are commonly used by webmasters to help or- 
ganize their sites. Hence, we can suppose that a 
pair of pages with this kind of pattern are probably 
parallel texts. 
22
First, we establish four lists for English pre- 
fixes, English suffixes, Chinese prefixes and Chi- 
nese suffixes. For example: Engl ish P re f ix  = 
{e, en, e_, en_, e - ,  en - ,  ...}. For each file in one lan- 
guage, if a segment in its name corresponds to one 
of the language affixes, several new names are gener- 
ated by changing the segment to the possible corre- 
sponding affixes of the other language. If a generated 
name corresponds to an existing file, then the file is 
considered as a candidate parallel document of the 
original file. 
2.5 Filtering 
Next, we further examine the contents of the paired 
files to determine if they are really parallel according 
to various external and internal features. This may 
further improve the pairing precision. The following 
methods have been implemented in our system. 
2.5.1 Text Length 
Parallel files often have similar file lengths. One sim- 
ple way to filter out incorrect pairs is to compare 
the lengths of the two files. The only problem is to 
set a reasonable threshold that will not discard too 
many good pairs, i.e. balance recall and precision. 
The usual difference ratio depends on the language 
pairs we are dealing with. For example, Chinese- 
English parallel texts usually have a larger differ- 
ence ratio than English-French parallel texts. The 
filtering threshold had to be determined empirically, 
from the actual observations. For Chinese-English, 
a difference up to 50% is tolerated. 
2.5.2 Language and  Character Set 
It is also obvious that the two files of a pair have 
to be in the two languages of interest. By auto- 
matically identifying language and character set, we 
can filter out the pairs that do not satisfy this basic 
criterion. Some Web pages explicitly indicate the 
language and the character set. More often such 
information is omitted by authors. We need some 
language identification tool for this task. 
SILC is a language and encoding identification 
system developed by the RALI laboratory at the 
University of Montreal. It employs a probabilistic 
model estimated on tri-grams. Using these mod- 
els, the system is able to determine the most proba- 
ble language and encoding of a text (Isabelle et al, 
1997). 
2.5.3 HTML Structure and Alignment 
In the STRAND system (Resnik, 1998), the candi- 
date pairs are evaluated by aligning them according 
to their HTML structures and computing confidence 
values. Pairs are assumed to be wrong if they have 
too many mismatching markups or low confidence 
values. 
Comparing HTML structures seems to be a sound 
way to evaluate candidate pairs since parallel pairs 
usually have similar HTML structures. However, we 
also noticed that parallel texts may have quite dif- 
ferent HTML structures. One of the reasons is that 
the two files may be created using two HTML ed- 
itors. For example, one may be used for English 
and another for Chinese, depending on the language 
handling capability of the editors. Therefore, cau- 
tion is required when measuring structure difference 
numerically. 
Parallel text alignment is still an experimental 
area. Measuring the confidence values of an align- 
ment is even more complicated. For example, the 
alignment algorithm we used in the training of the 
statistical translation model produces acceptable 
alignment results but it does not provide a confi- 
dence value that we can "confidently" use as an eval- 
uation criterion. So, for the moment his criterion is 
not used in candidate pair evaluation. 
3 Generated  Corpus  and Trans la t ion  
Mode l  Tra in ing  
In this section, we describe the results of our parallel 
text mining and translation model training. 
3.1 The Corpus 
Using the above approach for Chinese-English, 185 
candidate sites were searched from the domain hk. 
We limited the mining domain to hk because Hong 
Kong is a bilingual English-Chinese city where high 
quality parallel Web sites exist. Because of the small 
number of candidate sites, the host crawler was used 
to thoroughly explore each site. The resulting cor- 
pus contains 14820 pairs of texts including 117.2Mb 
Chinese texts and 136.5Mb English texts. The entire 
mining process lasted about a week. Using length 
comparison and language identification, we refined 
the precision of the corpus to about 90%. The preci- 
sion is estimated by examining 367 randomly picked 
pairs. 
3.2 Statistical Translation Model 
Many approaches in computational linguistics try to 
extract ranslation knowledge from previous trans- 
lation examples. Most work of this kind establishes 
probabilistic models from parallel corpora. Based 
on one of the statistical models proposed by Brown 
et al (1993), the basic principle of our translation 
model is the following: given a corpus of aligned sen- 
tences, if two words often co-occur in the source and 
target sentences, there is a good likelihood that they 
are translations of each other. In the simplest case 
(model 1), the model earns the probability, p(tls), of 
having a word t in the translation of a sentence con- 
taining a word s. For an input sentence, the model 
then calculates a sequence of words that are most 
probable to appear in its translation. Using a sim- 
ilar statistical model, Wu (1995) extracted a large- 
scale English-Chinese l xicon from the HKUST cor- 
23  
<s id="00~"> 
<HTML> <HEAD> 
<META HTrP-EQUIV="Content-type" 
CONTENT="text/html; charset--iso-8859-1"> 
<META HTI'P-EQUIV="Content-language" 
CONTENT="Western"> 
</s> 
<s id="0001"> 
<TITLE>Journal of Primary Education 1996, 
VoI., No. l&2, pp. 19-27 </TITLE> 
</HEAD> 
</s> 
<s id="0002"> 
<BODY BACKGROUND=".Jgif/pejbg.jpg" 
TEXT="#000(3(O" BGCOLOR="#ffffff"> 
<CENTER> 
</s> 
<s id="0003"> 
<HI>Journal of Primary Education </HI> 
</s> 
<s id="0004"> 
<HR> <B>Volume 6, No l&2, pp. 19-27 (May, 
1996) </B> <HR> 
</s> 
<s id="0005"> 
<H3>Principles for Redesigning Teacher 
Education </H3> Alan TOM </CENTER> 
</s> 
<s id="0006"> 
<P> <B> <I> Abstract </I> </B> 
</s> 
<s id="0000"> 
<HTML> <HEAD> 
<META H'ITP-EQUW="Content-type" 
CONTENT="text/html; charset=bigS"> 
<META HTTP-EQUIV="Content-language" 
CONTENT="zh"> 
<Is> 
<s id="0001"> 
<TITLE> Journal of Primary Education 1996, 
Vol., No. l&2, Page 19-27 </TITLE> 
</HEAD> 
</s> 
<s id="0002"> 
<BODY BACKGROUND=".Jgif/pejbg.jpg" 
TEXT="#000000" BGCOLOR="#ffffff"> <A 
HREF="/erdpej/b2g__pej.phtml?URL=%2fen%2fp 
ej%2f0601%2f0601019c.htm"> 
<IMG SRC="/en/gif/kan.gif" ALT="~"  
BORDER=0 ALIGN=R IGHT> </A> <CENTER> 
</s> 
<s id="0003"> 
<H2>~ ~ 11I ~ O.</H2> 
</s> 
<s id="0004"> 
<HR> (~:~h-fv-c?.JLJl) ~,-\]'?~.. 
</s> 
<s id="0005"> 
~ 19-27\]~ <I-1R> 
</s> 
Figure 2: An alignment example using pure length-based method. 
pus which is built manually. In our case, the prob- 
abilistic translation model will be used for CLIR. 
The requirement on our translation model may be 
less demanding: it is not absolutely necessary that 
a word t with high p(tls ) always be a true trans- 
lation of s. It is still useful if t is strongly related 
to s. For example, although "railway" is not a true 
translation of "train" (in French), it is highly useful 
to include "railway" in the translation of a query on 
"train". This is one of the reasons why we think a 
less controlled parallel corpus can be used to train a 
translation model for CLIR. 
3.3 Parallel Text Al ignment 
Before the mined documents can be aligned into par- 
allel sentences, the raw texts have to undergo a se- 
ries of some preprocessing, which, to some extent, is 
language dependent. For example, the major opera- 
tions on the Chinese-English corpus include encod- 
ing scheme transformation (for Chinese), sentence 
level segmentation, parallel text alignment, Chinese 
word segmentation (Nie et al, 1999) and English 
expression extraction. 
The parallel Web pages we collected from vari- 
ous sites are not all of the same quality. Some are 
highly parallel and easy to align while others can be 
very noisy. Aligning English-Chinese parallel texts 
is already very difficult because of the great differ- 
ences in the syntactic structures and writing sys- 
tems of the two languages. A number of alignment 
techniques have been proposed, varying from statis- 
tical methods (Brown et al, 1991; Gale and Church, 
1991) to lexical methods (Kay and RSscheisen, 1993; 
Chen, 1993). The method we adopted is that of 
Simard et al (1992). Because it considers both 
length similarity and cognateness as alignment cri- 
teria, the method is more robust and better able 
to deal with noise than pure length-based methods. 
Cognates are identical sequences of characters in cor- 
responding words in two languages. They are com- 
monly found in English and French. In the case of 
English-Chinese alignment, where there are no cog- 
nates shared by the two languages, only the HTML 
markup in both texts are taken as cognates. Be- 
cause the HTML structures of parallel pages are nor- 
mally similar, the markup was found to be helpful 
for alignment. 
To illustrate how markup can help with the align- 
ment, we align the same pair with both the pure 
length-based method of Gale & Church (Fig. 2), 
and the method of Simard et al (Fig. 3). First of 
all, we observe from the figures that the two texts are 
24
<s id="0000"> 
<HTML> <HEAD> 
<META HTTP-EQUIV="Content-type" 
CONTENT="text/html; charset=iso-8859-1 "> 
<META HTTP-EQUIV="Content-language" 
CONTENT="Westem"> 
</s> 
<s id="0001"> 
<TITLE>Journal of Primary Education 1996, 
Vol., No. l&2, pp. 19-27 </TITLE> 
</HEAD> 
</s> 
<s id="0002"> 
<BODY BACKGROUND=-". Jgif/pejbg.jpg" 
TEXT="#000000" BGCOLOR="#ffffff"> 
<CENTER> 
</s> 
<s id="0003"> 
<H 1 >Journal of Primary Education </H 1 > 
<Is> 
<s id="0004"> 
<HR> <B>Volume 6,No l&2, pp. 19-27 (May, 
1996) </B> <HR> 
</$> 
<s id="0000"> 
<HTML> <HEAD> 
<META HTrP-EQUIV="Content-type" 
CONTENT="text/html; charset=big5"> 
<META H'lTP-EQUIV="Content-language" 
CONTENT="zh"> 
<Is> 
<s id="0001"> 
:<TITLE> Journal of Primary Education 1996, 
Vol., No. l&2, Page 19-27 </TITLE> 
</HEAD> 
</s> 
<s id="0002"> 
<BODY BACKGROUND=-". Jgiffpejbg.jpg" 
TEXT="#O00000" BGCOLOR="#fffffff> <A 
HREF="/ergpej/b2g_pej.phtml?URL=%2fen%2fp 
ej %2f0601%2 f0601019c.htm"> 
<IMG SRC="/erdgif/kan.gif" ALT="~k" 
BORDER={) ALIGN=R IGHT> </A> <CEHTEIL~ 
</s> 
<s id="0003"> 
<H2>~k ~ ~ ~\[1.</H2> 
</s> 
<s id="0004"> 
<HR> (~t~-~?-#cJL.~) ,-~?~. 
</s> 
<s id="0005"> 
~ $ ~  19-27 \]~ <HR> 
<\]s> 
<s id="0005"> <s id="0006"> 
<H3>Principles for Redesigning Teacher <H3>.~ k~4Vt ~'~ ~ ~J </H3> Alan TOM 
Education </H3> Alan TOM </CENTER> </CENTER> 
<Is> <Is> 
<s id="0006"> <s id="0007"> 
<P> <B> <I> Abstract </I> </B> <P> <I> <B> ~4\[- </B> </I> <P> 
</s> </s> 
Figure 3: An alignment example considering cognates. 
divided into sentences. The sentences are marked by 
<s id="xxxx"> and </s>.  Note that we determine 
sentences not only by periods, but also by means of 
HTML markup. 
We further notice that it is difficult to align sen- 
tences 0002. The sentence in the Chinese page is 
much longer than its counterpart in the English page 
because some additional information (font) is added. 
The length-based method thus tends to take sen- 
tence 0002, 0003, and 0004 in the English page as 
the translation of sentence 0002 in the Chinese page 
(Fig. 2), which is wrong. This in turn provocated 
the three following incorrect alignments. As we can 
see in Fig. 3, the cognate method did not make the 
same mistake because of the noise in sentence 0002. 
Despite their large length difference, the two 0002 
sentences are still aligned as a 1-1 pair, because the 
sentences in the following 4 alignments (0003 - 0003; 
0004 - 0004, 0005; 0005 - 0006; 0006 - 0007) have 
rather similar HTML markups and are taken by the 
program to be the most likely alignments. 
Beside HTML markups, other criteria may also 
be incorporated. For example, it would be helpful 
to consider strong correspondence b tween certain 
English and Chinese words, as in (Wu, 1994). We 
hope to implement such correspondences in our fu- 
ture research. 
3.4 Lex icon  Eva luat ion  
To evaluate the precision of the English-Chinese 
translation model trained on the Web corpus, we 
examined two sample lexicons of 200 words, one in 
each direction. The 200 words for each lexicon were 
randomly selected from the training source. We ex- 
amined the most probable translation for each word. 
The Chinese-English lexicon was found to have a 
precision of 77%. The English-Chinese l xicon has 
a higher precision of 81.5%. Part of the lexicons 
are shown in Fig. 4, where t / f  indicates whether a 
translation is true or false. 
These precisions seem to be reasonably high. 
They are quite comparable to that obtained by Wu 
(1994) using a manual Chinese-English parallel cor- 
pus. 
3.5 Effect  o f  S topwords  
We also found that stop-lists have significant effect 
on the translation model. Stop-list is a set of the 
most frequent words that we remove from the train- 
2fi 
English word 
a .n l .  
access 
adaptation 
add 
adopt 
agent 
agree 
airline 
amendment 
, appliance 
apply 
attendance 
auditor 
- ,average 
base_on 
t/f 
t 
f 
t 
t 
t 
t 
t 
t 
t 
t 
t 
t 
f 
t 
f 
Translmion Probability Chinese word 
~'~- 0.201472 ~t l :  
~"  0.071705 "~"  
~f~.,~ 0.179633 JllL~ 
0.317435 
~ 0.231637 ~.~ 
1~tA~ 0.224902 4J~'~ 
0.36569 
0.344001 
0.367518 
J~ 4~ 0.136319 
i~.~I 0.19448 J~  
~',1~ 0.171769 ,~- JJ~ 
*~ 0.15011 -~-~ 
~- ~ 0.467646 * *~ 
0.107304 
Figure 4: Part of the evaluation lexicons. 
t/f 
t 
t 
t 
t 
t 
f 
t 
f 
t 
t 
t 
t 
t 
t 
t 
Translation Probability 
office 0.375868 
protection 0.343071 
report 0.358592 
prepare 0.189513 
loca l  0.421837 
follow 0.023685 
standard 0.445453 
adu l t  0.044959 
inadequate 0.093012 
part 0.313676 
financial 0.16608 
visit 0.309642 
bill 0.401997 
vehicle 0.467034 
saving 0.176695 
Figure 5: Effect of stop lists in C-E translation. 
ing source. Because these words exist in most align- 
ments, the statistical model cannot derive correct 
translations for them. More importantly, their ex- 
istence greatly affects the accuracy of other transla- 
tions. They can be taken as translations for many 
words. 
A priori, it would seem that both the English and 
Chinese stop-lists hould be applied to eliminate the 
noise caused by them. Interestingly, from our ob- 
servation and analysis we concluded that for better 
precision, only the stop-list of the target language 
should be applied in the model training. 
We first explain why the stop-list of the target lan- 
guage has to be applied. On the left side of Fig. 5, 
if the Chinese word C exists in the same alignments 
with the English word E more than any other Chi- 
nese words, C will be the most probable translation 
for E. Because of their frequent appearance, some 
Chinese stopwords may have more chances to be in 
the same alignments with E. The probability of the 
translation E --+ C is then reduced (maybe ven less 
than those of the incorrect ones). This is the reason 
why many English words are translated to "~ '  (of) 
by the translation model trained without using the 
Chinese stop-list. 
We also found that it is not necessary to remove 
the stopwords of the source language. In fact, as il- 
lustrated on the right side of Fig. 5, the existence of 
the English stopwords has two effects on the proba- 
bility of the translation E -~ C: 
1 They may often be found together with the Chi- 
nese word C. Owing to the Expectation Maxi- 
mization algorithm, the probability of E -~ C 
may therefore be reduced. 
2 On the other hand, there is a greater likelihood 
that English stopwords will be found together 
with the most frequent Chinese words. Here, 
we use the term "Chinese frequent words" in- 
stead of "Chinese stopwords" because ven if a 
stop-list is applied, there may still remain some 
common words that have the same effect as the 
stopwords. The coexistence ofEnglish and Chi- 
nese frequent words reduces the probability that 
the Chinese frequent words are the translations 
of E, and thus raise the probability of E -+ C. 
The second effect was found to be more signifi- 
cant than the first, since the model trained without 
the English stopwords has better precision than the 
model trained with the English stopwords. For the 
correct ranslations given by both models, the model 
26
Mono-Lingual IR 
Translation Model 
Dictionary 
C-E CLIR 
0.3861 
0.1504 (39.0%mono) 
0.1530 (39.6%mono) 
0.2583 (66.9%mono) 
E-C CLIR 
0.3976 
0.1841 (46.3%mono) 
0.1427 (35.9%mono) 
0.2232 (56.1%mono) 
Table 1: CLIR results. 
trained without considering the English stopwords 
gives higher probabilities. 
4 Eng l i sh -Ch inese  CL IR  Resu l ts  
Our final goal was to test the performance of the 
translation models trained on the Web parallel cor- 
pora in CLIR. We conducted CLIR experiments u - 
ing the Smart IR system. 
4.1 Results  
The English test corpus (for C-E CLIR) was the 
AP corpus used in TREC6 and TREC7. The short 
English queries were translated manually into Chi- 
nese and then translated back to English by the 
translation model. The Chinese test corpus was the 
one used in the TREC5 and TREC6 Chinese track. 
It contains both Chinese queries and their English 
translations. 
Our experiments on these two corpora produced 
the results hown in Tab. 1. The precision of mono- 
lingual IR is given as benchmark. In both E-C and 
C-E CLIR, the translation model achieved around 
40% of monolingual precision. To compare with the 
dictionary-based approach, we employed a Chinese- 
English dictionary, CEDICT (Denisowski, 1999), 
and an English-Chinese online dictionary (Anony- 
mous, 1999a) to translate queries. For each word 
of the source query, all the possible translations 
given by the dictionary are included in the translated 
query. The Chinese-English dictionary has about 
the same performace as the translation model, while 
the English-Chinese dictionary has lower precision 
than that of the translation model. 
We also tried to combine the translations given by 
the translation model and the dictionary. In both 
C-E and E-C CLIR, significant improvements were 
achieved (as shown in Tab. 1). The improvements 
show that the translations given by the translation 
model and the dictionary complement each other 
well for IR purposes. The translation model may 
give either exact ranslations orincorrect but related 
words. Even though these words are not correct in 
the sense of translation, they are very possibly re- 
lated to the subject of the query and thus helpful 
for IR purposes. The dictionary-based approach ex- 
pands a query along another dimension. It gives 
all the possible translations for each word including 
those that are missed by the translation model. 
4.2 Comparison Wi th  MT Systems 
One advantage of a parallel text-based translation 
model is that it is easier to build than an MT system. 
Now that we have examined the CLIR performance 
of the translation model, we will compare it with 
two existing MT systems. Both systems were tested 
in E-C CLIR. 
4.2.1 Sunshine WebTran Server 
Using the Sunshine WebTran server (Anonymous, 
1999b), an online Engiish-Chinese MT system, to 
translate the 54 English queries, we obtained an 
average precision of 0.2001, which is 50.3% of the 
mono-lingual precision. The precision is higher than 
that obtained using the translation model (0.1804) 
or the dictionary (0.1427) alone, but lower than the 
precison obtained using them together (0.2232). 
4.2.2 Transperfect 
Kwok (1999) investigated the CLIR performance of
an English-Chinese MT software called Transper- 
fect, using the same TREC Chinese collection as we 
used in this study. Using the MT software alone, 
Kwok achieved 56% of monolingual precision. The 
precision is improved to 62% by refining the trans- 
lation with a dictionary. Kwok also adopted pre- 
translation query expansion, which further improved 
the precison to 70% of the monolingual results. 
In our case, the best E-C CLIR precison using the 
translation model (and dictionary) is 56.1%. It is 
lower than what Kwok achieved using Transperfect, 
however, the difference is not large. 
4.3 Further  Problems 
The Chinese-English translation model has a fax 
lower CLIR performance than that of the English- 
French model established using the same method 
(Nie et al, 1999). The principal reason for this is the 
fact that English and Chinese are much more differ- 
ent than English and French. This problem surfaced 
in many phases of this work, from text alignment to 
query translation. Below, we list some further fac- 
tors affecting CLIR precision. 
? The Web-collected corpus is noisy and it is dif- 
ficult to align English-Chinese t xts. The align- 
ment method we employed has performed more 
poorly than on English-French alignment. This 
in turn leads to poorer performance of the trans- 
lation model. In general, we observe a higher 
27 
variability in Chinese-English translations than 
in English-French translations. 
? For E-C CLIR, although queries in both lan- 
guages were provided, the English queries were 
not strictly translated from the original Chi- 
nese ones. For example, A Jg ,~ (human right 
situation) was translated into human right is- 
sue. We cannot expect he translation model 
to translate issue back to ~ (situation). 
? The training source and the CLIR collections 
were from different domains. The Web cor- 
pus are retrieved from the parallel sites in Hong 
Kong while the Chinese collection is from Peo- 
ple's Daily and Xinhua News Agency, which are 
published in mainland China. As the result, 
some important erms such as ~$ $ (most- 
favored-nation) and --- I!! ~ ~ (one-nation-two- 
systems) in the collection are not known by the 
model. 
5 Summary  
The goal of this work was to investigate he feasibil- 
ity of using a statistical translation model trained on 
a Web-collected corpus to do English-Chinese CLIR. 
In this paper, we have described the algorithm and 
implementation we used for parallel text mining, 
translation model training, and some results we ob- 
tained in CLIR experiments. Although further work 
remains to be done, we can conclude that it is pos- 
sible to automatically construct a Chinese-English 
parallel corpus from the Web. The current system 
can be easily adapted to other language pairs. De- 
spite the noisy nature of the corpus and the great 
difference in the languages, the evaluation lexicons 
generated by the translation model produced accept- 
able precision. While the current CLIR results are 
not as encouraging asthose of English-French CLIR, 
they could be improved in various ways, such as im- 
proving the alignment method by adapting cognate 
definitions to HTML markup, incorporating a lexi- 
con and/or removing some common function words 
in translated queries. 
We hope to be able to demonstrate in the near 
future that a fine-tuned English-Chinese translation 
model can provide query translations for CLIR with 
the same quality produced by MT systems. 
Re ferences  
Anonymous. 1999a. Sunrain.net - English-Chinese 
dictionary, http://sunrain.net/r_ecdict _e.htm. 
Anonymous. 1999b. Sunshine WebTran server. 
http://www.readworld.com/translate.htm. 
P. F. Brown, J. C. Lai, and R. L. Mercer. 1991. 
Aligning sentences in parallel corpora. In 29th 
Annual Meeting of the Association for Computa- 
tional Linguistics, pages 89-94, Berkeley, Calif. 
P. F. Brown, S. A. Della Pietra, V. J. Della Pietra, 
and R. L. Mercer. 1993. The mathematics of ma- 
chine translation: Parameter estimation. Compu- 
tational Linguistics, 19:263-311. 
S. F. Chen. 1993. Aligning sentences in bilingual 
corpora using lexical information. In Proceedings 
of the 31th Annual Meeting of the Association for 
Computational Linguistics, pages 9-16, Colum- 
bus, Ohio. 
Paul Denisowski. 1999. Cedict (chinese-english dic- 
tionary) project, http://www.mindspring.com/ 
paul_denisowski/cedict.html. 
William A. Gale and Kenneth W. Church. 1991. A 
program for aligning sentences in bilingual cor- 
pora. In Proceedings of the 29th Annual Meeting 
of the Association for Computational Linguistics, 
pages 177-184, Berkeley, Calif. 
P. Isabelle, G. Foster, and P. Plamondon. 
1997. SILC: un syst~me d'identification 
de la langue et du codage, http://www- 
rali.iro.umontreal.ca/ProjetSILC.en.html. 
M. Kay and M. RSscheisen. 1993. Text-translation 
alignment. Computational Linguistics, 19:121- 
142. 
K. L. Kwok. 1999. English-chinese cross-language 
retrieval based on a translation package. In Work- 
shop of Machine Translation for Cross Language 
Information Retrieval, Machine Translation Sum- 
mit VII, Singapore. 
P. Langlais, G. Foster, and G. Lapalme. 2000. Unit 
completion for a computer-aided translation typ- 
ing system. In Applied Natural Language Pro- 
cessing Conference (ANLP), Seattle, Washington, 
May. 
Jianyun Nie, Michel Simard, Pierre Isabelle, and 
Richard Durand. 1999. Cross-language informa- 
tion retrieval based on parallel texts and auto- 
matic mining parallel texts from the Web. In 
ACM SIGIR '99, pages 74-81, August. 
Philip Resnik. 1998. Parallel stands: A preliminary 
investigation i to mining the Web for bilingual 
text. In AMTA '98, October. 
Michel Simard, George F. Foster, and Pierre Is- 
abelle. 1992. Using cognates to align sentences 
in bilingual corpora. In Proceedings of TMI-92, 
Montreal, Quebec. 
Dekai Wu. 1994. Aligning a parallel English- 
Chinese corpus statistically with lexical criteria. 
In ACL-9$: 32nd Annual Meeting of the Assoc. 
for Computational Linguistics, pages 80-87, Las 
Cruces, NM, June. 
Dekai Wu. 1995. Large-scale automatic extraction 
of an English-Chinese l xicon. Machine Transla- 
tion, 9(3-4):285-313. 
28 
