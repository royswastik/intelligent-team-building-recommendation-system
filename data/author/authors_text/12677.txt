CoNLL 2008: Proceedings of the 12th Conference on Computational Natural Language Learning, pages 243?247
Manchester, August 2008
The Integration of Dependency Relation Classification and Semantic Role
Labeling Using Bilayer Maximum Entropy Markov Models
Weiwei Sun and Hongzhan Li and Zhifang Sui
Institute of Computational Linguistics
Peking University
{weiwsun, lihongzhan.pku}@gmail.com, szf@pku.edu.cn
Abstract
This paper describes a system to solve
the joint learning of syntactic and seman-
tic dependencies. An directed graphical
model is put forward to integrate depen-
dency relation classification and semantic
role labeling. We present a bilayer di-
rected graph to express probabilistic re-
lationships between syntactic and seman-
tic relations. Maximum Entropy Markov
Models are implemented to estimate con-
ditional probability distribution and to do
inference. The submitted model yields
76.28% macro-average F1 performance,
for the joint task, 85.75% syntactic depen-
dencies LAS and 66.61% semantic depen-
dencies F1.
1 Introduction
Dependency parsing and semantic role labeling are
becoming important components in many kinds of
NLP applications. Given a sentence, the task of de-
pendency parsing is to identify the syntactic head
of each word in the sentence and classify the rela-
tion between the dependent and its head; the task
of semantic role labeling consists of analyzing the
propositions expressed by some target predicates.
The integration of syntactic and semantic parsing
interests many researchers and some approaches
has been proposed (Yi and Palmer, 2005; Ge and
Mooney, 2005). CoNLL 2008 shared task pro-
poses the merging of both syntactic dependencies
and semantic dependencies under a unique unified
representation (Surdeanu et al, 2008). We explore
c
? 2008. Licensed under the Creative Commons
Attribution-Noncommercial-Share Alike 3.0 Unported li-
cense (http://creativecommons.org/licenses/by-nc-sa/3.0/).
Some rights reserved.
the integration problem and evaluate our approach
using data provided on CoNLL 2008.
This paper explores the integration of depen-
dency relation classification and semantic role la-
beling, using a directed graphical model that is also
known as Bayesian Networks. The directed graph
of our system can be seen as one chain of obser-
vations with two label layers: the observations are
argument candidates; one layer?s label set is syn-
tactic dependency relations; the other?s is semantic
dependency relations. To estimate the probability
distribution of each arc and do inference, we im-
plement a Maximum Entropy Markov Model (Mc-
Callum et al, 2000). Specially, a logistic regres-
sion model is used to get the conditional probabil-
ity of each arc; dynamic programming algorithm
is applied to solve the ?argmax? problem.
2 System Description
Our DP-SRL system consists of 5 stages:
1. dependency parsing;
2. predicate prediction;
3. syntactic dependency relation classification
and semantic dependency relation identifica-
tion;
4. semantic dependency relation classification;
5. semantic dependency relation inference.
2.1 Dependency Parsing
In dependency parsing stage, MSTParser
1
(Mc-
Donald et al, 2005), a dependency parser that
searches for maximum spanning trees over di-
rected graphs, is used. we use MSTParser?s default
1
http://www.seas.upenn.edu/ strctlrn/MSTParser/MSTParser.html
243
Lemma and its POS tag
Number of children
Sequential POS tags of children
Lemma and POS of Neighboring words
Lemma and POS of parent
Is the word in word list of NomBank
Is the word in word list of PropBank
Is POS of the word is VB* or NN*
Table 1: Features used to predict target predicates
parameters to train a parsing model. In the third
stage of our system, dependency relations between
argument candidates and target predicates are up-
dated, if there are dependency between the candi-
dates and the predicates.
2.2 Predicate Prediction
Different from CoNLL-2005 shared task, the tar-
get predicates are not given as input. Our system
formulates the predicate predication problem as a
two-class classification problem using maximum
entropy classifier MaxEnt
2
(Berger et al, 1996).
Table 1 lists features used. We use a empirical
threshold to filter words: if the ?being target? prob-
ability of a word is greater than 0.075, it is seen as
a target predicate. This strategy achieves a 79.96%
precision and a 98.62% recall.
2.3 Syntactic Dependency Relation
Classification and Semantic Dependency
Relation Identification
We integrate dependency parsing and semantic
role labeling to some extent in this stage. Some de-
pendency parsing systems prefer two-stage archi-
tecture: unlabeled parsing and dependency clas-
sification (Nivre et al, 2007). Previous semantic
role labeling approaches also prefer two-stage ar-
chitecture: argument identification and argument
classification. Our system does syntactic relations
classification and semantic relations identification
at the same time. Specially, using a pruning al-
gorithm, we collect a set of argument candidates;
then we classify dependency relations between ar-
gument candidates and the predicates and predict
whether a candidate is an argument. A directed
graphical model is used to represent the relations
between syntactic and semantic relations.
2
http://homepages.inf.ed.ac.uk/s0450736/maxent toolkit.h
tml
Lemma, POS tag voice of predicates
POS pattern of predicate?s children
Is the predicate from NomBank or PropBank
Predicate class. This information is extracted
form frame file of each predicate.
Position: whether the candidate is before or
after the predicate
Lemma and POS tag of the candidate
Lemma and POS of Neighboring words of the
candidate
Lemma and POS of sibling words of the
candidate
Length of the constituent headed by the
candidate
Lemma and POS of the left and right most
words of the constituent of the candidate
Punctuation before and after the candidate
POS path: the chain of POS from candidate to
predicate
Single Character POS path: each POS in a path
is clustered to a category defined by its
first character
POS Pattern (string of POS tags) of all
candidates
Single Character POS Pattern of all candidates
Table 2: Features used for semantic role labeling
2.4 Semantic Dependency Relation
Classification
This stage assigns the final argument labels to the
argument candidates supplied from the previous
stage. A multi-class classifier is trained to classify
the types of the arguments supplied by the previous
stage. Table 2 lists the features used. It is clear that
the general type of features used here is strongly
based on previous work on the SRL task (Gildea
and Jurafsky, 2002; Pradhan et al, 2005; Xue and
Palmer, 2004). Different from CoNLL-2005, the
sense of predicates should be labeled as a part of
the task. Our system assigns 01 to all predicates.
This is a harsh tactic since it do not take the lin-
guistic meaning of the argument-structure into ac-
count.
2.5 Semantic Dependency Relation Inference
The purpose of inference stage is to incorporate
some prior linguistic and structural knowledge,
such as ?each predicate takes at most one argument
of each type.? We use the inference process intro-
244
duced by (Punyakanok et al, 2004; Koomen et al,
2005). The process is modeled as an integer Lin-
ear Programming Problem (ILP). It takes the pre-
dicted probability over each type of the arguments
as inputs, and takes the optimal solution that max-
imizes the linear sum of the probability subject to
linguistic constraints as outputs. The constraints
are a subset of constraints raised by Koomen et al
(2005) and encoded as following: 1) No overlap-
ping or embedding arguments; 2) No duplicate ar-
gument classes for A0-A5; 3) If there is an R-arg
argument, then there has to be an arg argument;
4) If there is a C-arg argument, there must be an
arg argument; moreover, the C-arg argument must
occur after arg; 5) Given the predicate, some argu-
ment types are illegal. The list of illegal argument
types is extracted from framefile.
The ILP process can improve SRL performance
on constituent-based parsing (Punyakanok et al,
2004). In our experiment, it also works on
dependency-based parsing.
3 Bilayer Maximum Entropy Markov
Models
3.1 Sequentialization
The sequentialization of a argument-structure is si-
miliar to the pruning algorithm raised by (Xue and
Palmer, 2004). Given a constituent-based parsing
tree, the recursive pruning process starts from a tar-
get predicate. It first collects the siblings of the
predicate; then it moves to the parent of the pred-
icate, and collects the siblings of the parent. In
addition, if a constituent is a prepositional phrase,
its children are also collected.
Our system uses a similar pruning algorithm to
filter out very unlikely argument candidates in a
dependency-based parsing tree. Given a depen-
dency parsing tree, the pruning process also starts
from a target predicate. It first collects the depen-
dents of the predicate; then it moves to the parent
of the predicate, and collects all the dependents
again. Note that, the predicate is also taken into
account. If the target predicate is a verb, the pro-
cess goes on recursively until it reaches the root.
The process of a noun target ends when it sees a
PMOD, NMOD, SBJ or OBJ dependency relation.
If a preposition is returned as a candidate, its child
is also collected. When the predicate is a verb, the
set of constituents headed by survivors of our prun-
ing algorithm is a superset of the set of survivors of
the previous pruning algorithm on the correspond-
Figure 1: Directed graphical Model of The system
ing constituent-based parsing tree. This pruning
algorithm will recall 99.08% arguments of verbs,
and the candidates are 3.75 times of the real argu-
ments. If the stop relation such as PMOD of a noun
is not taken into account, the recall is 97.67% and
the candidates is 6.28 times of arguments. If the
harsh stop condition is implemented, the recall is
just 80.29%. Since the SRL performance of nouns
is very low, the harsh pruning algorithm works bet-
ter than the original one.
After pruning, our system sequentializes all ar-
gument candidates of the target predicate accord-
ing to their linear order in the given sentence.
3.2 Graphical Model
Figure 1 is the directed graph of our system.
There is a chain of candidates x = (x
0
=
BOS, x
1
, ..., x
n
) in the graph which are observa-
tions. There are two tag layers in the graph: the up
layer is information of semantic dependency rela-
tions; the down layer is information of syntactic
dependency relations.
Given x, denote the corresponding syntactic de-
pendency relations d = (d
0
= BOS, d
1
, ..., d
n
)
and the corresponding semantic dependency rela-
tions s = (s
0
= BOS, s
1
, ..., s
n
). Our system
labels the syntactic and semantic relations accord-
ing to the conditional probability in argmax fla-
vor. Formally, labels the system assigned make
the score p(d, s|x) reaches its maximum. We de-
compose the probability p(d, s|x) according to the
directed graph modeled as following:
p(d, s|x) = p(s
1
|s
0
, d
1
;x)p(d
1
|s
0
, d
0
;x) ? ? ?
p(s
i+1
|s
i
, d
i+1
;x)p(d
i+1
|s
i
, d
i
;x) ? ? ?
p(s
n
|s
n?1
, d
n
;x)p(d
n
|s
n?1
, d
n?1
;x)
=
n
?
i=1
p(s
i
|s
i?1
, d
i
;x)p(d
i
|s
i?1
, d
i?1
;x)
245
Lemma, POS tag voice of predicates
POS pattern of predicate?s children
Lemma and POS tag of the candidate
Lemma and POS of Neighboring words of the
candidate
Lemma and POS of sibling words of the
candidate
Length of the constituent headed by the
candidate
Lemma and POS of the left and right most
words of the constituent of the candidate
Conjunction of lemma of candidates and
predicates; Conjunction of POS of candidates
and predicates
POS Pattern of all candidates
Table 3: Features used to predict syntactic depen-
dency parsing
3.3 Probability Estimation
The system defines the conditional probability
p(s
i
|s
i?1
, d
i
;x) and p(d
i
|s
i?1
, d
i?1
;x) by using
the maximum entropy (Berger et al, 1996) frame-
work Denote the tag set of syntactic dependency
relations D and the tag set of semantic dependency
relations S. Formally, given a feature map ?
s
and
a weight vector w
s
,
p
w
s
(s
i
|s
i?1
, d
i
;x) =
exp{w
s
? ?
s
(x, s
i
, s
i?1
, d
i
)}
Z
x,s
i?1
,d
i
;w
s
where,
Z
x,s
i?1
,d
i
;w
s
=
?
s?S
exp{w
s
? ?
s
(x, s, s
i?1
, d
i
)}
Similarly, given a feature map ?
d
and
a weight vector w
d
, (p
w
d
(d
i
) is short for
p
w
d
(d
i
|s
i?1
, d
i?1
;x)
p
w
d
(d
i
) =
exp{w
d
? ?
d
(x, d
i
, s
i?1
, d
i?1
)}
Z
x,s
i?1
,d
i?1
;w
d
where,
Z
x,s
i?1
,d
i?1
;w
d
=
?
d?D
exp{w
d
? ?
d
(x, d, s
i?1
, d
i?1
)}
For different characteristic properties between
syntactic parsing and semantic parsing, different
feature maps are taken into account. Table 2
lists the features used to predict semantic depen-
dency relations, whereas table 3 lists the features
used to predict the syntactic dependency relations.
The features used for syntactic dependency rela-
tion classification are strongly based on previous
works (McDonald et al, 2006; Nakagawa, 2007).
We just integrate syntactic dependency Rela-
tion classification and semantic dependency rela-
tion here. If one combines identification and clas-
sification of semantic roles as one multi-class clas-
sification, the tag set of the second layer can be
substituted by the tag set of semantic roles plus a
NULL (?not an argument?) label.
3.4 Inference
The ?argmax problem? in structured prediction is
not tractable in the general case. However, the bi-
layer graphical model presented in form sections
admits efficient search using dynamic program-
ming solution. Searching for the highest probabil-
ity of a graph depends on the factorization chosen.
According to the form of the global score
p(d, s|x) =
n
?
i=1
p(s
i
|s
i?1
, d
i
;x)p(d
i
|s
i?1
, d
i?1
;x)
, we define forward probabilities ?
t
(s, d) to be the
probability of semantic relation being s and syn-
tactic relation being d at time t given observation
sequence up to time t. The recursive dynamic pro-
gramming step is
?
t+1
(d, s) = arg max
d?D,s?S
?
d
?
?D,s
?
?S
?
t
(d
?
, s
?
) ?
p(s
i
|s
i?1
, d
i
;x)p(d
i
|s
i?1
, d
i?1
;x)
Finally, to compute the globally most proba-
ble assignment (
?
d,
?
s) = argmax
d,s
p(d, s|x), a
Viterbi recursion works well.
4 Results
We trained our system using positive examples
extracted from all training data of CoNLL 2008
shared task. Table 4 shows the overall syntactic
parsing results obtained on the WSJ test set (Sec-
tion 23) and the Brown test set (Section ck/01-03).
Table 5 shows the overall semantic parsing results
obtained on the WSJ test set (Section 23) and the
Brown test set (Section ck/01-03).
246
Test Set UAS LAS Label Accuracy
WSJ 89.25% 86.37% 91.25%
Brown 86.12% 80.75% 87.14%
Table 4: Overall syntactic parsing results
Task Precision Recall F
?=1
WSJ ID 73.76% 85.24% 79.08
ID&CL 63.07% 72.88% 67.62
Brown ID 70.77% 80.50% 75.32
ID&CL 54.74% 62.26% 58.26
Table 5: Overall semantic parsing results
Test WSJ Precision(%) Recall(%) F
?=1
SRL of Verbs
All 73.53 73.28 73.41
Core-Arg 78.83 76.93 77.87
AM-* 62.51 64.83 63.65
SRL of Nouns
All 62.06 45.49 52.50
Core-Arg 61.47 46.56 52.98
AM-* 66.19 39.93 49.81
Table 6: Semantic role labeling results on verbs
and nouns. Core-Arg means numbered argument.
Table 6 shows the detailed semantic parsing re-
sults obtained on the WSJ test set (Section 23)
of verbs and nouns respectively. The comparison
suggests that SRL on NomBank is much harder
than PropBank.
Acknowlegements
The work is supported by the National Natural
Science Foundation of China under Grants No.
60503071, 863 the National High Technology Re-
search and Development Program of China un-
der Grants No.2006AA01Z144, and the Project of
Toshiba (China) Co., Ltd. R&D Center.
References
Berger, Adam, Stephen Della Pietra, and Vincent Della
Pietra. 1996. A Maximum Entropy Approach to
Natural Language Processing. Computional Lin-
guistics, 22(1):39?71.
Ge, Ruifang and Raymond J. Mooney. 2005. A Statis-
tical Semantic Parser that Integrates Syntax and Se-
mantics. In Proceedings of the Conference of Com-
putational Natural Language Learning.
Gildea, Daniel and Daniel Jurafsky. 2002. Automatic
Labeling of Semantic Roles. Computional Linguis-
tics, 28(3):245?288.
Koomen, Peter, Vasina Punyakanok, Dan Roth, and
Wen-tau Yih. 2005. Generalized Inference with
Multiple Semantic Role Labeling Systems. In Pro-
ceedings of Conference on Natural Language Learn-
ing.
McCallum, Andrew, Dayne Freitag, and Fernando
Pereira. 2000. Maximum Entropy Markov Mod-
els for Information Extraction and Segmentation.
In Proceedings of International Conference on Ma-
chine Learning.
McDonald, Ryan, Fernando Pereira, Kiril Ribarov, and
Jan Haji?c. 2005. Non-projective dependency pars-
ing using spanning tree algorithms. In Proceedings
of the conference on Human Language Technology
and Empirical Methods in Natural Language Pro-
cessing.
McDonald, Ryan, Kevin Lerman, and Fernando
Pereira. 2006. Multilingual Dependency Analysis
with a Two-Stage Discriminative Parser. In Proceed-
ings of Conference on Natural Language Learning.
Nakawa, Tetsuji. 2007. Multilingual Dependency
Parsing using Global Features. In Proceedings of
Conference on Natural Language Learning.
Nivre, Joakim, Johan Hall, Sandra K?ubler, Ryan Mc-
Donald, Jens Nilsson, Sebastian Riedel, and Deniz
Yuret. The CoNLL 2007 Shared Task on Depen-
dency Parsing. 2007. In Proceedings of the CoNLL
Shared Task Session of EMNLP-CoNLL 2007, 915?
932,
Pradhan, Sameer, Kadri Hacioglu, Valerie Krugler,
Wayne Ward, James Martin, and Daniel Jurafsky.
2005. Support Vector Learning for Semantic Argu-
ment Classification. In Proceedings of Conference
on Association for Computational Linguistics.
Punyakanok, Vasin , Dan Roth, Wen-tau Yih, and Dav
Zimak. 2004. Semantic Role Labeling via Integer
Linear Programming Inference. In Proceedings of
the 20th International Conference on Computational
Linguistics.
Surdeanu, Mihai, Richard Johansson, Adam Meyers,
Llu??s M`arquez, and Nivre, Joakim. 2008. The
CoNLL-2008 Shared Task on Joint Parsing of Syn-
tactic and Semantic Dependencies. In Proceedings
of the 12th Conference on Computational Natural
Language Learning (CoNLL-2008).
Xue, Nianwen and Martha Palmer. 2004. Calibrat-
ing Features for Semantic Role Labeling. In Pro-
ceedings of Empirical Methods in Natural Language
Processing.
Yi, Szu-ting and Martha Palmer. 2005. The Integra-
tion of Syntactic Parsing and Semantic Role Label-
ing. In Proceedings of the Conference of Computa-
tional Natural Language Learning.
247
