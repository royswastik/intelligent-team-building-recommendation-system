CoNLL 2008: Proceedings of the 12th Conference on Computational Natural Language Learning, pages 49?56
Manchester, August 2008
Picking them up and Figuring them out:
Verb-Particle Constructions, Noise and Idiomaticity
Carlos Ramisch
??
, Aline Villavicencio
??
, Leonardo Moura
?
and Marco Idiart
?
?
Institute of Informatics, Federal University of Rio Grande do Sul (Brazil)
?
GETALP Laboratory, Joseph Fourier University - Grenoble INP (France)
?
Department of Computer Sciences, Bath University (UK)
?
Institute of Physics, Federal University of Rio Grande do Sul (Brazil)
{ceramisch,avillavicencio,lfsmoura}@inf.ufrgs.br, idiart@if.ufrgs.br
Abstract
This paper investigates, in a first stage,
some methods for the automatic acquisi-
tion of verb-particle constructions (VPCs)
taking into account their statistical prop-
erties and some regular patterns found in
productive combinations of verbs and par-
ticles. Given the limited coverage pro-
vided by lexical resources, such as dictio-
naries, and the constantly growing number
of VPCs, possible ways of automatically
identifying them are crucial for any NLP
task that requires some degree of semantic
interpretation. In a second stage we also
study whether the combination of statis-
tical and linguistic properties can provide
some indication of the degree of idiomatic-
ity of a given VPC. The results obtained
show that such combination can success-
fully be used to detect VPCs and distin-
guish idiomatic from compositional cases.
1 Introduction
Considerable investigative effort has focused on
the automatic identification of Multiword Expres-
sions (MWEs), like compound nouns (science fic-
tion) and phrasal verbs (carry out) (e.g. Pearce
(2002), Evert and Krenn (2005) and Zhang et
al. (2006)). Some of them employ language
and/or type dependent linguistic knowledge for
the task, while others employ independent statis-
tical methods, such as Mutual Information and
Log-likelihood (e.g. Pearce (2002) and, Zhang et
al. (2006)), or even a combination of them (e.g.
c
? 2008. Licensed under the Creative Commons
Attribution-Noncommercial-Share Alike 3.0 Unported li-
cense (http://creativecommons.org/licenses/by-nc-sa/3.0/).
Some rights reserved.
Baldwin (2005) and Sharoff (2004)), as basis for
helping to determine whether a given sequence
of words is in fact an MWE. Although some re-
search aims at developing methods for dealing
with MWEs in general (e.g. Zhang et al (2006),
Ramisch et al (2008)), there is also some work that
deals with specific types of MWEs (e.g. Pearce
(2002) on collocations and Villavicencio (2005)
on verb-particle constructions (VPCs)) as each of
these MWE types has distinct distributional and
linguistic characteristics.
VPCs are combinations of verbs and particles,
such as take off in Our plane took off late, that due
to their complex characteristics and flexible na-
ture, provide a real challenge for NLP. In particu-
lar, there is a lack of adequate resources to identify
and treat them, and those that are available provide
only limited coverage, in face of the huge number
of combinations in use. For tasks like parsing and
generation, it is essential to know whether a given
VPC is possible or not, to avoid for example us-
ing combinations that sound unnatural or ungram-
matical to native speakers (e.g. give/lend/?grant
out for the conveying of something to someone or
some place - (Fraser, 1976)).
1
Thus, the knowl-
edge of which combinations are possible is cru-
cial for precision grammar engineering. In ad-
dition, as the semantics of VPCs varies from the
idiomatic to the more compositional cases, meth-
ods for the automatic detection and handling of id-
iomaticity are very important for any NLP task that
involves some degree of semantic interpretation
such as Machine Translation (in this case avoiding
the problem of producing an unrelated translation
for a source sentence). Automatic methods for the
identification of idiomaticity in MWEs have been
1
See Baldwin et al (2004) for a discussion of the effects of
multiword expressions like VPCs on a parser?s performance.
49
proposed using a variety of approaches such as
statistical, substitutional, distributional, etc. (e.g.
McCarthy et al (2003), Bannard (2005) and Fa-
zly and Stevenson (2006)). In particular, Fazly
and Stevenson (2006) look at the correlation be-
tween syntactic fixedness (in terms of e.g. pas-
sivisation, choice of determiner type and pluralisa-
tion) and non-compositionality of verb-noun com-
pounds such as shoot the breeze.
In this work we investigate the automatic extrac-
tion of VPCs, looking into a variety of methods,
combining linguistic with statistical information,
ranging from frequencies to association measures:
Mutual Information (MI), ?
2
and Entropy. We also
investigate the determination of compositionality
of VPCs verifying whether the degree of semantic
flexibility of a VPC combined with some statisti-
cal information can be used to determine if it is
idiomatic or compositional.
This paper starts with a brief description of
VPCs, research on their automatic identification
and determination of their semantics (? 2). We then
explain the research questions and the assumptions
that serve as the basis for the application of statis-
tical measures (? 3) on the dataset (? 4). Our meth-
ods and experiments are then detailed (? 5), and
the results obtained are analysed (? 6). We con-
clude with a discussion of the contributions that
this work brings to the research on verb-particle
constructions (? 7).
2 Verb-Particle Constructions in Theory
and Practice
Particles in VPCs are characterised by containing
features of motion-through-location and of com-
pletion or result in their core meaning (Bolinger,
1971). VPCs can range from idiosyncratic or semi-
idiosyncratic combinations, such as get on (in e.g.
Bill got on well with his new colleagues), to more
regular ones, such as tear up (e.g. in In a rage she
tore up the letter Jack gave her). A three way clas-
sification is adopted by (Deh?e, 2002) and (Jack-
endoff, 2002), where a VPC can be classified as
compositional, idiomatic or aspectual, depending
on its sense. In compositional VPCs the meaning
of the construction is determined by the literal in-
terpretations of the particle and the verb. These
VPCs usually involve particles with directional or
spatial meaning, and these can often be replaced
by the appropriate directional PPs (e.g. carry in
in Sheila carried the bags in/into the house Deh?e
(2002)). Idiomatic VPCs, on the other hand, can-
not have their meaning determined by interpreting
their components literally (e.g. get on, meaning to
be on friendly terms with someone). The third class
is that of aspectual VPCs, which have the parti-
cle providing the verb with an endpoint, suggesting
that the action described by the verb is performed
completely, thoroughly or continuously (e.g. tear
up meaning to tear something into a lot of small
pieces).
From a syntactic point of view, a given combi-
nation can occur in several different subcategorisa-
tion frames. For example, give up can occur as an
intransitive VPC (e.g. in I give up! Tell me the an-
swer), where no other complement is required, or
it may occur as a transitive VPC which requires a
further NP complement (e.g. in She gave up alco-
hol while she was pregnant ). Since in English par-
ticles tend to be homographs with prepositions (up,
out, in), a verb followed by a preposition/particle
and an NP can be ambiguous between a transitive
VPC and a prepositional verb (e.g. rely on, in He
relies on his wife for everything). Some criteria
that characterise VPCs are discussed by Bolinger
(1971):
2
C1 In a transitive VPC the particle may come ei-
ther before or after the NP (e.g. He backed
up the team vs. He backed the team up).
However, whether a particle can be separated
or not from the verb may depend on the de-
gree of bonding between them, the size of the
NP, and the kind of NP. This is considered by
many to be sufficient condition for diagnos-
ing a VPC, as prepositions can only appear in
a position contiguous to the verb (e.g. *He
got the bus off ).
C2 Unstressed personal pronouns must precede
the particle (e.g. They ate it up but not *They
ate up it).
C3 If the particle precedes a simple definite NP,
the particle does not take the NP as its object
(e.g. in He brought along his girlfriend) un-
like with PP complements or modifiers (e.g.
in He slept in the hotel). This means that in
the first example the NP is not a complement
of the particle along, while in the second it is.
2
The distinction between a VPC and a prepositional verb
may be quite subtle, and as pointed out by Bolinger, many
of the criteria proposed for diagnosing VPCs give different
results for the same combination, frequently including un-
wanted combinations and excluding genuine VPCs.
50
In this paper we use the first two criteria, therefore
the candidates may contain noise (in the form of
prepositional verbs and related constructions).
VPCs have been the subject of a considerable
amount of interest, and some analysis has been
done on the subject of productive VPCs. In many
cases the particle seems to be compositionally
adding a specific meaning to the construction and
following a productive pattern (e.g. in tear up,
cut up and split up, where the verbs are seman-
tically related and up adds a sense of completion
to the action of these verbs). Fraser (1976) points
out that semantic properties of verbs can affect
their ability to combine with particles: for exam-
ple, bolt/cement/clamp/glue/paste/nail are seman-
tically similar verbs where the objects represented
by the verbs are used to join material, and they can
all combine with down. There is clearly a com-
mon semantic thread running through this list, so
that a new verb that is semantically similar to them
can also be reasonably assumed to combine with
down. Indeed, frequently new VPCs are formed by
analogy with existing ones, where often the verb is
varied and the particle remains (e.g. hang on, hold
on and wait on). Similarly, particles from a given
semantic class can be replaced by other particles
from the same class in compositional combina-
tions: send up/in/back/away (Wurmbrand, 2000).
By identifying classes of verbs that follow patterns
such as these in VPCs, we can help in the identi-
fication of a new unknown candidate combination,
using the degree of productivity of a class to which
the verb belongs as a back-off strategy.
In terms of methods for automatic identifica-
tion of VPCs from corpora, Baldwin (2005) pro-
poses the extraction of VPCs with valence infor-
mation from raw text, exploring a range of tech-
niques (using (a) a POS tagger, (b) a chunker, (c) a
chunk grammar, (d) a dependency parser, and (e) a
combination of all methods). Villavicencio (2005)
uses the Web as a corpus and productive patterns
of combination to generate and validate candidate
VPCs. The identification of compositionality in
VPCs is addressed by McCarthy et al (2003) who
examine the overlap of similar words in an auto-
matically acquired distributional thesaurus for verb
and VPCs, and by Bannard (2005) who uses a
distributional approach to determine when and to
what extent the components of a VPC contribute
their simplex meanings to the interpretation of the
VPC. Both report a correlation between some of
the measures and compositionality judgements.
3 The Underlying Hypotheses
The problem of the automatic detection and classi-
fication of VPCs can be summarised as, for a given
VPC candidate, to answer to the questions:
Q1 Is it a real VPC or some free combination
of verb and preposition/adverb or a preposi-
tional verb?
Q2 If it is a true VPC, is it idiomatic or composi-
tional?
In order to answer the first question, we use two
assumptions. Firstly, we consider that the elements
of a true VPC co-occur above chance. The greater
the correlation between the verb and the particle
the greater the chance that the candidate is a true
VPC. Secondly, based on criterion C1 we also as-
sume that VPCs have more flexible syntax and are
more productive than non-VPCs. This second as-
sumption goes against what is usually adopted for
general MWEs, since it is the prepositional verbs
that allow less syntactic configurations than VPCs
and are therefore more rigid (? 2). To further dis-
tinguish VPCs from prepositional verbs and other
related constructions we also verify the possibil-
ity of the particle to be immediately followed by
an indirect prepositional complement (like in The
plane took off from London), which is a good in-
dicator/delimiter of a VPC since in non-VPC con-
structions like prepositional verbs the preposition
needs to have an NP complement. Therefore, we
will assume that a true VPC occurs in the following
configurations, according to Villavicencio (2005)
and Ramisch et al (2008):
S1 VERB + PARTICLE + DELIMITER, for intran-
sitive VPCs;
S2 VERB + NP + PARTICLE + DELIMITER, for
transitive split VPCs and;
S3 VERB + PARTICLE + NP + DELIMITER, for
transitive joint VPCs.
In order to answer Q2, we look at the link be-
tween productivity and compositionality and as-
sume that a compositional VPC accepts the sub-
stitution of one of its members by a semantically
related term. This is in accordance to Fraser
(1976), who shows that semantic properties of
51
verbs can affect their ability to combine with par-
ticles: for example verbs of hunting combining
with the resultative down (hunt/track/trail/follow
down) and verbs of cooking with the aspectual up
(bake/cook/fry/broil up), forming essentially pro-
ductive VPCs. Idiomatic VPCs, however, will
not accept the substitution of one of its members
by a related term (e.g. get and its synonyms in
get/*obtain/*receive over), even if at first glance
this could seem natural. In our experiments, we
will consider that a VPC is compositional if it ac-
cepts: the replacement of the verb by a synonym,
or of the preposition by another preposition. Sum-
marising our hypothesis, we get:
? For Q1: Is the candidate syntactically flexi-
ble, i.e. does it allow the configurations S1
through S3?
? NO: non-VPC
? YES: VPC
? For Q2: Is the candidate semantically flexi-
ble, allowing the substitution of a member by
a related word?
? NO: idiomatic VPC
? YES: compositional VPC
4 Data Sources
To generate a gold standard, we used the Bald-
win VPC candidates dataset (henceforth Baldwin
CD)
3
, which contains 3,078 English VPC candi-
dates annotated with information about idiomatic-
ity (14.5% are considered idiomatic). We fur-
ther annotated this dataset with information about
whether each candidate is a genuine VPC or not,
where a candidate is consider genuine if it be-
longs to at least one of a set of machine-readable
dictionaries: the Alvey Natural Language Tools
(ANLT) lexicon (Carroll and Grover, 1989), the
Comlex lexicon (Macleod and Grishman, 1998),
and the LinGO English Resource Grammar (ERG)
(Copestake and Flickinger, 2000)
4
. With this crite-
rion 81.8% of them are considered genuine VPCs.
To gather information about the candidates in
this work we employ both a fragment of 1.8M
sentences from the British National Corpus (BNC
Burnard (2000)) and the Web as corpora. The
BNC fragment is used to calculate the correlation
3
This dataset was provided by Timothy Baldwin for the
MWE2008 Workshop.
4
Version of November 2001.
measures since they require a corpus with known
size. The Web is used to generate frequencies
for the entropy measures, as discussed in ? 5.2.
Web frequencies are approximated by the number
of pages containing a candidate and indexed by
Yahoo Search API. In order to keep the searches
as simple and self-sufficient as possible, no addi-
tional sources of information are used (Villavicen-
cio, 2005). Therefore, the frequencies are quite
conservative in the sense that by employing in-
flected forms of verbs, potentially much more evi-
dence could be gathered.
For the generation of semantic variational pat-
terns, we use both Wordnet 3.0 (Fellbaum, 1998)
and Levin?s English Verb Classes and Alternations
(Levin, 1993). Wordnet is organised as a graph of
concepts, called synsets, linked by relations of syn-
onymy, hyponymy, etc. Each synset contains a list
of words that represent the concept. The verbs in
a synset and its synonym synsets are used to gen-
erate variations of a VPC candidate. Likewise we
use Levin?s classes, which define 190 fine-grained
classes for English verbs, based on their syntactic
and semantic features.
It is important to highlight that the generation
of the semantic variations strongly relies on these
resources. Therefore, cross-language extension
would depend on the availability of similar tools
for the target language.
5 Carrying out the experiments
Our experiments are composed of two stages, each
one consisting of three steps (corresponding to the
next three sections). The first stage filters out ev-
ery candidate that is evaluated as not being a VPC,
while the second one intends to identify the id-
iomatic VPCs among the remaining candidates of
the previous stage.
5.1 Generating candidates
For each of the 3,078 items in the Baldwin CD we
generated 2 sets of variations, syntactic and seman-
tic, and we will refer to these as alternative forms
or variations of a candidate.
The syntactic variations are generated using the
patterns S1 to S3 described in section 3. Following
the work of Villavicencio (2005) 3 frequently used
prepositions for, from and with are used as delim-
iters and we search for NPs in the form of pronouns
like this and definite NPs like the boy. The use of
alternative search patterns also helps to give an in-
52
dication about the syntactic distribution of a can-
didate VPC, and consequently if it has a preferred
syntactic realisation. For instance, for eat up and
the delimiter with, we propose a list of Web search
queries for its respective variations v
i
, shown with
their corresponding Web frequencies in table 1.
5
Variation (v
i
) Frequency (n
Y ahoo
(v
i
))
eat up with 49200
eat the * up with 2240
eat this up with 1120
eat up the * with 3110
Table 1: Distribution of syntactic variations for the
candidate eat up.
For the semantic variations, in order to capture
the idiomaticity of VPCs we generate the alterna-
tive forms by replacing the verb by its synonym
verbs as follows:
WNS Wordnet Strict variations. When using Word-
net, we consider any verb that belongs to the
same synset of the candidate as a synonym.
WNL Wordnet Loose variations. This is an indi-
rect synonymy relation capturing any verb
in Wordnet that belongs either to the same
synset or to a synset that is synonym of the
synset in which the candidate verb is con-
tained.
Levin These include all verbs in the same Levin
class as the candidate.
Multiword synonyms are ignored in this step to
avoid noisy search patterns, (e.g. *eat up up). The
examples for these variations are shown in table 2
for the candidate act in.
Wordnet and Levin are considered ambiguous
resources because one verb is potentially contained
in several synsets or classes. However, as Word
Sense Disambiguation is not within the scope of
this work we employ some heuristics to select a
given sense for the candidate verb. In order to test
the effect of frequency, the first heuristic adopts the
first synset in the list, as Wordnet organises synsets
in descending order of frequency (denoted as first).
To study the influence of the number of synonyms,
the second and third heuristics use respectively the
biggest (max) and smallest (min) synsets. The last
5
The Yahoo wildcard used in these searches matches any
word occurring in that particular position.
Variation (v
i
) Source n
Y ahoo
(v
i
)
act in ? 2690
playact in WNS 0
play in WNS 167000
behave in WNL 98
do in WNL 24600
pose in Levin 1610
qualify in Levin 358
rank in Levin 706
rate in Levin 16700
serve in Levin 2240
Table 2: Distribution of syntactic variations for the
candidate eat up.
heuristic is the union of all synonyms (all). These
heuristics are indicated using a subscript notation,
where e.g. WNS
all
symbolizes the WNS varia-
tions set using the union of all synsets as disam-
biguation heuristic. Finally, we generated two
additional sets of candidates by replacing the par-
ticle by one of the 48 prepositions listed in the
ANLT dictionary (prep) and also by one of 9 cho-
sen locative prepositions (loc-prep). It is impor-
tant to also verify possible variations of the prepo-
sition because compositional VPCs combine pro-
ductively with one or more groups of particles, e.g.
locatives, and present consequently a wider prob-
ability distribution among the variations, while an
idiomatic VPC presents a higher frequency for a
chosen preposition.
5.2 Working the statistical measures out
The classifications of the candidate VPCs are done
using a set of measures: the frequencies of the
VPC candidates and of their individual words,
their Mutual Information (MI), ?
2
and Entropies.
We calculate the MI and ?
2
indices of a candidate
formed by a verb and a particle based on their in-
dividual frequencies and on their co-occurrence in
the BNC fragment.
The Entropy measure is given by
H(V ) = ?
n
?
i=1
p(v
i
) ln [ p(v
i
) ]
where
p(v
i
) =
n(v
i
)
?
? v
j
?V
n(v
j
)
is the probability of the variation v
i
to occur
among the set of all possible variations V =
53
H(V ) ? 0.001081
n
BNC
(p) ? 51611
n
Y ahoo
(v
transitive
) ? 1
n
Y ahoo
(v) ? 2020000000 : yes
n
Y ahoo
(v) > 2020000000
?
2
? 25.99
? ? ?
Figure 1: Fragment of the decision tree that filters
out non-VPCs.
{v
1
, v
2
, . . . , v
n
}, and n(v
i
) is the Web frequency
for the variation v
i
.
The entropy of a probability distribution gives
us some clues about its shape. A very low en-
tropy is a sign of a heterogeneous distribution that
contains a peak. On the other hand, a distribution
that presents uniformity will lead to a high entropy
value.
The interest of H(V ) for the detection of VPCs
is in that true instances are more likely to not prefer
a canonical form, more widely distributing proba-
bilities over all alternative syntactic frames (S1 to
S3), while non-VPCs are more likely to choose one
frame and present low frequencies for the proposed
variations.
For the semantic variations, the entropy is cal-
culated from a set V of variations generated by the
Wordnet synset, Levin class and preposition sub-
stitutions described in ? 5.1. The interpretation of
the entropy at this point is that high entropy indi-
cates compositionality while low entropy indicates
idiomaticity, since compositional VPCs are more
productive and distribute well over a class of verbs
or a class of prepositions and idiomatic VPCs pre-
fer a specific verb or preposition.
5.3 Bringing estimations together
Once we got a set of measures to predict
VPCs and another to predict their idiomatic-
ity/compositionality, we would like to know which
measures are useful. Therefore, we combine our
measures automatically by building a decision tree
with the J48 algorithm, a version of the traditional
entropy-based C4.5 algorithm implemented in the
Weka package.
6
6 Weighting the results up
The first stage of our experiments applied to the
3,078 VPC candidates generated a decision tree us-
6
http://www.cs.waikato.ac.nz/ml/weka/
ing 10-fold cross validation that is partially repro-
duced in figure 1. From these, 2,848 candidates
were considered genuine VPCs, with 2,419 true
positives, 100 false negatives and 429 false posi-
tives. This leads to a recall of 96% of the VPCs
being kept in the list with a precision of 84.9%,
and an f-measure of 90.1%. We interpret this as a
very positive result since although some false neg-
atives have been filtered out, the remaining candi-
dates are now less noisy.
Figure 1 shows that the entropy of the variations
is the best predictor since it is at the root of the
tree. We can also see that there are several types
of raw frequencies being used before a correlation
measure appears (?
2
). We can conclude that the
frequency of each transitive, intransitive and split
configurations are also good predictors to detect
false from true VPCs. At this point, MI does not
seem to contribute to the classification task.
For our second stage, we generated Wordnet
synonym, Levin class and preposition variations
for a list of the 2,867 VPC candidates classified
as genuine cases. We also took into account the
proportion of synonyms that are MWEs (vpc-syn)
and the proportion of synonyms that contain the
candidate itself (self-syn).
In order to know what kind of contribution each
measure gives to the construction of the decision
tree, we used a simple iterative algorithm that con-
structs the set U of useful attributes. It first ini-
tialises U with all attributes, then calculates the
precision for each class (yes and no)
7
on a cross
validation using all attributes in U . For each at-
tribute a ? U , it ignores a and recalculates preci-
sions. If both precisions decrease, the contribution
of a is positive, if both increase then a is negative,
else its contribution remains unknown. All fea-
tures that contribute negatively are removed from
U , and the algorithm is repeated until there is no
negative attribute left.
The step-by-step execution of the algorithm
can be observed in table 3, where the inconclu-
sive steps are hidden. We found out that the
optimal features are U
?
= {self-syn, H(prep),
H(Levin
first
), H(WNS
first
), H(WNS
min
),
H(Levin
max
), H(Levin
min
).} The self-syn in-
formation seems to be very important, as without
it precisions of both classes decrease considerably
7
We use the precision as a quality estimator since it gives
a good idea of the amount of work that a grammar engineer
or lexicographer must perform in order to clear the list from
false positives.
54
Precision
# Ignored No Yes +/?
1
st
iteration
0 ? 86.6% 54.9%
1 vpc-syn 86.7% 56.6% ?
2 self-syn 85.2% 28.7% +
4 H(loc-prep) 86.7% 56.1% ?
6 H(WNS
max
) 87.5% 57.4% ?
9 H(WNLfirst) 86.7% 57.9% ?
10 H(WNL
max
) 86.7% 57.8% ?
11 H(WNL
min
) 86.9% 57.6% ?
16 H(Levin
all
) 86.7% 55.1% ?
2
nd
iteration
17 ? 87.7% 60.3%
18 H(prep) 87.6% 59.2% +
21 H(WNS
all
) 87.8% 61.6% ?
22 H(WNL
all
) 87.8% 61.0% ?
23 H(Levin
first
) 87.5% 60.2% +
3
rd
iteration
26 ? 87.8% 61.9%
27 H(WNS
first
) 87.8% 61.9% ?
28 H(WNS
min
) 87.7% 61.1% +
29 H(Levin
max
) 87.8% 61.6 ?
30 H(Levin
min
) 87.7% 61.5% +
Table 3: Iterative attributes selection process. Pre-
cision in each class is used as quality estimator.
(experiment #2).
All entropies of the WNL heuristics are of little
or no utility. This could probably be explained by
either the choice of simple WSD heuristics for se-
lecting synsets, or because the indirect synonymy
information is too far related to the original verb to
be used in variational patterns. Inspecting the gen-
erated variations, we notice that most of the syn-
onym synsets are related to secondary senses or
very specific uses of a verb and are thus not cor-
rectly disambiguated.
In what concerns the WNS sets, only the small-
est and first synset were kept, suggesting again that
it may not be a good idea to maximise the syn-
onyms set and for future work, we intent to es-
tablish a threshold for a synset to be taken into
account. In addition, we can also infer a posi-
tive contribution of the frequency of a sense with
the choice of the first synset returned by Word-
net resulting in a reasonable WSD heuristic (which
is compatible with the results by McCarthy et al
(2004)).
On the other hand, the algorithm selected the
first, the smallest and the biggest of the Levin?s
sets. This probably happens because the major-
ity of these verbs belongs only to one or two, but
never to a great number of classes. Since the gran-
ularity of the classes is coarser than for synsets,
the heuristics often offer four equal or very close
entropies and thus redundant information. As an
overall result, the last iteration shown in table 3
indicates a precision of 61.9% for the classifier in
detecting idiomatic VPCs, that is to say that we au-
tomatically retrieved 176 VPCs where 67 are false
positives and 109 are truly idiomatic. This value is
a quality estimator for the resulting VPCs that will
potentially be used in the construction of a lexi-
con. Recall of idiomatic VPCs goes from 16.7%
to 24.9%.
7 Conclusions
One of the important challenges for robust natu-
ral language processing systems is to be able to
successfully deal with Multiword Expressions and
related constructions. We investigated the identifi-
cation of VPCs using a combination of statistical
methods and linguistic information, and whether
there is a correlation between the productivity of
VPCs and their semantics that could help us detect
if a VPC is idiomatic or compositional.
The results confirm that the use of statistical
and linguistic information to automatically iden-
tify verb-particle constructions presents a reason-
able way of improving coverage of existing lexi-
cal resources in a very simple and straightforward
manner. In terms of grammar engineering, the in-
formation about compositional candidates belong-
ing to productive classes provides us with the ba-
sis for constructing a family of fine-grained redun-
dancy rules for these classes. These rules are ap-
plied in a constrained way to verbs already in the
lexicon, according to their semantic classes. The
VPCs identified as idiomatic, on the other hand,
need to be explicitly added to the lexicon, after
their semantic is determined. This study can also
be complemented with the results of investigations
into the semantics of VPCs, as discussed by both
Bannard (2005) and McCarthy et al (2003).
In addition, the use of clustering methods is an
interesting possibility for automatically identify-
ing clusters of productive classes of both verbs and
of particles that combine well together.
55
Acknowledgments
This research was partly supported by the CNPq
research project Recuperac??ao de Informac??oes
Multil??ng?ues (CNPq Universal 484585/2007-0).
References
Baldwin, Timothy, Emily M. Bender, Dan Flickinger, Ara
Kim, and Stephan Oepen. 2004. Road-testing the English
Resource Grammar over the British National Corpus. In
Fourth International Conference on Language Resources
and Evaluation (LREC 2004), Lisbon, Portugal.
Baldwin, Timothy. 2005. Deep lexical acquisition of verb-
particle constructions. Computer Speech and Language,
19(4):398?414.
Bannard, Colin J. 2005. Learning about the meaning of verb-
particle constructions from corpora. Computer Speech and
Language, 19(4):467?478.
Bolinger, Dwight. 1971. The phrasal verb in English. Har-
vard University Press, Harvard, USA.
Burnard, Lou. 2000. User reference guide for the British Na-
tional Corpus. Technical report, Oxford University Com-
puting Services.
Carroll, John and Claire Grover. 1989. The derivation of a
large computational lexicon of English from LDOCE. In
Boguraev, B. and E. Briscoe, editors, Computational Lexi-
cography for Natural Language Processing. Longman.
Copestake, Ann and Dan Flickinger. 2000. An open-source
grammar development environment and broad-coverage
English grammar using HPSG. In Proceedings of the
2nd International Conference on Language Resources and
Evaluation (LREC 2000).
Deh?e, Nicole. 2002. Particle verbs in English: syntax, in-
formation structure and intonation. John Benjamins, Am-
sterdam/Philadelphia.
Evert, Stefan and Brigitte Krenn. 2005. Using small random
samples for the manual evaluation of statistical association
measures. Computer Speech and Language, 19(4):450?
466.
Fazly, Afsaneh and Suzanne Stevenson. 2006. Automatically
constructing a lexicon of verb phrase idiomatic combina-
tions. In EACL. The Association for Computer Linguis-
tics.
Fellbaum, Christiane, editor. 1998. WordNet: An Electronic
Lexical Database (Language, Speech, and Communica-
tion). The MIT Press, May.
Fraser, Bruce. 1976. The Verb-Particle Combination in En-
glish. Academic Press, New York, USA.
Jackendoff, Ray. 2002. English particle constructions, the
lexicon, and the autonomy of syntax. In N. Deh?e, R. Jack-
endoff, A. McIntyre and S. Urban, editors, Verb-Particle
Explorations. Berlin: Mouton de Gruyter.
Levin, Beth. 1993. English Verb Classes and Alternations:
a preliminary investigation. University of Chicago Press,
Chicago and London.
Macleod, Catherine and Ralph Grishman. 1998. Comlex syn-
tax reference manual, Proteus Project.
McCarthy, Diana, Bill Keller, and John Carroll. 2003. De-
tecting a continuum of compositionality in phrasal verbs.
In Proceedings of the ACL 2003 workshop on Multiword
expressions, pages 73?80, Morristown, NJ, USA. Associ-
ation for Computational Linguistics.
McCarthy, Diana, Rob Koeling, Julie Weeds, and John Car-
roll. 2004. Finding predominant word senses in untagged
text. In Proceedings of the 42nd Annual Meeting on Asso-
ciation for Computational Linguistics, page 279. Associa-
tion for Computational Linguistics.
Pearce, Darren. 2002. A comparative evaluation of colloca-
tion extraction techniques. In Third International Confer-
ence on Language Resources and Evaluation, Las Palmas,
Canary Islands, Spain.
Ramisch, Carlos, Paulo Schreiner, Marco Idiart, and Aline
Villavicencio. 2008. An evaluation of methods for the ex-
traction of multiword expressions. In Proceedings of the
LREC Workshop - Towards a Shared Task for Multiword
Expressions (MWE 2008), pages 50?53, Marrakech, Mo-
rocco, June.
Sharoff, Serge. 2004. What is at stake: a case study of rus-
sian expressions starting with a preposition. pages 17?23,
Barcelona, Spain.
Villavicencio, Aline. 2005. The availability of verb-particle
constructions in lexical resources: How much is enough?
Journal of Computer Speech and Language Processing,
19(4):415?432.
Wurmbrand, S. 2000. The structure(s) of particle verbs. Ms.,
McGill University.
Zhang, Yi, Valia Kordoni, Aline Villavicencio, and Marco
Idiart. 2006. Automated multiword expression prediction
for grammar engineering. In Proceedings of the Workshop
on Multiword Expressions: Identifying and Exploiting Un-
derlying Properties, pages 36?44, Sydney, Australia. As-
sociation for Computational Linguistics.
56
