Proceedings of EACL 2009 Workshop on Semantic Representation of Spoken Language - SRSL 2009, pages 26?33,
Athens, Greece, 30 March 2009. c?2009 Association for Computational Linguistics
Semantic Representation of Non-Sentential Utterances in Dialog 
 
 
 Silvie Cinkov? 
Charles University in Prague 
Faculty of Mathematics and Physics 
Institute of Formal and Applied Linguistics 
Malostransk? n?m?st? 25 
CZ-118 00 Praha 1 
cinkova@ufal.mff.cuni.cz 
 
 
  
 
Abstract 
Being confronted with spontaneous 
speech, our current annotation scheme 
requires alterations that would reflect the 
abundant use of non-sentential fragments 
with clausal meaning tightly connected to 
their context, which do not systematically 
occur in written texts. The purpose of this 
paper is to list the common patterns of 
non-sentential fragments and their con-
texts and to find a smooth resolution of 
their semantic annotation.  
1 Introduction 
Spontaneous speech, even assuming a perfect 
ASR, is hard to parse because of the enormous 
occurrence of disfluencies and syntactic devia-
tions. Some disfluencies can be regarded as 
speaker?s errors, which are being corrected or 
remain uncorrected during the speaker?s turn. 
Such disfluencies are e.g.: 
? stammering (We w-went there 
to-together)    
? restart with or without an interregnum 
(John no sorry Jane was 
there, too) 
? repetitions (So you like you 
like drinking) 
? hesitation sounds, long silence, fillers, 
filler phrases, etc. (EH so ... you 
kinda like you know HMM 
drinking)  
In NLP, such disfluencies can be removed be-
fore any syntactic or semantic processing since 
they cause confusion without adding any seman-
tic information. In machine-learning tasks, dis-
fluency is sought to be automatically removed by 
learning from disfluency-marked corpora or cor-
pora of text edits (Haji? et al, 2008; Fitzgerald 
and Jelinek, 2008) to smooth the input text into 
written-language standard before parsing. 
On the other hand, there is another sort of dis-
fluencies, which do not disturb the course of the 
dialog, namely contextual ellipsis: even though 
most people remember being taught at school to 
answer questions with a complete sentence, not 
even educated speakers performing a sophisti-
cated dialog always do so, and yet they do not 
sound incorrect. Clearly, an extensive use of el-
lipsis is an inherent feature of verbal interaction 
between speakers, which is usually smoothly 
perceived by the listener and thus all right in its 
place.  
Such ?fragmentary utterances that do not have 
the form of a full sentence according to most tra-
ditional grammars, but that nevertheless convey 
a complete clausal meaning? are called non-
sentential utterances (NSUs)1. A consistent 
reconstruction of their clausal meaning is inevi-
table for any semantic representation of dialogs. 
The present paper describes a tentative semantic 
representation of NSUs in the Functional Gen-
erative Description (FGD) framework (Sgall et 
al., 1986). 
                                                 
1 The term NSU as well as its definition comes from 
Fern?ndez et al, 2007. 
 
26
2 NSUs in PhotoPal Dialogs 
2.1 NSU taxonomy 
Fern?ndez et al (2007) introduce a taxonomy of 
NSUs based on the dialog transcripts from BNC 
(Burnard, 2000). They stress that NSUs are not 
limited to question-answer pairs but can appear 
as responses to any preceding utterance. Our ob-
servations confirm this. NSUs are highly am-
biguous without context. Consider the following 
example:  
A: I left it on the table. 
B: On the table. 
 I confirm/I understand 
what you say: you left it on 
the table. 
A: Where did you leave it? 
B: On the table. 
 I answer your question: I 
left it on the table. 
A: I think I put it er... 
B: On the table. 
 I know in advance what 
you want to say or what you 
would want to say if you 
knew that. 
A: Should I put it back on 
the shelf? 
B: On the table. 
 No, don?t put it back on 
the shelf, but put it on the 
table instead.  
If reconstructed into a complete sentence, the  
NSU would get different shapes in the respective 
contexts (see the paraphrases in italics). 
The NSU taxonomy proposed by Fern?ndez et 
al. (2007) divides the NSUs into 15 classes: 
? Clarification Ellipsis (Two people 
[did you say were there]?) 
? Check Question ([...]Okay?) 
? Reprise Sluice (What[did you say 
]?) 
? Direct Sluice (What?/Who?/When?) 
? Short Answer [to wh-question] (My 
Aunty Peggy.) 
? Plain Affirmative Answer / Rejection 
(Yes. / No.) 
? Repeated Affirmative Answer (Very 
loud, yes.) 
? Helpful Rejection (No, Billy.) 
? Plain Acknowledgement (Mhm.) 
? Repeated Acknowledgement (part of the 
preceding segment repeated) 
? Propositional and Factual Modifiers 
(Probably not. / Oh, 
great!) 
? Bare Modifier Phrase (adjuncts modify-
ing a contextual utterance) 
? Conjunct (fragments introduced by con-
junctions) 
? Filler (fragments filling a gap left by a 
previous unfinished utterance) 
2.2 PhotoPal Dialog Corpora 
Our goal is semantically annotated spoken con-
versations between two speakers over a family 
album. One English corpus (NAP) and one 
Czech corpus have been built within the Com-
panions project (www.companions-project.org) 
as gold-standard data for a machine-learning 
based dialog system (?PhotoPal?) that should be 
able to handle a natural-like conversation with a 
human user, helping to sort the user?s photo-
graphs and encouraging the user to reminisce. 
The PhotoPal is supposed to keep track of the 
mentioned entities as well as to make some in-
ferences. 
The NAP corpus (Bradley et al, 2008) com-
prises about 200k tokens of literal manual tran-
scriptions of audio recordings, which are inter-
linked with a multiple disfluency annotation 
(Cinkov? et al, 2008). The Czech PhotoPal cor-
pus is still growing (Haji? et al, 2009), compris-
ing about 200k tokens at the moment (including 
double annotation).  
 To ease the understanding, all authentic cor-
pus examples will be taken from the English 
NAP corpus.  However, most examples in this 
paper are taken from Fern?ndez et al (2007) and 
modified when needed to illustrate a contrast. 
3 Semantic representation of NAP 
NSUs  
3.1 Functional Generative Description  
The Functional Generative Description (FGD) is 
a stratified formal language description based on 
the structuralist tradition, developed since the 
27
1960?s. The unique contribution of FGD is the 
so-called tectogrammatical representation (TR). 
It is being implemented in a family of semanti-
cally annotated treebanks. 
3.2 Tectogrammatical Representation 
Being conceived as an underlying syntactic rep-
resentation, the TR captures the linguistic mean-
ing of the sentence, which is its basic description 
unit. In the TR annotation, each sentence is rep-
resented as a projective dependency tree with 
nodes and edges. The attribute values include 
references to the analytical (surface-syntax) 
layer. Only content words are represented by 
nodes. Function words are represented as attrib-
ute values. Each node has a semantic label 
(?functor?), which renders the semantic relation 
of the given node to its parent node. The TR an-
notation captures the following aspects of text: 
? syntactic and semantic dependencies 
? argument structure (data interlinked with 
a lexicon) 
? information structure (topic-focus articu-
lation) 
? grammatical and contextual coreference 
? ellipsis restoration. 
Fig. 1 shows a sentence with restored ellipsis. 
The elided predicate in the second conjunct was 
copied from the first conjunct predicate (copied 
and generated nodes have square shape). 
 
  
Fig.1 Mary prepared the lunch, and John [prepared] the 
dinner.  
3.3 Ellipsis Restoration and Contextual 
Coreference 
Assumingly, any tectogrammatical representa-
tion of NSUs is about the most appropriate reso-
lution of contextual ellipsis and coreference. 
TR distinguishes two types of ellipsis: 
? contextual ellipsis, i.e. ellipsis occurring 
when the lexical content of the omitted 
element is clear from the context and 
easily recoverable. The speaker omitted 
this element, since he considered its 
repetition unnecessary. 
? grammatical ellipsis, i.e. such ellipsis 
that occurs when the elided element can-
not appear on the surface for grammati-
cal reasons but is cognitively present in 
the meaning of the utterance (e.g. the 
unexpressed subject of controlled infini-
tives). 
Every occurrence of a given verb must corre-
spond to the appropriate lexicon frame. Any 
obligatory arguments missing must be filled in as 
node substitutes even if the node could be copied 
from the context. The substitutes have special 
lemmas according to their function.  
Fig. 2 illustrates a contextual ellipsis of a de-
pendent node. The tree represents the answer: He 
has [wrapped the book] to the ques-
tion: Has the shop assistant 
wrapped the book? In fact, the tree ren-
ders the sentence He has. To complete the ar-
gument structure frame of the verb wrap, the 
node book with the Patient semantic label is 
inserted into the frame in form of a node with the 
t-lemma substitute for personal pronoun 
(#PersPron, square node) exactly in the 
same way as the expressed he. The node-
constituting lexical verb wrap is copied from the 
previous sentence as a square node while has 
becomes its attribute value, since it is an auxil-
iary verb. The subject He is only converted into 
the #PersPron substitute (with appropriate 
values inside).  
 
 
Fig. 2 He has [wrapped the book].  
 
In the complete TR annotation, a contextual-
coreference arrow would lead from the 
28
#PersPron nodes to their antecedent nodes in 
the previous sentence (to assistant and 
book, respectively). 
3.4 Basic Principles of  NSU Representation 
in TR 
The effort to reconstruct the clausal meaning of 
non-sentential utterances was motivated by the 
following basic assumptions: 
? The text contains utterance-response 
pairs. 
? NSU is the response to an utterance U2. 
? The utterance U has a finite-verb predi-
cate UPred with or without modifiers 
(arguments and adjuncts) UMods, which 
can be assigned functors. 
? Even UPred can be an elided predicate. 
? All NSUs (except interjections but incl. 
plain yes and no) contain an implicit 
(elided) predicate NSUPred. NSUPred is 
either identical with UPred, or it is an 
unknown verb, but we can imagine how 
it relates NSU and U. 
? NSU can be attached to a finite clause. 
? NSU inherits UPred along with all 
UMods. 
? When there is a semantic conflict, 
NSUMods overrule the inherited implicit 
UMods in NSU (repetition is also re-
garded as conflict). 
? NSUMod overrules UMod in the highest 
position possible in the subtree. 
3.5 TR Representation Elements for NSU 
This annotation introduced a new category into 
the annotation scheme. We called the category 
response_type and designed it in the same way as 
the coreference annotation. It is visualized as 
arrows of various colors pointing from NSUMod 
to UMod. Each type is indicated by a different 
color.  
The utterance-response pair consists of two 
parts: the antecedent utterance U and the re-
sponse NSU. The finite verb predicate UPred is 
typically the effective root of U, which has the 
functor PRED, but not necessarily. On the other 
hand, the elided predicate of NSU, called NSU-
                                                 
2 NSU is regarded as a response even if U is a statement and 
NSU a question. 
Pred, is the effective root of NSU and has the 
functor PRED. Fig. 3 describes U in more detail. 
 
 
Fig 3. Utterance-response pair. 
 
Whenever the clausal meaning of NSU can be 
reconstructed by using the copy of UPred as 
predicate, the t-lemma substitute for NSUPred is 
#VerbPron, which is normally also used for 
the pro-form do (dummy-do). NSUPred is al-
ways linked to UPred by a contextual-
coreference arrow. When the clausal meaning of 
NSU cannot be directly reconstructed by using 
the copy of UPred as the predicate, NSUPred is 
rendered as the coreference-less t-lemma substi-
tute #EmpVerb, which is normally used for 
cases of grammatical ellipsis of the predicate. 
#EmpVerb has no obligatory arguments and 
inherits no modifiers from anywhere. An NSU-
Pred that has coreference inherits all modifiers 
from UPred, but these are not explicitly copied to 
NSUPred. NSUPred?s own arguments are re-
garded as added to the inherited modifiers. 
Hence the NSU ?Peggy.? does not have to be 
explicitly reconstructed as ?That is 
Peggy.? (the left figure in Fig.4), but just with 
the coreferential predicate (the right figure). 
 
 
  Fig. 4 Response NSU: Full explanative reconstruction 
(left) and the actual annotation resolution (right).
 
29
Obviously, NSUMods can be in a semantic 
conflict with the inherited UMods. These cases 
are marked by several types of arrows leading 
from the given NSUMod to the conflicting 
UMod in the antecedent utterance U. We distin-
guish four types of semantic conflict between 
NSUMod and UMod: 
? overruling 
? rephrasing 
? wh-path 
? other 
3.6  Overruling 
Overruling is the most typical semantic conflict 
where an NSUMod gives exactly the same type 
of information, but relating to a different entity 
in the real world. If NSU is to be expressed as a 
clause that uses the predicate of U, the conflict-
ing UMod is erased (or prevented from inherit-
ing) by the explicitly present NSUMod. E.g. in 
the following utterance-response pair:  
U: I?m in a little place 
called Hellenthorpe. 
NSU: Ellenthorpe.  
NSU-paraphrase: You are in a 
little place called Hellen-
thorpe Ellenthorpe. 
 Even the explicit repetition is regarded as over-
ruling: 
U: There were just two peo-
ple in the class. 
NSU: Two people?.  
NSU-paraphrase: Were there 
just two people two people 
in the class? 
In the tree representation, the crossed text would 
be visible only in the tree of U, and an overrul-
ing-reference arrow would point at them from 
the relevant NSUMod. This conception prevents 
doubling the same modifier in NSU. 
3.7 Rephrasing 
When an NSUMod is rephrasing an UMod, then 
UMod and NSUMod refer to the same entity in 
the real world, or one refers to the entire entity 
whereas the other one refers only to its part, etc., 
using a different wording. The NSUMod-UMod 
relation marked as rephrasing is meant to be-
come the starting material for bridging anaphora 
research. Example:  
U: There were just two peo-
ple in the class. 
NSU: Just two students? 
NSU-paraphrase: Were there 
just two people two students 
in the class? 
It is also applied when the context is unambigu-
ous for the speakers but ambiguous for the anno-
tator, who lacks their background knowledge of 
the given situation. In the following example the 
annotator may not know whether this part 
or just the end of this part should come up, 
because he does not see the speakers pointing at 
the crane, but it is rather evident that it is not a 
completely different part of the crane but some-
thing at the end of it: 
U1: You lift the crane, so 
this part comes up. 
NSU1/U2: The end? 
NSU1/U2-paraphrase1: Do you 
mean the end comes up? 
NSU1/U2-paraphrase2: Do you 
mean the end of this part 
comes up? 
NSU2/U3: Just this. 
NSU3: Okay. 
The category ?Other? (see below) is though 
strongly preferred in ambiguous cases. 
 
3.8 Wh-path3 
The wh-path relation is the relation between the 
modifier that is focused by a wh-word in an U 
that is a direct or indirect question and a NSU-
Mod that makes a good answer.  
Overruling as well as rephrasing assume that 
the conflicting modifiers have the same functor.  
The wh-path category is different from the others 
in that it allows setting in conflict a UMod with 
an NSUMod with different semantic labels 
(functors). Our tentative annotation suggests that 
regular patterns will occur; e.g. with the question 
about direction/location. When asking where, 
speakers often get replies that would actually 
match questions with whom (functor ACMP) 
or with which intention (functor INTT, 
                                                 
3 The term was found in Haji?ov? (1995) and reused 
by placing it in context with other response types. 
30
e.g., go shopping), and yet they are per-
ceived as good answers.  
The relation between an utterance U which is 
a statement and an NSU which is a sluice is not 
wh-path but overruling. Cf.: 
U: Where would you like to 
go tomorrow? 
NSU: Downtown with Mary, to 
do some shopping. (wh-path) 
U: I would like to go down-
town with Mary tomorrow. 
NSU: Where? (overruling) 
Sluices are not regarded as ambiguous in the 
sense whether referring to the same entity as the 
corresponding wh-word or not. They are not eli-
gible for the relation ?other? (see next section). 
3.9 Other 
?Other? is meant for inherently ambiguous cases 
of conflicting UMod and NSUMod where it is 
impossible to decide whether NSUMod is re-
phrasing or overruling UMod. Textual ambiguity 
arises when NSU is a question that does not find 
a proper answer in the context: 
U1: He?s got the best room. 
NSU1/U2: Room 128? 
NSU1/U2-paraphrase: Has he 
got the best room Room 128? 
U3: I don?t know which num-
ber. 
3.10 TR-Conditioned Criteria for NSU types 
The original idea of the tectogrammatical repre-
sentation of NSU was to adopt the taxonomy 
proposed by Fern?ndez et al (2007). However, 
the rules of TR made some classes collapse as 
they yielded identical tectogrammatical tree 
structures. The main criteria for tectogrammati-
cal representation of NSU were the following: 
Is the NSU a phrase or just an interjection? (Cf. 
Fig. 5 and 6) 
? If it is a content word or a phrase, it 
should be reconstructed into a clause by 
adding a predicate. 
? If it is an interjection except yes and no 
(and their colloquial variants), no predi-
cate is added. 
? If it is yes/no (and variants), a predi-
cate should be added.  
? If the interjection acts as a backchannel, 
yes and no make no exception. 
 
Fig. 5 Interjection 
 
 
Fig. 6 Is this John? No, Billy [This is not John, this is Billy.] 
 
 
Can we copy UPred to make NSU a clause?
? If we can, NSUPred has the t-lemma 
substitute #VerbPron and a corefer-
ential arrow points from NSUPred to 
UPred.  
? If we cannot, NSUPred has the t-lemma 
#EmpVerb with no coreferential arrow. 
No response type arrows point from 
NSUMods to UMods. In specific cases 
the coreference to UPred leads from 
elsewhere (Fig.7). 
31
 
Fig. 7 Check question/Evaluative response related to text: 
U: I am allowed to record you.  
NSU (same speaker): Okay? 
NSU-paraphrase: Is it (that I?m allowed 
to record you) okay?  
or 
U: I am allowed to record you. 
NSU (turn switch): Okay.  
NSU-paraphrase: It <is> okay that you 
are allowed to record me.  
 
3.11 More Examples of U-NSU relation reso-
lution 
Fern?ndez et al (2007) distinguish two types of 
sluice: the direct and the reprise sluice. In TR, 
each has a different semantic representation. The 
direct sluice has the coreferential predicate while 
the reprise sluice, which can be paraphrased as 
What did you mean by saying 
this?,  has the empty-verb predicate and the 
wh-word gets the functor EFF, which is normally 
assigned to what is being said in the argument 
structure pattern of verbs of saying (Fig. 8). 
 
 
Fig. 8 Reprise sluice 
 
Fig. 9 shows a sentence with wh-path linking 
modifiers with different functors. 
 
Fig. 9 Wh-path linking Mods with different functors 
 
U: Where would you like to go tomorrow? 
NSU: Shopping with Mary. 
NSU-paraphrase: Tomorrow I would like to 
go shopping with Mary. 
 
Choice questions (Fig.10) represent an interest-
ing example in which one NSUMod can enter 
different relations to different UMods. The 
NSUMod beer overrules the coordinated UMod 
Coke or Pepsi, and at the same time it is 
connected with the wh-question Which do 
you like to drink? by wh-path. 
 
  
Fig. 10 Choice question.  
 
U: Which do you like to drink: Coke or 
Pepsi? 
NSU: Beer. 
NSU-paraphrase: I like to drink beer. 
 
Seeing the many rephrasing cases in the data, 
which are supposed to be subject to further 
anaphora annotation (bridging etc.), we had to 
ask the question whether the boundary between 
response_type and coreference can be reliably 
determined. We found good evidence in the 
made-up but not unlikely example below (Fig. 
32
11). In this context, him will be coreferential 
with Paul and her will be coreferential with 
Mary. On the other hand, him will overrule 
Mary and her will overrule Paul (only the 
relations of him are marked in the figure). 
 
 
Fig. 11 Coreference vs. response type 
3.12 Current and Future Work 
The proposed enhancement of the annotation 
scheme has been tested on a corpus of approx. 
200 NSUs with context manually extracted from 
the NAP transcripts as well as on example sen-
tences from Fern?ndez et al (2007) and many 
sentences obtained by their modification per-
formed in order to get potentially difficult coun-
terexamples. As this is still a preparatory work, 
neither the inter-annotator agreement nor any 
other evaluation could be done so far. 
In the next future, parts of the spoken corpora 
should get tectogrammatical parsing. The manual 
annotation is supposed to adopt this new feature 
of the annotation scheme, and we will try to in-
corporate it into our statistically trained auto-
matic parsing tools.  
   
Conclusion 
The confrontation of our current annotation 
scheme with spoken dialog data has raised issues 
of ellipsis restoration and textual coreference in 
non-sentential utterances. We have found com-
mon relations between non-sentential utterances 
and their contexts, and we have integrated them 
into our semantic annotation scheme without 
violating its general principles. A tentative man-
ual annotation of these relations in a small corpus 
suggests that such annotation is feasible. Further 
investigation on larger data along with machine-
learning experiments is intended. 
Acknowledgements 
This work was funded in part by the Companions 
project (www.companions-project.org) spon-
sored by the European Commission as part of the 
Information Society Technologies (IST) pro-
gramme under EC grant number IST-FP6-
034434, as well as by the Czech Science Founda-
tion (GA405/06/0589), and by the Czech Minis-
try of Education (MSM0021620838, M?MT ?R 
LC536). 
References 
Jay Bradley, Oli Mival, and D. Benyon. 2008. A 
Novel Architecture for Designing by Wizard of Oz. 
In: Proceeding of CREATE08, British computer 
Society, Covent Garden, London, 24-25 June 2008. 
Lou Burnard. 2000. Reference Guide for the British 
National Corpus (World Edition). Oxford Univer-
sity Computing Services. Available from 
ftp://sable.ox.ac.uk/pub/ota/BNC.
Silvie Cinkov?, Jan Haji?, Jan Pt??ek. 2008. An An-
notation Scheme for Speech Reconstruction on a 
Dialog Corpus. In Fourth International Workshop 
on Human-Computer Conversation. Bellagio, Italy: 
[http://www.companions-project.org/events/ 
200810_bellagio.cfm],2008:1-6. 
Raquel Fern?ndez, Jonathan Ginzburg, and Shalom 
Lappin. 2007. Classifying Non-Sentential Utter-
ances in Dialogue: A Machine Learning Approach. 
Computational Linguistics, Volume 33, Nr. 3. MIT  
Press for the Association for Computational Lin-
guistics. 
Erin Fitzgerald and Frederick Jelinek. 2008.  Linguis-
tic Resources for Reconstructing Spontaneous 
Speech Text. In: LREC 2008 Proceedings. 
Jan Haji?, Silvie Cinkov?, Marie Mikulov?, Petr Pa-
jas, Jan Pt??ek, Josef Toman, Zde?ka Ure?ov?. 
2008. PDTSL: An Annotated Resource For Speech 
Reconstruction. In Proceedings of the 2008 IEEE 
Workshop on Spoken Language Technology. 
IEEE, 2008. 
Jan Haji?, Marie Mikulov?, Martina Otradovcov?, 
Petr Pajas, Nino Peterek, Pavel ?e?ka, Miroslav 
Spousta. 2009. PDTSL - Prague Dependency Tree-
bank of Spoken Language - Czech, Institute of 
Formal and Applied Linguistics, Charles Univer-
sity in Prague. 
Eva Haji?ov? (ed.) 1995. Text And-Inference-Based 
Approach to Question Answering. Prague.  
Petr Sgall, Eva Haji?ov?, and Jarmila Panevov?. 
1986. The Meaning of the Sentence in Its Semantic 
and Pragmatic Aspects. Dordrecht:Reidel Publish-
ing Company and Prague:Academia.  
 
33
Proceedings of the Workshop on Frontiers in Linguistically Annotated Corpora 2006, pages 94?97,
Sydney, July 2006. c?2006 Association for Computational Linguistics
Constructing an English Valency Lexicon?
Jir??? Semecky?, Silvie Cinkova?
Institute of Formal and Applied Linguistics Afliation
Malostransk?e n?amest? 25
CZ11800 Prague 1
Czech Republic
(semecky,cinkova)@ufal.mff.cuni.cz
Abstract
This paper presents the English valency
lexicon EngValLex, built within the Func-
tional Generative Description framework.
The form of the lexicon, as well as the
process of its semi-automatic creation is
described. The lexicon describes valency
for verbs and also includes links to other
lexical sources, namely PropBank. Basic
statistics about the lexicon are given.
The lexicon will be later used for anno-
tation of the Wall Street Journal section
of the Penn Treebank in Praguian for-
malisms.
1 Introduction
The creation of a valency lexicon of English verbs
is part of the ongoing project of the Prague En-
glish Dependency Treebank (PEDT). PEDT is be-
ing built from the Penn Treebank - Wall Street
Journal section by converting it into dependency
trees and providing it with an additional deep-
syntactic annotation layer, working within the lin-
guistic framework of the Functional Generative
Description (FGD)(Sgall et al, 1986).
The deep-syntactic annotation in terms of FGD
pays special attention to valency. Under va-
lency we understand the ability of lexemes (verbs,
nouns, adjectives and some types of adverbs) to
combine with other lexemes. Capturing of valency
is profitable in Machine Translation, Information
Extraction and Question Answering since it en-
ables the machines to correctly recognize types of
? The research reported in this paper has been partially
supported by the grant of Grant Agency of the Czech Repub-
lic GA405/06/0589, the project of the Information Society
No. 1ET101470416, and the grant of the Grant Agency of
the Charles University No. 372/2005/A-INF/MFF.
events and their participants even if they can be
expressed by many different lexical items. A va-
lency lexicon of verbs is inevitable for the project
of the Prague English Dependency Treebank as a
supporting tool for the deep-syntactic corpus an-
notation.
We are not aware of any lexical source from
which such a lexicon could be automatically de-
rived in the desired quality. Manual creation of
gold-standard data for computational applications
is yet very time-consuming and expensive. Hav-
ing this in mind, we decided to adapt the already
existing lexical source PropBank (M. Palmer and
D. Gildea and P. Kingsbury, 2005) to FGD, mak-
ing it comply with the structure of the origi-
nal Czech valency lexicons VALLEX (Z?abokrtsky?
and Lopatkova?, 2004) and PDT-VALLEX (J. Hajic?
et al, 2003), which have been designed for the
deep-syntactic annotation of the Czech FGD-
based treebanks (The Prague Dependency Tree-
bank 1.0 and 2.0) (J. Hajic? et al, 2001; Hajic?,
2005). Manual editing follows the automatic pro-
cedure. We are reporting on a work that is still
ongoing (which is though nearing completion).
Therefore this paper focuses on the general con-
ception of the lexicon as well as on its technical
solutions, while it cannot give a serious evaluation
of the completed work yet.
The paper is structured as follows. In Section 2,
we present current or previous related projects in
more detail. In Section 3, we introduce the formal
structure of the EngValLex lexicon. In Section 4,
we describe how we semi-automatically created
the lexicon and describe the annotation tool. Fi-
nally in Section 5, we state our outlooks for the
future development and uses of the lexicon.
94
2 Valency Lexicon Construction
2.1 FGD
The Functional Generative Description (FGD)
(Sgall et al, 1986) is a dependency-based for-
mal stratificational language description frame-
work that goes back to the functional-structural
Prague School. For more detail see (Panevova?,
1980) and (Sgall et al, 1986). The theory of FGD
has been implemented in the Prague Dependency
Treebank project (Sgall et al, 1986; Hajic?, 2005).
FGD captures valency in the underlying syntax
(the so-called tectogrammatical language layer). It
enables listing of complementations (syntactically
dependent autosemantic lexemes) in a valency lex-
icon, regardless of their surface (morphosyntac-
tic) forms, providing them with semantic labels
(functors) instead. Implicitly, a complementation
present in the tectogrammatical layer can either be
directly rendered by the surface shape of the sen-
tence, or it is omitted but can be inferred from the
context or by common knowledge. A valency lex-
icon describes the valency behavior of a given lex-
eme (verb, noun, adjective or adverb) in the form
of valency frames.
2.2 Valency within FGD
A valency frame in the strict sense consists of in-
ner participants and obligatory free modifications
(see e.g. (Panevova?, 2002)). Free modifications
are prototypically optional and do not belong to
the valency frame in the strict sense though some
frames require a free modification (e.g. direction
in verbs of movement). Free modifications have
semantic labels (there are some more than 40 in
PDT) and they are distributed according to seman-
tic judgments of the annotators. FGD introduces
five inner participants. Unlike free modifications,
inner participants cannot be repeated within one
frame. They can be obligatory as well as optional
(which is to be stated by the judgment on gram-
maticality of the given sentence and by the so-
called dialogue test, (Panevova?, 1974 75)). Both
the obligatory and the optional inner participants
belong to the valency frame in the strict sense.
Like the free modifications, the inner participants
have semantic labels according to the cognitive
roles they typically enter: ACT (Actor), PAT (Pa-
tient), ADDR (Addressee), ORIG (Origin) and
EFF (Effect). Syntactic criteria are used to identify
the first two participants ACT and PAT (?shifting?,
see (Panevova?, 1974 75)). The other inner partic-
ipants are identified semantically; i.e. a verb with
one inner participant will have ACT, a verb with
two inner participants will have ACT and PAT re-
gardless the semantics and a verb with three and
more participants will get the label assigned by the
semantic judgment.
2.3 The Prague Czech-English Dependency
Treebank
In order to develop a state-of-the-art machine
translation system we are aiming at a high-quality
annotation of the Penn Treebank data in a for-
malism similar to the one developed for PDT.
When building PEDT we can draw on the suc-
cessfully accomplished Prague Czech-English De-
pendency Treebank 1.0 (J. Cur???n and M. C?mejrek
and J. Havelka and J. Hajic? and V. Kubon? and Z.
Z?abokrtsky?, 2004) (PCEDT).
PCEDT is a Czech-English parallel corpus,
consisting of 21,600 sentences from the Wall
Street Journal section of the Penn Treebank 3
corpus and their human translations to Czech. The
Czech data was automatically morphologically
analyzed and parsed by a statistical parser on
the analytical (i.e. surface-syntax) layer. The
Czech tectogrammatical layer was automatically
generated from the analytical layer. The En-
glish analytical and tectogrammatical trees were
derived automatically from the Penn Treebank
phrasal trees.
2.4 The Prague English Dependency
Treebank
The Prague English Dependency Treebank
(PEDT) stands for the data from Wall Street Jour-
nal section of the Penn Treebank annotated in the
PDT 2.0 shape. EngValLex is a supporting tool
for the manual annotation of the tectogrammatical
layer of PEDT.
3 Lexicon Structure
On the topmost level, EngValLex consists of word
entries, which are characterized by lemmas. Verbs
with a particle (e.g. give up) are treated as separate
word entries.
Each word entry consists of a sequence of
frame entries, which roughly correspond to indi-
vidual senses of the word entry and contain the
valency information.
95
Figure 1: EngValLex editor: the list of words and frames
Each frame entry consists of a sequence of va-
lency slots, a sequence of example sentences and
a textual note. Each valency slot corresponds to a
complementation of the verb and is described by
a tectogrammatical functor defining the relation
between the verb and the complementation, and a
form defining the possible surface representations
of the functor. Valency slots can be marked as op-
tional, if not, they are considered to be obligatory.
The form is listed in round brackets following
the functor name. Surface representations of func-
tors are basically defined by combination of mor-
phological tags and lemmas. Yet to save annota-
tors? effort, we have introduced several abbrevia-
tions that substitute some regularly co-occurring
sequences. E.g. the abbreviation n means ?noun
in the subjective case? and is defined as follows:
NN:NNS:NP:NPS
meaning one of the Penn Treebank part-of-
speech tags: NN, NNS, NP and NPS (colon delim-
its variants). Abbreviation might be defined recur-
sively.
Apart from describing only the daughter node
of the given verb, the surface representation can
describe an entire analytical subtree whose top-
most node is the daughter of the given verb node.
Square brackets are used to indicate descendant
nodes. Square brackets allow nesting to indicate
the dependency relations among the nodes of a
given subtree. For example, the following state-
ment describes a particle to whose daughter node
is a verb.
to.TO[VB]
The following statement is an example of a def-
inition of three valency slots and their correspond-
ing forms:
ACT(.n) PAT(to.TO[VB])
LOC(at.IN)
The ACT (Actor) can be any noun in the sub-
jective case (the abbreviation n), the PAT (Patient)
can be a particle to with a daughter verb, and the
LOC (Locative) can be the preposition at.
Moreover, EngValLex contains links to external
data sources (e.g. lexicons) from words, frames,
valency slots and example sentences.
The lexicon is stored in an XML format which
is similar to the format of the PDT-VALLEX lexi-
con used in the Prague Dependency Treebank 2.0.
4 Creating the Lexicon
The lexicon was automatically generated from
PropBank using XSLT templates. Each PropBank
example was expanded in a single frame in the
destination lexicon. When generating the lexicon,
we have kept as many back links to PropBank as
possible. Namely, we stored links from frames
to Propbank rolesets, links from valency slots to
PropBank arguments and links from examples to
PropBank examples. Rolesets were identified by
the roleset id attribute. Arguments were identified
by the roleset id, the name and the function of the
96
role. Examples were identified by the roleset id
and their name.
After the automatic conversion, we had 8,215
frames for 3,806 words.
Tectogrammatical functors were assigned semi-
automatically according to hand-written rules,
which were conditioned by PropBank arguments.
It was yet clear from the beginning that manual
corrections would be necessary as the relations of
Args to functors varied depending on linguistic de-
cisions1 .
The annotators were provided with an anno-
tation editor created on the base of the PDT-
VALLEX editor. Apart from interface for editing
EngValLex, the tool contains integrated viewers
of PropBank and VerbNet, which allows offline
browsing of the lexicons. Those viewers can be
run as a stand-alone application as well and are
published freely on the web2. The editor allows
the annotator to create, delete, and modify word
entries, and frame entries. Links to PropBank can
be set up, if necessary.
Figure 1 displays the main window of the editor.
The left part of the window shows list of words.
The central part shows the list of the frames con-
cerning the selected verb.
For the purpose of annotation, we divided the
lexicon into 1,992 files according to the name of
PropBank rolesets (attribute name of the XML el-
ement roleset), and the files are annotated sepa-
rately. When the annotation is finished, the files
will be merged again. Currently, we have about
80% of the lexicon annotated, which already con-
tains the most difficult cases.
5 Outlook
We have annotated the major part of EngValLex.
In the final version, a small part of the lexicon will
be annotated by a second annotator in order to de-
termine the inter-annotator agreement.
The annotation of the Prague English Depen-
dency Treebank on the tectogrammatical level will
be started soon and we will use EngValLex for as-
signing valency frames to verbs. The annotation
1E.g. Arg0 typically corresponds to ACT, and Arg1 to
PAT when they co-occur. Yet, a roleset including an inchoa-
tive sentence (The door.ARG1 opened.) and a causative sen-
tence (John.Arg0 opened the door.Arg1) will be split into two
FGD frames. The causative frame will keep Arg0?ACT and
Arg1?PAT whereas the inchoative will get Arg1?ACT.
2 http://ufal.mff.cuni.cz/?semecky/
software/{propbank|verbnet}viewer/
will be based on the same theoretical background
as the Prague Dependency Treebank.
Due to the PropBank links in EngValLex, we
will be able to automatically derive frame anno-
tation of PEDT from PropBank annotation of the
Penn Treebank.
As the Wall Street Journal sentences are manu-
ally translated into Czech, we will be able to ob-
tain their Czech tectogrammatical representations
automatically using state-of-art parsers.
A solid platform for testing Czech-English and
English-Czech machine translation will be given.
In the future we will also try to improve the trans-
lation by mapping the Czech PDT-ValLex to the
English EngValLex.
References
J. Hajic?, 2005. Complex Corpus Annotation: The
Prague Dependency Treebank, pages 54?73. VedaBratislava, Slovakia.
J. Cur???n and M. C?mejrek and J. Havelka and J. Hajic?
and V. Kubon? and Z. Z?abokrtsky?. 2004. PragueCzech-English Dependency Treebank Version 1.0.(LDC2004T25).
J. Hajic? et al 2001. Prague Dependency Treebank 1.0.LDC2001T10, ISBN: 1-58563-212-0.
J. Hajic? et al 2003. PDT-VALLEX: Creating a Large-coverage Valency Lexicon for Treebank Annotation.
In Proceedings of The Second Workshop on Tree-
banks and Linguistic Theories, volume 9.
M. Palmer and D. Gildea and P. Kingsbury. 2005. The
Proposition Bank: An Annotated Corpus of Seman-tic Roles. Computational Linguistics, 31(1):71.
J. Panevova?. 1974?75. On verbal Frames in FunctionalGenerative Description. Prague Bulletin of Mathe-
matical Linguistics (PBML), 22, pages 3?40, Part II,PBML 23, pages. 17?52.
J. Panevova?. 1980. Formy a funkce ve stavbe? c?eske?
ve?ty [Forms and functions in the structure of the
Czech sentence]. Academia, Prague, Czech Rep.
J. Panevova?. 2002. Sloveso: centrum ve?ty; va-lence: centra?ln?? pojem syntaxe. In Aktua?lne ota?zky
slovenskej syntaxe, pages x1?x5.
P. Sgall, E. Hajic?ova?, and J. Panevova?. 1986. TheMeaning of the Sentence in its Semantic and Prag-matic Aspects. Academia, Prague, Czech Repub-
lic/Reidel Publishing Company, Netherlands.
Z. Z?abokrtsky? and M. Lopatkova?. 2004. ValencyFrames of Czech Verbs in VALLEX 1.0. In Fron-
tiers in Corpus Annotation. Proceedings of the
Workshop of the HLT/NAACL Conference, pages70?77, May 6, 2004.
97
