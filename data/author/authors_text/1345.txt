Proceedings of the 2008 Conference on Empirical Methods in Natural Language Processing, pages 955?964,
Honolulu, October 2008. c?2008 Association for Computational Linguistics
Acquiring Domain-Specific Dialog Information from Task-Oriented 
Human-Human Interaction through an Unsupervised Learning 
 
Ananlada Chotimongkol Alexander I. Rudnicky 
Language Technologies Institute Language Technologies Institute 
Carnegie Mellon University Carnegie Mellon University 
Pittsburgh, PA 15213, USA Pittsburgh, PA 15213, USA 
ananlada@cs.cmu.edu air@cs.cmu.edu 
 
 
 
 
Abstract 
We describe an approach for acquiring the 
domain-specific dialog knowledge required to 
configure a task-oriented dialog system that 
uses human-human interaction data. The key 
aspects of this problem are the design of a di-
alog information representation and a learning 
approach that supports capture of domain in-
formation from in-domain dialogs. To 
represent a dialog for a learning purpose, we 
based our representation, the form-based di-
alog structure representation, on an observa-
ble structure. We show that this representation 
is sufficient for modeling phenomena that oc-
cur regularly in several dissimilar task-
oriented domains, including information-
access and problem-solving. With the goal of 
ultimately reducing human annotation effort, 
we examine the use of unsupervised learning 
techniques in acquiring the components of the 
form-based representation (i.e. task, subtask, 
and concept). These techniques include statis-
tical word clustering based on mutual infor-
mation and Kullback-Liebler distance, 
TextTiling, HMM-based segmentation, and 
bisecting K-mean document clustering. With 
some modifications to make these algorithms 
more suitable for inferring the structure of a 
spoken dialog, the unsupervised learning algo-
rithms show promise. 
1 Introduction 
In recent dialog management frameworks, such as 
RavenClaw (Bohus and Rudnicky, 2003) and Col-
lagen (Rich et al, 2001), domain-dependent com-
ponents of a dialog manager are clearly separated 
from domain-independent components. This sepa-
ration allows rapid development of a dialog man-
agement module in a new task-oriented domain as 
dialog system developers can focus only on speci-
fying domain-specific dialog information (e.g. the 
Dialog Task Specification in RavenClaw and Task 
Models in Collagen) while general dialog beha-
viors (e.g. turn-taking, confirmation mechanism, 
and generic help) are provided by the framework. 
For task-oriented domains, the domain-specific 
dialog information is equivalent to task-specific 
information. Examples of the task-specific infor-
mation are steps in a task and domain keywords. 
Specifying task-specific knowledge by hand is 
still a time consuming process (Feng et al, 2003). 
Furthermore, the hand-crafted knowledge may not 
reflect users? perceptions of a task (Yankelovich, 
1997). To reduce the subjectivity of system devel-
opers, recorded conversations of humans perform-
ing a similar task as a target dialog system have 
been used to help the developers design the task 
specification. Nevertheless, analyzing a corpus of 
dialogs by hand requires a great deal of human ef-
fort (Bangalore et al, 2006). This paper investi-
gates the feasibility of automating this dialog 
analysis process through a machine-learning ap-
proach. By inferring the task-specific dialog in-
formation automatically from human-human 
interaction data, the knowledge engineering effort 
could be reduced as the developers need to only 
revise learned information rather than analyzing a 
large amount of data.  
Acquiring the task-specific knowledge from a 
corpus of human-human dialogs is considered a 
knowledge acquisition process, where the target 
task structure has not yet been specified but will be 
explored from data before a dialog system is built. 
This is contrasted with a dialog structure recogni-
tion process (Alexandersson and Reithinger, 1997; 
955
Bangalore et al, 2006; Hardy et al, 2004), where 
pre-specified dialog structure components are rec-
ognized as a dialog progresses. 
We use an unsupervised learning approach in 
our knowledge acquisition process as it can freely 
explore the structure in the data without any influ-
ence from human supervision. Woszczyna and 
Waibel (1994) showed that when modeling a di-
alog state transition diagram from data an unsuper-
vised approach outperformed a supervised one as it 
better reflects the characteristic of the data. It is 
also interesting to see how well a machine-learning 
approach can perform on the problem of task-
specific knowledge acquisition when no assump-
tion about the domain is made and no prior know-
ledge is used. 
Examination of task-oriented human-human di-
alogs show that task-specific information can be 
observed in dialog transcription; therefore, it 
should be feasible to be infer it through an unsu-
pervised learning approach. Figure 1 (a) shows a 
dialog in an air travel domain. This dialog is orga-
nized into three parts according to the three steps 
(i.e. reserve a flight, reserve a car, reserve a hotel) 
required to accomplish the task, creating a travel 
itinerary. Domain keywords (highlighted in bold) 
required to accomplish each step are clearly com-
municated.  
To infer task-specific knowledge from data us-
ing an unsupervised learning approach, two prob-
lems need to be addressed: 1) choosing an 
appropriate dialog representation that captures ob-
servable task-specific knowledge in a dialog, and 
2) developing an unsupervised learning approach 
that infers the task-specific knowledge modeled by 
this representation from in-domain human-human 
dialogs. The first problem is discussed in Section 3 
where a form-based dialog structure representa-
tion is proposed. After describing the definition of 
each component in the form-based dialog structure 
representation, examples of how a domain expert 
models the task-specific information in a dialog 
with the form-based representation are given Sec-
tion 3.1. Then the annotation experiment which 
was used to verify that the form-based representa-
tion can be understood and applied by other human 
annotators is discussed in Section 3.2. For the 
second problem, we modify existing unsupervised 
learning approaches to make them suitable for in-
ferring the structure of a spoken dialog. Section 4 
describes these modifications and their perfor-
mances when inferring the components of the 
form-based dialog structure representation from 
interaction data. 
 
 
Figure 1: An example of a dialog in the air travel domain and its corresponding form-based representation  
(d) 
(b) 
(c) 
Form: flight reservation 
FlightInfo: 
FlightInfo: 
Fare: 
PassengerName: 
PaymentMethod: 
Form: hotel reservation 
HotelInfo: 
PassengerName: 
PaymentMethod: 
 
Form: car reservation 
CarInfo: 
PassengerName: 
PaymentMethod: 
 
Client   1:  I?d like to fly to Houston Texas 
Agent  2:  And departing Pittsburgh on what date? 
Client:  3: Departing on February twentieth 
Agent  4: What time would you like to depart Pittsburgh? 
Client   5: Seven a.m. 
Agent  6: The only non-stop flight I have would be on Continental Air-
lines that?s at six thirty a.m. arrive Houston at eight fifty 
Client   7: That?s okay I will take that 
Agent  8: And what day would you be returning? 
Client   9: On Monday February twenty third 
  ... 
Agent  16:  Do you need a car? 
Client  17:  Yeah 
Agent  18: The least expensive rate I have is Thrifty rental car for twen-
ty three ninety a day 
Client  19:  Okay 
Agent  20:  Would you like me to book that car for you? 
Client   21:  Yes 
Agent  22:  Okay and would you need a hotel while you're in Houston? 
Client  23:  Yes 
Agent  24:  And where at in Houston? 
Client  25:  Downtown 
  ... 
re
se
rve
 a
 flig
h
t 
re
se
rve
 a
 ca
r 
re
se
rve
 a
 h
o
te
l 
A
c
tio
n
: m
ake_
 
a_
car _
reservatio
n
 
A
c
tio
n
: m
ake_
 
a_
flig
h
t _
reservatio
n
 
A
c
tio
n
: m
ake_
 
a_
h
o
tel _
reservatio
n
 
(a) 
956
2 Related Work  
Automatic task-specific knowledge acquisition for 
configuring a dialog system is a relatively new re-
search area. Supervised learning approaches were 
used to acquire a task model for a collaborative 
agent (Garland et al, 2001) and task-specific in-
formation for a customer care service (Feng et al, 
2003). These supervised algorithms were trained 
on rich knowledge sources (examples described in 
a specific annotation language and a well-
organized website respectively) annotated by do-
main experts. In contrast, the unsupervised concep-
tual clustering algorithm in DIA-MOLE (M?ller, 
1998) requires no additional human annotation to 
infer a set of domain-specific dialog acts from in-
domain dialogs. The motivation behind the use of 
an unsupervised approach is similar to ours, to re-
duce human effort in creating a new dialog system.  
3 Form-based Dialog Structure Represen-
tation 
Many models have been proposed to account for 
the structure of a human-human conversation. 
Many such models focus on other aspects of a di-
alog such as coordinated activities, i.e. turn-taking 
and grounding, (Traum and Hinkelman, 1992) and 
regular patterns in the dialog (Carletta et al, 1997) 
rather than the domain-specific information com-
municated by participants. More complicated di-
alog representations (Grosz and Sidner, 1986; 
Litman and Allen, 1987) model several aspects of 
a dialog including domain-specific information. 
However, additional components in these models, 
such as beliefs and intentions, are difficult to ob-
serve directly from a conversation and, as for the 
current technology, may not be learnable through 
an unsupervised learning approach. 
Since the task-specific information that we 
would like to model will be used for configuring a 
dialog system, we can view this information from a 
dialog system perspective. Our dialog representa-
tion is based on form, a data representation used in 
a form-based (or frame-based) dialog system. A 
form is a simple representation that captures neces-
sary task-specific information communicated 
through dialog. This information is observable 
from dialog transcription (see below) and thus 
could be inferred through an unsupervised learning 
approach.  
Typically, a form corresponds to a database 
query form while slots in the form represent search 
criteria. Nevertheless, a form can represent related 
pieces of information required to perform any do-
main action not just a database query action. With 
this more general definition of a form, a form-
based dialog structure representation can be ap-
plied to various types of task-oriented domains 
where dialog participants have to gather pieces of 
information, analogous to search criteria, through 
dialog in order to perform domain actions that ful-
fill a dialog goal. Chotimongkol (2008) provided 
examples of these domains, for instance, meeting 
(Banerjee and Rudnicky, 2006) and flight simula-
tion control (Gorman et al, 2003). 
In the form-based dialog structure representa-
tion, task-specific information in each dialog is 
organized into a three-level structure of concept, 
subtask and task. A concept is a word or a group of 
words which captures a piece of information re-
quired to perform a domain action. A subtask is a 
subset of a dialog which contains sufficient con-
cepts to execute a domain action that advances a 
dialog toward its goal. A task is a subset of a di-
alog (usually the entire dialog) which contains all 
the subtasks that belong to the same goal. A sub-
task can also be considered as a step in a task. In 
terms of representation, a task is represented by a 
set of forms, one for each of its subtasks. A con-
cept is a slot in a form.  
To model the structure of a dialog in a new do-
main with the form-based dialog structure repre-
sentation, a list of tasks, subtasks, and concepts in 
that domain has to be specified. This list is consi-
dered a domain-specific tagset. The form-based 
dialog structure framework only provides the defi-
nitions of these components (i.e. task, subtask, and 
concept), which can be regarded as meta-tags and 
are domain-independent. A list of tasks, subtasks, 
and concepts can be identified manually as shown 
in Section 3.1 or automatically through a machine-
learning approach as discussed in Section 4. Sec-
tion 3.1 illustrates how a domain expert models the 
task-specific information in two task-oriented do-
mains, air travel planning (information-accessing) 
and map reading (problem-solving), with the form-
based representation. These examples also show 
that the form-based dialog structure representation 
957
is sufficient for modeling task-specific information 
in dissimilar domains. 
Nonetheless, by focusing on observable task-
specific information and describing this informa-
tion using a simple model, the form-based dialog 
structure representation cannot model the informa-
tion that is not clearly expressed in a dialog. Ex-
ample of such information in an air travel domain 
is the pickup date of a car rental which may not be 
discussed in a dialog as it can be inferred from the 
arrival date of the corresponding flight. Further-
more, the form-based representation is not well 
suited for modeling a complex dialog that has a 
dynamic structure such as a tutoring dialog. 
3.1 Dialog Structure Modeling Examples 
Figure 1 illustrates how a dialog in the air travel 
domain (Eskenazi et al, 1999) can be represented 
with the form-based dialog structure representa-
tion. A dialog in this domain usually has a single 
goal, to create an air-travel itinerary which may 
include hotel and car reservations. Thus, the entire 
dialog corresponds to one task. The dialog in Fig-
ure 1 (a) contains three subtasks, one for each 
make_?_reservation action. The forms that 
represent these subtasks are shown in Figure 1 (b) 
? (d). Each form contains a set of concepts neces-
sary for making the corresponding reservation. For 
a display purpose, the values of these slots are 
omitted. 
A subtask can be further decomposed. For ex-
ample, to reserve a round trip ticket, two database 
lookup actions, one for each leg, are required. A 
reserve_flight subtask in Figure 1 is decomposed 
into two query_flight_info subtasks. The corres-
ponding forms of these subtasks are illustrated in 
Figure 2. Each FlighInfo concept in the flight res-
ervation form is a result of a database lookup ac-
tion that corresponds to each flight query form. 
Figure 2: An example of subtask decomposition 
Figure 3 show a dialog in the map reading do-
main (Anderson et al, 1991) and its corresponding 
form-based dialog structure representation. The 
goal of a dialog in this domain is to have a route 
follower draw a route on his/her map according to 
a description given by a route giver. Since drawing 
an entire route involves several drawing strokes, a 
draw_a_route task is divided into several 
draw_a_segment subtasks, one for each drawing 
action. This action required a set of concepts that 
describe a segment as shown in a segment descrip-
tion form. Since the landmarks on the giver?s map 
can be different from those in the follower?s map, 
the participants have to explicitly define the Loca-
tion of a mismatched Landmark before using it in 
a segment description. In this case grounding be-
comes another subtask and can be represented by a 
form. This type of grounding is not necessary in 
the air travel domain. 
 
Figure 3: An example of a dialog in the map reading domain and its corresponding form-based representation 
  ? 
Giver 3: right, below the start do you have 
a missionary camp? 
Follower 4: yeah.  
Giver 5: okay, well if you take it from the 
start just run horizontally. 
Follower 6: uh-huh. 
Giver 7: to the left for about an inch. 
Follower 8: right. 
Giver 9: then go down along the side of 
the missionary camp. 
  ?. 
Form: grounding 
Landmark: missionary camp 
Location: below the start 
Form: segment description 
StartLocation: the start 
Direction: left 
Distance: an inch 
EndLocation:  
 
 
d
ra
w
_
a
_
se
g
m
e
n
t 
g
ro
u
n
d
in
g
 
A
c
tio
n
:  
d
efin
e_
a_
lan
d
m
ark 
A
c
tio
n
: 
d
raw
in
g
 
Form: flight query 
DepartCity: Houston 
ArriveCity: Pittsburgh 
DepartDate: Monday   
February twenty third 
DepartTime: five p.m. 
Form: flight query 
DepartCity: Pittsburgh 
ArriveCity: Houston 
ArriveState: Texas 
DepartDate: February 
twentieth 
DepartTime: seven a.m. 
Form: flight reservation 
FlightInfo: 
 Airline: Continental 
 DepartTime: six thirty a.m. 
 ArriveCity: Houston 
 ArriveTime: eight fifty 
FlightInfo: 
 Airline: Continental 
 DepartCity: Houston 
 DepartTime: six forty p.m. 
 ArriveCity: Pittsburgh 
 ArriveTime: ten twenty p.m. 
Fare: four hundred dollars  
Name: 
PaymentMethod: 
958
3.2 Annotation Experiment 
The goal of this annotation experiment is to verify 
that the form-based dialog structure framework can 
be understood by human annotators other than its 
developers, and that they can consistently apply the 
framework to model task-specific information in a 
dialog. In this experiment, each annotator had to 
design a form-based dialog structure representation 
for a given task-oriented domain by specifying a 
hierarchical structure of tasks, sub-tasks and con-
cepts in that domain. Note that we are interested in 
the process of designing a domain-specific tagset 
from the definitions of task, subtask, and concept 
provided by the framework, not in the process of 
using an existing tagset to annotate data (see for 
example (Carletta et al, 1997)). The description of 
the framework is provided in annotation guidelines 
along with examples from the domains that were 
not used in the experiment.  
The experimental procedure is as follows: the 
subjects first developed their own tagset according 
to the guidelines by analyzing a set of in-domain 
dialogs, and then annotate those dialogs with the 
tagset they had designed. To obtain enough anno-
tated instances for each dialog structure component 
and to make the annotation simple, the dialog 
structure annotation part of the experiment was 
divided into two sub-parts: concept annotation and 
task/sub-task annotation. Two domains were used 
in the experiment, air travel planning and map 
reading. Four subjects were assigned to each do-
main. None had used the scheme previously. The 
average number of tags that each subject annotated 
is shown in the first row of Table 1. 
Since some variations in tagset designs are ac-
ceptable as long as they conform to the guidelines, 
each subject?s annotation is judged against the 
guidelines rather than one specific reference anno-
tation. An annotation instance is marked as incor-
rect only when it does not conform to the 
guidelines. Each subject?s annotation was eva-
luated by both a coding scheme expert and by oth-
er subjects. Accuracy is computed from the 
expert?s judgment while acceptability is computed 
from peers? judgments. Acceptability scores shown 
in Table 1 were averaged from all other subjects in 
the same group. Please note that the result pre-
sented in this table should not be compared to the 
results from machine-learning approaches pre-
sented in Table 2 and Table 3 as the evaluation 
procedures and data sets are different. 
 
Measure 
Air Travel Map Reading 
C T C T 
Number of tags 178.8 50.5 347.8 60.8 
Accuracy (%) 96.5 89.7 89.0 65.2 
Acceptability (%) 95.6 81.1 94.9 84.5 
Table 1: Accuracy and acceptability on concept annota-
tion (C), and task/subtask annotation (T) 
Both accuracy and acceptability are high for all 
annotation tasks except for the accuracy of 
task/subtask annotation in the map reading domain. 
Most of the errors come from the annotation of the 
grounding subtasks. Since its corresponding ac-
tion is quite difficult to observe, subjects may not 
have a concrete definition of grounding and were 
more likely to produce errors. In addition, they 
were less critical when judging other subjects? an-
notations. Consistency in applying the form-based 
dialog structure representation shows that the re-
presentation is unambiguous and could potentially 
be identified through a machine-learning approach. 
When comparing among components, concepts 
were annotated more consistently than tasks and 
subtasks in terms of both accuracy and acceptabili-
ty. One possible reason is that, a concept is easier 
to observe as its unit is smaller than a task or a sub-
task. Moreover, dialog participants have to clearly 
communicate the concepts in order to execute a 
domain action. The subjects usually agreed on 
tasks and top-level subtasks, but did not quite 
agree on low-level subtasks. The low-level sub-
tasks are correlated with the implementation of a 
dialog system; hence, the designs of these subtasks 
are more subjective and likely to be different.  
4 Learning Approaches  
This section describes machine-learning approach-
es for inferring the task-specific information mod-
eled by the form-based dialog structure 
representation from human-human conversations. 
Specifically, the learning approach has to infer a 
list of tasks, sub-tasks and concepts in a given do-
main from in-domain dialogs similar to what a 
human does in Section 3. To make the problem 
tractable, components in the form-based represen-
tation are acquired separately. For most task-
oriented dialogs that we encountered, each dialog 
corresponds to one task. Hence, the learning effort 
959
can be focused on identifying concept and subtask. 
Since we can only observe instances or values of 
these components in a dialog, we have to first iden-
tify these instances and then make a generalization 
for its type. For instant, to infer that there is a con-
cept City in the air travel domain, a set of city 
names has to be identified and grouped together. 
To identify a set of domain concepts from the 
transcription of in-domain dialogs, we follow the 
algorithm described in (Chotimongkol and Rud-
nicky, 2002). This algorithm utilizes an unsuper-
vised clustering algorithm which clusters words 
based on context similarity, e.g. mutual informa-
tion-based and Kullback-Liebler-based clustering, 
since the members of the same domain concept are 
usually used in similar contexts in a particular do-
main. Examples of the clusters obtained from the 
KL-based clustering algorithm are shown in Figure 
4. These clusters represent Hour, RentalCompa-
ny, and City respectively. Underlined cluster 
members belong to other concepts. The clustering 
algorithm can identify all 12 members of Hour and 
about half of RentalCompany.  In the third clus-
ter, some airport names got merged with city 
names because they occur in quite similar context. 
Figure 4: Learned concepts in the air travel domain 
The rest of this section describes an approach 
for identifying subtasks and their corresponding 
forms in a given domain. We decided to simplify 
the form-learning problem by first segmenting a 
dialog into form-filling episodes (which are equiv-
alent to sub-tasks), then grouping the ones that cor-
respond to the same form together so that we can 
determine a set of necessary slots in each form 
from the concepts present in its corresponding 
cluster. We further simplify the problem by con-
centrating on the domains that have only one top-
level task (though in principle the approach can be 
extended to the domains that have multiple top-
level tasks). Since we utilize well-known unsuper-
vised algorithms, only the modifications which are 
applied to make these algorithms suitable for infer-
ring the structure of a spoken dialog are discussed.  
Two unsupervised discourse segmentation algo-
rithms are investigated: TextTiling (Hearst, 1997) 
and Hidden Markov Modeling (Barzilay and Lee, 
2004). These algorithms only recover the sequence 
of subtasks but not the hierarchical structure of 
subtasks similar to Bangalore et al?s (2006) 
chunk-based model. Nevertheless, this simplifica-
tion is sufficient when a subtask is embedded at the 
beginning or the end of the higher-level subtask 
which is the case for most embedded structures we 
have found. Both algorithms, while performing 
well with expository text, require modifications 
when applying to a fine-grained segmentation 
problem of spoken dialogs. In WSJ text, the aver-
age topic length is 428 words (Beeferman et al, 
1999) while in the air travel domain the average 
subtask length is 84 words (10 utterances). 
For TextTiling, the modifications include a dis-
tance weight and a data-driven stop word list. For 
the subtasks that are much shorter than the average 
length, distant words in the context window can be 
irrelevant. A distance weight demotes the impor-
tance of the context word that is far away from the 
considered boundary by giving it a lower weight. 
A manually prepared stop word list, containing 
common words, may not be suitable for every ap-
plication domain. We propose a novel approach 
that determines a list of stop words directly from 
word distribution in each data set. TextTiling as-
sumes that words that occur regularly throughout a 
dialog are not informative. However, the regularity 
of a particular word is determined from its distribu-
tion over the dialog rather than from its frequency. 
A high frequency word is useful if its instances 
occur only in a specific location. For example, the 
word ?delta? which occurs many times in a re-
serve_flight subtask but does not occur in other 
subtasks is undoubtedly useful for determining 
subtask boundaries while the word ?you? which 
can occur anywhere in a dialog is not useful. Spe-
cifically, a regularity count of word w is defined as 
the number of sliding context windows in the simi-
larity score calculation of TextTiling that contain 
the word w in each dialog. A data-driven stop 
word list contains words that have a regularity 
count greater than a pre-defined threshold. 
For HMM-based segmentation, we modified 
Barzilay and Lee?s (2004) content models by using 
larger text spans when inducing the HMM states. 
HMM states are created automatically by cluster-
ing similar text spans together. When using an ut-
? ONE, TWO, THREE, NINE, SIX, FOUR, SEVEN, FIVE, 
EIGHT, TEN, TWELVE, ELEVEN 
? HERTZ, BUDGET, THRIFTY 
? MIDWAY, LAGUARDIA, GATWICK, PHILADELPHIA, 
DALLAS, DENVER, MONTEREY, BOSTON, CHICAGO, 
AUSTIN, NEWARK, PITTSBURGH, SEATTLE, OTTAWA, 
SYRACUSE, BALTIMORE, HOUSTON, MADRID, L.A., 
ATLANTA, DULLES, HONOLULU 
960
terance as a text span, it may not contain enough 
information to indicate its relevant subtask as some 
utterances in a task-oriented dialog are very short 
and can occur in any subtask (e.g. acknowledge-
ments and yes/no responses). Larger text spans, 
reference topics, were used in (Yamron et al, 
1998). Nevertheless, this approach requires true 
segment boundaries. To eliminate the need of an-
notated data in our algorithm, HMM states are in-
duced from predicted segments generated by 
TextTiling instead. 
After segmenting all dialogs into sequences of 
subtasks, the bisecting K-means clustering algo-
rithm (Steinbach et al, 2000) is used to group the 
segments that belong to the same type of subtask 
together as they represent the same form type. The 
clustering is done based on cosine similarity be-
tween segments. This unsupervised clustering al-
gorithm is also used to infer a set of HMM states in 
the HMM-based segmentation described above.  
Words are used as features for both segmenta-
tion and clustering algorithms. If a set of domain 
concepts has already been identified, we can use 
this information to enhance the features. When 
concept annotation is available, we can incorporate 
a concept label into a representation of a concept 
word. A Label+Word representation joins a word 
string and its label and can help disambiguate be-
tween similar words that belong to different con-
cepts. For instance, ?one? in ?that one? is not the 
same token as ?[Hour]:one?. A Label representa-
tion, on the other hand, only represents a concept 
word by its label. This representation is based on 
the assumption that a list of concepts occurring in 
one subtask is distinguishable from a list of con-
cepts occurring in other subtasks regardless of the 
values of the concepts; hence, a concept label is 
more informative than its value. This representa-
tion provides an abstraction over all different val-
ues of the same concept type. For example, 
[Airline]:northwest and [Airline]:delta are 
represented with the same token [Airline]. In all 
experiments, concept labels are provided by a do-
main expert as we assume that a set of domain 
concepts has already been identified. 
4.1 Dialog Segmentation Results 
To evaluate dialog segmentation performance, we 
compare predicted boundaries against subtask 
boundaries annotated by a domain expert. Subtask 
boundaries could occur only at utterance bounda-
ries. Two metrics are used: Pk (Beeferman et al, 
1999) and concept-based f-measure (C. F-1). Pk 
measures the probability of misclassifying two ut-
terances that are k utterances apart as belonging to 
the same sub-task or different sub-tasks. k is set to 
half the average sub-task length. C. F-1 is a mod-
ification of the standard f-measure (a harmonic 
mean of precision and recall) that gives credit to 
some near misses. Since the segmented dialogs 
will later be used to identify a set of forms and 
their associated slots, the segment that contains the 
same set of concepts as the reference segment is 
acceptable even if its boundaries are slightly dif-
ferent from the reference. For this reason, a near-
miss counts as a match if there is no concept be-
tween the near-miss boundary and the reference 
boundary. 
We evaluated the proposed dialog segmentation 
algorithms with 24 dialogs from the air travel do-
main and 20 dialogs from the map reading domain. 
The window size for TextTiling was set to 4 utter-
ances. The cut-off threshold for choosing subtask 
boundaries was set to ? - ?/2; where ? is the mean 
of the depth scores (Hearst, 1997), the relative 
change in word co-occurrence similarities on both 
sides of a candidate boundary, in each dialog and ? 
is their standard deviation. We found that a small 
window size and a low cut-off threshold are more 
suitable for identifying fine-grained segments as in 
the case of subtasks. However, we also found that 
TextTiling is quite robust as varying these two pa-
rameters doesn?t severely degrade its performance 
(Chotimongkol, 2008). The threshold for selecting 
data-driven stop words was set to ? + 2*?; where ? 
is the mean of the regularity counts of all the words 
in a given dialog and ? is their standard deviation. 
The performance of TextTiling and HMM-based 
segmentation algorithm is shown in Table 2. 
Augmented TextTiling, which uses a data-
driven stop word list, distance weights, and the 
Label+Word representation, performed significant-
ly better than the baseline in both domains. Each of 
these augmenting techniques can on their own im-
prove segmentation performance but not signifi-
cantly. Unsurprisingly, the proposed regularity 
counts discover stop words that are specific to spo-
961
ken dialogs, but are absent from the hand-crafted 
list1, e.g. ?okay? and ?yeah?.  
 
Algorithm 
Air Travel Map Reading 
Pk C. F-1 Pk C. F-1 
TextTiling (baseline) 0.387 0.621 0.412 0.396 
TextTiling (augmented) 0.371 0.712 0.384 0.464 
HMM-based (utterance) 0.398 0.624 0.392 0.436 
HMM-based (segment) 0.385 0.698 0.355 0.507 
HMM-based (segment + 
Label representation) 
0.386 0.706 0.250 0.686 
Table 2: Dialog segmentation results 
For HMM-based segmentation, the segmenta-
tion result obtained when modeling the HMM 
states from predicted subtasks generated by Text-
Tiling (4th row) is better than the result obtained 
when modeling the HMM states from utterances 
(3rd row). Predicted segments provide more context 
to the clustering algorithm that induces the HMM 
states. As a result a more robust state representa-
tion is obtained. A more efficient clustering algo-
rithm can also improve the performance of the 
HMM-based segmentation algorithm since it pro-
vides a state representation that better differentiates 
among dialog segments which belong to dissimilar 
subtasks. When the Label representation which 
yielded a better subtask clustering result (see Sec-
tion 4.2) was used, HMM-based segmentation pro-
duced a better result (5th row) especially in the map 
reading domain. These numbers may appear mod-
est compared to the numbers obtained when seg-
menting expository text. However, predicting the 
boundaries of fine-grained subtasks is more diffi-
cult even with a supervised learning approach (Ar-
guello and Ros?, 2006). Our results are comparable 
to Arguello and Ros??s (2006) results. 
Between the two segmentation algorithms, the 
HMM-based algorithm performed slightly worse 
than TextTiling in the air travel domain but per-
formed significantly better in the map reading do-
main. The HMM-based algorithm can identify 
more boundaries between fine-grained subtasks, 
which occur more often in the map reading do-
main. TextTiling, which relies on local lexical co-
hesion, is unlikely to find two significant drops in 
lexical similarity that are only a couple of utter-
ances apart, and thus fails to detect boundaries of 
short segments. However, HMM-based segmenta-
                                                          
1 http://search.cpan.org/~creamyg/Lingua-StopWords-
0.08/lib/Lingua/StopWords.pm. 
tion misses more boundaries between two subtask 
occurrences of the same type, which occurs more 
often in the air travel domain, as they are usually 
represented by the same state. 
4.2 Subtask Clustering Results 
We evaluated the subtask clustering algorithm on 
the same data set used in the dialog segmentation 
evaluation. Table 3 presents the quality score (QS) 
for each clustering result. These QSs were obtained 
by comparing the output clusters against a set of 
reference subtasks. See (Chotimongkol and Rud-
nicky, 2002) for the definition of QS. 
 
Feature Representation Air Travel Map Reading 
Label+Word (oracle) 0.738 0.791 
Label+Word 0.577 0.675 
Label 0.601 0.823 
Table 3: Subtask clustering results 
When predicted segments were clustered, the 
quality of the output (2nd row) is not as good as 
when the reference segments were used (1st row) as 
inaccurate segment boundaries affected the per-
formance of the clustering algorithm. However, the 
qualities of subtasks that occur frequently are not 
much different. In terms of feature representation, 
the clustering algorithm that uses the Label repre-
sentation achieved better performance in both do-
mains. When the sets of concepts in all of the 
subtasks are disjoint, the clustering algorithm that 
uses the Label representation can achieve a very 
good result as in the map reading domain. This 
result is even better than the result obtained when 
the reference segments were clustered by the algo-
rithm that uses the Label+Word representation. 
These results demonstrate that an appropriate fea-
ture representation provides more useful informa-
tion to the clustering algorithm than accurate 
segment boundaries. However, when the subtasks 
contain overlapping sets of concepts as in the air 
travel domain, the performance gain obtained from 
the Label representation is quite small.  
Figure 5 shows four types of forms in the air 
travel domain that were acquired by the proposed 
form identification approach. The slot names are 
taken from concept labels. The number in paren-
theses is slot frequency in the corresponding clus-
ter. The underlined slots are the ones that belong to 
other forms. Some slots in the car query form are 
962
missing as some instances of its corresponding 
subtask get merged into other clusters. 
 
Figure 5: Examples of forms obtained by the proposed 
unsupervised learning approach 
4.3 Discussions on Learning Approaches 
The results presented in the previous sections show 
that existing unsupervised learning algorithms are 
able to identify components of the form-based di-
alog structure representation.. However, some 
modifications are required to make these algo-
rithms more suitable for inferring the structure of a 
spoken dialog. The advantages of different learn-
ing algorithms can be combined to improve per-
formance. For example, TextTiling and HMM-
based segmentation are good at detecting different 
types of boundaries; therefore, combining the pre-
dictions made by both algorithms could improve 
segmentation performance. Additional features 
such as prosodic features could also be useful.  
Subsequent steps in the learning process are sub-
jected to propagation errors. However, the pro-
posed learning algorithms, which are based on 
generalization of recurring patterns, are able to 
learn from inaccurate information given that the 
number of errors is moderate, so that there are 
enough correct examples to learn from. Given re-
dundant information in dialog corpora, a domain 
knowledge acquisition process does not require 
high learning accuracy and an unsupervised learn-
ing approach is reasonable. The overall quality of 
the learning result is acceptable. The proposed un-
supervised learning approach can infer much use-
ful task-specific dialog information needed for 
automatically configuring a task-oriented dialog 
system from data. 
5 Conclusion and Future Directions 
To represent a dialog for a learning purpose, we 
based our representation, the form-based dialog 
structure representation, on observable informa-
tion. Components of the form-based representation 
can be acquired with acceptable accuracy from 
observable structures in dialogs without requiring 
human supervision. We show that this dialog re-
presentation can capture task-specific information 
in dissimilar domains. Additionally, it can be un-
derstood and applied by annotators other than the 
developers. 
Our investigation shows that it is feasible to au-
tomatically acquire the domain-specific dialog in-
formation necessary for configuring a task-oriented 
dialog system from a corpus of in-domain dialogs. 
This corpus-based approach could potentially re-
duce human effort in dialog system development. 
A limitation of this approach is that it can discover 
only information present in the data. For instance, 
the corpus-based approach cannot identify city 
names absent in the corpus while a human devel-
oper would know to include these. Revision may 
be required to make learned information more ac-
curate and complete before deployment; we expect 
that this effort would be less than the one required 
for manual analysis. A detailed evaluation of cor-
rection effort would be desirable. 
In this paper, task-specific knowledge was ac-
quired from in-domain dialogs without using any 
prior knowledge about the domain. In practice, 
existing knowledge sources about the world and 
the domain, such as WordNet, could be used to 
improve learning. Some human supervision can be 
valuable particularly in the form of semi-
supervised learning and active learning. In particu-
lar a process that integrates human input at appro-
priate times (for example seeding or correction) is 
likely to be part of a successful approach. 
Acknowledgments 
This research was supported by DARPA grant NB 
CH-D-03-0010. The content of the information in 
this publication does not necessarily reflect the 
position or the policy of the US Government, and 
no official endorsement should be inferred. 
Form: flight query 
Airline  (79) 
ArriveTimeMin  (46) 
DepartTimeHour (40) 
DepartTimeMin  (39) 
ArriveTimeHour (36) 
ArriveCity (27) 
FlightNumber (15) 
ArriveAirport (13) 
DepartCity (13) 
 
Form: hotel query 
Fare  (75) 
City (36) 
HotelName (33) 
Area (28) 
ArriveDateMonth (14) 
Form: flight reservation 
Fare (257) 
City (27) 
RentalCompany (17) 
HotelName (15) 
ArriveCity (14) 
AirlineCompany (11) 
Form: car query 
CarType (13) 
City (3) 
State (1) 
963
References  
J. Alexandersson and N. Reithinger. 1997. Learning 
Dialogue Structures From A Corpus. In Proceedings 
of EuroSpeech-97. Rhodes, Greece. 
A. H. Anderson, M. Bader, E. G. Bard, E. Boyle, G. 
Doherty, S. Garrod, S. Isard, J. Kowtko, J. McAllis-
ter, J. Miller, C. Sotillo, H. Thompson, and R. Wei-
nert. 1991. The HCRC Map Task Corpus. Language 
and Speech, 34(4):351-366. 
J. Arguello and C. P. Ros?. 2006. Topic Segmentation 
of Dialogue. In Proceedings of Workshop on Analyz-
ing Conversations in Text and Speech. 
S. Banerjee and A. I. Rudnicky. 2006. You Are What 
You Say: Using Meeting Participants? Speech to 
Detect their Roles and Expertise. In the NAACL-HLT 
2006 workshop on Analyzing Conversations in Text 
and Speech. New York, NY. 
S. Bangalore, G. D. Fabbrizio, and A. Stent. 2006. 
Learning the Structure of Task-Driven Human-
Human Dialogs. In Proceedings of COLING/ACL 
2006. Sydney, Australia. 
R. Barzilay and L. Lee. 2004. Catching the Drift: Prob-
abilistic Content Models, with Applications to Gen-
eration and Summarization. In Proceedings of HLT-
NAACL 2004. Boston, MA. 
D. Beeferman, A. Berger, and J. Lafferty. 1999. Statis-
tical Models for Text Segmentation. Machine Learn-
ing, 34(1-3):177-210. 
D. Bohus and A. I. Rudnicky. 2003. RavenClaw: Dialog 
Management Using Hierarchical Task Decomposi-
tion and an Expectation Agenda. In Proceedings of 
Eurospeech2003. Geneva, Switzerland. 
J. Carletta, S. Isard, G. Doherty-Sneddon, A. Isard, J. C. 
Kowtko, and A. H. Anderson. 1997. The reliability of 
a dialogue structure coding scheme. Computational 
Linguistics, 23(1):13-31. 
A. Chotimongkol. 2008. Learning the Structure of Task-
Oriented Conversations from the Corpus of In-
Domain Dialogs, Ph.D. Thesis CMU-LTI-08-001. 
Pittsburgh, Carnegie Mellon University. 
A. Chotimongkol and A. Rudnicky. 2002. Automatic 
Concept Identification in Goal-Oriented Conversa-
tions. In Proceedings of ICSLP 2002. Denver, CO. 
M. Eskenazi, A. Rudnicky, K. Gregory, P. Constanti-
nides, R. Brennan, C. Bennett, and J. Allen. 1999. 
Data Collection and Processing in the Carnegie Mel-
lon Communicator. In Proceedings of Eurospeech 
1999. Budapest, Hungary. 
J. Feng, S. Bangalore, and M. Rahim. 2003. WebTalk: 
Mining Websites for Automatically Building Dialog 
Systems. In Proceedings of ASRU '03. St. Thomas, 
U.S. Virgin Islands. 
A. Garland, N. Lesh, and C. Sidner. 2001. Learning 
Task Models for Collaborative Discourse. In Pro-
ceedings of Workshop on Adaptation in Dialogue 
Systems, NAACL '01. Pittsburgh, PA. 
J. C. Gorman, N. J. Cooke, P. W. Foltz, P. A. Kiekel, 
and M. J. Martin. 2003. Evaluation of Latent Seman-
tic Analysis-based measures of team communications 
content. In Proceedings of the Human Factors and 
Ergonomic Society 47th Annual Meeting, (HFES 
2003). 
B. J. Grosz and C. L. Sidner. 1986. Attention, Inten-
tions, and the Structure of Discourse. Computational 
Linguistics, 12(3):175-204. 
H. Hardy, A. Biermann, R. B. Inouye, A. Mckenzie, T. 
Strzalkowski, C. Ursu, N. Webb, and M. Wu. 2004. 
Data-Driven Strategies for an Automated Dialogue 
System. In Proceedings of ACL '04. Barcelona, 
Spain. 
M. A. Hearst. 1997. TextTiling: Segmenting Text into 
Multi-paragraph Subtopic Passages. Computational 
Linguistics, 23(1):33-64. 
D. Litman and J. Allen. 1987. A Plan Recognition Mod-
el for Subdialogues in Conversations. Cognitive 
Science, 11(2):163-200. 
J.-U. M?ller. 1998. Using Unsupervised Learning for 
Engineering of Spoken Dialogues. In Proceedings of 
AAAI 1998 Spring Symposium on Applying Machine 
Learning to Discourse Processing. 
C. Rich, C. L. Sidner, and N. Lesh. 2001. Collagen: 
applying collaborative discourse theory to human-
computer interaction. AI Magazine, 22(4):15-25. 
M. Steinbach, G. Karypis, and V. Kumar. 2000. A 
Comparison of Document Clustering Techniques. In 
Proceedings of KDD Workshop on Text Mining. 
D. R. Traum and E. A. Hinkelman. 1992. Conversation 
Acts in Task-Oriented Spoken Dialogue. Computa-
tional Intelligence, 8(3):575--599. 
M. Woszczyna and A. Waibel. 1994. Inferring linguistic 
structure in spoken language. In Proceedings of the 
International Conference on Spoken Language 
Processing (ICSLP). 
J. P. Yamron, I. Carp, L. Gillick, S. Lowe, and P. v. 
Mulbregt. 1998. A Hidden Markov Model Approach 
to Text Segmentation and Event Tracking. In Pro-
ceedings of ICASSP '98. Seattle, WA. 
N. Yankelovich. 1997. Using Natural Dialogs as the 
Basis for Speech Interface Design. In Susann Luper-
foy (Ed.), Automated Spoken Dialog Systems. Cam-
bridge, MA: MIT Press. 
 
964
Proceedings of the ACL Workshop on Feature Engineering for Machine Learning in NLP, pages 24?31,
Ann Arbor, June 2005. c?2005 Association for Computational Linguistics
Using Semantic and Syntactic Graphs for Call Classication
Dilek Hakkani-Tu?r Gokhan Tur
AT&T Labs ? Research
Florham Park, NJ, 07932
 
dtur,gtur  @research.att.com
Ananlada Chotimongkol
Carnegie Mellon University
Pittsburgh, PA 15213
ananlada@cs.cmu.edu
Abstract
In this paper, we introduce a new data
representation format for language pro-
cessing, the syntactic and semantic graphs
(SSGs), and show its use for call classifi-
cation in spoken dialog systems. For each
sentence or utterance, these graphs in-
clude lexical information (words), syntac-
tic information (such as the part of speech
tags of the words and the syntactic parse of
the utterance), and semantic information
(such as the named entities and seman-
tic role labels). In our experiments, we
used written language as the training data
while computing SSGs and tested on spo-
ken language. In spite of this mismatch,
we have shown that this is a very promis-
ing approach for classifying complex ex-
amples, and by using SSGs it is possible
to reduce the call classification error rate
by 4.74% relative.
1 Introduction
Goal-oriented spoken dialog systems aim to iden-
tify intents of humans, expressed in natural lan-
guage, and take actions accordingly to satisfy their
requests. The intent of each speaker is identified
using a natural language understanding component.
This step can be seen as a multi-label, multi-class
call classification problem for customer care appli-
cations (Gorin et al, 1997; Chu-Carroll and Carpen-
ter, 1999; Gupta et al, To appear, among others).
As an example, consider the utterance I would like
to know my account balance, from a financial do-
main customer care application. Assuming that the
utterance is recognized correctly by the automatic
speech recognizer (ASR), the corresponding intent
(call-type) would be Request(Balance) and the ac-
tion would be telling the balance to the user after
prompting for the account number or routing this
call to the billing department.
Typically these application specific call-types are
pre-designed and large amounts of utterances man-
ually labeled with call-types are used for training
call classification systems. For classification, gen-
erally word  -grams are used as features: In the
How May I Help You?  (HMIHY) call routing sys-
tem, selected word  -grams, namely salient phrases,
which are salient to certain call-types play an im-
portant role (Gorin et al, 1997). For instance, for
the above example, the salient phrase ?account bal-
ance? is strongly associated with the call-type Re-
quest(Balance). Instead of using salient phrases, one
can leave the decision of determining useful features
(word  -grams) to a classification algorithm used as
described in (Di Fabbrizio et al, 2002) and (Gupta
et al, To appear). An alternative would be using
a vector space model for classification where call-
types and utterances are represented as vectors in-
cluding word  -grams (Chu-Carroll and Carpenter,
1999).
Call classification is similar to text categorization,
except the following:
 The utterances are much shorter than typical
documents used for text categorization (such as
broadcast news or newspaper articles).
24
0 1
<bos>
2
WORD:I
3
WORD:paid
4
WORD:six
5
WORD:dollars
6
<eos>
Figure 1: An example utterance represented as a single path FSM.
 Since it deals with spontaneous speech, the ut-
terances frequently include disfluencies or are
ungrammatical, and
 ASR output is very noisy, typically one out of
every four words is misrecognized (Riccardi
and Hakkani-Tu?r, 2003).
Even though the shortness of the utterances may
imply the easiness of the call classification task, un-
fortunately this is not the case. The call classifi-
cation error rates typically range between 15% to
30% depending on the application (Gupta et al, To
appear). This is mainly due to the data sparseness
problem because of the nature of the input. Even for
simple call-types like Request(Balance), there are
many ways of uttering the same intent. For instance,
in one of the applications we used in our experi-
ments, as a response to the greeting prompt, there
are 2,697 unique utterances out of 3,547 utterances
for that call-type. Some examples include:
 I would like to know my account balance
 How much do I owe you
 How much is my bill
 What is my current bill
 account balance
 You can help me by telling me what my phone
bill is

...
Given this data sparseness, current classification ap-
proaches require an extensive amount of labeled data
in order to train a call classification system with a
reasonable performance. In this paper, we present
methods for extending the classifier?s feature set by
generalizing word sequences using syntactic and se-
mantic information represented in compact graphs,
called syntactic and semantic graphs (SSGs). For
each sentence or utterance, these graphs include
lexical information (words), syntactic information
(such as the part of speech tags of the words and the
syntactic parse of the utterance), and semantic in-
formation (such as the named entities and semantic
role labels). The generalization is expected to help
reduce the data sparseness problem by applying var-
ious groupings on word sequences. Furthermore, the
classifier is provided with additional syntactic and
semantic information which might be useful for the
call classification task.
In the following section, we describe the syntac-
tic and semantic graphs. In Section 3, we describe
our approach for call classification using SSGs. In
Section 4, we present the computation of syntactic
and semantic information for SSGs. In the last Sec-
tion, we present our experiments and results using
a spoken dialog system AT&T VoiceTone R Spoken
Dialog System (Gupta et al, To appear).
2 Semantic and Syntactic Graphs
Consider the typical case, where only lexical infor-
mation, i.e. word  -grams are used for call classifi-
cation. This is equivalent to representing the words
in an utterance as a directed acyclic graph where
the words are the labels of the transitions and then
extracting the transition  -grams from it. Figure 1
shows the graph for the example sentence I paid six
dollars, where  bos 	 and  eos 	 denote the begin-
ning and end of the sentence, respectively.
Syntactic and semantic graphs are also directed
acyclic graphs, formed by adding transitions encod-
ing syntactic and semantic categories of words or
word sequences to the word graph. The first addi-
tional information is the part of speech tags of the
words. In the graph, as a parallel transition for each
word of the utterance, the part of speech category
of the word is added, as shown in Figure 2 for the
example sentence. Note that, the word is prefixed
by the token WORD: and the part-of-speech tag is
prefixed by the token POS:, in order to distinguish
between different types of transitions in the graph.
The other type of information that is encoded in
these graphs is the syntactic parse of each utterance,
namely the syntactic phrases with their head words.
For example in the sentence I paid six dollars, six
dollars is a noun phrase with the head word dollars.
In Figure 2, the labels of the transitions for syntactic
phrases are prefixed by the token PHRASE:. There-
25
0 1
<bos>
2
POS:PRP
WORD:I
SRL:pay.A0
PHRASE:NP_I
5
PHRASE:S_paid
PHRASE:VP_paid
3
POS:VBD
WORD:paid
SRL:pay.V
6
<eos>
NE:m
SRL:pay.A1
PHRASE:NP_dollars
4
POS:CD
WORD:six
POS:NNS
WORD:dollars
Figure 2: The SSG for the utterance I paid six dollars, where words (WORD:), part-of-speech tags (POS:),
syntactic parse (PHRASE:), named entities (NE:) and semantic roles (SRL:) are included.
?:?0 321
?:?
?:?
?:?
?:?
?:??:?
Figure 3: The FST used to extract unigram, bigram and trigrams. 
 represents the alphabet,  represents the
epsilon transition.
fore, six dollars is also represented by the transition
labeled PHRASE:NP dollars. As an alternative, one
may drop the head word of the phrase from the rep-
resentation, or insert an epsilon transition parallel to
the transitions of the modifiers of the head word to
eliminate them from some  -grams.
Generic named entity tags, such as person, lo-
cation and organization names and task-dependent
named entity tags, such as drug names in a medical
domain, are also incorporated into the graph, where
applicable. For instance, for the example sentence,
six dollars is a monetary amount, so the arc NE:m is
inserted parallel to that sequence.
As another source of semantic information, se-
mantic role labels of the utterance components are
incorporated to the SSGs. The semantic role labels
represent the predicate/argument structure of each
sentence: Given a predicate, the goal is to identify
all of its arguments and their semantic roles. For
example, in the example sentence the predicate is
pay, the agent of this predicate is I and the amount
is six dollars. In the graph, the labels of the tran-
sitions for semantic roles are prefixed by the token
SRL: and the corresponding predicate. For exam-
ple, the sequence six dollars is the amount of the
predicate pay, and this is shown by the transition
with label SRL:pay.A1 following the PropBank no-
tation (Kingsbury et al, 2002)1.
In this work, we were only able to incorporate
part-of-speech tags, syntactic parses, named entity
tags and semantic role labels in the syntactic and se-
mantic graphs. Insertion of further information such
as supertags (Bangalore and Joshi, 1999) or word
stems can also be beneficial for further processing.
3 Using SSGs for Call Classification
In this paper we propose extracting all  -grams from
the SSGs to use them for call classification. The  -
grams in an utterance SSG can be extracted by con-
verting it to a finite state transducer (FST),  . Each
transition of  has the labels of the arcs on the SSG
as input and output symbols2. Composing this FST
with another FST,  , representing all the possible
 -grams, forms the FST,  , which includes all  -
grams in the SSG:




1A1 or Arg1 indicates the object of the predicate, in this case
the amount.
2Instead of the standard notation where ?:? is used to sepa-
rate the input and output symbols in finite state transducers, we
use ?:? to separate the type of the token and its value.
26
Then, extracting the  -grams in the SSG is equiva-
lent to enumerating all paths of   . For ff