Proceedings of the 12th European Workshop on Natural Language Generation, pages 66?73,
Athens, Greece, 30 ? 31 March 2009. c?2009 Association for Computational Linguistics
A Model for Human Readable Instruction Generation Using Level-Based
Discourse Planning and Dynamic Inference of Attributes Disambiguation
Daniel Dionne, Salvador de la Puente, Carlos Leo?n, Raquel Herva?s, Pablo Gerva?s
Universidad Complutense de Madrid
Madrid, Spain
{dionnegonzalez,neo.salvador}@gmail.com,
{cleon,raquelhb}@fdi.ucm.es,pgervas@sip.ucm.es
Abstract
This paper shows a model of automatic in-
struction giving for guiding human users
in virtual 3D environments. A multilevel
model for choosing what instruction to
give in every state is presented, and so
are the different modules that compose the
whole generation system. How 3D in-
formation in the virtual world is used is
explained, and the final order generation
is detailed. This model has been imple-
mented as a solution for the GIVE Chal-
lenge, an instruction generation challenge.
1 Introduction
Recent technology advances have made it possi-
ble to use handheld devices, like mobile phones
or PDAs, to guide the user by issuing commands
or descriptions about the world the user is per-
ceiving in some sense (Muller, 2002). This pos-
sibility opens interesting avenues of research in
the shape of Natural Language Generation (NLG)
Systems that adapt to the user in order to provide
him with the most accurate expression. However,
fully operational systems applicable in real life sit-
uations are difficult and expensive to implement.
Under these circumstances, virtual environments
may be seen as an intermediate solution, suitable
for fast prototyping of experimental solutions. Vir-
tual environments permit experimenting in a re-
duced, closed world, where everything that is rel-
evant for the purpose at hand is explicitly repre-
sented in a graphical model and under the direct
control of the researcher. This allows fast set up of
experimental situations where the topography, the
position of landscape features, colour, light con-
ditions and visibility factors can be modified and
adapted to suit the best conditions for testing par-
ticular approaches (Blue et al, 2002) or challenges
(such as guidance for disabled users with different
disabilities, for instance). In view of these obser-
vations, our research is focused on developing an
interactive virtual guide (VG), based on NLG, to
give to a human user the required set of instruc-
tions to complete a specific task.
Such a set of instructions is called a plan. For-
mally, a plan is a sorted-in-time list of instructions
that the user must fulfill in order to reach some
goal. There are many planning algorithms that,
with the proper world representation and a list of
goals, can return a list like this (LaValle, 2006).
The VG can take this basic plan as the actual set
of instructions to convert into natural language to
explain what the user must do to complete the task.
However, these instructions are usually exhaustive
(step by step) and very simple because they are
based on basic world representations (and inter-
pretations) and are simple enough to perform com-
putational operations on them. A VG that gener-
ates this kind of simple instructions, from the point
of view of a human user, can be tedious, boring
and a time wasting. Consider the discourse ?Turn
right. Turn right. Go ahead. Turn left. Press
button-1. Turn around. Go ahead. Go ahead. Take
item-1. . . ? as an example. Instead, the VG should
take advantage of the environmental knowledge of
the user inferring higher level instructions (less de-
tailed and more human-like) from the basic plan
(something more along the lines of ?Go press the
buton in the far wall, come back and take item-1?).
The difference is shown graphically for a simple
example in Figure 1.
There are several aspects to be considered in
achieving this goal. First, a human guide would
phrase his or her instructions at different levels of
abstraction, to optimise the communicative effect
of his/her utterances in terms of striking balance
between sufficient informative content and econ-
omy of expression. Second, a human guide may
operate in a reactive manner, providing additional
feedback whenever the user requests help. But
66
7 instructions 1 instruction
Figure 1: A comparison of a step by step plan
versus a human readable plan like ?Walk out the
door?. Note the difference in the number of in-
structions given.
human guides are also likely to observe the per-
son that is being guided, and be ready to intervene
proactively if they notice the user seems lost or at
risk. These two points are elaborated below.
In order to build more human levels, a VG must
consider the virtual environment in a manner as
close as possible to the way a human being senses
the real world. To model the different levels of ab-
straction employed by human guides, a good solu-
tion may be to model the world as a hierarchy of
spatial levels. People tend to limit the area where
they do certain activities by some kind of logical
borders. Sometimes, these borders match physi-
cal borders such as the walls that define a room
or a corridor, the outside perimeter of a building,
the limits of a park, or a city boundary. In other
cases, such as outdoor settings, borders can be
more abstract, such as the line of horizon in all di-
rections from the observer?s current position. The
areas defined by these borders may be contained
inside one other, resulting in a tree-like structure
from the smallest spaces to greater areas, i.e. from
the room where the user is standing to the city he
lives in. Of course, the areas are connected in a
multigraph way where each edge is a connection
like a door or a natural transition. To build a us-
able model of this type of cognitive representation
of the world is far from trivial. We will describe
how we faced this point in Section 3.1 (Construct-
ing the World). Considering such a hierarchical
view of the environment when generating instruc-
tions, results in more natural and human-friendly
results. Instructing someone to ?exit the room?
works better than asking them to ?advance until
passing through the door?; ?leave the building
using the main entrance? is better than a set of
instructions refering to more specific spaces like
?exit this room, now go down the stairs, now go to
the elevator? and so on. We return to this matter
in Section 3.2 (Planning the Discourse).
The issue of abstractions in world modelling
also affects a different language generation task:
referring expression generation. In providing in-
structions, human guides often refer to abstract
concepts such as corners or ?the middle of the
room?. These are not usually represented explic-
itly in your run of the mill world representation,
which usually prevents NLG systems from em-
ploying them as means of optimising references.
In Section 3.4 (Hidden Reference Discovery), we
will see how, besides visible information, a natural
approach based on the inference of other ?hidden?
elements or references that can be extracted from
the environment helps to reduce the length of the
explanation needed, and to build better references.
These elements are hidden because they are not
visible or trivial, and they require a specific study
and calculation.
The second point to consider is reactive versus
proactive guidance. A reactive guidance system
may rely on feedback from the user to decide when
to intervene. Consider the following two represen-
tative examples: the user can say ?I did not un-
dertand last instruction? and the VG system can
answer by repeating the instruction or building a
new one phrased in a different way but with the
same meaning; or the user can say ?I am lost?
and the VG will ask the planning software to re-
calculate the plan considering the new user?s sit-
uation. However, there are situations where the
user may not realize that he is lost or that he is
about to perform a dangerous action (like walking
on a slippery surface, pressing an incorrect button,
going in the wrong direction or crossing a street
when the traffic light is red). A good guide will
warn the user before he does something wrong but
it should not oppress the user each time he decides
to explore another route to reach the goal. In other
words, the VG must watch the user actions and
take part when he is on the verge of commiting
a serious mistake. We will discuss about how to
warn the user in Section 3.3 (Warning the User).
2 Previous Work
Many NLG systems have considered generation
of instructions in the past. A good review is pro-
vided in (Bourne, 1999). However, most existing
instruction generating system focused on perform-
67
ing different types of static actions (actions that do
not involve changes of location of the user). The
present work is focused on the task of guiding the
user through virtual environments.
The GIVE (Generating Instructions in Virtual
Environments) Challenge (Byron et al, 2007) op-
erates on a scenario where a user has to solve a
particular task in a simulated 3D space. A gen-
eration module has to guide the human user using
natural language instructions. A software architec-
ture is provided that allows the generation module
to abstract away from the rest of the system, while
having access to world information from the 3D
environment, user feedback from the client mod-
ule, and plans generated by an off-the-shelf plan-
ner. The work presented in this paper arose from
the author?s participation in the GIVE Challenge,
and relies on the software architecture provided
for the challenge to implement all details of the
system other than the NLG module.
A fundamental task to be solved for correct in-
struction generation is the construction of appro-
priate referring expressions. This task has been
the object of many research efforts in the recent
past. To construct a reference to a particular en-
tity, the algorithm takes as input a symbol corre-
sponding to the intended referent and a list of sym-
bols corresponding to other entities in focus based
the intended referent, known as the contrast set.
The algorithm returns a list of attribute-value pairs
that correspond to the semantic content of the re-
ferring expression to be realized. The algorithm
operates by iterating over the list of available at-
tributes, looking for one that is known to the user
and rules out the largest number of elements of the
contrast set that have not already been ruled out.
Referring Expression Generation in physically
situated environments has been studied in (Kelle-
her and Kruijff, 2005). The goal of this work is to
develop embodied conversational robots that are
capable of natural, fluent visually situated dialog
with one or more interlocutors. In this kind of
situation a very important aspect to take into ac-
count is how to refer to objects located in the phys-
ical environment. The authors present in the paper
a computational framework for the generation of
spatial locative expressions in such contexts, rely-
ing on the Reiter and Dale (Reiter and Dale, 1992)
algorithm.
Another interesting work related to referring ex-
pression generation in spatial environments can be
found in (Varges, 2005). The author uses the maps
of the Map Task dialogue corpus as domain mod-
els, and treats spatial descriptions as referring ex-
pressions that distinguish particular points on the
map from all other points (considered as distrac-
tors).
Related research can be found in (Stoia et al,
2006), where a study of how humans give orders in
navigation environmnets and an algorithm imple-
menting the observed behaviour is shown. There
are many other approaches to instruction giving.
Directly related with this work, it is worth men-
tioning CORAL (Dale and Geldof, 2003), which
shows a full architecture for instruction giving,
and REAL (Muller, 2002), which shows a multi-
modal system (graphics and text) for communicat-
ing with the user, adapting them to user behaviour.
3 A Functional Model of a Virtual Guide
The model of a virtual guide presented here ad-
dresses four specific issues: how to construct a
representation of the world with higher levels of
representation, how to generate higher instructions
referring to the more abstract levels of represen-
tation, how the construction of references is im-
plemented in terms of reference agents. A brief
overview of the complete architecture of the mod-
ule is also included.
3.1 Constructing the World
In GIVE, the world is discretized as a set of tiles.
These tiles are the minimum portions of space and
the user can move around from tile to tile. Orienta-
tions are discretized: the user can only face North,
East, South or West. By default, the world consists
of an infinite area of adjacent and accesible tiles.
World representation assertations may state there
is a wall between two adjacent tiles, blocking ac-
cess from one to other. A 3D representation of this
basic world gives the user an illusion of rooms but,
from the point of view of the VG there is no data
structure that reflects a hierarchy of rooms. This
representation does not fit very well with the hu-
man sense of space, so a more abstract one had to
be built to provide the abstract referents (rooms,
corners, intersections, doors...) which we wanted
our guide to use.
The first problem we had was defining a room.
In architecture, a definition of room is ?any dis-
tinguishable space within a structure?, but distin-
guishable is too vague to be of use. Figure 2 illus-
68
A) One big room
B) Three smaller rooms
Figure 2: Defining a distinguishable space.
trates the problem of defining when two spaces are
distiguishable. Notice the only difference betwen
A and B is the width of the gaps in relation to the
size of the rooms. This problem has been exten-
sively studied in robotics. An interesting exam-
ple (Galindo et al, 2005) consists on identifying
interconected ?open spaces? in order to obtain an
adjacency graph. From that graph, another graph
can be calculated, grouping spaces to form rooms,
corridors, etc.
For practical purposes, we have decided to con-
sider that two spaces are distinguishable when the
user has to go through a door to get from one to the
other, with a door being a one-tile gap in a wall.
Based on this definition, we have developed an
algorithm to group adjacent tiles into rooms. The
idea is to follow a wall around the room until the
starting point is reached, thereby establishing the
perimeter of the room, then establish the set of
tiles corresponding to the room using a floodfill
algorithm. Breaks in walls are handled by check-
ing whether they are small enough to be consid-
ered doors into other rooms or not. If they are
doors, they are noted as entrances to other rooms
(which are stored in a room list for subsequent pro-
cessing). If they are not, the wall beyond the gap
is followed as part of the boundary of the current
room. A small practical example of the algorithm
in operation is shown in Figure 3.
Adjoining rooms stored in the room list are
recursively processed. Each new room discovered
is connected to its adjacent rooms to obtain a high
level map of the available space. An analyzer is
applied to each room to establish its type (room,
hall, corridor, etc) and additional properties such
as size or shape. This new world representation
A) First, nd anywall B) Not a door,the gap is too big
C) Was not a door,so go back. D) Small gap (door),so add it to DC.
Figure 3: Looking for rooms.
GOAL
A5
A3
H1 H2 H3 H5H4
A5
Time ow 
H7H6
Figure 4: Tree representation of the plan at several
levels.
allows the VG to refer to doors and rooms.
3.2 Planning the Discourse
Discourse planning must take place at two differ-
ent levels of detail. The VG must plan the dis-
course corresponding to the whole set of instruc-
tions to be imparted until the final goal is reached.
But it also needs to plan how much of that is to
be communicated to the user in the next turn of
the dialogue. We solve the first issue by build-
ing a multi-level representation of the expected
discourse for the whole of the plan to be carried
out by the user. This representation is structured
like a tree, with the set of low-level instructions as
leafs, and subsequent nodes of the tree represent-
ing higher level instructions that group together
the lower level instructions represented by their
subtrees. The solution to the second issue is de-
scribed below.
We define action as anything the user can do
69
Line of sightCheckpoint User?sroute
Figure 5: An n-shaped room does not let the user
see the exit of the room so VG can guide the user
from checkpoint to checkpoint.
that modifies the state of the world and instruc-
tion as an action that the user should perform in
order to advance in the plan. Instructions are de-
fined in terms of preconditions and postconditions.
Preconditions are conditions that must be satis-
fied for the instruction to be performed, and post-
conditions are the conditions that must be satisfied
to consider the instruction done. The instruction
tree representation of the plan is built by group-
ing together sets of low-level instructions into a
single high-level instruction. For instance, we
group all tile-by-tile steps inside the same room
to build a new instruction such as ?go from room1
to room2?. We do not discard any low-level in-
struction, we just group them under the new high-
level instruction, building a tree that represents the
plan at different levels of abstraction (see Figure
4). This allows the user to fall back on low-level
instructions at need (if, for instance, the light goes
out and the VG has to guide him step by step).
An additional abstraction has been introduced
to account for the tendency of humans to break
the description of a complex path (where not all
of the path is visible at the start) into segments
made of the portions of the path that are visible at
each particular point (see Figure 5). The concept
of checkpoint is introduced for the end of each of
these segments.
We have defined five types of high-level in-
structions: MovementInstruction (guides the
user from tile to tile), CheckPointInstruction
(guides the user from a his current position to
a checkpoint), Room2RoomInstruction (guides
the user from room to room), ActionInstruc-
tion (tells the user to interact with some ele-
ment) and GoalInstruction (subtype of ActionIn-
struction concerned with achieving the final goal).
Each of these high-level instructions has its own
preconditions and postconditions.
The issue of how much of the instruction tree
representation of the plan is addressed in terms of
two conditions: how far in the original plan the
user has advanced, and what level of abstraction is
required for the next instruction. The first condi-
tion is easily checked over the state of the world, to
establish what the current situation is. The second
condition is determined by checking for satisfac-
tion of preconditions and postconditions of the in-
structions at all possible levels that start from the
current situation. The check starts at the highest
possible level.
Instructions whose postconditions are already
satisfied are pruned from the tree, as there is no
longer any need to provide that instruction to the
user. If preconditions are met but postconditions
are not, the VG uses this instruction in the next
turn, and then waits for a user action. If neither
postconditions nor preconditions are satisfied for
this instruction, the next (lower) level of instruc-
tions in the instruction tree is considered instead
of this one. These decisions are handled by mod-
ules known as Guide Agents.
3.3 Warning the User
If the user is going to cross a street when the traffic
light is red, the VG will have to warn him about it.
If the warning information is more important than
the guiding, the VG will have to delay instruction
giving, and warn the user first. To decide about the
importance of the warning part of the discourse,
we defined agents as entities in charge of watch-
ing for special situations. Each agent takes care of
a specific kind of situation that may imply some
sort of hazardous or bad result. They are all inde-
pendent, and may differ depending on the kind of
environment, goals or even the kind of user.
Each agent has a weight that reflects its priority
when being considered. An agent always evalu-
ates its situation and returns a value in the [0, 1]
interval. A near zero value means there are low
probabilities for the situation to happen and a near
to one value means the situation is on the verge
to happening. All agents that exceed a threshold
value will be considered as contributors to the dis-
course. We sort them in descending order based
on the result of multiplying each return value by
the weight of the agent. If an agent is considered
70
as a contributor, its warning is introduced in the
discourse.
We defined three types of agents: information
agents watch for interesting hotspots in an area,
status agents watch over the user?s status, and
area agents watch over special areas, including
dangerous areas.
In our entry for the GIVE challenge there was
a status agent that checked how much time had
passed since the last user action to identify when
the user might be lost. There was one agent that
checked for booby traps the user might step on
(some of them resulted in loosing the game in-
mediately). Another one ensured the user re-
mained within a security area that abstracted all
possible common routes to reach the intended des-
tination. If a user leaves the security area, he is
going in the wrong direction.This security area is
dynamicaly updated attending to the current user?s
position. Finally, alarm agents watch for wrong
actions, controlling if user is on the verge of press-
ing the wrong button or leaving the room using
a wrong exit. We implemented no information
agents, but they would be interesting in real sit-
uations.
3.4 Hidden Reference Discovery
The center spot in a room is not a visible or tan-
gible object, and finding it requires a non-trivial
calculation of the room?s shape. Adding it to
the references container can help creating simpler
and richer sentences. A reference like ?the table
across the room? can be generated when the lis-
tener and the target are in line with the center spot
of the room, on opposite sides, independently of
where the user is facing. In an indoor environ-
ment, architectural elements usually make many
inferences possible. Two hallways that intersect
make an intersection, two walls make a corner, etc.
and though these elements might not be referenced
as they are in the given environment, they should
be taken into account. In a similar way, hidden
relations discovery can be accomplished. Object
alignments or arrangements can be revealed and
used for the same purpose. Sentences like ?the car
in line with these pillars? can be generated. All of
these additional high-level concepts and relations
between them and low-level world entities are ob-
tained by abstraction over the available represen-
tation. We create a family of reference agents,
each one specialized in identifying candidate dis-
Oppositethe green door
Room Center
Corner
Betweenthe bluedoors
Figure 6: Hidden references in a room.
ambiguating properties of a different kind. Some
of these properties are already explicit in the world
representation (colour) and some require a pro-
cess of abstraction (relations to corners, for in-
stance). Once obtained, they become available as
additional properties that may be used to disam-
biguate references.
The goal of our design is to leverage the sys-
tem?s ability to express itself using different com-
binations of the complete set of disambiguating
properties made available in this manner. This
gives system designers a choice between having
many simple agents or fewer more expressive,
complex agents. This choice should be considered
in terms of particular implementation details.
Reference agents rely on the Reiter and Dale al-
gorithm (Reiter and Dale, 1992). Considering a
list of distractors and the reference object, the goal
is to filter the distractors list, building a reference
that takes out all the distractors, so that the refer-
ence is good, not ambiguous. Each reference agent
has the ability of taking out a different set of dis-
tractors, using different properties that are trivial
or hidden, as explained above. Combining these
agents in different ways generates different refer-
ence sentences, some of them longer but more spe-
cific, others shorter but ambiguous. What we tried
to achieve is to find the right combination of refer-
ence agents that create the shortest non-ambiguous
sentence. This is not a natural approach, as some-
one could prefer to have an ambiguous (but more
human) spatial relation (Viethen and Dale, 2008)
in a reference sentence. Or for example, someone
could prefer having a longer reference like ?the big
red box that?s on the third shelf from the bottom?
than a perfectly specific (but not natural) reference
like ?the 3 kg box?.
71
REALWORLD
WORLDANALYSIS EXPANDEDWORLD
GOALS
DISAMBIGUATION
APPROXIMATION STAGE
ALERTS
INSTRUCTION TREE1
2
3
LEVELS
GUIDE MANAG
ERGUIDE AGENT 1GUIDE AGENT 2
G. 3.1G. 3.n ...
REFER
RER M
ANAGE
R ReferrerReferrerReferrer
Referrer
ReferrerReferrerALARM
 MANA
GERAlarm AgentAlarm AgentAlarm AgentAlarm Agent
Alarm Agent
Alarm Agent
GOAL SUBSETCURRENTINSTRUCTION
GOAL
PLANNER
generatedoutput
GENERATIONMANAGER
Figure 7: General design.
3.5 Guide architecture
The architecture design can be divided into two
main parts. The instruction tree, shown as three
interconnected lists in Figure 7, that contains all
the generated levels of instructions as explained
in section 3.2, and a set of components that per-
form the different guiding tasks. One input for the
system is the ?Real World?, as opposed to the Ex-
panded World that is generated after the analysis,
as explained in sections 3.1 and 3.4. The second
input is the set of goals to be achieved. After the
basic instruction set is generated by the planner
from the given set of goals, the instruction tree is
generated, level by level.
Figure 7 represents a state of the guiding pro-
cess where the user is trying to achieve some in-
termediate GOAL. The current instruction marker
represents the location of the instruction that is to
be given to the user to achieve the current GOAL
(the one on the upper level). Since at this point
the system has determined that level 2 instructions
should be used, the level 2 subset of instructions
are represented here as part of the current instruc-
tion. As explained in section 3.2, the algorithm
chooses what level should be used at each mo-
ment.
The Guide Manager makes use of the Alarm
Manager and Referrer Manager to create the
proper output. As explained in 3.3, the Alarm
Agents examine the environment, and tell the
Guide Manager if the user should be warned about
any hazardous situation. The Referrers help build-
ing the proper reference sentences, as explained
in sections 3.2 and 3.4, finally the different Guide
help building the proper guiding sentences. The
Guide Manager sends the output to the Genera-
tion Manager, which is in charge of generating the
final output.
4 Discussion
The layered, multilevel hierarchy tries to imitate
the way humans think about local plans, and the
agent based view attemps to make instruction giv-
ing proactive rather than reactive. The algorithm
first gives generalistic, global orders to get the
user near the particular objective. Then, once
the irrelevant information has been removed from
the user point of view and it can not confuse the
user, more specific orders are given. In this way,
the algorithm decides what to say the ?human
way?. Although the ?human? generation of in-
structions could have been obtained with different
algorithms, doing it the same way creates a more
maintainable, natural form of expressing the oper-
ation. It would be interesting to input real human
data, as done in (Stoia et al, 2006), in order to
guarantee this objective.
Traditionally, planning systems have certain
world representation based on discrete states
which are more or less useful for finding a good
solution (Chih-Wei Hsu and Chen, 2006). How-
ever, this representation is not necessarily useful
for creating a natural language representation of
each planning operator. For a good instruction
to be generated, plain operators like ?turn right?
usually do not contain much information. Instruc-
tion generation systems have to find a compromise
between planning efficiency and natural language
content. Creating the instruction tree depends di-
rectly on figuring out what elements to include in
the discourse.
The architecture shown in Section 3 has been
designed with adaptability in mind, following the
architecture presented in (Dale and Geldof, 2003).
This shows a module layout where the text plan-
72
ner and the surface realizer are independently con-
nected in the generation pipeline.
5 Conclusions and Future Work
The decisions to consider higher level of abstrac-
tion for both the representation of the world and
the granularity of instructions, and the introduc-
tion of alarms have shown very satisfactory results
over informal tests with users. Further evaluation
is in process as part of the GIVE Challenge (Koller
et al, 2007)1. The decisions presented in this pa-
per should be revised in view of these results. The
definition of a security area enables the system to
provide suitable warning when the user really goes
out of the way, but makes the system robust with
respect to minor variations with respect to the lit-
eral plan provided by the planner.
The GIVE challenge set up was a good starting
point to begin our experiments, but we are con-
sidering more complex environments to test ad-
vanced features. Extensions that promise interest-
ing challenges are: the consideration of a contin-
uous world representation (rather than discretised
in terms of tiles and four cardinal points), more re-
alistic test maps to extend the level of hierarchy to
buildings and urban areas, and new environments
designed to experiment with distorted representa-
tions of the scenary in order to simulate physical
impediments like blindness.
Acknowledgments
This research is funded by the Ministerio de In-
vestigacio?n, Ciencia e Innovacio?n (GALANTE:
TIN2006-14433-C02-01), and Universidad Com-
plutense de Madrid and Comunidad de Madrid
(MILU: CCG07-UCM/TIC 2803).
References
Russell S. Blue, Jeff Wampler, G. Bowden Wise,
Louis J. Hoebel, Boris Yamrom, Christopher R.
Volpe, Bruce Wilde, Pascale Rondot, Ann E. Kelly,
Anne Gilman, Wesley Turner, Steve Linthicum, and
George Ryon. 2002. An automated approach and
virtual environment for generating maintenance in-
structions. In CHI ?02: CHI ?02 extended abstracts
on Human factors in computing systems, pages 494?
495, New York, NY, USA. ACM.
Juliet C. Bourne. 1999. Generating Effective Natu-
ral Language Instructions based on Agent Expertise.
Ph.D. thesis, University of Pennsylvania.
1The results of this challenge will be made available as
part of the ENLG 2009 Workshop.
Donna Byron, Alexander Koller, Jon Oberlander, Laura
Stoia, and Kristina Striegnitz. 2007. Generating in-
structions in virtual environments (GIVE): A chal-
lenge and evaluation testbed for NLG. In Proceed-
ings of the Workshop on Shared Tasks and Compar-
ative Evaluation in Natural Language Generation,
Arlington.
Ruoyun Huang Chih-Wei Hsu, Benjamin W. Wah and
Yixin Chen. 2006. Handling soft constraints and
goals preferences in SGPlan. In ICAPS Workshop
on Preferences and Soft Constraints in Planning.
Robert Dale and Sabine Geldof. 2003. Coral: Using
natural language generation for navigational assis-
tance. In Proceedings of the 26th Australasian Com-
puter Science Conference.
C. Galindo, A. Saffiotti, S. Coradeschi, P. Buschka,
J.A. Fernandez-Madrigal, and J. Gonzalez. 2005.
Multi-hierarchical semantic maps for mobile
robotics. Intelligent Robots and Systems, 2005.
(IROS 2005). 2005 IEEE/RSJ International Confer-
ence on, pages 2278?2283, Aug.
John D. Kelleher and Geert-Jan M. Kruijff. 2005. A
context-dependent algorithm for generating locative
expressions in physically situated environments. In
Proceedings of ENLG-05, Aberdeen, Scotland.
Alexander Koller, Johanna Moore, Barbara di Eugenio,
James Lester, Laura Stoia, Donna Byron, Jon Ober-
lander, and Kristina Striegnitz. 2007. Shared task
proposal: Instruction giving in virtual worlds. In
Michael White and Robert Dale, editors, Working
group reports of the Workshop on Shared Tasks and
Comparative Evaluation in Natural Language Gen-
eration.
S. M. LaValle. 2006. Planning Algorithms. Cam-
bridge University Press, Cambridge, U.K. Available
at http://planning.cs.uiuc.edu/.
Christian Muller. 2002. Multimodal dialog in a mobile
pedestrian navigation system. IDS-2002.
E. Reiter and R. Dale. 1992. A fast algorithm for the
generation of referring expressions. In Proceedings
of the 14th conference on Computational linguistics,
Nantes, France.
Laura Stoia, Donna Byron, Darla Shockley, and Eric
Fosler-Lussier. 2006. Sentence planning for real-
time navigational instructions. In Proceedings of
the Human Language Technology Conference of the
North American Chapter of the ACL.
Sebastian Varges. 2005. Spatial descriptions as refer-
ring expressions in the maptask domain. In Proc. of
the 10th European Workshop on Natural Language
Generation.
Jett Viethen and Robert Dale. 2008. The use of spatial
relations in referring expression generation. In Fifth
International Natural Language Generation Confer-
ence.
73
NIL-UCM: Most-Frequent-Value-First Attribute Selection and
Best-Scoring-Choice Realization
Pablo Gerva?s, Raquel Herva?s, Carlos Leo?n
Natural Interaction based on Language (NIL)
Universidad Complutense de Madrid
c/ Profesor Jose? Garc??a Santesmases s/n, 28040 Madrid, Spain
pgervas@sip.ucm.es, raquelhb@fdi.ucm.es, cleon@fdi.ucm.es
1 Introduction
The NIL entry for the challenge has been con-
structed upon the general architecture for develop-
ing Natural Language Generation systems provided
by the TAP project (Gerva?s, 2007). TAP (Text Ar-
ranging Pipeline) is a set of interfaces that define
generic functionality for a pipeline of tasks oriented
toward natural language generation, from an initial
conceptual input to surface realization as a string,
with intervening stages of content planning and sen-
tence planning.
The TAP architecture considers three basic stages:
content planning, sentence planning and surface re-
alization. Of these, the first stage is not relevant to
the challenge tasks. The configuration choices ap-
plied to the other two stages to adapt them to the
challenge tasks are described below.
2 NIL-UCM-MFVF Entry for Task 1
The NIL-UCM-MFVF for Task 1 applies a Most-
Frequent-Value-First method for Attribute Selec-
tion. Of the five evaluation dimensions considered
in this challenge (Dice, MASI, accuracy, minimal-
ity and uniqueness), this method has been designed
to address explicitly only three: Dice, MASI and
uniqueness. Minimality was abandoned in view of
results in previous challenges (Herva?s and Gerva?s,
2007) that showed good minimality results tended to
produce low Dice scores. We have also opted for not
using accuracy evaluation to fit the performance of
our system, since the corpus contains a wide range
of style of reference and we are interested in pro-
viding our system with only a subset of these that
ensure correct identification.
2.1 Most-Frequent-Value-First Attribute
Selection
The selection algorithm employed is an adapta-
tion of the algorithm described in (Reiter and Dale,
1992). The original algorithm has been modified to
allow for a dynamically changing list of preferred
attributes, which determine the particular order in
which attributes are considered to generate the dis-
tinguishing expression. This list is constructed dy-
namically for each reference by computing the prob-
ability of occurrence in the corpus of the particu-
lar attribute-value pairs associated with the referent,
and using those probabilities to rank them into a spe-
cific list of preferred attributes. The idea is that at-
tributes should be considered in a particular order
depending highly on their values. For example, in
the people domain we have observed that almost
the 100% of the target entities that have beard (at-
tribute has value 1) are referred using the attribute
hasBeard, but when this attribute has value 0 it is
never used. For the hasHair attribute, the opposite
seems to be the case (mentioned only when lacking).
The training data was studied to obtain the prob-
ability of occurrence of an attribute given a certain
value for it. This probability was calculated using
Formula 1:
probvali =
?
appsV alueInAttSet
?
appsV alueInTarget (1)
For each possible value of each of the attributes
of the domains, the sum of the appearances of this
value in the ATTRIBUTE-SET elements (appsVal-
ueInAttSet) and the sum of the appearances of this
value in the attributes of all targets (appsValueInTar-
get) are calculated. The division of these two values
is the probability of mentioning an attribute when it
has a specific value.
215
Dice MASI Accuracy Uniqueness Minimality
Train. Furniture 79,18% 56,95% 41,69% 100% 0%
People 69,71% 42,41% 22,99% 100% 0%
Both 74,80% 50,23% 34,81% 100% 0%
Dev. Furniture 77,55% 53,97% 41,25% 100% 0%
People 70,86% 42,59% 22,06% 100% 0%
Both 74,48% 48,75% 32,43% 100% 0%
Table 1:Task 1 results for training and development data
Some examples of the results obtained are that the
attribute hasGlasses is mentioned in the 60% of
the situations when its value is 1, and in the 0% of
the situations when its value is 0. On the contrary,
the attribute hasShirt is almost never mentioned
(0.8% when its value is 1 and 0% with value 0).
The only exception in the algorithm is the type
attribute for the people domain. As every entity in
this domain is of type person, the attribute selector
does not choose this attribute because no distractor
is discarded by it. However, the experiments have
shown us that in the corpus a lot of descriptions in-
clude the type person even when it is redundant.
Following this idea, our algorithm always includes
the type in the list of chosen attributes for the peo-
ple domain.1
2.2 Obtained Results
Results obtained over the training and development
data are shown in Table 1. As can be seen com-
paring both tables there are no surprises in the final
results: the system gets similar results with both do-
mains and with both the training and development
data. These results confirm that the probability of
appearance of an attribute depending on its value is
more or less the same in the whole corpus.
3 NIL-UCM-BSC Entry for Task 2
The NIL-UCM-BSC for Task 2 applies a Best-
Scoring-Choice approach to Realization.
The realization tasks of the 2008 GRE challenge
required specific instantiations of the Referring Ex-
1We have only recently discovered that the surprising differ-
ence between NIL-UCM results for the people and the furniture
domains in the 2007 GRE challenge was the mostly due to our
not having taken this issue into account at the time. The effect
is noticeable only when the type attribute is redundant, as it is
in the people domain.
pression Generation, Syntactic Choice, and Lexical-
ization stages of the Sentence Planning module of
TAP, and it draws on the SurReal (Gerva?s, 2006) sur-
face realization module. SurReal provides a Java im-
plementation of the surface realization mechanisms
of FUF described in Elhadad (Elhadad, 1993), op-
erating over a grammar which follows the notational
conventions of the SURGE grammar in Elhadad (El-
hadad and Robin, 1996), but it is not systemic in na-
ture. It currently has much smaller coverage than the
original, but quite sufficient to deal with the kind of
realizations required for the challenge tasks.
3.1 Realization Choices in the Corpus
An analysis of the domain was carried out to ascer-
tain what the various alternatives required for real-
ization were for the given corpus, both in terms of
how to realize syntactically the different concepts
and what alternative lexicalizations should be con-
sidered. With respect to linguistic variation in the
form of expression we have distinguished between
choices that give rise to different syntactic struc-
tures (which we consider as syntactic choices) and
choices which give rise to the same syntactic struc-
tures but with different lexical items (which we con-
sider as lexical choices).
With respect to the Referring Expression Genera-
tion stage, the following issues required specific de-
cisions. The use of determiners is erratic. Some
examples in the corpus use indefinite article, some
use definite articles, and some omit the determin-
ers altogether. The corpus shows many cases where
spatial expressions describing the location of refer-
ents are used, many using different systems of refer-
ence (north-south vs. top-bottom). The use of par-
ticular features of the object in its description, as
in ?the desk with the drawers facing the viewer? or
?the chair with the seat facing away?. Comparison
216
with all or some of the distractors are also used, ei-
ther as adjuncts describing their position relative to
other distractors, as in ?the blue fan next to the green
fan?, or as comparative adjectives used for particu-
lar attributes, as in ?the largest red couch? (and even
combinations of the two as in ?the smaller of the two
blue fans?). Finally, there are samples in the corpus
of use of ellipsis and ungrammatical expressions.
The mention of particular features and the use of
comparison would involve operating on more data
than are generated in task 1, and the current sub-
mission is aimed to interconnection with task 2 for
addressing task 3. The issue of ungrammaticality is
important since it implies that there is an upper limit
to the possible scores that the system may achieve
over the corpus under the circumstances, totally un-
related with the correctness of the generated expres-
sions.
With respect to Syntactic Choice, some attributes
show more than one possible option for syntac-
tic realization. The number of alternatives varies
from color (?grey chair - chair that is gray?), through
beards (?with beard - with the beard - with whiskers
- the bearded man - with a beard - with facial hair?)
to orientation (12 different syntactic alternatives for
expressing orientation: back).
There are slight variations of Lexical Choice over
the corpus, as in ?sofa - couch - settee - loveseat?,
?ventilator - fan - windmill? or ?man - guy - bloke?
(for nouns) and ?large - big? or ?small - little? (for
adjectives). Because it has a significant impact on
the edit distance measure, it is also important to con-
sider the existence of a large number of misspellings
in the corpus. Finally, there are some conceptual
mismatches in annotation, between the attribute
set and the given realization in some cases (?purple
- blue?, ?black and white - grey?,...).
3.2 Best Scoring Choice Solution
The solution employed in the present submission
for selecting among the features described above
implements straight forward realization rather than
choice, in the sense in which (Cahill, 1998) uses the
terms for lexicalization. To implement real choice
the system would have to consider more than one al-
ternative for a specific feature and to select one of
them based on some criteria. This has not been done
in the present submission. Instead, a single alterna-
tive has been implemented for each feature, using
it consistently across all samples. The selection of
which particular alternative to implement has been
done empirically to ensure the best possible score
over the training corpus.
3.3 Results and Discussion
Results obtained over the training and development
data are shown in Table 2.
SE distance Accuracy
Train. Furniture 4,26 14,15%
People 5,43 9,12%
Both 4,8 11,82%
Dev. Furniture 4,21 15%
People 4,94 7,35%
Both 4,54 11,48%
Table 2:Task 2 results for training and development data
An important point to consider with respect to
the current submission is whether a solution im-
plementing real choice would have obtained bet-
ter results. Such a solution might have benefited
from the information that can be extracted from the
ANNOTATED-WORD-STRING to train a decision
procedure on the various features. This has not been
addressed in the present submission more for lack of
time than lack of conviction on its merit.
Addressing explicitly some of the possible con-
structions that are described in section 3.1 may also
have a positive effect on the results.
4 NIL-UCM-FVBS Entry for Task 3
The NIL-UCM-FVBS entry for Task 3 applies
a combination of the Most-Frequent-Value-First
method for Attribute Selection and the Best-
Scoring-Choice approach to Realization.
The modular architecture of TAP has allowed
easy integration for Task 3 of the solution for at-
tribute selection described in section 2, and the so-
lution for realization described in section 3.
4.1 Results and Discussion
Results obtained over the training and development
data are shown in Table 3. Comparing both sets of
results there are no surprises in the final results: the
system gets similar results with both domains and
217
with both the training and development data. These
results confirm that the probability of appearance of
an attribute depending on its value is more or less
the same in the whole corpus.
SE distance Accuracy
Train. Furniture 5,03 5,03%
People 6,11 5,47%
Both 5,53 5,24%
Dev. Furniture 5,06 3,75%
People 6,24 1,47%
Both 5,60 2,70%
Table 3:Task 3 results for training and development data
The results obtained are a bit lower than the ones
obtained by both the attribute selection and realiza-
tion submodules separately. This is not an unex-
pected result. Bad choices produced in the attribute
selection are propagated through the realization, re-
sulting in accumulated errors in the final evaluation.
However, there are additional shortcomings that
arise from considering the general goal of task 3
as a composition of task 2 over task 1. The re-
duction of the types of expression produced by hu-
man subjects to a set of attributes involves in some
cases a certain loss of information. This is par-
ticularly the case when the human-produced ex-
pressions involve attributes for which additional in-
formation is provided. This can be seen if the
ANNOTATED-WORD-STRING is compared with
the actual attribute set generated for some of the
human-produced expressions. For instance, the cor-
pus contains examples in which the hasBeard at-
tribute has a nested attribute that indicates the beard
is white. Other examples provide color information
on pieces of clothing worn. This information is lost
to the realization stage if the data have to go through
task 1, which reduces the available format to a set of
individual unstructured attributes.
Considering a version of task 3 that allowed full
realization directly from input data as considered for
task 1, with no requirements on the stages of inter-
mediate representation to be employed in the pro-
cess, may result in a richer range of realizations, and
possibly in improved performance with respect to
human evaluation.
In more general terms, it seems that the corpus
does contain adequate data for informing system
performance at the level of sentence planning sub-
tasks such as lexical choice or syntactic choice. Nev-
ertheless, some of the variations in the corpus, such
as the free use of determiners or the flexibility that
subjects exhibit in the way they refer to the images
do introduce a certain ?noise?. Instances of these oc-
cur when human-produced descriptions involve in-
tense forms of ellipsis, and agrammatical ordering
of attributes. Some of these might be reduced if a re-
fined version of the corpus were produced with more
control on the experimental settings, to ensure that
subjects either described the elements as images or
as the things represented in the images, for instance.
Acknowledgments
This research is funded by the Spanish Ministry
of Education and Science (TIN2006-14433-C02-01
project) and the UCM and the Direccio?n General de
Universidades e Investigacio?n of the CAM (CCG07-
UCM/TIC-2803).
References
Cahill, Lyne. 1998. Lexicalisation in applied NLG sys-
tems. Technical Report ITRI-99-04.
Elhadad, Michael. 1993. Technical Report CUCS-038-
91. Columbia University.
Elhadad, Michael and Robin, Jacques. 1996. Technical
Report 96-03. Department of Computer Science, Ben
Gurion University.
Gerva?s, Pablo. 2006. SurReal: a Surface Realiza-
tion module. Natural Interaction based on Language
Group Technical Report, Universidad Complutense de
Madrid, Spain.
Gerva?s, Pablo. 2007. TAP: a Text Arranging Pipeline.
Natural Interaction based on Language Group Tech-
nical Report, Universidad Complutense de Madrid,
Spain.
Herva?s, Raquel and Gerva?s, Pablo. 2007. NIL: Attribute
Selection for Matching the Task Corpus Using Rela-
tive Attribute Groupings Obtained from the Test Data.
First NLG Challenge on Attribute Selection for Gener-
ating Referring Expressions (ASGRE), UCNLG+MT
Workshop, Machine Translation Summit XI, Copen-
hagen.
Reiter, Ehud and Dale, Robert. 1992. A fast algorithm
for the generation of referring expressions. Proceed-
ings of the 14th conference on Computational Linguis-
tics, pp. 232-238. Association for Computational Lin-
guistics.
218
