Proceedings of the 2012 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural
Language Learning, pages 1445?1454, Jeju Island, Korea, 12?14 July 2012. c?2012 Association for Computational Linguistics
Unified Dependency Parsing of Chinese Morphological
and Syntactic Structures
Zhongguo Li Guodong Zhou
Natural Language Processing Laboratory
School of Computer Science and Technology
Soochow University, Suzhou, Jiangsu Province 215006, China
{lzg, gdzhou}@suda.edu.cn
Abstract
Most previous approaches to syntactic pars-
ing of Chinese rely on a preprocessing step
of word segmentation, thereby assuming there
was a clearly defined boundary between mor-
phology and syntax in Chinese. We show
how this assumption can fail badly, leading
to many out-of-vocabulary words and incom-
patible annotations. Hence in practice the
strict separation of morphology and syntax in
the Chinese language proves to be untenable.
We present a unified dependency parsing ap-
proach for Chinese which takes unsegmented
sentences as input and outputs both morpho-
logical and syntactic structures with a single
model and algorithm. By removing the inter-
mediate word segmentation, the unified parser
no longer needs separate notions for words
and phrases. Evaluation proves the effective-
ness of the unified model and algorithm in
parsing structures of words, phrases and sen-
tences simultaneously. 1
1 Introduction
The formulation of the concept of words has baf-
fled linguists from ancient to modern times (Hock-
ett, 1969). Things are even worse for Chinese, partly
due to the fact that its written form does not delimit
words explicitly. While we have no doubt that there
are linguistic units which are definitely words (or
phrases, for that matter), it?s a sad truth that in many
cases we cannot manage to draw such a clear bound-
ary between morphology and syntax, for which we
now give two arguments.
1Corresponding author is Guodong Zhou.
The first argument is that many sub-word linguis-
tic units (such as suffixes and prefixes) are so pro-
ductive that they can lead to a huge number of out-
of-vocabulary words for natural language process-
ing systems. This phenomenon brings us into an
awkward situation if we adhere to a rigid separa-
tion of morphology and syntax. Consider charac-
ter ? ?someone? as an example. On the one hand,
there is strong evidence that it?s not a word as it can
never be used alone. On the other hand, taking it as a
mere suffix leads to many out-of-vocabulary words
because of the productivity of such characters. For
instance, Penn Chinese Treebank (CTB6) contains
??? ?one that fails? as a word but not ???
?one that succeeds?, even with the word ?? ?suc-
ceed? appearing 207 times. We call words like ?
?? ?one that succeeds? pseudo OOVs. By defini-
tion, pseudo OOVs are OOVs since they do not occur
in the training corpus, though their components are
frequently-seen words. Our estimation is that over
60% of OOVs in Chinese are of this kind (Section 2).
Of course, the way out of this dilemma is to parse
the internal structures of these words. That is to
say, we can still regard characters like ? as suf-
fixes, taking into account the fact that they cannot be
used alone. Meanwhile, pseudo OOVs can be largely
eliminated through analyzing their structures, thus
greatly facilitating syntactic and semantic analysis
of sentences. In fact, previous studies have revealed
other good reasons for parsing internal structures of
words (Zhao, 2009; Li, 2011).
The second argument is that in Chinese many lin-
guistic units can form both words and phrases with
exactly the same meaning and part-of-speech, which
1445
?? NN ?? NN ? NN
MOD MOD
? NN ? NN
MOD
Figure 1: Unified parsing of words and phrases.
causes lots of incompatible annotations in currently
available corpora. Take character? ?law? as an ex-
ample. It is head of both?? ?criminal law? and?
???? ?environmental protection law?, but CTB
treat it as a suffix in the former (with the annotation
being ??_NN) and a word in the later (the anno-
tation is??_NN??_NN?_NN). These annota-
tions are incompatible since in both cases the char-
acter ? ?law? bears exactly the same meaning and
usage (e.g. part-of-speech). We examined several
widely used corpora and found that about 90% of
affixes were annotated incompatibly (Section 2). In-
compatibility can be avoided through parsing struc-
tures of both words and phrases. Figure 1 conveys
this idea. A further benefit of unified parsing is to
reduce data sparseness. As an example, in CTB6?
?machine? appears twice in phrases but 377 times in
words (e.g. ??? ?accelerator?). Word structures
in Chinese can be excellent guide for parsing phrase
structures, and vice versa, due to their similarity.
The present paper makes two contributions in
light of these issues. Firstly, in order to get rid of
pseudo OOVs and incompatible annotations, we have
annotated structures of words in CTB6, after which
statistical models can learn structures of words as
well as phrases from the augmented treebank (Sec-
tion 4). Although previous authors have noticed
the importance of word-structure parsing (Li, 2011;
Zhao, 2009), no detailed description about annota-
tion of word structures has been provided in the liter-
ature. Secondly, we designed a unified dependency
parser whose input is unsegmented sentences and
its output incorporates both morphological and syn-
tactic structures with a single model and algorithm
(Section 5). By removing the intermediate step of
word segmentation, our unified parser no longer de-
pends on the unsound notion that there is a clear
boundary between words and phrases. Evaluation
(Section 6) shows that our unified parser achieves
satisfactory accuracies in parsing both morphologi-
cal and syntactic structures.
corpus OOV pseudo percent
CTB6 158 112 70.9
MSR 1,783 1,307 73.3
PKU 2,860 1,836 64.2
AS 3,020 2,143 71.0
CITYU 1,665 1,100 66.0
Table 1: Statistics of pseudo OOVs for five corpora.
2 Pseudo OOVs and Incompatible
Annotations
In this section we show the surprisingly pervasive
nature of pseudo OOVs and incompatible annota-
tions through analysis of five segmented corpora,
which are CTB6 and corpus by MSR, PKU, AS
and CITYU provided in SIGHAN word segmentation
Bakeoffs 2.
First we use the standard split of training and test-
ing data and extract all OOVs for each corpus, then
count the number of pseudo OOVs. Table 1 gives the
result. It?s amazing that for every corpus, over 60%
of OOVs are pseudo, meaning they can be avoided if
their internal structures were parsed. Reduction of
OOVs at such a large scale can benefit greatly down-
stream natural language processing systems.
We then sample 200 word types containing a pro-
ductive affix from each corpus, and check whether
the affix also occurs somewhere else in a phrase,
i.e, the affix is annotated as a word in the phrase.
The results are in Table 2. It?s clear and somewhat
shocking that most affixes are annotated incompat-
ibly. We believe it is not the annotators to blame,
rather the root cause lies deeply in the unique char-
acteristics of the Chinese language. This becomes
obvious in comparison with English, where suffix
like ?-ism? in ?capitalism? cannot be used alone as a
word in phrases. 3 Incompatible annotations can
be removed only through unified parsing of word
and phrase structures, as mentioned earlier and il-
lustrated in Figure 1.
2http://www.sighan.org/bakeoff2005/
3Actually English allows examples like ?pre- and post-war
imperialism? where a prefix like ?pre? can appear on its own as
long as the hyphen is present and it is in a coordination struc-
ture. Note that such examples are much rarer than what we
discuss in this paper for Chinese. We thank the reviewer very
much for pointing this out and providing this example for us.
1446
corpus incompatible percent
CTB6 190 95
MSR 178 89
PKU 192 96
AS 182 91
CITYU 194 97
Table 2: Statistics of incompatibly annotated affixes in
200 sampled words for five segmented corpora.
?? NR ? NN ?? VV ?? NN ? NN
MOD MOD
OBJ
SUBJ
Figure 2: Example output of unified dependency parsing
of Chinese morphological and syntactic structures.
3 Unified Parsing Defined
Given an unsegmented sentence ???????
? ?Gansu province attaches great importance to in-
surance industry?, the output of unified dependency
parser is shown in Figure 2. As can be seen, this
output contains information about word (such as?
?_VV) as well as phrase structures (such as ?
?_VV ??_NN ?_NN), which is what we mean
by ?unified? parsing. Now, it?s no longer vital to dif-
ferentiate between morphology and syntax for Chi-
nese. People could regard??? ?insurance indus-
try? as a word or phrase, but either way, there will be
no disagreements about its internal structure. From
the perspective of the unified parser, linguistic units
are given the same labels as long as they function
similarly (e.g, they have the same parts-of-speech).
As a bonus, output of unified parsing incorpo-
rates Chinese word segmentation, part-of-speech
tagging and dependency parsing. To achieve these
goals, previous systems usually used a pipelined
approach by combining several statistical models,
which was further complicated by different decod-
ing algorithms for each of these models. The present
paper shows that a single model does all these jobs.
Besides being much simpler in engineering such a
parser, this approach is also a lot more plausible for
modeling human language understanding.
4 Annotation of Word Structures
Unified parsing requires a corpus annotated with
both morphological and syntactic structures. Such
a corpus can be built with the least effort if we be-
gin with an existing treebank such as CTB6 already
annotated with syntactic structures. It only remains
for us to annotate internal structures of words in this
treebank.
4.1 Scope of Annotation
In order to get rid of pseudo OOVs and incompati-
ble annotations, internal structures are annotated for
two kinds of words. The first kind contains words
with a productive component such as suffix or pre-
fix. One example is??? ?speaker? whose suffix
is the very productive? ?person? (e.g, in CTB6 there
are about 400 words having this suffix). The second
kind includes words with compositional semantics.
Examples are ??? ?Monday? and ??? ?Sun-
day?. Though ?? ?week? is not very productive,
the meaning of words with this prefix is deducible
from semantics of their components.
Other compound words such as ?? ?research?
have no productive components and are not a cause
of pseudo OOVs. They are universally consid-
ered as words instead of phrases due to their non-
compositional semantics. Hence their structures are
not annotated in the present research. Meanwhile,
for single-morpheme words with no structures what-
soever, like??? ?Iraq? and?? ?bat?, annotation
of internal structures is of course unnecessary either.
Of all the 54, 214 word types in CTB6, 35% are
annotated, while the percentage is 24% for the 782,
901 word tokens. Around 80% of sentences contain
words whose structures need annotation. Our anno-
tations will be made publicly available for research
purposes.
4.2 From Part-of-speeches to Constituents
Of all 33 part-of-speech tags in CTB, annotation of
word structures is needed for nine tags: NN, VV, JJ,
CD, NT, NR, AD, VA and OD. Since part-of-speech
tags are preterminals and can only have one terminal
word as its child, POS tags of words become con-
stituent labels after annotation of word structures.
The mapping rules from POS tags to constituent la-
bels are listed in Table 3. Readers should note that
1447
POS tags constituent label
NR, NN, NT NP
JJ ADJP
AD ADVP
CD, OD QP
VV, VA VP
Table 3: Correspondence between POS tags and con-
stituent labels after annotation.
PP
????
P
?
NP
NN
???
? PP????
P
?
NP
????
NN
??
NN
?
Figure 3: Example annotation for the word ??? NN
in CTB6: POS tag NN changes to constituent label NP
after annotation.
such mapping is not arbitrary. The constraint is that
in the treebank the POS tag must somewhere be the
unique child of the constituent label. Figure 3 de-
picts an example annotation, in which we also have
an example of NP having a tag NN as its only child.
4.3 Recursive Annotation
Some words in CTB have very complex structures.
Examples include ??????? ?physicist ma-
joring in nuclear physics?, ????? ?anti-trust
laws? etc. Structures of these words are anno-
tated to their full possible depth. Existence of such
words are characteristic of the Chinese language,
since they are further demonstrations of the blurred
boundary between morphology and syntax. A full-
fledged parser is needed to analyze structures of
these words, which incidentally provides us with an-
other motivation for unified morphological and syn-
tactic parsing of Chinese.
5 Unified Dependency Parsing
All previous dependency parsers for Chinese take it
for granted that the input sentence is already seg-
mented into words (Li et al 2011). Most systems
even require words to be tagged with their part-of-
speeches (Zhang and Nivre, 2011). Hence current
off-the-shelf algorithms are inadequate for parsing
unsegmented sentences. Instead, a new unified pars-
ing algorithm is given in this section.
5.1 Transitions
To map a raw sentence directly to output shown in
Figure 2, we define four transitions for the unified
dependency parser. They act on a stack containing
the incremental parsing results, and a queue holding
the incoming Chinese characters of the sentence:
SHIFT: the first character in the queue is shifted into
the stack as the start of a new word. The queue
should not be empty.
LEFT: the top two words of the stack are connected
with an arc, with the top one being the head. There
should be at least two elements on the stack.
RIGHT: the top two words of the stack are con-
nected, but with the top word being the child. The
precondition is the same as that of LEFT.
APPEND: the first character in the queue is appended
to the word at the top of the stack. There are two
preconditions. First, the queue should not be empty.
Second, the top of the stack must be a word with no
arcs connected to other words (i.e, up to now it has
got neither children nor parent).
We see that these transitions mimic the general arc-
standard dependency parsing models. The first three
of them were used, for example, by Yamada and
Matsumoto (2003) to parse English sentences. The
only novel addition is APPEND, which is necessary
because we are dealing with raw sentences. Its sole
purpose is to assemble characters into words with
no internal structures, such as ??? ?Seattle?.
Thus this transition is the key for removing the need
of Chinese word segmentation and parsing unseg-
mented sentences directly.
To also output part-of-speech tags and depen-
dency labels, the transitions above can be aug-
mented accordingly. Hence we can change SHIFT to
SHIFT?X where X represents a certain POS tag. Also,
LEFT and RIGHT should be augmented with appro-
priate dependency relations, such as LEFT?SUBJ for
a dependency between verb and subject.
As a demonstration of the usage of these tran-
sitions, consider sentence ?????? ?I love
Seattle?. Table 4 lists all steps of the parsing pro-
cess. Readers interested in implementing their own
1448
step stack queue action
1 ?????? SHIFT?PN
2 ? PN ????? SHIFT?VV
3 ? PN? VV ???? APPEND
4 ? PN?? VV ??? LEFT?SUBJ
5 ? PN SUBJ?????? VV ??? SHIFT?NR
6 ? PN SUBJ?????? VV? NR ?? APPEND
7 ? PN SUBJ?????? VV?? NR ? APPEND
8 ? PN SUBJ?????? VV??? NR RIGHT?OBJ
9 ? PN SUBJ?????? VV OBJ?????? NR STOP
Table 4: Parsing process of a short sentence with the four transitions defined above.
unified dependency parsers are invited to study this
example carefully.
5.2 Model
Due to structural ambiguity, there might be quite a
lot of possibilities for parsing a given raw sentence.
Hence at each step in the parsing process, all four
transitions defined above may be applicable. To re-
solve ambiguities, each candidate parse is scored
with a global linear model defined as follows.
For an input sentence x, the parsing result F (x) is
the one with the highest score in all possible struc-
tures for this x:
F (x) = argmax
y?GEN(x)
Score(y) (1)
Here GEN(x) is a set of all possible parses for sen-
tence x, and Score(y) is a real-valued linear func-
tion:
Score(y) = ?(y) ? ~w (2)
where ?(y) is a global feature vector extracted from
parsing result y, and ~w is a vector of weighting pa-
rameters. Because of its linearity, Score(y) can be
computed incrementally, following the transition of
each parsing step. Parameter vector ~w is trained
with the generalized perceptron algorithm of Collins
(2002). The early-update strategy of Collins and
Roark (2004) is used so as to improve accuracy and
speed up the training.
5.3 Feature Templates
For a particular parse y, we now describe the way
of computing its feature vector ?(y) in the linear
Description Feature Templates
1 top of S S0wt; S0w; S0t
2 next top of S S1wt; S1w; S1t
3 S0 and S1 S1wtS0wt; S1wtS0w
S1wS0wt; S1wtS0t
S1tS0wt; S1wS0w; S1tS0t
4 char unigrams Q0; Q1; Q2; Q3
5 char bigrams Q0Q1; Q1Q2; Q2Q3
6 char trigrams Q0Q1Q2; Q1Q2Q3
7 ST+unigrams STwtQ0; STwQ0; STtQ0
8 ST+bigrams STwtQ0Q1; STwQ0Q1
STtQ0Q1
9 ST+trigrams STwtQ0Q1Q2
STwQ0Q1Q2; STtQ0Q1Q2
10 parent P of ST PtSTtQ0; PtSTtQ0Q1
PtSTtQ0Q1Q2
11 leftmost child STtLCtQ0; STtLCtQ0Q1
LC and STtLCtQ0Q1Q2
rightmost STtRCtQ0; STtRCtQ0Q1
child RC STtRCtQ0Q1Q2
Table 5: Transition-based feature templates. Q0 is the
first character in Q, etc. w = word, t = POS tag.
model of Equation (2). If S denotes the stack hold-
ing the partial results, and Q the queue storing the
incoming Chinese characters of a raw sentence, then
transition-based parsing features are extracted from
S and Q according to those feature templates in Ta-
ble 5.
Although we employ transition-based parsing,
nothing prevents us from using graph-based fea-
tures. As shown by Zhang and Clark (2011), depen-
1449
Description Feature Templates
1 parent word Pwt; Pw; Pt
2 child word Cwt; Cw; Ct
3 P and C PwtCwt; PwtCw; PwCwt
PtCwt; PwCw; PtCt
PwtCt
4 neighbor word PtPLtCtCLt; PtPLtCtCRt
of P and C PtPRtCtCLt; PtPRtCtCRt
left (L) or PtPLtCLt; PtPLtCRt
right (R) PtPRtCLt; PtPRtCRt
PLtCtCLt; PLtCtCRt
PRtCtCLt; PRtCtCRt
PtCtCLt; PtCtCRt
PtPLtCt; PtPRtCt
5 sibling(S) of C CwSw;CtSt; CwSt
CtSw; PtCtSt
6 leftmost and PtCtCLCt
rightmost child PtCtCRCt
7 left (la) and Ptla; Ptra
right (ra) Pwtla; Pwtra
arity of P Pwla; Pwra
Table 6: Graph-based feature templates for the unified
parser. Most of these templates are adapted from those
used by Zhang and Clark (2011). w = word; t = POS tag.
dency parsers using both transition-based and graph-
based features tend to achieve higher accuracy than
parsers which only make use of one kind of features.
Table 6 gives the graph-based feature templates used
in our parser. All such templates are instantiated at
the earliest possible time, in order to reduce as much
as possible situations where correct parses fall out of
the beam during decoding.
5.4 Decoding Algorithm
We use beam-search to find the best parse for a given
raw sentence (Algorithm 1). This algorithm uses
double beams. The first beam contains unfinished
parsing results, while the second holds completed
parses. Double beams are necessary because the
number of transitions might well be different for dif-
ferent parses, and those parses that finished earlier
are not necessarily better parses. During the search-
ing process, correct parse could fall off the beams,
resulting in a search error. However, in practice
beam search decoding algorithm works quite well.
In addition, it?s not feasible to use dynamic program-
ming because of the complicated features used in the
model.
The B in Algorithm 1 is the width of the two
beams. In our experiments we set B to 64. This
value of B was determined empirically by using the
standard development set of the data, with the goal
of achieving the highest possible accuracy within
reasonable time. Note that in line 20 of the algo-
rithm, the beam for completed parsers are pruned at
each iteration of the parsing process. The purpose
of this action is to keep this beam from growing too
big, resulting in a waste of memory space.
Algorithm 1 Beam Search Decoding
1: candidates? {STARTITEM()}
2: agenda? ?
3: completed? ?
4: loop
5: for all candidate in candidates do
6: for all legal action of candidate do
7: newc? EXPAND(candidate, action)
8: if COMPLETED(newc) then
9: completed.INSERT(newc)
10: else
11: agenda.INSERT(newc)
12: end if
13: end for
14: end for
15: if EMPTY(agenda) then
16: return TOP(completed)
17: end if
18: candidates? TOPB(agenda, B)
19: agenda? ?
20: completed? TOPB(completed, B)
21: end loop
6 Experiments and Evaluation
We describe the experiments carried out and our
method of evaluation of the unified dependency
parser. We used Penn2Malt 4 to convert constituent
trees of CTB to dependency relations. The head rules
for this conversion was given by Zhang and Clark
(2008). In all experiments, we followed the stan-
4http://w3.msi.vxu.se/
?
nivre/research/
Penn2Malt.html
1450
P R F
our method, labeled 78.54 80.93 79.72
our method, unlabeled 81.01 83.77 82.37
ZC2011, unlabeled N/A N/A 75.09
Table 7: Evaluation results on the original CTB5. N/A
means the value is not available to us. ZC2011 is Zhang
and Clark (2011).
dard split of the data into training, testing and devel-
opment data (Zhang and Clark, 2011). Though we
annotated structures of words in CTB6, most previ-
ously results were on CTB5, a subset of the former
treebank. Hence we report our results of evaluation
on CTB5 for better comparability.
6.1 Dependency Parsing of Morphological and
Syntactic Structures
If we look back at the Figure 2, it?s clear that a
dependency relation is correctly parsed if and only
if three conditions are met: Firstly, words at both
ends of the dependency are correctly segmented.
Secondly, part-of-speech tags are correct for both
words. Thirdly, the direction of the dependency re-
lation are correct. Of course, if labeled precision and
recall is to be measured, the label of the dependency
relation should also be correctly recovered. Let nc
be the number of dependencies correctly parsed with
respect to these criterion, no be the total number of
dependencies in the output, and nr the number of
dependencies in the reference. Then precision is de-
fined to be p = nc/no and recall is defined to be
r = nc/nr.
6.1.1 Results on the Original CTB5
We first train our unified dependency parser with
the original treebank CTB5. In this case, all words
are considered to be flat, with no internal structures.
The result are shown in Table 7. Note that on ex-
actly the same testing data, i.e, the original CTB5,
unified parser performs much better than the result
of a pipelined approach reported by Zhang and Clark
(2011). There are about 30% of relative error reduc-
tion for the unlabeled dependency parsing results.
This is yet another evidence of the advantage of joint
modeling in natural language processing, details of
which will be discussed in Section 7.
P R F
original dependencies 82.13 84.49 83.29
in CTB5
ZN2011 with Gold N/A N/A 84.40
segmentation & POS
original dependencies 85.71 87.18 86.44
plus word structures
Table 8: Evaluation results on CTB5 with word structures
annotated. All results are labeled scores.
6.1.2 Results on CTB with Structures of Words
Annotated
Then we train the parser with CTB5 augmented
with our annotations of internal structures of words.
For purpose of better comparability, we report re-
sults on both the original dependencies of CTB5 and
on the dependencies of CTB5 plus those of the in-
ternal structures of words. The results are shown
in Table 8. First, note that compared to another re-
sult by Zhang and Nivre (2011), whose input were
sentences with gold standard word segmentation and
POS tags, our F-score is only slightly lower even
with input of unsegmented sentences. This is un-
derstandable since gold-standard segmentation and
POS tags greatly reduced the uncertainty of parsing
results.
For the unified parser, the improvement of F-score
from 79.72% to 83.29% is attributed to the fact that
with internal structures of words annotated, parsing
of syntactic structures is also improved due to the
similarity of word and phrase structures mentioned
in Section 1, and also due to the fact that many
phrase level dependencies are now facing a much
less severe problem of data sparsity. The improve-
ment of F-score from 83.29% to 86.44% is attributed
to the annotation of word structures. Internal struc-
tures of words are be mostly local in comparison
with phrase and sentence structures. Therefore, with
the addition of word structures, the overall depen-
dency parsing accuracy naturally can be improved.
6.2 Chinese Word Segmentation
From the example in Figure 2, it is clear that output
of unified parser contains Chinese word segmenta-
tion information. Therefore, we can get results of
word segmentation for each sentence in the test sets,
1451
P R F
K2009 N/A N/A 97.87
This Paper 97.63 97.38 97.50
Table 9: Word segmentation results of our parser and
the best performance reported in literature on the same
dataset. K2009 is the result of Kruengkrai et al(2009).
P R F
K2009 N/A N/A 93.67
ZC2011 N/A N/A 93.67
This Paper 93.42 93.20 93.31
Table 10: Joint word segmentation and POS tagging
scores. K2009 is result of Kruengkrai et al(2009).
ZC2011 is result of Zhang and Clark (2011).
and evaluate their accuracies. For maximal compa-
rability, we train the unified parser on the original
CTB5 data used by previous studies. The result is
in Table 9. Despite the fact that the performance
of our unified parser does not exceed the best re-
ported result so far, which probably might be caused
by some minute implementation specific details, it?s
fair to say that our parser performs at the level of
state-of-the-art in Chinese word segmentation.
6.3 Joint Word Segmentation and POS Tagging
From Figure 2 we see that besides word segmenta-
tion, output of the unified parser also includes part-
of-speech tags. Therefore, it?s natural that we evalu-
ate the accuracy of joint Chinese word segmentation
and part of speech tagging, as reported in previous
literature (Kruengkrai et al 2009). The results are
in Table 10, in which for ease of comparison, again
we train the unified parser with the vanilla version
of CTB5. We can see that unified parser performs at
virtually the same level of accuracy compared with
previous best systems.
7 Related Work
Researchers have noticed the necessity of parsing
the internal structures of words in Chinese. Li
(2011) gave an method that could take raw sentences
as input and output phrase structures and internal
structures of words. This paper assumes that the in-
put are unsegmented, too, and our output also in-
cludes both word and phrase structures. There are
? ? ? ? ? ? ? ?
Figure 4: Example output of Zhao?s parser.
two key differences, though. The first is we output
dependency relations instead of constituent struc-
tures. Although dependencies can be extracted from
the constituent trees of Li (2011), the time complex-
ity of their algorithm is O(n5) while our parser runs
in linear time. Secondly, we specify the details of
annotating structures of words, with the annotations
being made publicly available.
Zhao (2009) presented a dependency parser which
regards each Chinese character as a word and then
analyzes the dependency relations between charac-
ters, using ordinary dependency parsing algorithms.
Our parser is different in two important ways. The
first is we output both part-of-speech tags and la-
beled dependency relations, both of which were ab-
sent in Zhao?s parser. More importantly, the AP-
PEND transition for handling flat words were unseen
in previous studies as far as we know. The difference
can best be described with an example: For the sen-
tence in Section 3, Zhao?s parser output the result in
Figure 4 while in contrast our output is Figure 2.
In recent years, considerable efforts have been
made in joint modeling and learning in natural lan-
guage processing (Lee et al 2011; Sun, 2011; Li et
al., 2011; Finkel and Manning, 2009; Kruengkrai et
al., 2009; Jiang et al 2008; Goldberg and Tsarfaty,
2008). Joint modeling can improve the performance
of NLP systems due to the obvious reason of being
able to make use of various levels of information si-
multaneously. However, the thesis of this paper, i.e,
unified parsing of Chinese word and phrase struc-
tures, bears a deeper meaning. As demonstrated in
Section 1 and by Li (2011), structures of words and
phrases usually have significant similarity, and the
distinction between them is very difficult to define,
even for expert linguists. But for real world applica-
tions, such subtle matters can safely be ignored if we
could analyzed morphological and syntactic struc-
tures in a unified framework. What applications re-
ally cares is structures instead of whether a linguistic
unit is a word or phrase.
1452
Another notable line of research closely related
to the present work is to annotate and parse the flat
structures of noun phrases (NP) (Vadas and Curran,
2007; Vadas and Curran, 2011). This paper dif-
fers from those previous work on parsing NPs in at
least two significant ways. First, we aim to parse
all kinds of words (e.g, nouns, verbs, adverbs, ad-
jectives etc) whose structures are not annotated by
CTB, and whose presence could cause lots of pseudo
OOVs and incompatible annotations. Second, the
problem we are trying to solve is a crucial obser-
vation specific to Chinese language, that is, in lots
of cases forcing a separation of words and phrases
leads to awkward situations for NLP systems. Re-
member that in Section 2 we demonstrated that all
corpora we examined had the problem of pseudo
OOVs and incompatible annotations. In comparison,
the problem Vadas and Curran (2007) tried to solve
is a lack of annotation for structures of NPs in cur-
rently available treebanks, or to put it in another way,
a problem more closely related to treebanks rather
than certain languages.
8 Discussion and Conclusion
Chinese word segmentation is an indispensable step
for traditional approaches to syntactic parsing of
Chinese. The purpose of word segmentation is to
decide what goes to words, with the remaining pro-
cessing (e.g, parsing) left to higher level structures
of phrases and sentences. This paper shows that it
could be very difficult to make such a distinction
between words and phrases. This difficulty cannot
be left unheeded, as we have shown quantitatively
that in practice it causes lots of real troubles such as
too many OOVs and incompatible annotations. We
showed how these undesirable consequences can be
resolved by annotation of the internal structures of
words, and by unified parsing of morphological and
syntactic structures in Chinese.
Unified parsing of morphological and syntactic
structures of Chinese can also be implemented with
a pipelined approach, in which we first segment in-
put sentences into words or affixes (i.e, with the
finest possible granularity), and then we do part-
of-speech tagging followed by dependency (or con-
stituent) parsing. However, a unified parsing ap-
proach using a single model as presented in this
paper offers several advantages over pipelined ap-
proaches. The first one is that joint modeling tends
to result in higher accuracy and suffer less from er-
ror propagation than do pipelined methods. Sec-
ondly, both the unified model and the algorithm
are conceptually much more simpler than pipelined
approaches. We only need one implementation of
the model and algorithm, instead of several ones in
pipelined approaches. Thirdly, our model and al-
gorithm might comes closer to modeling the pro-
cess of human language understanding, because hu-
man brain is more likely a parallel machine in un-
derstanding languages than an alternative pipelined
processor. Hence this work, together with previ-
ous studies by other authors like Li (2011) and Zhao
(2009), open up a possibly new direction for future
research efforts in parsing the Chinese language.
Acknowledgments
Reviewers of this paper offered many detailed and
highly valuable suggestions for improvement in pre-
sentation. The authors are supported by NSFC under
Grant No. 90920004 and National 863 Program un-
der Grant No. 2012AA011102.
References
Michael Collins and Brian Roark. 2004. Incremental
parsing with the perceptron algorithm. In Proceedings
of the 42nd Meeting of the Association for Computa-
tional Linguistics (ACL?04), Main Volume, pages 111?
118, Barcelona, Spain, July.
Michael Collins. 2002. Discriminative training meth-
ods for hidden markov models: Theory and experi-
ments with perceptron algorithms. In Proceedings of
the 2002 Conference on Empirical Methods in Natu-
ral Language Processing, pages 1?8. Association for
Computational Linguistics, July.
Jenny Rose Finkel and Christopher D. Manning. 2009.
Joint parsing and named entity recognition. In Pro-
ceedings of Human Language Technologies: The 2009
Annual Conference of the North American Chapter of
the Association for Computational Linguistics, pages
326?334, Boulder, Colorado, June. Association for
Computational Linguistics.
Yoav Goldberg and Reut Tsarfaty. 2008. A single gener-
ative model for joint morphological segmentation and
syntactic parsing. In Proceedings of ACL-08: HLT,
pages 371?379, Columbus, Ohio, June. Association
for Computational Linguistics.
1453
C. F. Hockett. 1969. A Course in Modern Linguistics.
Macmillan.
Wenbin Jiang, Liang Huang, Qun Liu, and Yajuan Lu?.
2008. A cascaded linear model for joint Chinese word
segmentation and part-of-speech tagging. In Proceed-
ings of ACL-08: HLT, pages 897?904, Columbus,
Ohio, June. Association for Computational Linguis-
tics.
Canasai Kruengkrai, Kiyotaka Uchimoto, Jun?ichi
Kazama, Yiou Wang, Kentaro Torisawa, and Hitoshi
Isahara. 2009. An error-driven word-character hybrid
model for joint Chinese word segmentation and POS
tagging. In Proceedings of the Joint Conference of the
47th Annual Meeting of the ACL and the 4th Interna-
tional Joint Conference on Natural Language Process-
ing of the AFNLP, pages 513?521, Suntec, Singapore,
August. Association for Computational Linguistics.
John Lee, Jason Naradowsky, and David A. Smith. 2011.
A discriminative model for joint morphological disam-
biguation and dependency parsing. In Proceedings of
the 49th Annual Meeting of the Association for Com-
putational Linguistics: Human Language Technolo-
gies, pages 885?894, Portland, Oregon, USA, June.
Association for Computational Linguistics.
Zhenghua Li, Min Zhang, Wanxiang Che, Ting Liu, Wen-
liang Chen, and Haizhou Li. 2011. Joint models for
Chinese POS tagging and dependency parsing. In Pro-
ceedings of the 2011 Conference on Empirical Meth-
ods in Natural Language Processing, pages 1180?
1191, Edinburgh, Scotland, UK., July. Association for
Computational Linguistics.
Zhongguo Li. 2011. Parsing the internal structure of
words: A new paradigm for Chinese word segmenta-
tion. In Proceedings of the 49th Annual Meeting of
the Association for Computational Linguistics: Hu-
man Language Technologies, pages 1405?1414, Port-
land, Oregon, USA, June. Association for Computa-
tional Linguistics.
Weiwei Sun. 2011. A stacked sub-word model for
joint chinese word segmentation and part-of-speech
tagging. In Proceedings of the 49th Annual Meeting
of the Association for Computational Linguistics: Hu-
man Language Technologies, pages 1385?1394, Port-
land, Oregon, USA, June. Association for Computa-
tional Linguistics.
David Vadas and James Curran. 2007. Adding noun
phrase structure to the penn treebank. In Proceed-
ings of the 45th Annual Meeting of the Association
of Computational Linguistics, pages 240?247, Prague,
Czech Republic, June. Association for Computational
Linguistics.
David Vadas and James R. Curran. 2011. Parsing noun
phrases in the penn treebank. Computational Linguis-
tics, 37(4):753?809.
Hiroyasu Yamada and Yuji Matsumoto. 2003. Statisti-
cal dependency analysis with support vector machines.
In Proceeding of the 8th International Workshop of
Parsing Technologies (IWPT), pages 195?206, Nancy,
France.
Yue Zhang and Stephen Clark. 2008. A tale of two
parsers: Investigating and combining graph-based and
transition-based dependency parsing. In Proceedings
of the 2008 Conference on Empirical Methods in Nat-
ural Language Processing, pages 562?571, Honolulu,
Hawaii, October. Association for Computational Lin-
guistics.
Yue Zhang and Stephen Clark. 2011. Syntactic process-
ing using the generalized perceptron and beam search.
Computational Linguistics, 37(1):105?151.
Yue Zhang and Joakim Nivre. 2011. Transition-based
dependency parsing with rich non-local features. In
Proceedings of the 49th Annual Meeting of the Asso-
ciation for Computational Linguistics: Human Lan-
guage Technologies, pages 188?193, Portland, Ore-
gon, USA, June. Association for Computational Lin-
guistics.
Hai Zhao. 2009. Character-level dependencies in Chi-
nese: Usefulness and learning. In Proceedings of the
12th Conference of the European Chapter of the ACL
(EACL 2009), pages 879?887, Athens, Greece, March.
Association for Computational Linguistics.
1454
Punctuation as Implicit Annotations
for Chinese Word Segmentation
Zhongguo Li?
Tsinghua University
Maosong Sun??
Tsinghua University
We present a Chinese word segmentation model learned from punctuation marks which are
perfect word delimiters. The learning is aided by a manually segmented corpus. Our method
is considerably more effective than previous methods in unknown word recognition. This is a
step toward addressing one of the toughest problems in Chinese word segmentation.
1. Introduction
Paragraphs are composed of sentences. Hence when a paragraph begins, a sentence
must begin, and as a paragraph closes, some sentence must finish. This observation
is the basis of the sentence boundary detection method proposed by Riley (1989).
Similarly, sentences consist of words. As a sentence begins or ends there must be word
boundaries.
Inspired by this notion, we invent a method to learn a Chinese word segmenta-
tion model with punctuation marks in a large raw corpus. The learning is guided by
a segmented corpus (Section 3.2). Section 4 demonstrates that our method improves
notably the recognition of out-of-vocabulary (OOV) words with respect to approaches
which use only annotated data (Xue 2003; Low, Ng, and Guo 2005). This work has
practical implications in that the OOV problem has long been a big challenge for the
research community.
2. Segmentation as Tagging
We call the first character of a Chinese word its left boundary L, and the last character
its right boundary R. If we regard L and R as random events, then we can derive four
events (or tags) from them:
b = L ?R, m = L ? R, s = L ?R, e = L ? R
? Department of Computer Science and Technology, Tsinghua University, Beijing 100084, China.
E-mail: eemath@gmail.com.
?? Department of Computer Science and Technology, Tsinghua University, Beijing 100084, China.
E-mail: sms@mail.thu.edu.cn.
Submission received: 16 July 2008; revised submission received: 26 March 2009; accepted for publication:
4 May 2009.
? 2009 Association for Computational Linguistics
Computational Linguistics Volume 35, Number 4
Here R means not R, and thus tag b represents the left but not the right boundary of
a word. The other tags can be interpreted similarly. This coding scheme was used by
Borthwick (1999) and Xue (2003), where b, m, s, and e stand for begin, middle, only
member, and end of a word, respectively. We reformulate them in terms of L and R to
facilitate the presentation of our method.
For a sentence S = c1c2 ? ? ? cn and a sequence T = t1t2 ? ? ? tn of b, m, s, e tags, we
define
P (T|S) =
n?
i=1
Pr(ti|contexti) (1)
where contexti is ci with up to four surrounding characters. The legal tag sequence
(e.g., tag b followed by s is illegal) with highest P gives the segmentation result of
S. Then from Equation (1) it is obvious that knowing the probability distribution of
b, m, s, and e given context is adequate for carrying out Chinese word segmentation. The
purpose of this article is to show that punctuation can play a major role in estimating
this distribution.
We use the maximum entropy approach to model the conditional probability
Pr(y|x), which has the following parametric form according to Berger, Della Pietra, and
Della Pietra (1996):
Pr(y|x) = 1Z(x) exp
(?
i
?i fi(x, y)
)
(2)
Z(x) =
?
y
exp
(?
i
?i fi(x, y)
)
(3)
For Chinese word segmentation, the binary valued functions fi are defined through the
10 features shown in Table 2. Xue (2003) explains how these features map to the feature
functions in Equations (2) and (3).
3. Method
Our key idea is to approximate probabilities of b, m, s, and e with those of L and R.
To do this, we assume L and R are conditionally independent given context. Then we
have
Pr(b |context) = Pr(L ?R|context) (definition of b)
= Pr(L |context) ? Pr(R|context) (independence)
= Pr(L |context) ? (1 ? Pr(R |context)) (4)
Probabilities for m, s, and e can be derived in the same way and so their derivations are
not provided here. As mentioned earlier, these probabilities are sufficient for Chinese
word segmentation. Now to model Pr(L |context) and Pr(R |context) with the maximum
506
Li and Sun Punctuation as Implicit Annotations
entropy technique, we must have positive and negative examples of L and R. It is here
that punctuation comes into play.
3.1 Positive Examples
Punctuation offers directly positive examples of L and R. For instance, we can extract
four training examples from the sentence in Table 1, as listed in Table 2.
3.2 Negative Examples
Suppose for the moment we know the real probability distribution of tags b, m, s, and e
given context. Then a character in context is itself a word and should be tagged s if
Pr(s |context) > max
y?{b,m,e}
Pr(y|context) (5)
Each positive example given by punctuation is subjected to the test in (5). If an example
labeled L passes this test, then it is also a positive example of R because s = L ?R, and
failing this test gives a negative R. In a similar way we obtain negative examples of L.
This process is summarized in Figure 1.
A segmented corpus is needed to estimate the probabilities in test (5) with maxi-
mum entropy modeling. Here we use the data provided by Microsoft Research in the
SIGHAN 2005 Bakeoff. The trained model (the MSR model) was used in earlier work
(Low, Ng, and Guo 2005) and is one of the state-of-the-art models for Chinese word
segmentation.
With the MSR model, only the last example in Table 2 passes test (5). Hence we get
the three negative examples shown in Table 3. Examples like 1, 3, 6, and 8 are used to
estimate Pr(L |context) and those like 2, 4, 5, and 7 are used to estimate Pr(R |context).
Appendix A provides more details on this issue.
Table 1
Illustration of word boundaries near punctuation in a simple sentence.
? means the label is unknown with only the help of punctuation.
sentence 3 I  ?  0  G ? 
word boundary L ? ? R L ? ? R
Table 2
Positive training examples extracted from the sentence in Table 1.
features of context
No. label c?2 c?1 c0 c1 c2 c?1c1 c?2c?1 c?1c0 c0c1 c1c2
1 L 3 I  3I I
2 R I  ? 0  0 I ? ?0 0
3 L  ? 0  G ? ? ?0 0 G
4 R  G ? G G?
507
Computational Linguistics Volume 35, Number 4
Figure 1
How to get negative examples of L and R. Test (5) is applied to all positive examples given by
punctuation. Those failing this test are negative training examples. It is test (5) that invokes the
need of a manually segmented corpus.
Table 3
Training examples derived from those in Table 2. We have 1?5, 2?6, 3?7, and 4?8.
features of context
No. label c?2 c?1 c0 c1 c2 c?1c1 c?2c?1 c?1c0 c0c1 c1c2
5 R 3 I  3I I
6 L I  ? 0  0 I ? ?0 0
7 R  ? 0  G ? ? ?0 0 G
8 L  G ? G G?
3.3 Training
In all, we collected 10 billion L-L and R-R examples, each from a comprehensive Web
corpus.1 To cope with so much training data, we use the partitioning method of Yamada
and Matsumoto (2003). An alternative is the Vowpal Wabbit (fast on-line learning)
algorithm.2 Such an algorithm allows incremental training as more raw texts become
available.
4. Evaluation
We evaluate our method with the data and scoring script provided by the SIGHAN 2005
Bakeoff. The data sets of Academia Sinica and City University of Hong Kong, which are
in Traditional Chinese, are not used here because the raw corpus is mainly in Simplified
Chinese. Table 4 gives the evaluation results on the data from Microsoft Research (MSR)
and Peking University (PKU).
It seems our method is over 10% below state of the art in precision on the MSR data.
However, we find that multiword expressions are consistently segmented into smaller
words. Take the one multiword ?-?z/vb-??v@? [Institute of Chinese
1 Freely available for research purposes. See www.sogou.com/labs.
2 http://hunch.net/?vw/. We thank one of the anonymous reviewers for telling us about this
implementation.
508
Li and Sun Punctuation as Implicit Annotations
Culture, Chinese Academy of Arts] in the standard answer of the test data as an example.
Our method segments it into six correct words ?-? z/ vb -? ? v@?
[China, art, academy, China, culture, institute], all of which are considered wrong by the
scoring script. This is arguable because the only difference is the granularity of the
segmentation.
4.1 Influence of Granularity
We check every error detected by the scoring script on the MSR data, and find that
for our method, 15,071 errors are actually correct segmentations of 5,463 multiwords,
whereas for the MSR model, the corresponding counts are 858 and 355, respectively. The
gold standard contains 106,873 words. These statistics combined with Table 4 allow us
to calculate the metrics as in Table 5, if errors caused by correctly segmented multiwords
are not counted.
We see that, when the influence of granularity is considered, our method is slightly
better than the MSR model. However, as Table 4 shows, both models degrade on the
PKU data due to the difference in segmentation standards. This kind of degradation
was also documented by Peng, Feng, and McCallum (2004).
4.2 Named Entity List Recovery
The SIGHAN data sets contain relatively few OOV words (2.6% for the MSR data). What
if the rate is much higher than that? We expect our model to be less vulnerable to OOV
problems because it is trained with billions of examples from a large corpus. To verify
this, we generate four data sets from each of these lists of names:
(a) 702 cities and counties of China seen in the MSR data
(b) 1,634 cities and counties of China not seen in the MSR data
(c) 7,470 Chinese personal names seen in the MSR data
(d) 20,000 Chinese personal names not seen in the MSR data
Table 4
Evaluation results on SIGHAN Bakeoff 2005 data sets.
our method the MSR model
data set P R F P R F
MSR 84.8 91.3 87.9 96.0 95.6 95.8
PKU 84.2 86.1 85.1 85.2 82.3 83.7
Table 5
Amended evaluation results for MSR data.
P R F
our method 98.0 96.7 97.3
the MSR model 96.7 96.0 96.3
509
Computational Linguistics Volume 35, Number 4
Table 6
Results on tasks of named entity list recovery.
our method the MSR model
data set P R F P R F
(a) 91.0 93.8 92.4 43.3 29.1 34.8
(b) 79.4 85.3 82.2 25.1 16.9 20.2
(c) 74.9 85.0 79.6 69.4 66.5 67.9
(d) 86.3 91.5 88.8 65.4 61.0 63.1
The generation method is: Randomly permute each list and then put the result into lines,
with each line having about 30 names, and repeat this process until we get 1 million
tokens for each data set. We use the MSR model and our method to segment these data
sets. The results are in Table 6.
It is clear that our method performs better on these data sets. This provides evidence
that it could handle situations where many OOV words turn up. Table 6 also indicates
that, especially for the MSR model, recognition of Chinese personal names is easier
than location names. This is reasonable because the former has more regularity than the
latter. Besides, although there are no OOV words in data sets (a) and (c), many words
occur very sparsely in the MSR data. Hence the MSR model doesn?t do well even on
these two data sets.
4.3 Unknown Words Recognition
To further test our model?s ability to recognize unknown words, we make 27,470 sen-
tences with the pattern ?X / Y ?  X ?" Y ? (X is a resident of Y, and X loves
Y), where X and Y are the personal and location names in Section 4.2. The results on
this data set are in Table 7. Again our method outperforms the MSR model by a large
margin, proving once more that it is stronger in unknown word recognition. For both
methods, the metrics in Table 7 are better than those in Table 6, reflecting the fact that
unknown word recognition here is easier than the named entity list recovery task.
4.4 Summary
Evaluation shows that when there are many new words, the improvement of our
method is obvious. In addition, a model is of limited use if it fits the SIGHAN data well,
but can?t maintain that accuracy elsewhere. Our model has a wider coverage through
Table 7
Results of unknown word recognition in 24,470 sentences.
P R F
our method 96.2 97.9 97.1
the MSR model 88.3 84.5 86.3
510
Li and Sun Punctuation as Implicit Annotations
mining the Web. It tends to segment long multiword expressions into their component
words. This is not a disadvantage as long as the result is consistent.
5. Related Work
Punctuation gives naturally occurring unambiguous word boundaries. Gao et al (2005)
described how to remove overlapping ambiguities in an annotated corpus to train a
model for resolving these ambiguities. A raw corpus doesn?t play a role in that method,
and the model involves no punctuation marks.
Chinese word segmentation based on position tagging was initiated by Xue (2003).
This method and its subsequent developments have achieved state-of-the-art perfor-
mance in word segmentation (Peng, Feng, and McCallum 2004; Low, Ng, and Guo 2005;
Zhao, Huang, and Li 2006). Yet the system degrades when there are lots of previously
unknown words, whereas our method performs particular well in this case thanks to
the use of a huge Web corpus.
In the past decade, much work has been done in unsupervised word segmentation
(Sun, Shen, and Tsou 1998; Peng and Schuurmans 2001; Feng et al 2004; Goldwater,
Griffiths, and Johnson 2006; Jin and Tanaka-Ishii 2006). These methods could also take
advantage of the ever-growing amount of online text to model Chinese word segmen-
tation, but usually are less accurate and more complicated than ours.
6. Conclusion
With a virtually unlimited supply of raw corpus data, punctuation marks give us ample
training examples and thus can be quite useful as implicit annotations for Chinese
word segmentation. We also note that shallow parsing (Sha and Pereira 2003) is a close
analogy to word segmentation. Hence our method can potentially be applied to this
task as well.
Appendix A: Input to the Training Algorithm
We give readers a feel for the input data used to train our probability models. First, to
estimate Pr(L |context), the input to the learning algorithm for the maximum entropy
models looks like this:
+L C0=3 C1=I C2= C0C1=3I C1C2=I
+L C0=0 C1= C2=G C0C1=0 C1C2=G
-L C-2=I C-1= C0=? C-2C-1=I C-1C0=?
+L C-2= C-1=G C0=? C-2C-1=G C-1C0=G?
Whereas to estimate Pr(R | context), the input data are something like the following
+R C-2=I C-1= C0=? C-2C-1=I C-1C0=?
+R C-2= C-1=G C0=? C-2C-1=G C-1C0=G?
-R C0=3 C1=I C2= C0C1=3I C1C2=I
-R C0=0 C1= C2=G C0C1=0 C1C2=G
To save space, not all features in Table 2 are included here. From this illustration,
interested readers can get a general idea of our input to the learning algorithm in
Section 3.3.
511
Computational Linguistics Volume 35, Number 4
Acknowledgments
This work is supported by the National
Science Foundation of China under Grant
No. 60621062 and 60873174, and the National
863 Project under Grant No. 2007AA01Z148.
We thank our reviewers sincerely for many
helpful comments and suggestions which
greatly improved this article. Thanks also go
to sogou.com for sharing their Web corpora
and entity names. The maximum entropy
modeling toolkit used here is contributed by
Zhang Le of the University of Edinburgh.
References
Berger, Adam L., Vincent J. Della Pietra, and
Stephen A. Della Pietra. 1996. A maximum
entropy approach to natural language
processing. Computational Linguistics,
22(1):39?71.
Borthwick, Andrew. 1999. A Maximum
Entropy Approach to Named Entity
Recognition. Ph.D. thesis, New York
University.
Feng, Haodi, Kang Chen, Xiaotie Deng, and
Weimin Zheng. 2004. Accessor variety
criteria for Chinese word extraction.
Computational Linguistics, 30(1):75?93.
Gao, Jianfeng, Mu Li, Andi Wu, and
Chang-Ning Huang. 2005. Chinese word
segmentation and named entity
recognition: A pragmatic approach.
Computational Linguistics, 31(4):531?574.
Goldwater, Sharon, Thomas L. Griffiths,
and Mark Johnson. 2006. Contextual
dependencies in unsupervised word
segmentation. In Proceedings of the 21st
International Conference on Computational
Linguistics and 44th Annual Meeting of the
Association for Computational Linguistics,
pages 673?680, Sydney.
Jin, Zhihui and Kumiko Tanaka-Ishii. 2006.
Unsupervised segmentation of Chinese
text by use of branching entropy. In
Proceedings of the COLING/ACL on Main
Conference Poster Sessions, pages 428?435,
Morristown, NJ.
Low, Jim Kiat, Hwee Tou Ng, and Wenyuan
Guo. 2005. A maximum entropy
approach to Chinese word segmentation.
In Proceedings of the Fourth SIGHAN
Workshop on Chinese Language Processing,
pages 161?164, Jeju Island.
Peng, Fuchun, Fangfang Feng, and Andrew
McCallum. 2004. Chinese segmentation
and new word detection using conditional
random fields. In COLING ?04: Proceedings
of the 20th International Conference on
Computational Linguistics, pages 562?569,
Morristown, NJ.
Peng, Fuchun and Dale Schuurmans.
2001. Self-supervised Chinese word
segmentation. Lecture Notes in Computer
Science, 2189:238?249.
Riley, Michael D. 1989. Some applications
of tree-based modelling to speech and
language. In HLT ?89: Proceedings of the
Workshop on Speech and Natural Language,
pages 339?352, Morristown, NJ.
Sha, Fei and Fernando Pereira. 2003.
Shallow parsing with conditional
random fields. In NAACL ?03: Proceedings
of the 2003 Conference of the North
American Chapter of the Association for
Computational Linguistics on Human
Language Technology, pages 134?141,
Morristown, NJ.
Sun, Maosong, Dayang Shen, and
Benjamin K. Tsou. 1998. Chinese word
segmentation without using lexicon and
hand-crafted training data. In Proceedings
of the 17th International Conference on
Computational Linguistics, pages 1265?1271,
Morristown, NJ.
Xue, Nianwen. 2003. Chinese word
segmentation as character tagging.
Computational Linguistics and Chinese
Language Processing, 8(1):29?48.
Yamada, Hiroyasu and Yuji Matsumoto.
2003. Statistical dependency analysis
with support vector machines. In
Proceedings of the 8th International Workshop
on Parsing Technologies (IWPT2003),
pages 195?206, Nancy.
Zhao, Hai, Chang-Ning Huang, and Mu Li.
2006. An improved Chinese word
segmentation system with conditional
random field. In Proceedings of the Fifth
SIGHAN Workshop on Chinese Language
Processing, pages 162?165, Sydney.
512
Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics, pages 1405?1414,
Portland, Oregon, June 19-24, 2011. c?2011 Association for Computational Linguistics
Parsing the Internal Structure of Words:
A New Paradigm for Chinese Word Segmentation
Zhongguo Li
State Key Laboratory on Intelligent Technology and Systems
Tsinghua National Laboratory for Information Science and Technology
Department of Computer Science and Technology
Tsinghua University, Beijing 100084, China
eemath@gmail.com
Abstract
Lots of Chinese characters are very produc-
tive in that they can form many structured
words either as prefixes or as suffixes. Pre-
vious research in Chinese word segmentation
mainly focused on identifying only the word
boundaries without considering the rich inter-
nal structures of many words. In this paper we
argue that this is unsatisfying in many ways,
both practically and theoretically. Instead, we
propose that word structures should be recov-
ered in morphological analysis. An elegant
approach for doing this is given and the result
is shown to be promising enough for encour-
aging further effort in this direction. Our prob-
ability model is trained with the Penn Chinese
Treebank and actually is able to parse both
word and phrase structures in a unified way.
1 Why Parse Word Structures?
Research in Chinese word segmentation has pro-
gressed tremendously in recent years, with state of
the art performing at around 97% in precision and
recall (Xue, 2003; Gao et al, 2005; Zhang and
Clark, 2007; Li and Sun, 2009). However, virtually
all these systems focus exclusively on recognizing
the word boundaries, giving no consideration to the
internal structures of many words. Though it has
been the standard practice for many years, we argue
that this paradigm is inadequate both in theory and
in practice, for at least the following four reasons.
The first reason is that if we confine our defi-
nition of word segmentation to the identification of
word boundaries, then people tend to have divergent
opinions as to whether a linguistic unit is a word or
not (Sproat et al, 1996). This has led to many dif-
ferent annotation standards for Chinese word seg-
mentation. Even worse, this could cause inconsis-
tency in the same corpus. For instance, ???
?vice president? is considered to be one word in the
Penn Chinese Treebank (Xue et al, 2005), but is
split into two words by the Peking University cor-
pus in the SIGHAN Bakeoffs (Sproat and Emerson,
2003). Meanwhile, ??? ?vice director? and ?
?? ?deputy manager? are both segmented into two
words in the same Penn Chinese Treebank. In fact,
all these words are composed of the prefix? ?vice?
and a root word. Thus the structure of??? ?vice
president? can be represented with the tree in Fig-
ure 1. Without a doubt, there is complete agree-
NN
ll,,
JJf
?
NNf
??
Figure 1: Example of a word with internal structure.
ment on the correctness of this structure among na-
tive Chinese speakers. So if instead of annotating
only word boundaries, we annotate the structures of
every word, 1 then the annotation tends to be more
1Here it is necessary to add a note on terminology used in
this paper. Since there is no universally accepted definition
of the ?word? concept in linguistics and especially in Chinese,
whenever we use the term ?word? we might mean a linguistic
unit such as ??? ?vice president? whose structure is shown
as the tree in Figure 1, or we might mean a smaller unit such as
?? ?president? which is a substructure of that tree. Hopefully,
1405
consistent and there could be less duplication of ef-
forts in developing the expensive annotated corpus.
The second reason is applications have different
requirements for granularity of words. Take the per-
sonal name ??? ?Zhou Shuren? as an example.
It?s considered to be one word in the Penn Chinese
Treebank, but is segmented into a surname and a
given name in the Peking University corpus. For
some applications such as information extraction,
the former segmentation is adequate, while for oth-
ers like machine translation, the later finer-grained
output is more preferable. If the analyzer can pro-
duce a structure as shown in Figure 4(a), then ev-
ery application can extract what it needs from this
tree. A solution with tree output like this is more el-
egant than approaches which try to meet the needs
of different applications in post-processing (Gao et
al., 2004).
The third reason is that traditional word segmen-
tation has problems in handling many phenomena
in Chinese. For example, the telescopic compound
???? ?universities, middle schools and primary
schools? is in fact composed of three coordinating el-
ements?? ?university?,?? ?middle school? and
?? ?primary school?. Regarding it as one flat word
loses this important information. Another example
is separable words like ?? ?swim?. With a lin-
ear segmentation, the meaning of ?swimming? as in
??? ?after swimming? cannot be properly rep-
resented, since ?? ?swim? will be segmented into
discontinuous units. These language usages lie at the
boundary between syntax and morphology, and are
not uncommon in Chinese. They can be adequately
represented with trees (Figure 2).
(a) NN
H
HH


JJ
HHH


JJf
?
JJf
?
JJf
?
NNf
?
(b) VV
H
HH


VV
ZZ