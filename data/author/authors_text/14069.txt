Coling 2008: Companion volume ? Posters and Demonstrations, pages 83?86
Manchester, August 2008
A Language-Independent Approach to
Keyphrase Extraction and Evaluation
Mari-Sanna Paukkeri, Ilari T. Nieminen, Matti Po?lla? and Timo Honkela
Adaptive Informatics Research Centre, Helsinki University of Technology
first.last@tkk.fi
Abstract
We present Likey, a language-independent
keyphrase extraction method based on sta-
tistical analysis and the use of a reference
corpus. Likey has a very light-weight pre-
processing phase and no parameters to be
tuned. Thus, it is not restricted to any sin-
gle language or language family. We test
Likey having exactly the same configura-
tion with 11 European languages. Further-
more, we present an automatic evaluation
method based on Wikipedia intra-linking.
1 Introduction
Keyphrase generation is an approach to collect the
main topics of a document into a list of phrases.
The methods for automatic keyphrase generation
can be divided into two groups: keyphrase assign-
ment and keyphrase extraction (Frank et al, 1999).
In keyphrase assignment, all potential keyphrases
appear in a predefined vocabulary and the task is to
classify documents to different keyphrase classes.
In keyphrase extraction, keyphrases are supposed
to be available in the processed documents them-
selves, and the aim is to extract these most mean-
ingful words and phrases from the documents.
Most of the traditional methods for keyphrase
extraction are highly dependent on the language
used and the need for preprocessing is extensive,
e.g. including part-of-speech tagging, stemming,
and use of stop word lists and other language-
dependent filters.
c
? 2008. Licensed under the Creative Commons
Attribution-Noncommercial-Share Alike 3.0 Unported li-
cense (http://creativecommons.org/licenses/by-nc-sa/3.0/).
Some rights reserved.
1.1 Related Work
In the statistical keyphrase extraction, many vari-
ations for term frequency counts have been
proposed in the literature including relative
frequencies (Damerau, 1993), collection fre-
quency (Hulth, 2003), term frequency?inverse
document frequency (tf.idf) (Salton and Buck-
ley, 1988), among others. Additional fea-
tures to frequency that have been experimented
are e.g. relative position of the first occur-
rence of the term (Frank et al, 1999), impor-
tance of the sentence in which the term oc-
curs (HaCohen-Kerner, 2003), and widely stud-
ied part-of-speech tag patterns, e.g. Hulth (2003).
Matsuo and Ishizuka (2004) present keyword ex-
traction method using word co-occurrence statis-
tical information. Most of the presented methods
need a reference corpus or a training corpus to pro-
duce keyphrases. The reference corpus acts as a
sample of general language, whereas the training
corpus is used to tune the parameters of the sys-
tem.
Statistical keyphrase extraction methods with-
out reference corpora have also been proposed,
e.g. (Matsuo and Ishizuka, 2004; Bracewell et al,
2005). The later study is carried out for bilingual
corpus.
1.2 Reference Corpora
The reference corpus of natural language pro-
cessing systems acts as a sample of general lan-
guage. The corpus should be as large as possi-
ble to get sufficiently many examples of language
use. In our study, we used the Europarl corpus that
consists of transcriptions of European Parliament
speeches in eleven European languages, includ-
ing four Romance languages (Spanish, French,
Italian and Portuguese), five Germanic languages
83
(Danish, German, English, Dutch and Swedish),
Finnish and Greek (Koehn, 2005). The number
of words in the corpora is between 23 million in
Finnish and 38 million in French, while the num-
ber of word types differs from 98 thousand in En-
glish to 563 thousand in Finnish.
2 The Likey Method
We present a keyphrase extraction method Likey
that is an extension of Damerau?s method (Honkela
et al, 2007). In Damerau?s (1993) method, terms
are ranked according to the likelihood ratio and the
top m terms are used as index terms. Both sin-
gle words and bigrams are considered to be terms.
Likey produces keyphrases using relative ranks
of n-gram frequencies. It is a simple language-
independent method: The only language-specific
component is a reference corpus in the correspond-
ing language. Likey keyphrases may be single
words as well as longer phrases.
The preprocessing phase of Likey consists of ex-
traction of the main text body without captions of
figures and tables, and removing special characters
(except for some hyphens and commas). Numbers
are replaced with <NUM> tags.
An integer rank value is assigned to each phrase
according to its frequency of occurrence, where
the most frequent phrase has rank value one and
phrases with the same frequency are assigned the
same rank. Rank values rank
a
and rank
r
are cal-
culated from the text and the reference corpus, re-
spectively, for each phrase. Rank order rank is cal-
culated separately for each phrase length n. Thus
we get ranks from unity to max rank for each n.
This way n-gram frequencies for n ? 2 are scaled
to follow approximately the same distribution as
1-grams in the corpus. The ratio
ratio =
rank
a
rank
r
(1)
of ranks is used to compare the phrases.
In highly inflective languages, such as Finnish,
and languages with frequent word concatenation,
such as German, many of the phrases occurring in
the analysed document do not occur in the refer-
ence corpus. Thus, their ratio value is related to
the maximum rank value, according to Eq. 2,
ratio =
rank
a
max rank
r
+ 1
(2)
where max rank
r
is the maximum rank in the ref-
erence corpus. The ratios are sorted in increasing
order and the phrases with the lowest ratios are se-
lected as the extracted keyphrases. Phrases occur-
ring only once in the document cannot be selected
as keyphrases.
3 Evaluation
The most straightforward way to evaluate the ex-
tracted keyphrases is to first decide which phrases
are appropriate to the document and then calculate
how many of the extracted keyphrases belong to
the appropriate phrases set, e.g. by using precision
and recall measures.
There are two widely used approaches for defin-
ing the appropriate phrases for a document. The
first method is to use human evaluators for rat-
ing extracted keyphrases. The other approach is to
analyse documents that have author-provided key-
word lists. Each document has a list of keyphrases
which are easy to accept to be correct. Anyway,
automated keyphrase extraction methods are usu-
ally poor in predicting author-provided keyphrases
since many of the provided phrases do not exist
in the document at all but they are sort of super-
concepts.
3.1 Multilingual Approach
In our framework, there are keyphrases in 11
languages to be evaluated. Due to many prob-
lems related to human evaluation in such a con-
text, we needed a new way of evaluating the re-
sults of our language-independent keyphrase ex-
traction method. We took our evaluation data from
Wikipedia, a free multilingual online encyclope-
dia.1 We present a novel way to use Wikipedia ar-
ticles in evaluation of a multilingual keyphrase ex-
traction method. Wikipedia corpus has lately been
used as a resource for automatic keyword extrac-
tion for English (Mihalcea and Csomai, 2007) as
well as to many other tasks.
We suppose that those articles which are linked
from the article at hand and which link back to the
article, are potential keyphrases of the article. For
example, a Wikipedia article about some concept
may link to its higher-level concept. Likewise, the
higher-level concept may list all concepts includ-
ing to the group.
3.2 Evaluation Data
Finding Wikipedia articles of adequate extent in all
the languages is quite challenging, basically due
1http://wikipedia.org
84
to generally quite short articles in Greek, Finnish
and Danish. We gathered 10 articles that have suf-
ficient amount of content in each of the 11 Eu-
roparl languages. These 110 selected Wikipedia
articles were collected in March 2008 and their En-
glish names are Beer, Cell (biology), Che Guevara,
Leonardo da Vinci, Linux, Paul the Apostle, Sun,
Thailand, Vietnam War, and Wolfgang Amadeus
Mozart.
The average lengths of articles in Finnish, Dutch
and Swedish are below 2 000 words, the lengths
of articles in Portuguese, Greek and Danish are
around 3 000 words and the rest are between 5 000
and 7 000 words. The normalised lengths would
switch the order of the languages slightly.
Among the 67 links extracted from the En-
glish Wikipedia article Cell include phrases such
as adenosine triphosphate, amino acid, anabolism,
archaea, bacteria, binary fission, cell division, cell
envelope, cell membrane, and cell nucleus. The
extracted links serve as evaluation keyphrases for
the article.
4 Results
In our study, we extracted keyphrases of length
n = 1 . . . 4 words. Longer phrases than
four words did not occur in the keyphrase list
in our preliminary tests. As a baseline, the
state-of-the-art keyphrase extraction method tf.idf
keyphrases were extracted from the same material.
Tf.idf (Salton and Buckley, 1988) is another sim-
ple and non-parameterized language-independent
method that can be used for keyphrase extraction.
For tf.idf we split the Europarl reference corpora
in ?documents? of 100 sentences and used the same
preprocessing that for Likey. To remove uninterest-
ing tf.idf-produced phrases like of the cell, a Likey-
like post processing was tried, and it gave slightly
better results. Thus the post processing is used for
all the reported results of tf.idf.
Generally, Likey produces longer phrases than
tf.idf. Each keyphrase list characterises the topic
quite well, and most of the extracted keyphrases
recur in every language. Both methods extracted a
French word re that is frequently used in the article
as an acronym for re?ticulum endoplasmique. The
same word in Dutch is extracted by tf.idf in a form
endoplasmatisch reticulum er.
We compared our Likey keyphrase extraction
method to the baseline method tf.idf by calculat-
ing precision and recall measures according to the
Wikipedia-based evaluation keyphrases for both
methods. We extracted 60 keyphrases from each
document for the first evaluation round and the
number of keyphrases available in the evaluation
keyphrase list for the document for the second
evaluation round. Precision and recall values of
both Likey and tf.idf evaluated with Wikipedia
intra-links are comparatively low (Table 1) but one
has to take into account the nature of the evalua-
tion set with notably varying number of ?correct
keyphrases?.
60 keyphrases N keyphrases
Method Prec. Recall Prec. Recall
Likey 0.1475 0.2470 0.1795 0.1795
tf.idf 0.1225 0.2203 0.1375 0.1375
tf.idf + p 0.1343 0.2341 0.1622 0.1622
Table 1: Average precisions and recalls for Likey,
tf.idf and tf.idf with post processing (p). N
keyphrases refers to the amount of evaluation
keyphrases available for each article.
The obtained precisions and recalls of the
first evaluation differed significantly between lan-
guages. In Figure 1, the precision and recall of
Likey and tf.idf with post processing for each lan-
guage is given. Within the 11 European languages,
English and German performed best according to
the precision (Likey: 23.0% and 22.8%, respec-
tively), but not that well according to the recall,
where best performed Dutch and Greek (Likey:
33.4% and 31.8%, respectively).
5 Conclusions and Discussion
In this paper, we have introduced Likey, a sta-
tistical keyphrase extraction method that is able
to analyse texts independently of the language in
question. In the experiments, we have focused
on European languages among which Greek and
Finnish differ considerably from Romance and
Germanic languages. Regardless of these differ-
ences, the method gave comparable results for
each language.
The method enables independence from the
language being analysed. It is possible to ex-
tract keyphrases from text in previously un-
known language provided that a suitable refer-
ence corpus is available. The method includes
only lightweight preprocessing, and no auxil-
iary language-dependent methods such as part-of-
speech tagging are required. No particular param-
85
el da fi sv nl pt es it de fr en
0
0.05
0.1
0.15
0.2
0.25
0.3
0.35
0.4
0.45
0.5
 
 
Likey
tf.idf
el da fi sv nl pt es it de fr en
0
0.05
0.1
0.15
0.2
0.25
0.3
0.35
0.4
0.45
0.5
Figure 1: Average precisions (left-hand side) and recalls (right-hand side) of Likey and tf.idf with post
processing for each language. The number of extracted keyphrases is 60.
eter tuning is needed either. A web-based demon-
stration of Likey is available at http://cog.hut.
fi/likeydemo/ as well as more detailed infor-
mation on the method. The system highlights
keyphrases of a document written in one of eleven
languages.
Future research includes an extension of Likey in
which unsupervised detection of morphologically
motivated intra-word boundaries (Creutz, 2006) is
used. This extension could also handle languages
that have no white space between words. We also
plan to apply the method within statistical ma-
chine translation. A methodological comparison
of keyphrase-based dimension reduction and e.g.
PCA will also be conducted.
Acknowledgements
This work was supported by the Academy of Fin-
land through the Adaptive Informatics Research
Centre that is a part of the Finnish Centre of Ex-
cellence Programme. We warmly thank Jaakko
J. Va?yrynen and Sami Hanhija?rvi for their useful
comments and ideas.
References
Bracewell, David B., Fuji Ren, and Shingo Kuriowa.
2005. Multilingual single document keyword ex-
traction for information retrieval. In Proceedings of
NLP-KE?05.
Creutz, Mathias. 2006. Induction of the Morphol-
ogy of Natural Language: Unsupervised Morpheme
Segmentation with Application to Automatic Speech
Recognition. Ph.D. thesis, Helsinki University of
Technology.
Damerau, Fred. 1993. Generating and evaluating
domain-oriented multi-word terms from text. In-
formation Processing and Management, 29(4):433?
447.
Frank, Eibe, Gordon W. Paynter, Ian H. Witten, Carl
Gutwin, and Craig G. Nevill-Manning. 1999.
Domain-specific keyphrase extraction. In Proceed-
ings of IJCAI?99, pages 668?673.
HaCohen-Kerner, Yaakov. 2003. Automatic extrac-
tion of keywords from abstracts. In Palade, V., R.J.
Howlett, and L.C. Jain, editors, KES 2003, LNAI
2773, pages 843?849. Springer-Verlag.
Honkela, Timo, Matti Po?lla?, Mari-Sanna Paukkeri, Ilari
Nieminen, and Jaakko J. Va?yrynen. 2007. Termi-
nology extraction based on reference corpora. Tech-
nical Report E12, Helsinki University of Technol-
ogy, Laboratory of Computer and Information Sci-
ence, Espoo. Unpublished.
Hulth, Anette. 2003. Improved automatic keyword ex-
traction given more linguistic knowledge. In Pro-
ceedings of the Conference on Empirical Methods in
Natural Language Processing, pages 216?223.
Koehn, Philipp. 2005. Europarl: A parallel corpus for
statistical machine translation. In MT Summit 2005.
Matsuo, Yutaka and Mitsuru Ishizuka. 2004. Keyword
extraction from a single document using word co-
occurrence statistical information. Int?l Journal on
Artificial Intelligence Tools, 13(1):157?169.
Mihalcea, Rada and Andras Csomai. 2007. Wikify!:
linking documents to encyclopedic knowledge. In
CIKM ?07: Proceedings of the sixteenth ACM con-
ference on Conference on information and knowl-
edge management, pages 233?242, New York, NY,
USA. ACM.
Salton, G. and C. Buckley. 1988. Term weighting
approaches in automatic text retrieval. Information
Processing and Management, 24(5):513?523.
86
