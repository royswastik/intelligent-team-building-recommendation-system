JEP-TALN-RECITAL 2012, Atelier DEFT 2012: D?fi Fouille de Textes, pages 41?48,
Grenoble, 4 au 8 juin 2012. c?2012 ATALA & AFCP
D?tection de mots-cl?s par approches au grain caract?re et au
grain mot
Ga?lle Doualan, Mathieu Boucher, Romain Brixtel, Ga?l Lejeune, Ga?l Dias
?quipe HULTECH (GREYC, Universit? de Caen), Bd Mar?chal juin, 14032 Caen Cedex
prenom.nom@unicaen.fr
R?SUM?
Nous pr?sentons dans cet article les m?thodes utilis?es par l??quipe HULTECH pour sa partici-
pation au D?fi Fouille de Textes 2012 (Deft 2012). La t?che de cette ?dition du d?fi consiste ?
retrouver dans des articles scientifiques, les mots-cl?s choisis par les auteurs. Nous nous appuyons
sur la d?tection de cha?nes r?p?t?es maximales (rst rmax), au grain caract?re et au grain mot. Lam?thode d?velopp?e est simple et non supervis?e. Elle a permis ? notre syst?me d?atteindre la 3e
place (sur 10 ?quipes) sur la premi?re piste du d?fi.
ABSTRACT
Keywords extraction by repeated string analysis
We present here the HULTECH(Human Language Technology) team approach for the Deft 2012
(french text mining challenge). The aim of the challenge is to retrieve the keywords given by
the authors of scientific articles. Our method relies on a text algorithmics technic : detection of
maximal repeated strings. This technic is applied at character level and word level. We achieved
the third rank (over 10) of the first track.
MOTS-CL?S : Recherche d?information, extraction de mots-cl?s, algorithmique du texte.
KEYWORDS: Information retrieval, keywords extraction, string algorithmics.
1 Introduction
La t?che propos?e dans le cadre du D?fi Fouille de Textes 2012 consiste ? retrouver dans des
articles de sciences humaines les mots-cl?s propos?s par les auteurs. Le corpus de travail est
scind? en deux pistes, la premi?re comportant 140 articles et la seconde 141. Une terminologie
qui regroupe tous les mots-cl?s des articles est propos?e avec la premi?re piste. Dans cet article
nous proposerons deux approches : une bas?e sur la connaissance de la terminologie, une autre
adapt?e ? l?absence de cette terminologie. Ce sera pour nous l?occasion de comparer les deux
approches et leurs r?sultats. Nos deux approches s?appuient sur un algorithme de recherche
de cha?nes r?p?t?es maximales, ci-apr?s rst rmax 1. Dans la premi?re approche, bas?e sur laterminologie, nous prenons comme grain d?analyse le caract?re. Dans la seconde approche nous
prenons comme grain d?analyse le mot graphique, sans appui sur la terminologie ni pour la
piste 1 ni pour la piste 2. Dans la section 2, nous proc?dons ? une analyse du corpus qui nous
permet d?appr?hender le mat?riau sur lequel nous travaillons. Dans la section 3, nous d?taillons
1. L?implantation en python utilis?e est disponible ? l?url suivante : code.google.com/p/py-rstr-max
41
nos deux approches. Ensuite, nous pr?senterons les r?sultats dans la section 4et proposons une
confrontation de ces deux approches dans la section 5.
2 Description du corpus
Le corpus utilis? comporte des articles de sciences humaines provenant de quatre revues diffus?es
sur le site Erudit 2. Nous pr?senterons ici plus pr?cis?ment les articles2.1 ? traiter et les mots-cl?s
qui leur sont associ?s2.2.
2.1 Les articles du corpus DEFT 2012
Le corpus DEFT 2012 est constitu? de 300 articles r?partis sur 4 revues de sciences humaines :
? Anthropologie et Soci?t? (AS)
? Revue des Sciences de l?Education (RSE)
? Traduction, Terminologie et R?daction (TTR)
? M?ta : journal des traducteurs (META)
2.1.1 Configuration des articles
Les articles sont au format xml. Ils sont constitu?s d?un identifiant, de la liste des mots-cl?s
fournis par l?auteur, d?un r?sum? et du corps de l?article lui-m?me. Le nom de la revue n?appara?t
pas dans le fichier xml mais dans le nom du fichier. De m?me, le nom de l?auteur et le titre de
l?article ne figurent pas dans le fichier xml. Ceci a rendu plus complexe la recherche des mots-cl?s
notamment du fait que le nom de l?auteur figurait syst?matiquement parmi les mots-cl?s des
articles de la revue Anthropologie et Soci?t?.
Nous pr?sentons dans la figure 1 un exemple d?article du corpus afin de montrer sa configuration
et sa structure, notons que les titres et sous-titres des articles n??taient pas disponibles.
2.1.2 Statistiques sur les articles
Nous avons effectu? des statistiques sur les articles afin de pouvoir mieux les appr?hender
(Tableau 2).
Nombre de documents Taille moyenne en paragraphes Taille moyenne en caract?res
Piste 1 94 67,8 41235
Piste 2 93 80,2 39153
Tableau 1 ? Statistiques sur les documents du corpus d??valuation
Le nombre moyen de paragraphes ne varie pas particuli?rement en fonction de la revue, ?
l?exception de certains articles de META pour lequel le d?coupage en paragraphes ?tait mauvais.
2. http://www.erudit.org
42
< ?xml version="1.0" encoding="UTF-8" ?>
-<doc id="0001">
-<motscles>
<nombre>4</nombre>
<mots>Labrecque ;?conomie politique ;f?minisme ;ethnographie</mots>
</motscles>
-<article>
-<resume>
<p>Tout en poursuivant l?objectif de la pr?sentation du num?ro,
. . . . . . . . . . . . . . . . . .
la consolidation de la th?orie.</p>
</resume>
-<corps>
<p>Qui sape l?ethnographie ?branle la th?orie
. . . . . . . . . . . . . . . . . . . . . . . .
d?une anthropologie engag?e, d?autre part.</p>
</corps>
</article>
</doc>
FIGURE 1 ? Un exemple d?article du jeu d?entra?nement
43
2.2 Les mots-cl?s
Nous avons remarqu? que les articles ne comportent pas le m?me nombre de mots-cl?s : en
moyenne 5,4 95,2 sur la piste 2 et 5,7 sur la piste 1). Mais une grande disparit? peut exister
d?un texte ? l?autre, l??tendue ?tant de 9 (1 ? 10 mots cl?s par article). Nous avons not? que le
premier mot-cl? est syst?matiquement le nom de l?auteur de l?article pour la revue Anthropologie
et Soci?t?. C?est dans un tel cas que la mention du nom de l?auteur dans le fichier nous aurait ?t?
utile.
2.2.1 Nature des mots-cl?s
? Noms propres : nom de l?auteur (ex : Labrecque), auteur faisant l?objet de l?article (ex : Jack
Kerouac), lieu g?ographique (ex : Japon)
? Noms communs : des noms communs seuls ou parfois accompagn?s d?adjectifs, mais jamais de
verbes ni d?adverbes (ex : f?minisme, ?conomie politique)
? Parfois les noms sont compl?t?s par des compl?ments du noms, formant des motifs tels que
celui-ci : N de art N (ex : traitement de l?information sociale)
? Cas particuliers : des noms coordonn?s (ex : traduction scientifique et technique)
Nous avons remarqu? que plus les mots-cl?s ?taient longs, moins on avait de chances de les
retrouver tels quels dans le texte. Lorsque l?on a la chance de les rencontrer dans le texte, ils y
sont peu fr?quents. Globalement 79% des mots-cl?s sont pr?sents tels quels dans le corps du
texte, 44,5% dans le r?sum? et 42% et dans le corps et dans le r?sum?.
3 Description des approches
Notre premi?re approche bas?e sur le grain caract?re utilise la terminologie afin de s?attaquer ? la
piste 1. Notre seconde approche n?utilise pas la terminologie et a ?t? utilis?e sur les deux pistes.
3.1 Approche au grain caract?re
Nous reprenons ici les principes de la m?thode utilis?e pour le Deft 2011 (Lejeune et al, 2011).
On suppose que les segments communs entre le r?sum? et le reste du texte constituent de bons
descripteurs. Pour s?lectionner les descripteurs pertinents nous nous fondons sur leur proximit?
avec des ?l?ments terminologie, technique utilis?e dans le domaine de l?Extraction d?Information
multilingue (Lejeune et al, 2010).
La m?thode rst rmax L?analyse au grain caract?re est effectu? en recherchant des motifs sanstrous (ci-apr?s motifs) tels que d?finis par (Ukkonen, 2009). Ces motifs sont des sous-cha?nes du
texte ayant les caract?ristiques suivantes 3 :
r?p?t?s : les motifs apparaissent au moins deux fois ;
maximaux : les motifs ne sont pas inclus dans des motifs plus grands et de m?me effectif
3. Pour une description plus formelle voir code.google.com/p/py-rstr-max
44
Nous comparons les deux segments textuels(r?sum? et corps) et l?ensemble de la terminologie
en une seule op?ration. Nous conservons les rst r ?max apparaissant dans ces deux segments et
dans un ?l?ment de la terminologie. Seuls les motifs respectant un crit?re de longueur donn?
sont consid?r?s comme pertinents. Pour tenir compte des variations morphologiques du fran?ais,
nous avons fix? la proximit? minimale entre un motif trouv? et un ?l?ment de la terminologie ?
0.9. Autrement dit, un ?l?ment t de la terminologie est consid?r? comme mot-cl? du texte s?il
existe une cha?ne c telle que :
? c est pr?sent dans le r?sum? et dans le corps de l?article
? c est une sous cha?ne de t
? len(c)len(t) ? 910 avec len le nombre de caract?res dans c et t
Nous n?avons pas appliqu? cette m?thode ? la seconde piste car la s?lection de cha?nes de
caract?res adapt?es ? l??valuation ?tait malais?e. Il aurait fallu un grand nombre d?heuristiques
pour retrouver des mots-cl?s comparables ? la r?f?rence. Nous avons pr?f?r? garder la "puret?"
de cette m?thode. En effet le seul pr?-traitement effectu? est le d?coupage en deux segments
textuels (r?sum? et corps). Aucun outillage linguistique (lemmatisation, ?tiquetage. . .) n?est
n?cessaire. Par ailleurs, aucun post-traitement n?est effectu?.
3.2 Approche au grain mot
Pour notre seconde approche, nous proc?dons ? un d?coupage plus classique en mots. Cette
m?thode est con?ue pour fonctionner en l?absence de terminologie de r?f?rence. Nous appliquons
l?algorithme de d?tection des rst rmax (section : 3.1) mais en l?appliquant cette fois sur des mots.
L?algorithme rst rmax est appliqu? ? tout ce qui est compris entre les balises <article> ce quicorrespond au r?sum? et au corps de l?article. Nous consid?rons le tout comme une cha?ne. Nous
obtenons ainsi un ensemble de cha?nes de mots r?p?t?es et maximales. Un grand nombre de
motifs sont d?tect?s dont certains sont partiellement redondants. Par exemple, on a les motif
ABC D et BC DF et on souhaite souvent ne garder que la partie centrale BC D. Pour am?liorer la
pr?cision, nous appliquons donc une seconde fois rst rmax sur la liste des cha?nes obtenues.
3.2.1 IDF
Pour am?liorer la pr?cision de nos r?sultats, nous voulons r?duire encore le nombre de cha?nes
obtenues. Cependant, il nous faut conserver un rappel correct. Pour ce faire nous avons choisi
de calculer l?IDF (Inverse Document Frequency) de chaque cha?ne. Cette mesure fait ressortir
les cha?nes sp?cifiques ? un texte par rapport au corpus. L?IDF est l?inverse de la fr?quence de
la cha?ne dans un ensemble de documents. Cette mesure est g?n?ralement coupl?e avec le TF
(term frequency ou effectif du mot dans un document) en Voici comment se calcule le T F ? I DF
d?une cha?ne C dans un document D 4 :
T F ? I DF = f req(C ,D)t(D) ?? log2 nd(C)N
45
Avec :
? freq(C,D) le nombre de fois que la cha?ne C appara?t dans le document D
? t(D) le nombre de mots du document D
? nd(C) le nombre de documents contenant C dans le corpus
? N la taille du corpus en documents
Cependant, nous ne conservons que l?IDF. Dans notre cas, il n??tait pas n?cessaire l?appliquer le
TF. En effet, gr?ce ? la m?thode rst rmax , nous obtenons les cha?nes maximales r?p?t?es, ce quisignifie qu?elles ont d?j? une certaine fr?quence dans le document. Par ailleurs, le TF a tendance
? privil?gier les cha?nes tr?s fr?quentes d?un texte, autrement dit des mots vides peu susceptibles
d??tre des mots-cl?s.
Pour calculer l?IDF, nous consid?rons l?ensemble des articles d?une piste. Cela nous permet de
caract?riser un article par rapport ? une piste. Cela se justifie si nous nous repla?ons dans
le s?mantique textuelle de Fran?ois Rastier : " le texte pour une linguistique ?volu?e l?unit?
minimale, et le corpus l?ensemble dans lequel cette unit? prend son sens "(Rastier, 2002). Ainsi,
un article ne prend son sens que dans le corpus de travail si bien que nous devons caract?riser
ces cha?nes et ces mots-cl?s par rapport ? l?ensemble du corpus. Lorsque nous calculons l?IDF des
cha?nes nous obtenons des r?sultats compris entre 0 et 5. Nous classons les cha?nes en ordre
d?croissant de leur IDF. Le but ?tant de r?duire le nombre de cha?nes, nous ne conservons que
celles dans l?IDF est sup?rieure ? 2.
3.2.2 Pond?ration des cha?nes
L?IDF constitue un premier filtrage par pond?ration mais ce n?est pas suffisant. Nous proc?dons
donc ? un second filtrage par pond?ration en attribuant un poids aux cha?nes restantes en
fonction des crit?res suivants :
? IDF
? fr?quence de la cha?ne dans l?article
? fr?quence de la cha?ne dans le r?sum?
? longueur de la cha?ne
? pr?sence de la cha?ne dans le premier paragraphe (a priori : introduction
? pr?sence de la cha?ne dans la dernier paragraphe (a priori : conclusion)
A chacune de ces mesures est attribu? un coefficient qui pond?re leur importance. Nous avons
effectu? des statistiques sur le corpus afin d?anticiper les places occup?es par les mots-cl?s dans
les articles. Ainsi, si une cha?ne est fr?quente dans le r?sum?, elle a davantage de chance d??tre
un mot-cl? qu?une autre cha?ne. Nous attribuons donc un certain poids ? ces mesures en fonction
de leur capacit? ? traduire le comportement des mots-cl?s. Notons que l?absence des titres dans
les documents analys?s rend difficile la d?tection des segments introductifs et conclusifs . Les
cha?nes sont rang?es en ordre d?croissant de poids et nous s?lectionnons les 7 premi?res cha?nes
en guise de mots-cl?s. Ce seuil a ?t? fix? ? partir des meilleurs r?sultats obtenus sur le corpus
d?entra?nement.
46
4 R?sultats
R?sultat piste 1 R?sultat piste 2
Approche 1 : rst rmax au grain caract?re 0.44, 3e/10 Approche 2 : rst rmax au grain mot 0,12 0,13, 7e/9Baseline : tf-idf simple 0,08 0,07
Tableau 2 ? R?sultats et rangs pour nos 2 approches et notre baseline
La premi?re approche donne de bons r?sultats en raison de l?appui de la terminologie, bien
meilleurs qu?avec l?approche par poids. Sans doute ces r?sultats auraient pu ?tre am?lior?s avec
quelques heuristiques, par exemple : chercher ? affecter chaque mot-cl? de la terminologie ? au
moins un document. Mais nous n?avons pas souhait? complexifier la proc?dure utilis?e.
Concernant la seconde approche, elle aurait sans doute eu de meilleurs r?sultats sur la piste 1 en
s?appuyant sur la terminologie mais nous avons souhait? pour les deux pistes conserver l?aspect
?sans ressources externes".
5 Discussion
Nous avons opt? pour des m?thodes simples ? mettre en place et peu co?teuses en temps,
peut ?tre au d?triment de la qualit? des r?sultats. La premi?re approche se voulait avant tout
ind?pendante de la langue consid?r?e. Travailler sur le grain caract?re permet de d?passer
les probl?mes de d?coupage des textes en mots. Toutefois pour se conformer aux modalit?s
d??valuation, le soutien de la terminologie s?est av?r? n?cessaire. La seconde approche se voulait
ind?pendante de tout support ext?rieur. En effet, ne pas utiliser la terminologie permet d?extraire
des informations nouvelles ? partir d?un document brut.
Nos deux approches ont en commun l?utilisation d?une m?thode d?algorithmique du texte :
rst rmax . L?algorithme recherche des cha?nes r?p?t?es maximales, suppos?es caract?ristiques d?untexte. Nos approches diff?rent par le grain d?analyse : caract?re pour l?une, mot pour l?autre.
La premi?re m?thode pr?sente l?avantage de la simplicit?, elle ne n?cessite aucun param?tre mais
e base sur la terminologie. La seconde m?thode ne n?cessite pas de terminologie mais impose
des traitements suppl?mentaires.
Nos deux m?thodes pr?sentent par ailleurs l?avantage de d?tecter facilement des unit?s multi-
mots, souvent plus pertinentes pour des t?ches d?indexation documentaire et de recherche
d?information.
Enfin, nos deux approches sont ind?pendantes de tout module d?analyse linguistique (lemma-
tisation, ?tiquetage. . .) ce qui les rend a priori moins sensibles ? une utilisation sur d?autres
langues que le fran?ais. Il serait donc int?ressant d?exp?rimenter ces techniques sur des corpus
multilingues.
47
R?f?rences
LEJEUNE, G., BRIXTEL, R., GIGUET, E. et LUCAS, N. (2011). Deft2011 : appariement de r?sum?s et
d?articles scientifiques fond? sur les cha?nes de caract?res. In D?fi Fouille de Textes/TALN 2011,
pages 53?64.
LEJEUNE, G., DOUCET, A., YANGARBER, R. et LUCAS, N. (2010). Filtering news for epidemic
surveillance : towards processing more languages with fewer resources. In 4th Workshop on
Cross Lingual Information Access, pages 3?10.
RASTIER, F. (2002). Enjeux ?pist?mologiques de la linguistique de corpus. In 2?me journ?es de la
linguistique de corpus.
UKKONEN, E. (2009). Maximal and minimal representations of gapped and non-gapped motifs
of a string. Theor. Comput. Sci., 410(43):4341?4349.
48
