JEP-TALN-RECITAL 2012, Atelier TALAf 2012: Traitement Automatique des Langues Africaines, pages 107?117,
Grenoble, 4 au 8 juin 2012. c?2012 ATALA & AFCP
Extraction de lexiques bilingues ? partir de Wikip?dia 
Rahma Sellami1  Fatiha Sadat2 Lamia Hadrich Belguith1 
(1) ANLP Research Group ? Laboratoire MIRACL 
Facult? des Sciences Economiques et de Gestion de Sfax 
B.P. 1088, 3018 - Sfax ? TUNISIE 
(2) Universit? du Qu?bec ? Montr?al, 201 av. President Kennedy, 
Montr?al, QC, H3X 2Y3, Canada 
Rahma.Sellami@fsegs.rnu.tn, sadat.fatiha@uqam.ca, 
l.belguith@fsegs.rnu.tn 
RESUME ____________________________________________________________________________________________________________   
Avec l'int?r?t accru de la traduction automatique, le besoin de ressources multilingues 
comme les corpus comparables et les lexiques bilingues s?est impos?. Ces ressources sont 
peu disponibles, surtout pour les paires de langues qui ne font pas intervenir l'anglais. 
Cet article pr?sente notre approche sur l'extraction de lexiques bilingues pour les paires 
de langues arabe-fran?ais et yoruba-fran?ais ? partir de l?encyclop?die en ligne 
Wikip?dia. Nous exploitons la taille gigantesque et la couverture de plusieurs domaines 
des articles pour extraire deux lexiques, qui pourront ?tre exploit?s pour d'autres 
applications en traitement automatique du langage naturel. 
ABSTRACT _________________________________________________________________________________________________________  
Bilingual lexicon extraction from Wikipedia 
With the increased interest of the machine translation, needs of multilingual resources 
such as comparable corpora and bilingual lexicon has increased. These resources are not 
available mainly for pair of languages that do not involve English. 
This paper aims to describe our approach on the extraction of bilingual lexicons for 
Arabic-French and Yoruba-French pairs of languages from the online encyclopedia, 
Wikipedia. We exploit the large scale of Wikipedia article to extract two bilingual 
lexicons that will be very useful for natural language applications.  
MOTS-CLES : Lexique bilingue, corpus comparable, Wikip?dia, arabe-fran?ais, yoruba-
fran?ais. 
KEYWORDS : Bilingual lexicon, comparable corpora, Wikipedia, Arabic-French, Yoruba-
French. 
 
107
1 Introduction 
Les ressources linguistiques multilingues sont g?n?ralement construites ? partir de corpus 
parall?les. Cependant, l'absence de ces corpus a incit? les chercheurs ? exploiter d'autres 
ressources multilingues, telles que les corpus comparables : ensembles de textes dans 
diff?rentes langues, qui ne sont pas des traductions les uns des autres (Adafre et de Rijke, 
2006), mais qui contiennent des textes partageant des caract?res communs, tel que le 
domaine, la date de publication, etc. Car moins contrains, ils sont donc plus faciles ? 
construire que les corpus parall?les.  
Les lexiques bilingues constituent une partie cruciale dans plusieurs applications telles 
que la traduction automatique (Och et Ney, 2003) et la recherche d?information 
multilingue  (Grefenstette, 1998). 
Dans cet article, nous cherchons ? exploiter l?aspect multilingue ainsi que la taille 
gigantesque de l?encyclop?die en ligne, Wikip?dia, comme un grand corpus comparable 
pour l'extraction de deux lexiques bilingues (arabe-fran?ais et yoruba-fran?ais). (Morin, 
2007) a montr? que non seulement la taille du corpus comparable mais aussi sa qualit? 
est importante pour l?extraction d?un dictionnaire bilingue. Nous proposons d'utiliser une 
m?thode simple mais efficace, il s?agit d?exploiter les liens inter-langues entre les articles 
Wikip?dia afin d'extraire des termes (simples ou compos?s) arabes et yoruba et leurs 
traductions en fran?ais, puis, utiliser une approche statistique pour aligner les mots des 
termes compos?s.  
Les lexiques extraits seront utilis?s pour l?extraction d?un corpus parall?le ? partir de 
wikip?dia. 
Le contenu de cet article se r?sume comme suit. La section 2 pr?sente un bref aper?u des 
travaux ant?rieurs sur l'extraction de lexiques bilingues. La section 3 d?crit certaines 
caract?ristiques de Wikip?dia que nous avons exploit?es pour l?extraction de nos lexiques 
bilingues. La section 4 pr?sente bri?vement les langues arabe et yoruba. Nous 
pr?sentons, dans la section 5, notre travail de construction des lexiques bilingues ? partir 
de Wikip?dia. Nous ?valuons nos lexiques, dans la section 6. La section 7 conclu cet 
article et donne des pointeurs et extensions pour le futur. 
2 Etat de l?art 
Dans un premier temps, les chercheurs construisent les lexiques bilingues ? partir des 
corpus parall?les. Mais, en raison de l'absence de ces ressources, l?exploitation des corpus 
108
comparables a attir? l?attention de plusieurs chercheurs. (Morin et Daille, 2004) 
pr?sentent une m?thode pour l'extraction de terminologie bilingue ? partir d?un corpus 
comparable du domaine technique. Ils extraient les termes compos?s dans chaque langue 
puis ils alignent ces termes au niveau mot en utilisant une m?thode statistique exploitant 
le contexte des termes. (Otero, 2007) a cr?e un lexique bilingue (anglais-espagnol), en se 
basant sur des informations syntaxiques et lexicales extraites ? partir d?un petit corpus 
parall?le. (Sadat et al, 2003) ont pr?sent? une m?thode hybride qui se base sur des 
informations statistiques (deux mod?les de traduction bidirectionnels) combin?es ? des 
informations linguistiques pour construire une terminologie anglais-japonais. (Morin et 
Prochasson, 2011) ont pr?sent? une m?thode pour l'extraction d?un lexique bilingue 
sp?cialis? ? partir d?un corpus comparable, agr?ment? d?un corpus parall?le. Ils extraient 
des phrases parall?les ? partir du corpus comparable, puis, ils alignent ces phrases au 
niveau mots pour en extraire un lexique bilingue. (Hazem et al, 2011) proposent une 
extension de l?approche par similarit? inter-langue abord?e dans les travaux pr?c?dents. 
Ils pr?sentent un mod?le inspir? des m?tamoteurs de recherche d?information. 
Dans ce qui suit, nous d?crivons les travaux ant?rieurs qui ont exploit? Wikip?dia comme 
corpus comparable pour la construction d?un lexique bilingue.  
(Adafre et de Rijke, 2006) a cr?? un lexique bilingue (anglais-n?erlandais) ? partir de 
Wikipedia dans le but de l?utiliser pour la construction d'un corpus parall?le ? partir des 
articles de Wikip?dia.  Le lexique extrait est compos? uniquement de titres des articles 
Wikip?dia reli?s par des liens inter-langues. Les auteurs ont montr? l?efficacit? de 
l?utilisation de ce lexique pour la construction d?un corpus parall?le. (Bouma et al, 2006) 
ont construit un lexique bilingue pour la cr?ation d'un syst?me de question r?ponse 
multilingue (fran?ais-n?erlandais). En outre, (Decklerck et al, 2006) ont extrait un 
lexique bilingue ? partir des liens inter-langues de Wikip?dia. Ce lexique a ?t? utilis? 
pour la traduction des labels d?une ontologie. Ces travaux sont caract?ris?s par le fait 
qu?ils exploitent uniquement les liens inter-langues de Wikip?dia. Par contre, (Erdmann 
et al, 2008) analysent non seulement les liens inter-langues de wikip?dia, mais 
exploitent aussi les redirections et les liens inter-wiki pour la construction d?un 
dictionnaire anglais-japonais. Les auteurs ont montr? l?apport de l?utilisation de 
Wikip?dia par rapport aux corpus parall?les pour l?extraction d?un dictionnaire bilingue. 
Cet apport apparait surtout au niveau de la large couverture des termes. (Sadat et 
Terrasa, 2010) proposent une approche pour l?extraction de terminologie bilingue ? 
partir de Wikip?dia. Cette approche consiste ? extraire d?abord des paires de termes et 
109
traductions ? partir des diff?rents types d?informations, des liens et des textes de 
Wikip?dia, puis, ? utiliser des informations linguistiques afin de r?ordonner les termes et 
leurs traductions pertinentes et ainsi ?liminer les termes cibles inutiles.  
3 Bref aper?u sur les langues arabe et yoruba  
3.1 La langue arabe 
L?arabe (???????) est une langue originaire de la p?ninsule Arabique. Elle est parl?e en Asie 
et en Afrique du Nord. L?Arabe est issue du groupe m?ridional des langues s?mitiques. 
Elle s??crit de droite ? gauche tout en utilisant des lettres qui prennent des formes 
diff?rentes suivant qu?elles soient isol?es, au d?but, au milieu ou ? la fin du mot.1  
La langue arabe est morphologiquement riche ce qui pose le probl?me de l?ambigu?t? au 
niveau de son traitement automatique, un mot en arabe peut encapsuler la signification 
de toute une phrase (? ? ??? ?? ? ??/est ce que vous souvenez de nous ?). 
3.2 La langue yoruba 
Le yoruba (yor?b?) est une langue tonale appartenant ? la famille des langues nig?ro-
congolaises. Le yorouba, langue maternelle d?environ 20% de la population nig?riane, est 
?galement parl? au B?nin et au Togo. Au Nig?ria, il est parl? dans la plus grande partie 
des ?tats d?Oyo, Ogun, Ondo, Osun, Kwara et Lagos, et ? l?ouest de l??tat de Kogi.  
La langue se subdivise en de nombreux dialectes. Il existe n?anmoins aussi une langue 
standard2. 
Le yoruba s'?crit au moyen de plusieurs alphabet fond?es sur l?alphabet latin muni 
d?accents pour noter les tons (dont la charge fonctionnelle est tr?s importante), et de 
points souscrits pour noter les voyelles ouvertes. 
La voyelle est le centre de la syllabe. Le ton appara?t comme une caract?ristique 
inh?rente ? la voyelle ou ? la syllabe. Il y a autant de syllabes que de tons. Le 
symbolisme se pr?sente comme suit : ton haut: (/), ton bas: (\), ton moyen: (-). 
Ces tons d?terminent le sens du mot, une forme peut avoir plusieurs sens (ex. Igba/deux 
cent, Igba/calebasse, ?gba/temps, etc)3.  
                                                          
1 http://fr.wikipedia.org/wiki/Arabe [consult? le 26/04/2012]. 
2 http://fr.wikipedia.org/wiki/Yoruba_(langue) [consult? le 18/04/2012]. 
3 http://www.africananaphora.rutgers.edu/downloads/casefiles/YorubaGS.pdf [consult? le 
24/04/2012]. 
110
La morphologie de la langue yoruba est riche, faisant, par exemple, un large emploi 
du redoublement (ex. Eso/fruit, so/donner de fruits, j?/ d?goutter , ?jo/pluie). 
4 Caract?ristiques de Wikip?dia 
Lors de l'extraction de terminologies bilingues ? partir de corpus parall?les ou 
comparables, il est difficile d'atteindre une pr?cision et une couverture suffisantes, en 
particulier pour les mots moins fr?quents tels que les terminologies sp?cifiques ? un 
domaine (Erdmann, 2008). Pour notre travail de construction de lexiques bilingues, nous 
proposons d?exploiter Wikip?dia, une ressource multilingue dont la taille est gigantesque 
et qui est en d?veloppement continu. 
Dans ce qui suit, nous d?crivons certaines caract?ristiques de Wikip?dia, ces 
caract?ristiques font de Wikip?dia une ressource pr?cieuse pour l'extraction de ressources 
bilingues. 
Actuellement, Wikip?dia contient 21 368 483 articles dont 1 221 995 articles fran?ais, 
170771 articles en langue arabe et 29 884 articles en langue yoruba4. Ces articles 
couvrent plusieurs domaines. Nous exploitons l?aspect multilingue et gigantesque de 
cette ressource afin d?extraire des lexiques bilingues de large couverture. 
La structure de Wikip?dia est tr?s dense en liens ; ces liens relient soit des articles d?une 
seule langue soit des articles r?dig?s en langues diff?rentes.  
Les liens Wikip?dia peuvent ?tre class?s en :  
- Lien inter-langue : un lien inter-langue relie deux articles en langues diff?rentes. Un 
article a au maximum un seul lien inter-langue pour chaque langue, ce lien a comme 
syntaxe [[code de la langue cible : titre de l?article en langue cible]] avec ? code de la 
langue cible ? identifie la langue de l?article cible  et ? titre de l?article en langue cible ? 
identifie son titre (ex. [[yo:J?p?t?r?]]). Puisque les titres des articles Wikip?dia sont 
uniques,  la syntaxe des liens inter-langue est suffisante pour identifier les articles en 
langues cibles.  
- Redirection : une redirection  renvoie automatiquement le visiteur sur une autre 
page. La syntaxe Wikip?dia d'une redirection est : #REDIRECTION[[page de 
destination]]. Les pages de redirection sont notamment utilis?es pour des abr?viations 
(ex. SNCF redirige vers Soci?t? Nationale des Chemins de Fer), des synonymes (ex. e-
                                                          
4 http://meta.wikimedia.org/wiki/List_of_Wikipedias [consult? le 01/03/2012]. 
111
mail, courriel, m?l et messagerie ?lectronique redirigent vers courrier ?lectronique), des 
noms alternatifs (ex. Karol Wojty?a redirige vers Jean-Paul II), etc. 
- Lien inter-wiki : c'est un lien vers une autre page de la m?me instance de Wikip?dia. 
Le texte du lien peut correspondre au titre de l'article qui constitue la cible du lien (la 
syntaxe en sera alors : [[titre de l'article]]), ou diff?rer du titre de l'article-cible (avec 
la syntaxe suivante : [[titre de l'article|texte du lien]]). 
5 Extraction des lexiques bilingues ? partir de Wikip?dia 
5.1 Extraction des termes 
Nous avons extrait deux lexiques bilingues en exploitant la syntaxe des liens inter-
langues de Wikip?dia. En effet, les liens inter-langues relient deux articles en langues 
diff?rentes dont les titres sont en traduction mutuelle. En outre, ces liens sont cr??s 
par les auteurs des articles, nous supposons que les auteurs ont correctement positionn? 
ces liens. Aussi, un article en langue source est li? ? un seul article en langue cible, donc, 
nous n?avons pas ? g?rer d??ventuels probl?mes d?ambigu?t? au niveau de l?extraction des 
paires de titres.  
Nous avons t?l?charg? la base de donn?es Wikip?dia arabe (janvier 2012)5 et yoruba 
(mars 2012)6 sous format XML et nous avons extrait 104 104 liens inter-langue arabe et 
15 345 liens inter-langue yoruba vers les articles fran?ais. Chaque lien correspond ? une 
paire de titres arabe-fran?ais et yoruba-fran?ais. Certains titres sont compos?s de termes 
simples et d?autres sont compos?s de termes compos?s de plusieurs mots. 
5.2 Alignement des mots 
Dans le but d?avoir un lexique compos? uniquement des termes simples, nous avons 
proc?der ? une ?tape d?alignement des mots. 
Cette ?tape pr?sente plusieurs difficult?s dont : Premi?rement, les alignements ne sont 
pas n?cessairement contigus : deux mots cons?cutifs dans la phrase source peuvent ?tre 
align?s avec deux mots arbitrairement distants de la phrase cible. On appelle ce 
ph?nom?ne distorsion. Deuxi?mement, un mot en langue source peut ?tre align? ? 
plusieurs mots en langue cible ; ce qui est d?fini en tant que fertilit?. 
                                                          
5 http://download.wikipedia.com/arwiki/20120114/ [consult? le 01/03/2012]. 
6 http://dumps.wikimedia.org/yowiki/20120316/ [consult? le 15/03/2012]. 
112
Nous avons proc?d? ? une ?tape d?alignement des mots des paires de titres en nous 
basant sur une approche statistique, nous avons utilis? les mod?les IBM [1-5] (Brown et 
al., 1993) combin?s avec les mod?les de Markov cach?s HMM (Vogel et al,1996) vu que 
ces mod?les standard se sont av?r?s efficaces dans les travaux d'alignement de mots. 
Les mod?les IBM sont des mod?les ? base de mots, c?est-?-dire que l?unit? de traduction 
qui appara?t dans les lois de probabilit? est le mot.  
Les cinq mod?les IBM permettent d?estimer les probabilit?s P(fr |ar) et P(fr |yo) de fa?on 
it?rative, tel que fr est un mot fran?ais, ar est un mot arabe et yo est un mot yoruba. 
Chaque mod?le s?appuie sur les param?tres estim?s par le mod?le le pr?c?dant et prend 
en compte de nouvelles caract?ristiques telles que la distorsion, la fertilit?, etc.  
Le mod?le de Markov cach? (nomm? usuellement HMM) (Vogel et al, 1996) est une 
am?lioration du mod?le IBM2. Il mod?lise explicitement la distance entre l?alignement 
du mot courant et l?alignement du mot pr?c?dent. 
Nous avons utilis? l?outil open source Giza++ (Och et Ney, 2003) qui impl?mente ces 
mod?les pour l?alignement des mots et nous avons extrait les  traductions candidates  ? 
partir d?une table de traductions cr??e par Giza++. Chaque ligne de cette table contient 
un mot en langue arabe (ar) (respectivement yoruba (yo)), une traduction  candidate (fr) 
et un score qui calcule la probabilit? de traduction P(fr|ar) (resp. yoruba P(fr|yo)). 
Apr?s l??tape d?alignement, nous avons extrait 65 049 mots arabes et 155 348 paires de 
traductions candidates en fran?ais. En ce qui concerne le lexique yoruba-fran?ais, nous 
avons extrait 11 235 mots yoruba et 20 089 paires de traductions candidates en fran?ais. 
Afin d?am?liorer la qualit? de nos lexiques, nous avons proc?d? ? une ?tape de filtrage 
qui ?limine les traductions candidates ayant un score inf?rieur ? un seuil.  
 
 
 
 
FIGURE 1 ? Extrait de la table de traduction ar-fr 
 
 
 
 
 
FIGURE 2 ? Extrait de la table de traduction yo-fr 
R?m?           Rome               0.7500 
R?m?           romaine           0.33333 
al?d?nid?     naturelles         1.00000 
?w?j?          Soci?t?             0.66666 
?w?j?          Communaut?    0.20000 
Mathim?t?k? Math?matiques 0.50000 
Copper         Cuivre              1.000 
?? ? ?      Flou               1.0000000 
?? ? ?      Diffusion        0.1666667 
????? ?      ?quipes           0.1250000 
????? ?      f?minin           0.0067568 
????? ?      masculin         0.6690141 
??? ??? ?   N?gociations   1.0000000 
??? ??????  Amazones        1.0000000 
 
113
6 Evaluation 
Puisque notre int?r?t est centr? sur les liens inter-langues de Wikip?dia, les lexiques 
extraits ne contiennent pas des verbes.  
Nous avons ?valu?, manuellement, la qualit? de notre lexique bilingue en calculant la 
mesure de pr?cision et en se r?f?rant ? un expert.  
????????? =
nombre de traductions extraites correctes 
nombre de traductions extraites
 
Nous avons calcul? la pr?cision en se basant sur les traductions candidates de 50 mots 
arabes et yoruba et nous avons fait varier le seuil de 0 ? 1 pour en identifier la valeur 
optimale en fonction de la pr?cision. 
La figure 3 pr?sente les valeurs de pr?cision des deux lexiques en variant le seuil.  
Remarquons qu?en augmentant le seuil, la pr?cision est am?lior?e. Sa valeur passe de 
0.46 (avec un seuil ?gale 0) ? 0.74 (quand le seuil ?gale ? 1) pour le lexique yoruba-
fran?ais et de 0.22 ? 0.75 pour le lexique arabe-fran?ais. 
La figure 4 montre que la couverture du lexique fran?ais-yoruba et presque stable, elle 
varie entre 14045 (quand le seuil ?gale ? 0) et 11184 (quand le seuil ?gale ? 1). Ces 
valeurs sont tr?s inf?rieures par rapport ? celles du lexique arabe-fran?ais, ceci est d? 
principalement au faible nombre des articles Wikip?dia yoruba.  
La figure 3 montre que les meilleures valeurs de pr?cision sont atteintes ? partir d?un 
seuil ?gal ? 0.6 pour le lexique arabe-fran?ais. Mais, remarquons dans la figure 4, qu?? 
partir de ce seuil, la couverture du lexique est affaiblie. Ceci est expliqu? par le fait que 
plusieurs fausses traductions ont ?t? ?limin?es ? partir de ce seuil. 
Les erreurs du lexique yoruba-fran?ais sont dues principalement au fait que certains 
titres wikip?dia sont introduits en anglais (ex. density/densit?) et aux erreurs 
d?alignements (ex. Tanaka/Giichi).  
Les erreurs de traduction du lexique arabe-fran?ais sont dues principalement au fait que 
certains titres arabes sont introduits en langue autre que l?arabe (ex. cv/cv), en majorit? 
en langue anglaise. Certaines traductions candidates sont des translit?rations et pas des 
traductions (ex. ???????/Intifada). Aussi, nous avons d?tect? des erreurs d?alignement (ex.  
?? ?? ?/diagnostique). D?autres erreurs sont dues au fait que les paires de titres des 
articles ne sont pas des traductions pr?cises mais il s?agit juste de la m?me notion  (ex. 
???/No?l). 
114
 
FIGURE 3 ?Variation de la pr?cision des lexiques yo-fr et ar-fr selon le seuil 
  
FIGURE 4 ? Variation de la couverture des lexiques yo-fr et ar-fr selon le seuil 
7 Conclusion 
L?exploitation de Wikip?dia pour la construction de ressources linguistiques multilingues 
fait l?objet de plusieurs travaux de recherches, comme la construction des corpus 
parall?les, des lexiques multilingues et des ontologies multilingues. 
Dans cet article, nous avons d?crit notre travail pr?liminaire d?extraction de lexiques 
(arabe-fran?ais et yoruba-fran?ais) ? partir de Wikip?dia. En effet, notre but majeur est 
d?exploiter Wikip?dia en tant que corpus comparable pour la traduction automatique 
statistique.  
La m?thode que nous proposons est efficace malgr? sa simplicit?. Il s?agit d?extraire les 
titres arabes, yorubas et fran?ais des articles de Wikip?dia, en se basant sur les liens 
inter-langues puis d?aligner les mots de ces titres en se basant sur une approche 
statistique. Nous avons atteint des valeurs de pr?cision et de couverture encourageantes 
qui d?passent respectivement 0.7 et 60 000 paires de traductions pour le lexique arabe-
fran?ais et 0.7 et 14 000 paires de traductions pour le lexique yoruba-fran?ais. 
0
0,1
0,2
0,3
0,4
0,5
0,6
0,7
0,8
pr?cision ar-fr pr?cision yo-fr
0
10000
20000
30000
40000
50000
60000
70000
couverture du lexique yo-fr couverture du lexique ar-fr
no
m
br
e 
de
 p
ai
re
s 
de
 tr
ad
uc
tio
ns
115
Comme travaux futurs, nous envisageons d??largir la couverture de nos lexiques en 
exploitant d?autres liens Wikip?dia comme les redirections et les liens inter-wiki. Nous 
envisageons aussi d?utiliser ces lexiques pour l?extraction des corpus parall?les (arabe- 
fran?ais et yoruba-fran?ais) ? partir de Wikip?dia. Ces corpus seront utilis?s au niveau de 
l?apprentissage des syst?mes de traduction automatique statistique arabe-fran?ais et 
yoruba-fran?ais.  
Re?fe?rences 
ADAFRE, S. F. ET DE RIJKE, M. (2006). Finding Similar Sentences across Multiple Languages 
in Wikipedia. In Proceedings of the EACL Workshop on NEW TEXT Wikis and blogs and 
other dynamic text sources, pages 62?69. 
BOUMA, G., FAHMI, I., MUR, J., G. VAN NOORD, VAN DER, L., ET TIEDEMANN, J. (2006). Using 
Syntactic Knowledge for QA. In Working Notes for the Cross Language Evaluation Forum 
Workshop. 
BROWN PETER, F., PIETRA, V. J., PIETRA, S. A., ET MERCER, R. L. (1993). The Mathematics of 
Statistical Machine Translation: Parameter Estimation. IBM T.J. Watson Research Center, 
pages 264-311. 
DECLERCK, T., PEREZ, A. G., VELA, O., , Z., ET MANZANO-MACHO, D. (2006). Multilingual 
Lexical Semantic Resources for Ontology Translation. In Proceedings of International 
Conference on Language Ressources and Evaluation (LREC), pages 1492 ? 1495. 
ERDMANN, M., NAKAYAMA, K., HARA, T. ET NISHIO, S. (2008). A bilingual dictionary 
extracted from the wikipedia link structure. In Proceedings of International Conference on 
Database Systems for Advanced Applications (DASFAA) Demonstration Track, pages 380-
392. 
ERDMANN, M. (2008). Extraction of Bilingual Terminology from the Link Structure of 
Wikipedia. MSc. Thesis, Graduate School of Information Science and Engineering, Osaka 
University. 
GREFENSTETTE, G. (1998). The Problem of Cross-language Information Retrieval. Cross-
language Information Retrieval. Kluwer Academic Publishers. 
HAZEM, A., MORIN, E. ET SEBASTIAN P. S. (2011). Bilingual Lexicon Extraction from 
Comparable Corpora as Metasearch. In Proceedings of the 4th Workshop on Building and 
116
Using Comparable Corpora, pages 35?43, 49th Annual Meeting of the Association for 
Computational Linguistics, Portland, Oregon.  
MORIN, E. (2007). Synergie des approches et des ressources d?ploy?es pur le traitement 
de l??crit. Ph.D. thesis, Habilitation ? Diriger les Recherches, Universit? de Nantes. 
MORIN, E. ET DAILLE, B. (2004). Extraction de terminologies bilingues ? partir de corpus 
comparables d?un domaine sp?cialis?. Traitement Automatique des Langues (TAL), pages 
103?122. 
MORIN, E. ET PROCHASSON E. (2011). Bilingual Lexicon Extraction from Comparable 
Corpora Enhanced with Parallel Corpora. In Proceedings of the 4th Workshop on Building 
and Using Comparable Corpora, pages 27?34. 
OCH, F.J. ET NEY, H. (2003). A systematic comparison of various statistical alignment 
models. Computational Linguistics, pages 19?51, March. 
OTERO, PABLO G. (2007). Learning bilingual lexicons from comparable english and 
spanish corpora. In Proceedings of Machine Translation Summit XI, pages 191?198. 
SADAT, F., YOSHIKAWA, M. ET UEMURA, S. 2003. Bilingual terminology acquisition from 
comparable corpora and phrasal translation to cross-language information retrieval. In 
Proceedings of the 41st Annual Meeting on Association for Computational Linguistics-Volume, 
pages 141?144. Association for Computational Linguistics. 
SADAT, F. ET TERRASSA, A. (2010). Exploitation de Wikip?dia pour l?Enrichissement et la 
Construction des Ressources Linguistiques. TALN 2010, Montr?al. 
VOGEL, S., NEY H. ET C. TILLMANN (1996). HMM-based word alignment in statistical 
translation. In Preceding of the Conference on Computational Linguistics, pages 836?841, 
Morristown, NJ, USA. 
117

Proceedings of the Second Workshop on Hybrid Approaches to Translation, pages 88?93,
Sofia, Bulgaria, August 8, 2013. c?2013 Association for Computational Linguistics
Building bilingual lexicon to create Dialect Tunisian corpora and 
adapt language model 
 
 
Rahma Boujelbane 
Miracl Laboratory, ANLP Research 
Group, University of Sfax, Tunisia 
Rahma.boujelbane@gmail.com 
Mariem Ellouze khemekhem 
Miracl Laboratory, ANLP Research 
Group, University of Sfax, Tunisia 
mariem.ellouze@planet.com 
 
         Siwar BenAyed 
Faculty of Economics and Management 
of Sfax 
siwar.ben.ayed@gmail.com 
    Lamia Hadrich Belguith 
Miracl Laboratory, ANLP Research 
Group, University of Sfax, Tunisia 
l.belguith@fsegs.rnu.tn 
 
Abstract 
Since the Tunisian revolution, Tunisian Dialect (TD) 
used in daily life, has became progressively used and 
represented in interviews, news and debate programs 
instead of Modern Standard Arabic (MSA). This situ-
ation has important negative consequences for natural 
language processing (NLP): since the spoken dialects 
are not officially written and do not have standard 
orthography, it is very costly to obtain adequate cor-
pora to use for training NLP tools. Furthermore, there 
are almost no parallel corpora involving TD and 
MSA. In this paper, we describe the creation of Tuni-
sian dialect text corpus as well as a method for build-
ing a bilingual dictionary, in order to create language 
model for speech recognition system for the Tunisian 
Broadcast News. So, we use explicit knowledge about 
the relation between TD and MSA.  
1 Introduction 
Recently, due to the political changes that 
have occurred in the Arab world, we noticed a 
new remarkable diversity in the media. Arabic 
dialects used in daily life have became progres-
sively used and represented in interviews, news 
and debate programs instead of Modern Standard 
Arabic (MSA). In Tunisia for example, the revo-
lution has affected not only the people but also 
the media. Since that, the media programs have 
been changed:  television channels, political de-
bates and broadcasts news have been multiplied. 
Therefore, this gave birth to a new kind of lan-
guage. Indeed, the majority of speech is no long-
er on MSA but alternating between MSA and 
dialect. Thus, we can distinguish in the same 
speech, MSA words, TD words and MSA-TD 
words such as a word with an MSA component 
(stem) and dialectal affixes.  This situation poses 
significant challenges to NLP, in fact applying 
NLP tools designed for MSA directly to TD 
yields significantly lower performance, making it 
imperative to direct the research to building re-
sources and tools to process this kind of lan-
guage. In our case we aim to convert this new 
language to text, but this process presents a se-
ries of linguistic and computational challenges 
some of these relate to language modeling: stud-
ying large amounts of text to learn about patterns 
of words in a language. This task is complicated 
because of the total lack of TD-MSA resources, 
whether parallel text or paper dictionaries. In this 
paper, we describe a method to create Tunisian 
Dialect (TD) text corpora and the associated lex-
ical resources as well as building bilingual dic-
tionary MSA-TD.  
2 Related work  
Spoken languages which have no written form 
can be classified as limited-resources languages. 
Therefore, several studies has attempted to over-
come the problems of computerization of these 
languages. (Scherrer, 2008) in order to computer-
ize the existing dialect in Switzerland, developed 
a translation system: standard German to any 
variety of the dialect continuum of German-
speaking Switzerland. Moreover, (Shaalan et al 
2007) proposed a system of translation MSA-
Egyptian dialect. For this, they tried to build a 
parallel corpus between Egyptian dialect and 
MSA-based on mapping rules EGY-MSA. Be-
sides dialects, there are several languages from 
the group of limited-resources languages that do 
not have a relation with a well-resourced lan-
guage. Indeed, (Nimaan et al, 2006) presented 
several scenarios to collect corpora in order to 
88
process the Somali language: Collecting corpus 
from the web, automatic synthesis of texts and 
machine translation French-Somali. (SENG, 
2010) selected news sites in Khmer to collect 
data in order to solicit the lack of resources in 
Khmer. 
The literature shows that there is little work that 
dealt with the Tunisian Arabic, the target lan-
guage of this work. (Graja et al 2011), for ex-
ample, treated the Tunisian Dialect for under-
standing speech. To train their system, research-
ers relied on manual transcripts of conversations 
between agents at the train station and travelers. 
However, a limited vocabulary is a problem if 
we want to model a language model for a system 
of recognition of television's programs with a 
wide and varied vocabulary. 
3 Method to create Tunisian Dialect 
Corpora  
In Arabic there are almost no parallel corpora 
involving TD and MSA. Therefore, Machine 
Translation (MT) is not easy, especially when 
there are no MT resources available such as natu-
rally occurring parallel text or transfer lexicon. 
So, to deal with this problem, we proposed to 
leverage the large available annotated MSA re-
sources by exploiting MSA/dialect similarities 
and addressing known differences. Our approach 
consists first on studying the morphological, syn-
tactic and lexical difference by exploiting the 
Penn Arabic Treebank. Second, presenting these 
differences by developing rules and building dia-
lectal concepts. Finally, storing these transfor-
mations into dictionaries.   
3.1 Penn Arabic TreeBank corpora to cre-
ate bilingual lexicon MSA-TD 
Treebanks, are an important resources that al-
lows for important research in general NLP ap-
plications. In the case of Arabic, two important 
treebanking efforts exist: the Penn Arabic Tree-
bank (PATB) (Maamouri et al, 2004; Maamouri 
et al, 2009) and the Prague Arabic Dependency 
Treebank (PADT) (Smr? and Haji, 2007; Smr? et 
al., 2008).  The PATB not only provides tokeni-
zation, complex POS tags, and syntactic struc-
ture; it also provides empty categories, 
diacritizations, lemma choices. The PATB con-
sists of 23,611 parse-annotated sentences (Bies 
and Maamouri, 2003; Maamouri and Bies, 2004) 
from Arabic newswire text in MSA. The PATB 
annotation scheme involves 497 different POS-
tags with morphological information. In this 
work we attempted to mitigate the genre 
differences by transforming the MSA-ATB to 
look like TD-ATB. This will allow us to create in 
tandem a bilingual lexicon with different 
dialectal concept (Figure1). For this, we adopted 
a transformation method based on the parts of 
speech of ATB's word.  
 
 
 
Figure1- Methodology for creating TD 
resources 
3.2 Modeling verbal lexical entries for the 
bilingual dictionary 
As we aim to adapt MSA tools to TD, we tried to 
build for TD verbs the same concepts as those in 
MSA. Therefore, we focused in this work on the 
study of correspondence that may exist among 
the concepts of MSA verbs and dialect verbs. In 
Arabic there are three principal verbal concepts: 
1-Root: It is the basic source of all forms of Ara-
bic verb. The root is not a real word rather it is a 
sequence of three consonants that can be found 
in all words that are related to it. Most roots are 
composed of three letters, very few are of four or 
five consonants. 
2-Pattern: In MSA, patterns are models with dif-
ferent structures that are applied to the root to 
create a lemma. For example, for the root ? ? ? : 
xrj, we can apply different patterns, which give 
different lemmas with different meanings  
Root1: xrj/ ? ?? / C1C2C3+ verbal pattern1: 
AistaC1oC2a3 =lemma1  ???????????/ to extract  
Root1: xrj/???/C1C2C3+ verbal pattern2 
FoEaL(FaEal)=lemma2   ?????? / to go out . 
Root1: xrj ( ? ?? )/C1C2C3+ verbal pattern3 
>aC1oC2aC3=lemma3  ???????? / to eject 
 2-Lemma: The lemma is a fundamental concept 
in the processing of texts in at least some lan-
guages. Arabic words can be analyzed as consist-
ing of a root inserted into a pattern.   
TD-lemma building: Verbs in the PATB corpus 
are presented in their inflected forms. So, we ex-
tracted lemmas and their roots using the morpho-
logical analyzer developed by Elexir FM (Smrz, 
2007). As we are native speakers of TD, we as-
sociate to each MSA-Lemma a TUN-Lemma. As 
a result, we found that 60% of verbs change to-
tally by passing from MSA to TD. As we have 
1500 TD-Lemmas, and starting from the fact that 
89
MSA verbs have patterns describing their mor-
phological behavior during conjugation, we tried 
to assign, if possible, to each TD-Lemma a TD-
Pattern. 
TD-pattern building: The challenge on building 
TD-pattern was to find patterns similar to those 
in MSA. Thus, by studying the morphology of  
TD-lemmas, we remarked  that it's possible to 
assign to TD-lemmas the same pattern as those 
on MSA but with defining other patterns that will 
be sub-patterns to these patterns. In fact, this 
process has allowed distinguishing 32 patterns 
for dialect verbs while there were 15 in MSA. 
This was due to the morphological richness and 
the frequent change of vowel within TD-lemmas. 
For example: 
In MSA $Arak/yu$Arik/to participate and 
dAfaE/yudAFiE/to defend belongs to the 
patternII: CACaC(perfectiveform)/yiCACiC 
(imperfectiveform). In TD the model of these 
tow verbs remains CACVC/yVCACVC but the 
vowel of the second consonant of the pattern 
(vowel letter ? / E) change. The mark of this 
vowel is a fundamental criterion for classifying a 
verb in MSA (Ouerhani, 2009), that's why we 
proposed to define tow sub-pattern for the pat-
tern II,  by dividing the pattern-II to II-i: 
CACiC/yVCACiC and II-a:CACaC/yVCACaC. 
As consequence, $Arak/yu$Arik/ becomes in TD 
$Arik/yi$Arik/ belongs to CACiC/yVCACiC and 
dAfaE/yudAFiE becomes in TD dAfaE/yidAFaE  
belongs to CACaC/yiVCACaC. 
 Therefore, by adopting this reasoning, we suc-
ceeded with the ATB's verbs to define pattern for 
the TD verb. Thus, knowing these new patterns, 
we will be able to assign a pattern for all TD 
verbs.  
TD-root building: In Tunisian dialect, there is 
no standard definition for the root. For this, con-
struction of root dialect was not obvious, espe-
cially when the root verb changes completely 
through the MSA to the dialect. In fact, to define 
a root for TD verbs, we have adopted a deductive 
method. Indeed, in MSA, the rule says: root + 
pattern= Lemma (1). In our case, we have al-
ready defined the TD-lemma and the TD-pattern. 
Following rule (1), the extraction of the root is 
then made easy. For example, we classified the 
lemma ????? /Aistan ~ aY/Wait in the pattern 
AistaCCaC then root(?) + AistaCCaC= ????? / ~ 
YAistana~ 
Following (1), the root for the verb  ?????  /Aistan 
~ aY/Wait is "???" [NNY]. In fact, we can say that 
the definition of roots is a problematic issue 
which could allow more discussion. According 
to (1), it was like we have forced the roots to be 
[NNY]. However, if we classified Aistann ~ aY 
under the pattern AiCCaCal, the root in this case 
must be snn. The root can also be quadrilateral 
???? / snnY if we classified Aistann~ aY under the 
pattern AiCCaCaC. But as there's no standard, 
we have done in our best to be the most logical 
possible to define dialectal root. 
3.3 Structure of verbal lexicon entries 
Different verbal transformations described above 
are modeled and stored at a dictionary of verb as 
follows: to each MSA verbal block containing 
MSA-lemma, MSA-pattern and MSA-root will 
correspond TD- block which containing TD-
lemma, TD-root and TD-pattern. So, knowing 
the pattern and the root we will able to generate 
automatically various inflected forms of the TUN 
verbs. That?s why we stored in our dictionary the 
active and the passive form of the TD-lemma in 
perfective and imperfective tense. We also store 
the inflected forms in the imperative (CV).  Fig-
ure 2 shows the structure that we have defined 
for the dictionary to present the TD-verbal con-
cepts (in section 4 we will explain how we will 
automate the enrichment of this dictionary). 
<DIC_TUN_VERBS_FORM> 
  <LEXICAL-ENTRY POS="VERB"> 
<VERB ID-VERB="48"> 
      <MSA-LEMMA> 
        <Headword-sa> ???????</Headword-MSA 
        <Pattern>????</Pattern> 
        <Root-Msa>???</Root-Msa> 
        <Gloss lang= "fr" > Observer</Gloss> 
      </MSA-LEMMA> 
<TUN-VERB Sense= "1" > 
<Cat-Tun-Verb Category= "TUN--VERB--I--au--yi" /> 
<Root-Tun-Verb>???</Root-Tun-Verb> 
<Conjug-Tun-Verb> 
<TENSE> 
<FORM Type= "IV" > 
<VOICE Label="Active"> 
<Features Val_Number_Gender="1S"> 
<Verb_Conj> ??????</Verb_Conj> 
<Struct-Deriv>?+ ????</Struct-Deriv> 
</Features> 
</VOICE> 
::: 
</DIC_TUN_VERBS_FORM> 
 
Figure2- Verbal structure in dictionary 
3.4 Modeling lexical entries for tools words 
in the bilingual dictionary 
Tools words or syntactic tools are an area that 
reflects the specific syntax of the dialect. It has a 
90
large amount in the Treebank and all MSA-texts. 
However, their transformation was not trivial and 
required, for each tool a study of its different 
context. In our approach, we defined two kinds 
of transformations. The first requires the study of 
different context of a tool word. In fact, the same 
word may have different translations depending 
on its context. Thus, to deal with the variation of 
context, we developed mapping rules. Note that 
among these contexts, there are those that cause 
a change in the syntactic order of words by pass-
ing to the dialect. The second transformation is 
direct, the word remains unchanged whatever the 
context. 
3.5 Context dependent transformation 
We mean by transformation-based context, the 
passage MSA-DT which is based on transfor-
mation rules. Indeed given a word W, we say 
that the transformation of W is based on context 
if it gives a new translation whenever it changes 
on context. RT :  X + W + Y = TDk 
X =
?m
j=
POSjWj
1
:
; Y = ?n
=i
POSiWi
1
:
; k var-
ies from 1 to z ;                                
RTk: transformation rules n?k ; POS : Part of 
speech ; W :word tool, TDk: Translation n?k 
The transformation of a tool word may depend to 
the words that it precedes (X), or the following 
word (Y), or both. If none of the contexts is pre-
sented, then a default translation will be assigned 
to the word tool. For example, For the tool word  
"???" [hatY]/So that  which have the POS: Prep-
osition, we developed three different  mapping 
rules depending to the context in the ATB corpo-
ra. 
1- ????? / HatY + verb = ??? (TUN-particle) + 
TUN_verb 
2-    ?????/ HatY + NEG_PART = ??? (TUN-
particle)+ TUN_NEG_PART 
                   otherwise 
3- ?????/HatY = ????? /HatY 
In total, we developed 316 rules for the ATB's 
tools words. Figure 3 shows how we present a 
transformation rule in the dictionary. For each 
tool word we have defined a set of contexts, each 
context contains one or more configurations. The 
configuration describes the position and the part 
of speech of the words of context. Each context 
corresponds to a new translation of the tool 
word. 
 
<PREP-MSA ID="9"> 
     <MSA-LEMMA>?????</MSA-LEMMA> 
     <GLOSS lang="ANG ">until </GLOSS> 
<CONTEXT ID="1"> 
  <CONFIG ID= "1" Position="Apr?s" PRC="DET" /> 
<CONFIG ID="2" Position="Apr?s" 
POS="NOUN">?????</CONFIG> 
<CONFIG ID="3" Position="Apr?s" POS="NOUN_NUM" /> 
    <TOKEN> 
      <TUN ID="1"> ?????? </TUN> 
      <TUN ID="2" POS="NOUN_NUM" /> 
    </TOKEN> 
         </CONTEXT> 
         ?? 
        <CONTEXT ID="6"> 
            ?.. 
</Prep-MSA> 
 
Figure3- Context dependent rule structure in 
dictionary 
 
Syntactic transformation:  
The order of the elements in the dialect sentence 
seems to be relatively less important than in oth-
er languages . However, the canonical word or-
der in Tunisian verbal sentences is SVO (Sub-
ject-Verb-Object) (Baccouche , 2004). In con-
trast, MSA word order can have the following 
three forms: SVO / VSO / VOS (2). 
(1) TD:  ???????? ???????  ??????  /AlTfol ktib aldars/the child 
wrote the lesson: SVO 
(2) MSA: ????? ??? ?????/ktib Altfol Ald~ars/wrote 
the boy the lesson: VSO. 
This opposition bestween the MSA and the dia-
lect is clearer in the case of proper names. In 
fact, MSA order is VSO (3) while the order in 
TD is SVO. (Mahfoudhi, 2002) 
(3) MSA: ??????? ???? ??? />akal Alqit Alfi>rAn / 
Cats rats 
(4) TD:  ??????? ??? ???? / Alqit >akal Alfi>rAn /Cats 
eat rats 
There are other types of simple dialect sentences 
named nominal sentences which do not contain a 
verb. They have the same order in both Tunisian 
and MSA. For example: 
MSA: ????? ??? /TaKs HAr/ weather is hot 
TD:  ????????  ??????? / TaKs sxuwn/ weather is hot 
In our work, we discussed the syntactic level at 
some nominal groups. The word order is general-
ly reversed by passing to TD. For example: 
(1)MSA: ADV + ADJ: 
???? />ayDaA/Also+ ??????? /muvaK~af/also educated 
 (2) TD: ADJ +ADV: 
 TD: ADJ/ ??????? +ADV/ ???? 
(2)MSA: Noun + ADJ: 
 ??????? ???? /kutubun kavira/many books 
91
TD: ADJ + Noun: 
???? ????  /bar$A ktub 
In the dictionary, we present this kind of rule as 
shown in the figure 4. 
<ADV-MSA ID="5"> 
<MSA-LEMMA> ????? ? </MSA- LEMMA> 
<GLOSS ang="ang">Also</GLOSS> 
<CONTEXT ID="1"> 
<CONFIG ID="1" Position="Before" POS="ADJ" /> 
<TOKEN> 
<TUN ID="1" DIC="ADJECTIVES" POS="ADJ" /> 
<TUN ID="2" /> 
<TUN ID=" ??????<" 3 </TUN> 
</TOKEN> 
</CONTEXT> 
Figure 4- Syntactic rule representation in  
the dictionary 
3.6 Context independent transformation  
In addition to the context-dependent 
transformations, the translation of some tools 
words in the corpus was direct "word to word", 
eg; the word remains the same regardless of the 
context. Figure 5 shows an example of how we 
represented this kind of translation in the 
dictionary 
<SUB_CONJ-MSA ID="7"> 
<MSA-LEMMA> ????</MSA-LEMMA> 
<GLOSS lang="ANG">In order to 
</GLOSS> 
<TOKEN> 
<TUN ID="1"> ?????</TUN> 
</TOKEN> 
</SUB_CONJ-MSA> 
Figure 5- Direct translation structure in the dic-
tionary 
4 Automatic generation of Tunisian Di-
alect corpora 
To test and improve the developed bilingual 
models, we tried by exploiting our dictionaries to 
automate the task of converting MSA corpora to 
a corpora with a dialect appearance.  
For this, we developed a tool called Tunisian 
Dialect Translator (TDT) which enables to pro-
duce TD texts and to enrich the MSA-TD dic-
tionary (Figure 6). This tool works according to 
the following steps: 
1-Morphosyntactic annotation of MSA texts: 
TDT annotate each MSA text 
morphosyntactically by using MADA analyzer 
(Morphological Analyser and disambiguisator of 
Arabic) (Habash, 2010). MADA is a toolkit that, 
given a raw MSA text, adds as much lexical and 
morphological information as possible by disam-
biguating in one operation part-of-speech tags, 
lexemes, diacritizations and full morphological 
analyses. 
2-Exploiting MSA-TD Dictionaries: Based on 
each part of speech of the MSA-word, TDT pro-
pose for each MSA structure the corresponding 
TD translation by exploiting the MSA-TD dic-
tionaries.  
3-Enriching lexicon:  As the lexical database 
does not cover all Arabic words, texts resulting 
from the previous step are not totally translated. 
Therefore, in order to improve the quality of 
translation and to enrich our dictionaries to be 
well used even in other NLP application, we 
added to TDT a semi-automatic enrichment 
module. This module filters first all MSA words 
for which a translation has not been provided. 
Then, TDT assigned for them their 
corresponding MSA-lemmas and POS, the user 
proposes, if the POS is verb or noun, a TD-root  
and a TD-pattern (described in subsection 3.2) 
and the TDT proposes automatically the 
appropriate Tunisian lemma and it's inflected 
forms. 
5 Evaluation  
To evaluate different translations of the verbs 
dictionary, we asked 47 judges (native speakers) 
to translate a sample containing 10% of verbs in 
the dictionary. The evaluation consists in com-
paring what we have proposed as a translation of 
lexical items taken from the ATB with the pro-
posals of judges who are native speakers of Tu-
nisian dialect. The percentages calculated reflect 
the percentage of agreement for each verb trans-
lations between judges and the translation pro-
posed in our lexicon. Table 1 shows the obtained 
results.  
       Table 1- Evaluation of verb translation  
For the same context, an MSA-Verb may have 
many translations. The agreement decreases for 
changed verbs because the judges may propose a 
valid translation different from what we have 
proposed in the dictionary. Moreover, as the 
translation of the majority of tool words depends 
on context, we asked 5 judges to translate 89 
sentences containing 133 words tools. In this 
sample, we made some tools words repeated in 
the same sentence but in different context. Table 
Verbs  Unchanged Changed  Total  
Number of 
verbs in the 
sample  
52 98 150 
Agreement 97,17%  63,21%  74,97%  
92
(2) gives the percentages of agreement between 
the translations of the judges and those of our 
dictionaries of tools words. The variation in 
percentage is due to the fact that for some words, 
judges do not agree among themselves. The table 
also shows the percentage of disagreement 
between judges and dictionaries.  
 
 2 
juges 
3 
juges 
4 
juges 
5 
juges 
Agree-
ment 
72,69
% 
74,53
% 
71,34 
% 
71,23 
% 
Dis-
greement 
18,79
% 
15,03
% 
14,28
%. 
12,03 
% 
Table 2- Evaluation of   tool word translation 
 
In fact, the disagreement arises when no judge 
gives translation similar to the translation 
proposed in the dictionaries. But, by increasing 
the number of judges, the disagreement 
decreases which proves that our dictionaries are 
able to give acceptable translations by several 
judges 
6 Conclusion 
This paper presented an effort to create resources 
and translation tool for Tunisian dialect. 
To deal with the total lack of written resource in 
Tunisian dialect, we described first a methodolo-
gy that allowed the creation of bilingual diction-
aries with in tandem TD-ATB. In fact, TD-ATB 
will serve as a source of insight on the phenome-
na that need to be addressed and as corpora to 
train TD-NLP tools. We focused second on de-
scribing TDT a tool to generate automatically 
TD corpora and to enrich semi-automatically the 
dictionaries we have built. 
We plan to continue working on improving the 
TD-resources by studying the transformation of 
nouns. We also plan to validate our approach by 
measuring the ability of a language model, built 
on a corpus translated by our TDT tool, to model 
transcriptions of Tunisian broadcast news.  
Experiments in progress showed that the integra-
tion of translated data improves significantly lex-
ical coverage and perplexity of language models. 
  
References  
Bies Ann. 2002. Developing an Arabic Treebank: 
Methods , Guidelines , Procedures , and Tools. 
Sopheap Seng, Sethserey Sam, Viet-Bac Le, Brigitte 
Bigi, Laurent Besacier , 2010. Reconnaissance au-
tomatique de la parole en langue khm?re : quelles 
unit?s pour la mod?lisation du langage et la mod?-
lisation acoustique.  
Diki-kidiri Marcel. 2007. Comment assurer la pr?-
sence d ?une langue dans le cyberespace 
Habash Nizar., Rambow Owen and Roth Ryan. 
MADA + TOKAN: A Toolkit for Arabic Tokeni-
zation , Diacritization , Morphological Disambigu-
ation , POS Tagging , Stemming and Lemmatiza-
tion.2009. In Proceedings of the 2nd International 
Conference on Arabic Language Resources and 
Tools (MEDAR), Cairo, Egypt. 
Graja Marwa, Jaoua Maher, Belguith Lamia. 2011. 
Building ontologies to understand spoken, CoRR.  
Maamouri Mahmoud and Bies Ann. 2004. Develop-
ing an Arabic Treebank: Methods, Guidelines, Pro-
cedures, and Tools, Workshop on Computational 
Approaches to Arabic Script-based Languages, 
COLING. 
Mohamed Maamouri , Ann Bies , Seth Kulick , Wajdi 
Zaghouani , David Graff , Michael Ciul. 2010. 
From Speech to Trees: Applying Treebank Annota-
tion to Arabic Broadcast News, (Lrec). 
Emad Mohamed, Behrang Mohit and Kemal Oflazer 
2012. Transforming Standard Arabic to Colloquial 
Arabic, (July), 176?180. 
Abdillahi Nimaan, Pascal Nocera, Juan-Manuel orres-      
Moreno. 2006. Bo?te ? outils TAL pour des langues 
peu informatis?es: le cas du Somali, JADT. 
Ouerhani Bechir,  Interf?rence entre le dialectal et le 
litt?ral en Tunisie: Le cas de la morphologie ver-
bale, 75?84. 
Scherrer Yyves. 2008. Transducteurs ? fen?tre glis-
sante pour l?induction lexicale, Gen?ve 
Smr? Otakar. 2007. Computational Approaches to 
Semitic Languages, ACL, Prague 
Otakar Smr?, Viktor Bielick?, Iveta Kourilov?, Jakub 
Kr??mar, Jan Hajic, Petr Zem?nek. 2008. Prague 
Arabic Dependency Treebank: A Word on the Mil-
lion Words 
 
 
 
 
 
 
93
