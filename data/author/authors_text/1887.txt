Usability Issues in an Interactive Speech-to-Speech 
Translation System for Healthcare 
 
 
Mark Seligman Mike Dillinger 
Spoken Translation, Inc. Spoken Translation, Inc. 
Berkeley, CA, USA 94705 Berkeley, CA, USA 94705 
mark.seligman 
@spokentranslation.com 
mike.dillinger 
@spokentranslation.com 
 
  
Abstract 
We describe a highly interactive system for 
bidirectional, broad-coverage spoken lan-
guage communication in the healthcare area. 
The paper briefly reviews the system's inter-
active foundations, and then goes on to dis-
cuss in greater depth issues of practical 
usability. We present our Translation Short-
cuts facility, which minimizes the need for 
interactive verification of sentences after 
they have been vetted once, considerably 
speeds throughput while maintaining accu-
racy, and allows use by minimally literate 
patients for whom any mode of text entry 
might be difficult. We also discuss facilities 
for multimodal input, in which handwriting, 
touch screen, and keyboard interfaces are of-
fered as alternatives to speech input when 
appropriate. In order to deal with issues re-
lated to sheer physical awkwardness, we 
briefly mention facilities for hands-free or 
eyes-free operation of the system. Finally, 
we point toward several directions for future 
improvement of the system. 
1 Introduction 
Increasing globalization and immigration have led 
to growing demands on US institutions for health-
care and government services in languages other 
than English. These institutions are already over-
whelmed:  the State of Minnesota, for example, 
had no Somali-speaking physicians for some 
12,000 Somali refugees and only six Hmong-
speaking physicians to serve 50,000 Hmong resi-
dents (Minnesota Interpreter Standards Advisory 
Committee, 1998). San Francisco General Hospi-
tal, to cite another example, receives approxi-
mately 3,500 requests for interpretation per month, 
or 42,000 per year for 35 different languages. 
Moreover, requests for medical interpretation ser-
vices are distributed among all the wards and clin-
ics, adding a logistical challenge to the problem of 
a high and growing demand for interpretation ser-
vices (Paras, et al, 2002). Similar situations are 
found throughout the United States. 
It is natural to hope that automatic real-time 
translation in general, and spoken language transla-
tion (SLT) in particular, can help to meet this com-
municative need. From the viewpoint of research 
and development, the high demand in healthcare 
makes this area especially attractive for fielding 
early SLT systems and seeking early adopters. 
With this goal in view, several speech transla-
tion systems have aimed at the healthcare area. 
(See www.sehda.com, DARPA?s CAST program, 
www.phraselator.com, etc.) However, these efforts 
have encountered several issues or limitations. 
First, they have been confined to narrow do-
mains. In general, SLT applications have been able 
to achieve acceptable accuracy only by staying 
within restricted topics, in which fixed phrases 
could be used (e.g., www.phraselator.com), or in 
which grammars for automatic speech recognition 
(ASR) and machine translation (MT) could be op-
timized. For example, MedSLT (Bouillon et al 
2005) is limited to some 600 specific words per 
sub-domain. IBM?s MASTOR system, with 30,000 
words in each translation direction, has much 
broader coverage, but remains comparable in lexi-
con size to commercial MT systems of the early 
1980s. 
Granted, restriction to narrow domains may of-
ten be appropriate, given the large effort involved 
in compiling extensive lexical resources and the 
time required for deployment. A tightly focused 
approach permits relatively quick development of 
new systems and provides a degree of flexibility to 
experiment with different architectures and differ-
ent languages.  
Our emphasis, however, is on breaking out of 
narrow domains. We seek to maximize versatility 
by providing exceptional capacity to move from 
topic to topic while maintaining adequate accu-
racy.  
To provide a firm foundation for such versatil-
ity, we ?give our systems a liberal arts education? 
by incorporating very broad-coverage ASR and 
MT technology. Our MT lexicons, for example, 
contain roughly 300,000 words in each direction. 
But of course, as coverage increases, perplexity 
and the ASR and MT errors due to it increase in 
proportion, especially in the absence of tight inte-
gration between these components. To compen-
sate, we provide a set of facilities that enable users 
from both sides of the language barrier to interac-
tively monitor and correct these errors. Putting us-
ers in the speech translation loop in this way does 
in fact permit conversations to range widely 
(Seligman, 2000). We believe that this highly in-
teractive approach will prove applicable to the 
healthcare area. 
We have described these interactive techniques 
in (Dillinger and Seligman, 2004; Zong and Selig-
man, forthcoming). We will review them only 
briefly here, in Section 2.  
A second limitation of current speech transla-
tion systems for healthcare is that bilingual (bidi-
rectional) communication has been difficult to 
enable. While speech-to-speech translation has 
sometimes proven practical from the English side, 
translation from the non-English side has been 
more difficult to achieve. Partly, this limitation 
arises from human factors issues: while na?ve ob-
servers might expect spoken input to be effortless 
for anyone who can talk, the reality is that users 
must learn to use most speech interfaces, and that 
this learning process can be difficult for users who 
are less literate or less computer literate. Further, 
many healthcare venues make speech input diffi-
cult: they may be noisy, microphones may be 
awkward to situate or to pass from speaker to 
speaker, and so on. 
Our group's approach to training- or venue-
related difficulties for speech input is to provide an 
array of alternative input modes. In addition to 
providing input through dictated speech, users of 
our system can freely alternate among three other 
input modes, using handwriting, a touch screen, 
and standard bilingual keyboards. 
In this paper, we will focus on practical usabil-
ity issues in the design of user interfaces for highly 
interactive approaches to SLT in healthcare appli-
cations. With respect to interactivity per se, we will 
discuss the following specific issues: 
? In a highly interactive speech translation 
system, monitoring and correction of ASR and MT 
are vital for accuracy and confidence, but can be 
time consuming ? in a field where time is always at 
a premium. 
? Interactivity demands a minimum degree 
of computer and print literacy, which some patients 
may lack.  
To address these issues, we have developed a 
facility called Translation Shortcuts?, to be ex-
plained throughout Section 3.  
Section 4 will describe our approach to multi-
modal input. As background, however, Section 2 
will quickly review our approach to highly interac-
tive ? and thus uniquely broad-coverage ? spoken 
language translation. Before concluding, we will in 
Section 5 point out planned future developments. 
2 Highly Interactive, Broad-coverage SLT  
We now briefly summarize our group?s approach 
to highly interactive, broad-coverage SLT. 
The twin goals of accuracy and broad-coverage 
have generally been in opposition: speech transla-
tion systems have gained tolerable accuracy only 
by sharply restricting both the range of topics that 
can be discussed and the sets of vocabulary and 
structures that can be used to discuss them. The 
essential problem is that both speech recognition 
and translation technologies are still quite error-
prone. While the error rates may be tolerable when 
each technology is used separately, the errors com-
bine and even compound when they are used to-
gether. The resulting translation output is generally 
below the threshold of usability ? unless restriction 
to a very narrow domain supplies sufficient con-
straints to significantly lower the error rates of both 
components. 
As explained, our group?s approach has been to 
concentrate on interactive monitoring and correc-
tion of both technologies.   
First, users can monitor and correct the speaker-
dependent speech recognition system to ensure that 
the text that will be passed to the machine transla-
tion component is completely correct. Voice com-
mands (e.g. Scratch That or Correct <incorrect 
text>) can be used to repair speech recognition 
errors. Thus, users of our SLT enrich the interface 
between ASR and MT.  
Next, during the MT stage, users can monitor, 
and if necessary correct, one especially important 
aspect of the translation ? lexical disambiguation. 
Our system?s approach to lexical disambigua-
tion is twofold: first, we supply a Back-
Translation, or re-translation of the translation. 
Using this paraphrase of the initial input, even a 
monolingual user can make an initial judgment 
concerning the quality of the preliminary machine 
translation output. (Other systems, e.g. IBM?s 
MASTOR, have also employed re-translation. Our 
implementations, however, exploit proprietary 
technologies to ensure that the lexical senses used 
during back translation accurately reflect those 
used in forward translation.)  
In addition, if uncertainty remains about the 
correctness of a given word sense, we supply a 
proprietary set of Meaning Cues? ? synonyms, 
definitions, etc. ? which have been drawn from 
various resources, collated in a database (called 
SELECT?), and aligned with the respective lexica 
of the relevant MT systems. With these cues as 
guides, the user can monitor the current, proposed 
meaning and select (when necessary) a different, 
preferred meaning from among those available. 
Automatic updates of translation and back transla-
tion then follow. Future versions of the system will 
allow personal word-sense preferences thus speci-
fied in the current session to be stored and reused 
in future sessions, thus enabling a gradual tuning 
of word-sense preferences to individual needs. Fa-
cilities will also be provided for sharing such pref-
erences across a working group. 
Given such interactive correction of both ASR 
and MT, wide-ranging, and even jocular, ex-
changes become possible (Seligman, 2000).  
As we have said, such interactivity within a 
speech translation system can enable increased 
accuracy and confidence, even for wide-ranging 
conversations. 
Accuracy of translation is, in many healthcare 
settings, critical to patient safety. When a doctor is 
taking a patient?s history or instructing the patient 
in a course of treatment, even small errors can have 
clinically relevant effects. Even so, at present, 
healthcare workers often examine patients and in-
struct them in a course of treatment through ges-
tures and sheer good will, with no translation at all, 
or use untrained human interpreters (friends, fam-
ily, volunteers, or staff) in an error-prone attempt 
to solve the immediate problem (Flores, et al, 
2003). As a result, low-English proficiency pa-
tients are often less healthy and receive less effec-
tive treatment than English speakers (Paras, et al, 
2002). We hope to demonstrate that highly interac-
tive real-time translation systems in general, and 
speech translation systems in particular, can help to 
bridge the language gap in healthcare when human 
interpreters are not available. 
Accuracy in an automatic real-time translation 
system is necessary, but not sufficient. If health-
care workers have no means to independently as-
sess the reliability of the translations obtained, 
practical use of the system will remain limited. 
Highly interactive speech translation systems can 
foster the confidence on both sides of the conversa-
tion, which is necessary to bring such systems into 
wide use. In fact, in this respect at least, they may 
sometimes prove superior to human interpreters, 
who normally do not provide clients with the 
means for judging translation accuracy. 
The value of enabling breadth of coverage, as 
well as accuracy and confidence, should also be 
clear: for many purposes, the system must be able 
to translate a wide range of topics outside of the 
immediate healthcare domain ? for example, when 
a patient tries to describe what was going on when 
an accident occurred. The ability to ask about in-
terests, family matters, and other life concerns is 
vital for establishing rapport, managing expecta-
tions and emotions, etc. 
3 Translation Shortcuts 
Having summarized our approach to highly inter-
active speech translation, we now turn to examina-
tion of practical interface issues for this class of 
SLT system. This section concentrates on Transla-
tion Shortcuts?. 
Shortcuts are designed to provide two main ad-
vantages:  
First, re-verification of a given utterance is un-
necessary. That is, once the translation of an utter-
ance has been verified interactively, it can be saved 
for later reuse, simply by activating a Save as 
Shortcut button on the translation verification 
screen. The button gives access to a dialogue in 
which a convenient Shortcut Category for the 
Shortcut can be selected or created. At reuse time, 
no further verification will be required. (In addition 
to such dynamically created Personal Shortcuts, 
any number of prepackaged Shared Shortcuts can 
be included in the system.) 
Second, access to stored Shortcuts is very 
quick, with little or no need for text entry. Several 
facilities contribute to meeting this design crite-
rion.  
? A Shortcut Search facility can retrieve a 
set of relevant Shortcuts given only keywords or 
the first few characters or words of a string. The 
desired Shortcut can then be executed with a single 
gesture (mouse click or stylus tap) or voice com-
mand.  
NOTE: If no Shortcut is found, the system 
automatically allows users access to the full power 
of broad-coverage, interactive speech translation. 
Thus, a seamless transition is provided between the 
Shortcuts facility and full, broad-coverage transla-
tion. 
? A Translation Shortcuts Browser is pro-
vided, so that users can find needed Shortcuts by 
traversing a tree of Shortcut categories. Using this 
interface, users can execute Shortcuts even if their 
ability to input text is quite limited, e.g. by tapping 
or clicking alone. 
Figure 1 shows the Shortcut Search and Short-
cuts Browser facilities in use. Points to notice:  
? On the left, the Translation Shortcuts Panel 
has slid into view and been pinned open. It con-
tains the Translation Shortcuts Browser, split into 
two main areas, Shortcuts Categories (above) and 
Shortcuts List (below).  
? The Categories section of the Panel shows 
current selection of the Conversation category, 
containing everyday expressions, and its Staff sub-
category, containing expressions most likely to be 
used by healthcare staff members. There is also a 
Patients subcategory, used for patient responses. 
Categories for Administrative topics and Pa-
tient?s Current Condition are also visible; and 
new ones can be freely created. 
? Below the Categories section is the Short-
cuts List section, containing a scrollable list of al-
phabetized Shortcuts. (Various other sorting 
criteria will be available in the future, e.g. sorting 
by frequency of use, recency, etc.)  
? Double clicking on any visible Shortcut in 
the List will execute it. Clicking once will select 
and highlight a Shortcut. Typing Enter will exe-
cute the currently highlighted Shortcut (here 
?Good morning?), if any.  
? It is possible to automatically relate op-
tions for a patient's response to the previous staff 
member?s utterance, e.g. by automatically going to 
the sibling Patient subcategory if the prompt was 
given from the Staff subcategory. 
Because the Shortcuts Browser can be used 
without text entry, simply by pointing and clicking, 
it enables responses by minimally literate users. In 
the future, we plan to enable use even by com-
pletely illiterate users, through two devices: we 
will enable automatic pronunciation of Shortcuts 
and categories in the Shortcuts Browser via text-to-
speech, so that these elements can in effect be read 
aloud to illiterate users; and we will augment 
Shared Shortcuts with pictorial symbols, as clues 
to their meaning. 
A final point concerning the Shortcuts Browser: 
it can be operated entirely by voice commands, 
although this mode is more likely to be useful to 
staff members than to patients. 
We turn our attention now to the Input Window, 
which does double duty for Shortcut Search and 
arbitrary text entry for full translation. We will 
consider the search facility first, as shown in Fig-
ure 2. 
? Shortcuts Search begins automatically as 
soon as text is entered by any means ? voice, 
handwriting, touch screen, or standard keyboard ? 
into the Input Window. 
? The Shortcuts Drop-down Menu appears 
just below the Input Window, as soon as there are 
results to be shown. The user has entered ?Good? 
and a space, so the search program has received its 
first input word. The drop-down menu shows the 
results of a keyword-based search.  
? Here, the results are sorted alphabetically. 
Various other sorting possibilities may be useful: 
by frequency of use, proportion of matched words, 
etc.  
? The highest priority Shortcut according to 
the specified sorting procedure can be highlighted 
for instant execution.  
? Other shortcuts will be highlighted differ-
ently, and both kinds of highlighting are synchro-
nized with that of the Shortcuts list in the Shortcuts 
Panel.  
? Arrow keys or voice commands can be 
used to navigate the drop-down list. 
? If the user goes on to enter the exact text of 
any Shortcut, e.g. ?Good morning,? a message will 
show that this is in fact a Shortcut, so that verifica-
tion will not be necessary. However, final text not 
matching a Shortcut, e.g. ?Good job,? will be 
passed to the routines for full translation with veri-
fication. 
4 Multimodal input 
As mentioned, an unavoidable issue for speech 
translation systems in healthcare settings is that 
speech input is not appropriate for every situation. 
Current speech-recognition systems are unfa-
miliar for many users. Our system attempts to 
overcome this training issue to some extent by in-
corporating standard commercial-grade dictation 
systems for broad-coverage and ergonomic speech 
recognition. These products already have estab-
lished user bases in the healthcare community. 
Even so, some training may be required: optional 
generic Guest profiles are supplied by our system 
for male and female voices in both languages; but 
optional voice enrollment, requiring five minutes 
or so, is helpful to achieve best results. Such train-
ing time is practical for healthcare staff, but will be 
realistic for patients only when they are repeat visi-
tors, hospital-stay patients, etc. 
As mentioned, other practical usability issues 
for the use of speech input in healthcare settings 
include problems of ambient noise (e.g. in emer-
gency rooms or ambulances) and problems of mi-
crophone and computer arrangement (e.g. to 
accommodate not only desktops but counters or 
service windows which may form a barrier be-
tween staff and patient). 
To deal with these and other usability issues, we 
have found it necessary to provide a range of input 
modes: in addition to dictated speech, we enable 
handwritten input, the use of touch screen key-
boards for text input, and the use of standard key-
boards. All of these input modes must be 
completely bilingual, and language switching must 
be arranged automatically when there is a change 
of active participant. Further, it must be possible to 
change input modes seamlessly within a given ut-
terance: for example, users must be able to dictate 
the input if they wish, but then be able to make 
corrections using handwriting or one of the re-
maining two modes. Figure 3 shows such seamless 
bilingual operation: the user has dictated the sen-
tence ?Tengo n?useas? in Spanish, but there was a 
speech-recognition error, which is being corrected 
by handwriting.  
Of course, even this flexible range of input op-
tions does not solve all problems. As mentioned, 
illiterate patients pose special problems. Again, 
na?ve users tend to suppose that speech is the ideal 
input mode for illiterates. Unfortunately, however, 
the careful and relatively concise style of speech 
that is required for automatic recognition is often 
difficult to elicit, so that recognition accuracy re-
mains low; and the ability to read and correct the 
results is obviously absent. Just as obviously, the 
remaining three text input modes will be equally 
ineffectual for illiterates. 
As explained, our current approach to low liter-
acy is to supply Translation Shortcuts for the mini-
mally literate, and ? in the future ? to augment 
Shortcuts with text-to-speech and iconic pictures. 
Staff members will usually be at least mini-
mally literate, but they present their own usability 
issues. 
Their typing skills may be low or absent. Han-
dling the computer and/or microphone may be 
awkward in many situations, e.g. when examining 
a patient or taking notes. (Speech translation sys-
tems are expected to function in a wide range of 
physical settings: in admissions or financial aid 
offices, at massage tables for physical therapy with 
patients lying face down, in personal living rooms 
for home therapy or interviews, and in many other 
locations.) 
To help deal with the awkwardness issues, our 
system provides voice commands, which enable 
hands-free operation. Both full interactive transla-
tion and the Translation Shortcut facility (using 
either the Browser or Search elements) can be run 
hands-free. To a limited degree, the system can be 
used eyes-free as well: text-to-speech can be used 
to pronounce the back-translation so that prelimi-
nary judgments of translation quality can be made 
without looking at the computer screen. 
5 Future developments 
We have already mentioned plans to augment the 
Translation Shortcuts facility with text-to-speech 
and iconic pictures, thus moving closer to a system 
suitable for communication with completely illiter-
ate or incapacitated patients. 
Additional future directions follow. 
? Server-based architectures:  We plan to 
move toward completely or partially server-based 
arrangements, in which only a very thin client 
software application ? for example, a web interface 
? will run on the client device. Such architectures 
will permit delivery of our system on smart phones 
in the Blackberry or Treo class. Delivery on hand-
helds will considerably diminish the issues of 
physical awkwardness discussed above, and any-
time/anywhere/any-device access to the system 
will considerably enlarge its range of uses. 
? Pooling Translation Shortcuts:  As ex-
plained above, the current system now supports 
both Personal (do-it-yourself) and Shared (pre-
packaged) Translation Shortcuts. As yet, however, 
there are no facilities to facilitate pooling of Per-
sonal Shortcuts among users, e.g. those in a work-
ing group. In the future, we will add facilities for 
exporting and importing shortcuts. 
? Translation memory: Translation Short-
cuts can be seen as a variant of Translation Mem-
ory, a facility that remembers past successful 
translations so as to circumvent error-prone re-
processing. However, at present, we save Shortcuts 
only when explicitly ordered. If all other successful 
translations were saved, there would soon be far 
too many to navigate effectively in the Translation 
Shortcuts Browser. In the future, however, we 
could in fact record these translations in the back-
ground, so that there would be no need to re-verify 
new input that matched against them. Messages 
would advise the user that verification was being 
bypassed in case of a match. 
? Additional languages: The full SLT sys-
tem described here is presently operational only for 
bidirectional translation between English and 
Spanish. We expect to expand the system to Man-
darin Chinese next. Limited working prototypes 
now exist for Japanese and German, though we 
expect these languages to be most useful in appli-
cation fields other than healthcare. 
? Testing: Systematic usability testing of the 
full system is under way. We look forward to pre-
senting the results at a future workshop. 
6 Conclusion 
We have described a highly interactive system for 
bidirectional, broad-coverage spoken language 
communication in the healthcare area. The paper 
has briefly reviewed the system's interactive foun-
dations, and then gone on to discuss in greater 
depth issues of practical usability.   
We have presented our Translation Shortcuts 
facility, which minimizes the need for interactive 
verification of sentences after they have been vet-
ted once, considerably speeds throughput while 
maintaining accuracy, and allows use by minimally 
literate patients for whom any mode of text entry 
might be difficult.  
We have also discussed facilities for multimo-
dal input, in which handwriting, touch screen, and 
keyboard interfaces are offered as alternatives to 
speech input when appropriate. In order to deal 
with issues related to sheer physical awkwardness, 
we have briefly mentioned facilities for hands-free 
or eyes-free operation of the system.   
Finally, we have pointed toward several direc-
tions for future improvement of the system. 
References  
Pierrette Bouillon, Manny Rayner, et al 2005. A Ge-
neric Multi-Lingual Open Source Platform for Lim-
ited-Domain Medical Speech Translation. Presented 
at EAMT 2005, Budapest, Hungary. 
 
Mike Dillinger and Mark Seligman. 2004. A highly 
interactive speech-to-speech translation system. Pro-
ceedings of the VI Conference of the Association of 
Machine Translation in the Americas. E. Strouds-
burg, PA:  American Association for Machine Trans-
lation. 
 
Glenn Flores, M. Laws, S. Mays, et al 2003. Errors in 
medical interpretation and their potential clinical 
consequences in pediatric encounters. Pediatrics, 
111: 6-14. 
 
Minnesota Interpreter Standards Advisory Committee. 
1998.  Bridging the Language Gap: How to meet the 
need for interpreters in Minnesota. Available at: 
http://www.cce.umn.edu/creditcourses/pti/ 
downloads.html. 
 
Melinda Paras, O. Leyva, T. Berthold, and R. Otake. 
2002. Videoconferencing Medical Interpretation:  
The results of clinical trials. Oakland, CA: Heath 
Access Foundation. 
 
PHRASELATOR (2006). http://www.phraselator.com. 
As of April 3, 2006. 
 
S-MINDS (2006). http://www.sehda.com/solutions.htm. 
As of April 3, 2006. 
 
Mark Seligman. 2000. Nine Issues in Speech Transla-
tion. Machine Translation, 15, 149-185. 
 
Chengqing Zong and Mark Seligman. Forthcoming. 
Toward Practical Spoken Language Translation. Ma-
chine Translation. 
 
 
 
 
 
Figure 1: The Input Screen, showing the Translation Shortcuts Browser and Search facilities. 
 
 
 
Figure 2: The Input Screen, showing automatic keyword search of the Translation Shortcuts. 
 
 
 
 
Figure 3: The Input Screen, showing correction of dictation with handwritten input. 
 
 
 
Converser?:  
Highly Interactive Speech-to-Speech 
Translation for Healthcare 
 
Mike Dillinger Mark Seligman 
Spoken Translation, Inc. Spoken Translation, Inc. 
Berkeley, CA, USA 94705 Berkeley, CA, USA 94705 
mike.dillinger 
@spokentranslation.com 
mark.seligman 
@spokentranslation.com 
 
  
Abstract 
We describe a highly interactive system for 
bidirectional, broad-coverage spoken lan-
guage communication in the healthcare area. 
The paper briefly reviews the system's inter-
active foundations, and then goes on to dis-
cuss in greater depth our Translation 
Shortcuts facility, which minimizes the need 
for interactive verification of sentences after 
they have been vetted. This facility also con-
siderably speeds throughput while maintain-
ing accuracy, and allows use by minimally 
literate patients for whom any mode of text 
entry might be difficult.  
1 Introduction 
Spoken Translation, Inc. (STI) of Berkeley, CA 
has developed a commercial system for interactive 
speech-to-speech machine translation designed for 
both high accuracy and broad linguistic and topical 
coverage. Planned use is in situations requiring 
both of these features, for example in helping 
Spanish-speaking patients to communicate with 
English-speaking doctors, nurses, and other health-
care staff. 
The twin goals of accuracy and broad cov-
erage have until now been in opposition: speech 
translation systems have gained tolerable accuracy 
only by sharply restricting both the range of topics 
which can be discussed and the sets of vocabulary 
and structures which can be used to discuss them. 
The essential problem is that both speech recogni-
tion and translation technologies are still quite er-
ror-prone. While the error rates may be tolerable 
when each technology is used separately, the errors 
combine and even compound when they are used 
together. The resulting translation output is gener-
ally below the threshold of usability ? unless re-
striction to a very narrow domain supplies 
sufficient constraints to significantly lower the er-
ror rates of both components. 
STI?s approach has been to concentrate on inter-
active monitoring and correction of both technolo-
gies.   
First, users can monitor and correct the 
speaker-dependent speech recognition system to 
ensure that the text, which will be passed to the 
machine translation component, is completely cor-
rect. Voice commands (e.g. Scratch That or Cor-
rect <incorrect text>) can be used to repair 
speech recognition errors. While these commands 
are similar in appearance to those of IBM's 
ViaVoice or ScanSoft?s Dragon NaturallySpeaking 
dictation systems, they are unique in that they will 
remain usable even when speech recognition oper-
ates at a server. Thus, they will provide for the first 
time the capability to interactively confirm or cor-
rect wide-ranging text, which is dictated from any-
where. 
Next, during the MT stage, users can monitor, 
and if necessary correct, one especially important 
aspect of the translation ? lexical disambiguation. 
STI's approach to lexical disambiguation is 
twofold: first, we supply a specially controlled 
back translation, or translation of the translation. 
Using this paraphrase of the initial input, even a 
monolingual user can make an initial judgment 
concerning the quality of the preliminary machine 
translation output. To make this technique effec-
tive, we use proprietary facilities to ensure that the 
lexical senses used during back translation are ap-
propriate. 
In addition, in case uncertainty remains about 
the correctness of a given word sense, we supply a 
proprietary set of Meaning Cues? ? synonyms, 
definitions, etc. ? which have been drawn from 
various resources, collated in a unique database 
(called SELECT?), and aligned with the respec-
tive lexica of the relevant machine translation sys-
tems. With these cues as guides, the user can select 
the preferred meaning from among those available. 
Automatic updates of translation and back transla-
tion then follow. 
The result is an utterance, which has been 
monitored and perhaps repaired by the user at two 
levels ? those of speech recognition and transla-
tion. By employing these interactive techniques 
while integrating state-of-the-art dictation and ma-
chine translation programs ? we work with Dragon 
Naturally Speaking for speech recognition; with 
Word Magic MT (for the current Spanish system); 
and with ScanSoft for text-to-speech ? we have 
been able to build the first commercial-grade 
speech-to-speech translation system which can 
achieve broad coverage without sacrificing accu-
racy. 
2 Translation Shortcuts 
In order to accumulate translations that have been 
verified by hand and to simplify interaction with 
the system, we have developed additional func-
tionality called Translation Shortcuts?. 
Shortcuts are designed to provide two main ad-
vantages:  
First, re-verification of a given utterance is un-
necessary. That is, once the translation of an utter-
ance has been verified interactively, it can be saved 
for later reuse, simply by activating a Save as 
Shortcut button on the translation verification 
screen. The button gives access to a dialogue in 
which a convenient Shortcut Category for the 
Shortcut can be selected or created. At reuse time, 
no further verification will be required. (In addition 
to such dynamically created Personal Shortcuts, 
any number of prepackaged Shared Shortcuts can 
be included in the system.) 
Second, access to stored Shortcuts is very 
quick, with little or no need for text entry. Several 
facilities contribute to meeting this design crite-
rion.  
? A Shortcut Search facility can retrieve a 
set of relevant Shortcuts given only keywords or 
the first few characters or words of a string. The 
desired Shortcut can then be executed with a single 
gesture (mouse click or stylus tap) or voice com-
mand.  
NOTE: If no Shortcut is found, the system 
automatically gives access to the full power of 
broad-coverage, interactive speech translation. T-
hus, a seamless transition is provided between 
Shortcuts and full translation. 
? A Translation Shortcuts Browser is pro-
vided, so that users can find needed Shortcuts by 
traversing a tree of Shortcut categories. Using this 
interface, users can execute Shortcuts even if their 
ability to input text is quite limited, e.g. by tapping 
or clicking alone. 
The demonstration will show the Shortcut 
Search and Shortcuts Browser facilities in use. 
Points to notice:  
? The Translation Shortcuts Panel contains 
the Translation Shortcuts Browser, split into two 
main areas, Shortcuts Categories (above) and 
Shortcuts List (below).  
? The Categories section of the Panel shows 
the current selected category, for example Conver-
sation, which contains everyday expressions. This 
category has a Staff subcategory, containing ex-
pressions most likely to be used by healthcare staff 
members. There is also a Patients subcategory, 
used for patient responses. Such categories as Ad-
ministrative topics and Patient?s Current Condi-
tion are also available; and new ones can be freely 
created. 
? Below the Categories section is the Short-
cuts List section, containing a scrollable list of al-
phabetized Shortcuts. (Various other sorting 
criteria will be available in the future, e.g. sorting 
by frequency of use, recency, etc.)  
? Double clicking on any visible Shortcut in 
the List will execute it. Clicking once will select 
and highlight a Shortcut. Typing Enter will exe-
cute the currently highlighted Shortcut, if any.  
? It is possible to automatically relate op-
tions for a patient's response to the previous staff 
member?s utterance, e.g. by automatically going to 
the sibling Patient subcategory if the prompt was 
given from the Staff subcategory. 
Because the Shortcuts Browser can be used 
without text entry, simply by pointing and clicking, 
it enables responses by minimally literate users. In 
the future, we plan to enable use even by com-
pletely illiterate users, through two devices: we 
will enable automatic pronunciation of Shortcuts 
and categories in the Shortcuts Browser via text-to-
speech, so that these elements can in effect be read 
aloud to illiterate users; and we will augment 
Shared Shortcuts with pictorial symbols, as clues 
to their meaning. 
A final point concerning the Shortcuts Browser: 
it can be operated entirely by voice commands, 
although this mode is more likely to be useful to 
staff members than to patients. 
We turn our attention now to the Input Window, 
which does double duty for Shortcut Search and 
arbitrary text entry for full translation. We will 
consider the search facility first. 
? Shortcuts Search begins automatically as 
soon as text is entered by any means ? voice, 
handwriting, touch screen, or standard keyboard ? 
into the Input Window. 
? The Shortcuts Drop-down Menu appears 
just below the Input Window, as soon as there are 
results to be shown. The user can enter a few 
words at a time, and the drop-down menu will per-
form keyword-based searches and present the 
changing results dynamically.  
? The results are sorted alphabetically. Vari-
ous other sorting possibilities may be useful: by 
frequency of use, proportion of matched words, 
etc.  
? The highest priority Shortcut according to 
the specified sorting procedure can be highlighted 
for instant execution.  
? Highlighting in the drop-down menu is 
synchronized with that of the Shortcuts list in the 
Shortcuts Panel.  
? Arrow keys or voice commands can be 
used to navigate the drop-down menu. 
? If the user goes on to enter the exact text of 
any Shortcut, e.g. ?Good morning,? a message will 
show that this is in fact a Shortcut, so that verifica-
tion will not be necessary. However, final text not 
matching a Shortcut, e.g. ?Good job,? will be 
passed to the routines for full translation with veri-
fication. 
3 Future developments 
We have already mentioned plans to augment the 
Translation Shortcuts facility with text-to-speech 
and iconic pictures, thus moving closer to a system 
suitable for communication with completely illiter-
ate or incapacitated patients. 
Additional future directions follow. 
? Server-based architectures:  We plan to 
move toward completely or partially server-based 
arrangements, in which only a very thin client 
software application ? for example, a web interface 
? will run on the client device. Such architectures 
will permit delivery of our system on smart phones 
in the Blackberry or Treo class. Delivery on hand-
helds will considerably diminish the issues of 
physical awkwardness discussed above, and any-
time/anywhere/any-device access to the system 
will considerably enlarge its range of uses. 
? Pooling Translation Shortcuts:  As ex-
plained above, the current system now supports 
both Personal (do-it-yourself) and Shared (pre-
packaged) Translation Shortcuts. As yet, however, 
there are no facilities to facilitate pooling of Per-
sonal Shortcuts among users, e.g. those in a work-
ing group. In the future, we will add facilities for 
exporting and importing shortcuts. 
? Translation memory: Translation Short-
cuts can be seen as a variant of Translation Mem-
ory, a facility that remembers past successful 
translations so as to circumvent error-prone re-
processing. However, at present, we save Shortcuts 
only when explicitly ordered. If all other successful 
translations were saved, there would soon be far 
too many to navigate effectively in the Translation 
Shortcuts Browser. In the future, however, we 
could in fact record these translations in the back-
ground, so that there would be no need to re-verify 
new input that matched against them. Messages 
would advise the user that verification was being 
bypassed in case of a match. 
? Additional languages: The full SLT sys-
tem described here is presently operational only for 
bidirectional translation between English and 
Spanish. We expect to expand the system to Man-
darin Chinese next. Limited working prototypes 
now exist for Japanese and German, though we 
expect these languages to be most useful in appli-
cation fields other than healthcare. 
4 Conclusion 
We have described a highly interactive system for 
bidirectional, broad-coverage spoken language 
communication in the healthcare area. The paper 
has briefly reviewed the system's interactive foun-
dations, and then gone on to discuss in greater 
depth issues of practical usability.   
We have presented our Translation Shortcuts 
facility, which minimizes the need for interactive 
verification of sentences after they have been vet-
ted once, considerably speeds throughput while 
maintaining accuracy, and allows use by minimally 
literate patients for whom any mode of text entry 
might be difficult.  
We have also discussed facilities for multimo-
dal input, in which handwriting, touch screen, and 
keyboard interfaces are offered as alternatives to 
speech input when appropriate. In order to deal 
with issues related to physical awkwardness, we 
have briefly mentioned facilities for hands-free or 
eyes-free operation of the system.   
Finally, we have pointed toward several direc-
tions for future improvement of the system. 
 
Coling 2008: Proceedings of the workshop on Speech Processing for Safety Critical Translation and Pervasive Applications, pages 40?47
Manchester, August 2008
Rapid Portability among Domains in an  
Interactive Spoken Language Translation System  
Mark Seligman  
Spoken Translation, Inc.  
Berkeley, CA, USA 94705 
mark.seligman 
@spokentranslation.com 
Mike Dillinger  
Spoken Translation, Inc.  
Berkeley, CA, USA 94705 
mike.dillinger 
@spokentranslation.com 
 
Abstract 
 
Spoken Language Translation systems have 
usually been produced for such specific domains as 
health care or military use. Ideally, such systems 
would be easily portable to other domains in which 
translation is mission critical, such as emergency 
response or law enforcement. However, porting has in 
practice proven difficult. This paper will comment on 
the sources of this difficulty and briefly present an 
approach to rapid inter-domain portability. Three 
aspects will be discussed: (1) large general-purpose 
lexicons for automatic speech recognition and 
machine translation, made reliable and usable through 
interactive facilities for monitoring and correcting 
errors; (2) easily modifiable facilities for instant 
translation of frequent phrases; and (3) quickly 
modifiable custom glossaries. As support for our 
approach, we apply our current SLT system, now 
optimized for the health care domain, to sample 
utterances from the military, emergency service, and 
law enforcement domains, with discussion of 
numerous specific sentences.  
1 Introduction  
Recent years have seen increasing research and 
commercial activity in the area of Spoken Language 
Translation (SLT) for mission-critical applications. In 
the health care area, for instance, such products as 
Converser (Dillinger & Seligman, 2006), S-MINDS 
(www.fluentialinc.com), and Med-SLT (Bouillon et 
al, 2005) are coming into use. For military 
applications, products like Phraselator 
(www.phraselator.com) and S-MINDS 
(www.fluentialinc.com) have been deployed. 
However, the demand for real-time translation is by 
no means restricted to these areas: it is clear in 
numerous other areas not yet extensively addressed ? 
emergency services, law enforcement, and others.  
Ideally, a system produced for one such domain 
(e.g., health care) could be easily ported to other 
domains. However, porting has in practice proven 
difficult. This paper will comment on the sources of 
                                                 
? 2008. Licensed under the Creative Commons Attri-
bution-Noncommercial-Share Alike 3.0 Unported 
license (http://creativecommons.org/licenses/by-nc-
sa/3.0/). Some rights reserved. 
this difficulty and briefly present an approach to rapid 
inter-domain portability that we believe is promising. 
Three aspects of our approach will be discussed: (1) 
large general-purpose lexicons for automatic speech 
recognition (ASR) and machine translation (MT), 
made reliable and usable through interactive facilities 
for monitoring and correcting errors; (2) easily 
modifiable facilities for instant translation of frequent 
phrases; and (3) quickly modifiable custom glossaries.  
As preliminary support for our approach, we 
apply our current SLT system, now optimized for the 
health care domain, to sample utterances from the 
military, emergency service, and law enforcement 
domains.  
With respect to the principal source of the porting 
problems affecting most SLT systems to date: most 
systems have relied upon statistical approaches for 
both ASR and MT (Karat and Nahamoo, 2007; 
Koehn, 2008); so each new domain has required 
extensive and high-quality in-domain corpora for best 
results, and the difficulty of obtaining them has 
limited these systems? portability. The need for in-
domain corpora can be eliminated through the use of a 
quite general corpus (or collection of corpora) for 
statistical training; but because large corpora give rise 
to quickly increasing perplexity and error rates, most 
SLT systems have been designed for specialized 
domains.  
By contrast, breadth of coverage has been a 
central design goal of our SLT systems. Before any 
optimization for a specific domain, we ?give our 
systems a liberal arts education? by incorporating 
very broad-coverage ASR and MT technology. (We 
presently employ rule-based rather than statistical MT 
components, but this choice is not essential.) For 
example, our MT lexicons for English<>Spanish 
translation in the health care area contain roughly 
350,000 words in each direction, of which only a 
small percentage are specifically health care terms. 
Our translation grammars (presently licensed from a 
commercial source, and further developed with our 
collaboration) are similarly designed to cover the 
structures of wide-ranging general texts and spoken 
discourse.  
To deal with the errors that inevitably follow as 
coverage grows, we provide a set of facilities that 
enable users from both sides of the language barrier to 
40
interactively monitor and correct such errors. We have 
described these interactive techniques in (Dillinger 
and Seligman, 2004; Zong and Seligman, 2005; 
Dillinger and Seligman, 2006; and Seligman and 
Dillinger, 2006). With users thus integrated into the 
speech translation loop, automatically translated 
spoken conversations can range widely with 
acceptable accuracy (Seligman, 2000). Users can 
move among domains with relative freedom, even in 
advance of lexical or other domain specialization, 
because most domains are already covered to some 
degree. After a quick summary of our approach (in 
Section 2), we will demonstrate this flexibility (in 
Section 3).  
While our system?s facilities for monitoring and 
correction of ASR and MT are vital for accuracy and 
confidence in wide-ranging conversations, they can be 
time consuming. Further, interactivity demands a 
minimum degree of computer and print literacy, 
which some patients may lack. To address these 
issues, we have developed a facility called 
Translation Shortcuts?, through which prepared 
translations of frequent or especially useful phrases in 
the current domain can be instantly executed by 
searching or browsing. The facility is described in 
(Seligman and Dillinger, 2006). After a quick 
description of the Translation Shortcuts facility 
(Section 4), this paper will emphasize the contribution 
of the Translation Shortcuts facility to domain 
portability, showing how a domain-specific set of 
Shortcuts can be composed and integrated into the 
system very quickly (Section 5).  
Finally, while the extensive lexical resources 
already built into the system provide the most 
significant boost to domain portability in our system, 
it will always be desirable to add specialized lexical 
items or specialized meanings of existing ones. 
Section 6 will briefly present our system?s glossary 
import facility, through which lexical items can be 
added or updated very quickly. Our concluding 
remarks appear in Section 7.  
2 Highly Interactive, Broad-coverage 
SLT  
We now briefly summarize our group?s approach 
to highly interactive, broad-coverage SLT. Our 
systems stress interactive monitoring and correction 
of both ASR and MT.  
First, users can monitor and correct the speaker-
dependent speech recognition system to ensure that 
the text which will be passed to the machine 
translation component is as correct as necessary. 
Voice commands (e.g., Scratch That or Correct 
<incorrect text>) can be used to repair speech 
recognition errors. Thus, users of our SLT systems in 
effect serve to enhance the interface between ASR 
and MT.  
Next, during the MT stage, users can monitor, 
and if necessary correct, translation errors.  
As an initial safeguard against translation errors, 
we supply a back-translation, or re-translation of the 
translation. Using this paraphrase of the initial input, 
even a monolingual user can make an initial judgment 
concerning the quality of the preliminary machine 
translation output. If errors are seen, the user can 
modify specific parts of the input and retranslate. 
(Other systems, e.g. IBM?s MASTOR (Gao et al 
2006), have also employed re-translation. Our 
implementations, however, exploit proprietary 
technologies to ensure that the lexical senses used 
during back-translation accurately reflect those used 
in forward translation. We also allow users to modify 
part or all of the input before regenerating the 
translation and back-translation.)  
In addition, if uncertainty remains about the 
correctness of a given word sense, we supply a 
proprietary set of Meaning Cues? ? synonyms, 
definitions, examples, pictures, etc. ? which have 
been drawn from various resources, collated in a 
database (called SELECT?), and aligned with the 
respective lexica of the relevant MT systems. (In the 
present English<>Spanish version of the system, this 
database contains some 140,000 entries, 
corresponding to more than 350,000 lexical entries. 
The cues are automatically grouped by meaning, and 
cue groups are automatically mapped to MT lexica 
using proprietary techniques ? thus in effect 
retrofitting an MT system with the ability to explain 
to users the meanings of its pre-existing lexical 
items.) With these cues as guides, the user can 
monitor the current, proposed meaning and if 
necessary select a different, preferred meaning from 
among those available. Automatic updates of 
translation and back-translation then follow. (Our 
current MT vendor has modified its rule-based 
translation engine to allow specification of a desired 
sense when translating a word or expression; we 
provide guidelines for other vendors to do likewise. 
Comparable modifications for statistical MT engines 
will entail the setting of temporary weightings that 
will bias the selection of word or phrase translations 
for the current sentence only.) Future versions of the 
system will allow personal word-sense preferences 
thus specified in the current session to be optionally 
stored for reuse in future sessions, thus enabling a 
gradual tuning of word-sense preferences to 
individual needs. (However, such persistent personal 
preferences will still be applied sentence by sentence, 
rather than by permanently modifying lexica or phrase 
tables. Further, users will always be able to 
temporarily override, or permanently reset, their 
personal preferences.) Facilities will also be provided 
for sharing such preferences across a working group.  
Given such interactive correction of both ASR 
and MT, wide-ranging, and even playful, exchanges 
become possible (Seligman, 2000). Such interactivity 
within a speech translation system enables increased 
accuracy and confidence, even for wide-ranging 
conversations.  
41
3 Advantages of Very Broad Coverage 
for Domain Switching  
This section discusses the advantages of very 
broad lexical coverage for rapid domain porting. 
Using our interactive SLT system in its present 
configuration, optimized for the health care domain 
but with a general-purpose foundation of over 60,000 
lexical items for ASR and 350,000 lexical items for 
rule-based MT, we will test several input sentences 
from each of three distinct domains in which 
translation is mission-critical ? military, emergency 
response, and law enforcement. The test sentences 
were invented by the authors; readers can judge their 
plausibility. They were pronounced by Seligman 
using the built-in microphone of a Motion Computing 
LE1600 tablet PC equipped with a push-to-talk 
button. 
For each input, we will show (1) the English 
input, (2) the original Spanish translation, and (3) the 
English back-translation. We also comment on several 
factors:  
? If ASR errors occurred, we describe their 
interactive resolution. (All inputs were corrected 
before proceeding with translation. All 
corrections were made by voice.)  
? If our Meaning Cues facility indicated 
questionable meanings for any of the expressions 
in the input, we note the problems and describe 
the resolutions.  
? Some problems in translation result from bugs or 
gaps in the translation component. These are 
marked for repair. (Because our MT components 
are presently rule-based, we can address such 
problems individually and manually. If a 
statistical MT component were used instead, the 
recorded errors could guide the selection of texts 
for further training.) 
 
As mentioned, in our system, the back-translation 
is designed to function as the first line of defense 
against inadequate translation. If an unsatisfactory 
back-translation is obtained, we advise users to re-
phrase the input and translate again until satisfied. 
(False negatives sometimes occur, though we work to 
eliminate them; however, it is best to err on the side of 
caution.) If the back-translation is satisfactory, we 
advise checking the Meaning Cues as a defense 
against false positives. These may result if an am-
biguous English input word is translated into Spanish 
in the wrong sense (for instance, bank may be trans-
lated as banco ("financial institution") when orilla del 
r?o ("riverbank") is wanted), but is nevertheless re-
translated as the same ambiguous English word 
(bank). We are experimenting with mechanisms to 
eliminate such cases by substituting non-ambiguous 
synonyms in the back-translation for ambiguous input 
words. In the current tests, if back-translations are 
judged insufficient to convey the intended meaning, 
paraphrases are substituted and any lexical translation 
errors are corrected until acceptable results are 
achieved. All such paraphrases are displayed below, 
whether they involve simple word substitutions or 
more extensive changes. 
Military Domain   
input initial transla-
tion 
back-
translation 
comments 
Watch out for 
mines around 
here  
tenga cuidado 
con minas por 
aqu? 
Be careful with 
mines around 
here 
ASR: mines misrecognized as minds 
MT: mines mistranslated as minas (?reserve, 
mine?); meaning interactively changed to 
minas (?booby trap, ground-emplaced mine, 
land mine?) 
[retranslation]  tenga cuidado 
con minas por 
aqu? 
Be careful with 
mines around 
here 
Spanish is unchanged, but correct meaning 
has been verified. 
We confiscated 
their arms last 
week  
confiscamos sus 
brazos la semana 
pasada 
We confiscated 
their arms last 
week 
MT: arms mistranslated as brazos (?bra-
chia?); retranslated as armas (?arm, gun, 
weapon?) 
[retranslation] confiscamos sus 
armas la semana 
pasada 
We confiscated 
their weapons 
last week 
 
The operation is 
scheduled for oh 
600  
la operaci?n es 
programada para 
oh 600 
The operation is 
programmed for 
oh 600. 
ASR: The misrecognized as knee.  
MT: Translation of oh 600 is uncertain 
The operation is 
scheduled for 6 
a.m. 
la operaci?n es 
programada para 
6 a.m. 
The operation is 
programmed for 
6 a.m. 
MT: Translation of 6 a.m. is still unclear. 
The operation is 
scheduled for six 
o?clock in the 
morning 
la operaci?n es 
programada para 
las seis de la 
ma?ana 
The operation is 
programmed for 
six in the morn-
ing 
MT: Translation is now verified, given slight 
rewording (six instead of six o'clock). 
42
We're training 
them as guerrillas 
Los entrenamos 
como guerrillas 
We train them 
like guerrillas 
ASR: Correct spelling (c.f. gorillas) was pro-
duced.  
MT: Bug: tolerable back-translation error: 
like should be as. 
NOTE: For the military domain and more generally, improved translation of day times, especially when expressed as military time, is 
clearly needed.  
  
Emergency Response Domain 
input initial transla-
tion 
back-
translation 
comments 
Tell them to drop 
the food at head-
quarters  
D?gales a ellos 
que dejen caer 
la comida en 
cuartel general 
Tell them to 
them that they 
drop the food in 
headquarters 
MT: Bug: tolerable Spanish>English mis-
translation of pattern ?digales a  ellos que 
<action>? (?tell them to <action>?); drop 
mistranslated as ?drop down, drop away, let 
fall, ??, but no suitable alternate meaning 
found; substituting drop off 
? drop off ? d?gales a ellos 
que dejen caer 
la comida en 
cuartel general 
Tell them to 
them that they 
drop the food in 
headquarters 
MT: translation and back-translation un-
changed; still no suitable meaning; substi-
tuting leave 
... leave ... D?gales a ellos 
que dejen la 
comida en cuar-
tel general 
Tell them to 
them that they 
leave the food at 
headquarters 
MT: back-translation and Meaning Cues now 
okay  
We need more 
shovels and 
crowbars right 
now 
Necesitamos 
m?s palas y m?s 
palancas ahora 
mismo 
we need more 
shovels and more 
levers right now 
MT: back-translation levers is considered 
okay for crowbars 
It's a matter of 
life and death 
es cuesti?n de la 
vida y la muerte 
it is issue of life 
and Death 
MT: capitalization of death prompts uncer-
tainty; rephrasing 
It's absolutely 
critical. 
Es absoluta-
mente cr?tico. 
it's absolutely 
critical 
MT: meaning cues for critical are okay: ?fi-
nal, significant, key, crucial ?? 
These people are 
desperately short 
of water  
Estas personas 
andan desespe-
radamente es-
casas de agua. 
These people are 
desperately 
scarce of water 
MT: Spanish is okay, but poor back-
translation of escasas de (should be ?short 
of/low on?) gives false negative, low confi-
dence. Substituting low on.  
.. low on ... Estas personas 
andan desespe-
radamente de 
capa ca?da en 
agua. 
These people 
incur in desper-
ately on water. 
MT: worse; rephrasing 
These people are 
desperate for 
water 
estas personas 
est?n desespe-
radas para agua. 
These people are 
desperate for 
water. 
MT: Preposition error in Spanish (para 
should be por) gives false positive, but 
meaning is clear 
    
Law Enforcement Domain      
input initial transla-
tion 
back-
translation 
comments 
Step away from 
the car 
Al?jese del coche Get away from 
the car 
MT: get away is acceptable for step away 
May I see your 
license, please 
Que pueda ver 
su licencia, por 
favor. 
That I can see 
your license, 
please. 
MT: Unacceptable mistranslation of pattern 
?que pueda <action>, por favor? (?may I 
<action>, please?); rephrasing 
Show me your 
license, please 
Mu?streme su 
licencia, por fa-
vor. 
Show me your 
license, please 
 
Keep your hands 
where I can see 
them  
Conserve sus 
manos donde las 
puedo ver. 
Preserve your 
hands where I 
can see them. 
MT: keep mistranslated as conserve (?take, 
hold, maintain, save, retain, preserve, ??); 
retranslated as mantenga (?keep?) 
43
[retranslation] Mantenga sus 
manos donde las 
puedo ver 
Keep your hands 
where I can see 
them 
 
How long have 
you been living at 
this address? 
Cu?nto tiempo 
usted ha vivido 
en esta direc-
ci?n? 
How long have 
you been living in 
this address? 
MT: minor but tolerable error with preposi-
tions  
Who's your in-
surer 
Qui?n es su 
asegurador 
Who is your in-
surer 
 
NOTE: General-purpose Spanish>English pattern ?que pueda <action>, por favor? (?may I <action>, please?) requires fix for all domains. 
 
4 Translation Shortcuts 
Having summarized our approach to highly 
interactive speech translation and discussed the 
advantages of very broad lexical and grammatical 
coverage for domain switching, we now turn to the 
use of Translation Shortcuts? in domain ports. This 
section briefly describes the facility; and Section 5 
explains the methods for quickly updating Shortcuts 
as an element of a rapid port.  
A Translation Shortcut contains a short 
translation, typically of a sentence or two, which has 
been pre-verified, whether by a human translator or 
through the use of the system?s interactive tools. Thus 
re-verification of the translation is unnecessary. In this 
respect, Translation Shortcuts provide a kind of 
translation memory. However, it is a handmade sort of 
memory (since Shortcuts are composed by linguists or 
explicitly saved by users) and a highly interactive sort 
as well (since users can browse or search for 
Shortcuts, can make and categorize their own 
Shortcuts, and are advised when the input matches a 
Shortcut). It is in the ease of composition or 
customization, as well as in the quality of the 
interaction, that innovation can be claimed.  
We can consider the quality of interaction first. 
Access to stored Shortcuts is very quick, with little or 
no need for text entry. Several facilities contribute to 
meeting this design criterion:  
? A Shortcut Search facility can retrieve a set of 
relevant Shortcuts given only keywords or the 
first few characters or words of a string. The 
desired Shortcut can then be executed with a 
single gesture (mouse click or stylus tap) or voice 
command.  
NOTE: If no Shortcut is found, the system 
automatically allows users access to the full 
power of broad-coverage, interactive speech 
translation. Thus, a seamless transition is 
provided between the Shortcuts facility and 
full, broad-coverage translation.  
? A Translation Shortcuts Browser is provided, so 
that users can find needed Shortcuts by traversing 
a tree of Shortcut categories. Using this interface, 
users can execute Shortcuts by tapping or 
clicking alone. 
 
Figure 1 below shows the Shortcut Search and 
Shortcuts Browser facilities in use.  
? On the left, the Translation Shortcuts Panel 
contains the Translation Shortcuts Browser, split 
into two main areas, Shortcuts Categories (above) 
and Shortcuts List (below).  
 
 
 
Figure 1: The Input Screen, showing the Translation Shortcuts Browser and Shortcut Search facilities. Note the 
new Nutrition category and the results of automatic Shortcut Search. 
44
? The Categories section of the Panel shows 
current selection of the Nutrition category, 
containing frequently used questions and 
answers for a nutrition interview. This new 
category was created overnight, as described in 
Section 5, below. Currently hidden is its Staff 
subcategory, containing expressions most 
likely to be used by health care staff members. 
There is also a Patients subcategory, used for 
patient responses. Categories for Background 
information, Directions, etc. are also visible.  
? Below the Categories section is the Shortcuts 
List section, containing a scrollable list of 
alphabetized Shortcuts. Double clicking on any 
visible Shortcut in the List will execute it. 
Clicking once will select and highlight a 
Shortcut. Typing Enter will execute any 
currently highlighted Shortcut. 
 
We turn our attention now to the Input 
Window, which does double duty for Shortcut 
Search and arbitrary text entry for full translation. 
The search facility is also shown in Figure 1.  
? Shortcuts Search begins automatically as soon 
as text is entered by any means ? voice, 
handwriting, touch screen, or standard 
keyboard ? into the Input Window.  
? The Shortcuts Drop-down Menu appears just 
below the Input Window, as soon as there are 
results to be shown. The user has entered ?Do 
you have?. The drop-down menu shows the 
results of a search within the new Nutrition 
category based upon these initial characters.  
 
If the user goes on to enter the exact text of 
any Shortcut in this category, e.g. ?Do you have 
any food allergies?,? the interface will show that 
this is in fact a Shortcut, so that verification of 
translation accuracy will not be necessary. 
However, final text not matching a Shortcut, e.g. 
?Do you have any siblings?? will be passed to the 
routines for full translation with verification. 
A Personal Translation Shortcuts? facility is 
in progress for future versions of the system: once a 
user has verified a translation via the interactive 
facilities described above, he or she can save it for 
future reuse by pressing a Save as Shortcut button. 
The new custom Shortcut will then be stored in a 
personal profile. Facilities for sharing Shortcuts 
will also be provided.  
5 Rapid Customization of Translation 
Shortcuts for New Domains  
Translation Shortcuts are stored and 
distributed as text-format XML files. Each file 
contains information about which categories (e.g. 
Nutrition) and subcategories (Staff, Patient, etc.) 
to which each phrase belongs. Since Shortcuts are 
stored as external data files, integration of new 
Shortcuts into the system is straightforward and 
highly scalable. Once we have built a database of 
frequently used expressions and their translations 
for a given domain (in which there may be 
thousands of expressions or just a few), we can 
automatically generate the associated files in XML 
format in minutes. Once this new file is added to 
the appropriate directory, the Shortcuts become 
usable in the next session for text- or voice-driven 
searching and browsing. The entire sequence can 
be completed overnight. In one case, the Nutrition 
Department of a major hospital submitted several 
pages of frequently asked questions, which were 
entered, translated, re-generated as an XML file, 
and integrated into the system for demonstration 
the next day.  
 
<Category categoryName1= "Nutrition" categoryName2="Alimentaci?n"> 
           <Categories> 
             <Category categoryName1="Staff" categoryName2="Personal"> 
                 <Shortcuts> 
                     <Shortcut categoryPath="Nutrition\\Staff"> 
                         <Language1Text>Do you have any food allergies?</Language1Text> 
                         <Language2Text>?Tiene alguna alergia a alguna comida?</Language2Text> 
                     </Shortcut> 
                     <Shortcut categoryPath="Nutrition\\Staff"> 
                         <Language1Text>Can you tolerate milk?</Language1Text> 
                         <Language2Text>?Tolera la leche?</Language2Text> 
                     </Shortcut> 
                     <Shortcut categoryPath="Nutrition\\Staff"> 
                         <Language1Text>Do you follow a special diet at home?</Language1Text> 
                         <Language2Text>?Sigue alguna dieta especial en casa?</Language2Text> 
                     </Shortcut> 
                 </Shortcuts> 
             </Category> 
             </Categories> 
           </Category> 
 
Figure 2: Sample fragment of an automatically formatted Translation Shortcuts file for the Nutrition>Staff 
category and subcategory. 
45
 6 Use of the Glossary Import for Quick 
Domain Switching  
Similarly, our system includes a glossary import 
function which supports quick addition of domain-
specific or other custom lexical information (e.g., site-
specific or client-specific vocabulary), once again in 
text format. This glossary file may provide additional 
terms or may stipulate preferred (and thus overriding) 
translations for existing terms. The glossary file is 
automatically generated from a simple, two-column 
text-format file in which each line contains the 
source-language and target-language terms. A system 
utility will then generate the necessary linguistic 
markup (in curly brackets in Figure 3) for each of the 
terms. (Markup can be elaborated as appropriate for 
the machine translation engine in use, e.g. to specify 
verb sub-categorization, semantic class, etc.) Like the 
XML file used for Translation Shortcuts, the resulting 
custom glossary file can simply be placed in the 
appropriate directory.  
 
hemol?tico  { A, 11, 6, 0,  } = hemolytic 
hemolitopoy?tico  { A, 11, 6, 0,  } = hemolytopoietic 
hemolizable  { A, 11, 6, 0,  } = hemolyzable 
hemolizaci?n  { N, 2, 2, 1,  } = hemolyzation 
hemolizar  { V, 7, 0, 1,  } = hemolyze  
derecho { A, 11, 6, 0,  } = right  
 
Figure 3. Sample glossary-import entries for the 
health care domain.  
 
Here, the entry for right establishes the "right-
hand" sense as the system-wide default, overriding the 
current global default sense ("correct"). (The new 
global default can, however, be overridden in turn by 
a personally preferred sense as specified by a user?s 
personal profile; and both kinds of preferences can be 
overridden interactively for any particular input 
sentence.) The other entries are domain-specific 
lexical additions for health care not in the general 
dictionary.  
We make no claims for technical innovation in 
our Glossary Import facility, but simply point out its 
usefulness for rapid porting, in that new lexical items, 
or new preferred senses for old items, can be altered 
per user and from session to session. 
 
7 Conclusion  
The principal source of the porting problems 
affecting most SLT systems to date, we have 
observed, is that, given the general current reliance 
upon statistical approaches for both ASR and MT, 
each new domain has required an extensive and 
difficult-to-obtain new corpus for best results. One 
might consider the use of a single very large and quite 
general corpus (or collection of corpora) for statistical 
training; but large corpora engender quickly 
increasing perplexity and error rates, so this very-
broad-coverage approach has generally been avoided.  
Our approach, however, has been to adopt a 
broad-coverage design nevertheless, and to 
compensate for the inevitable increase in ASR and 
MT errors by furnishing users with interactive tools 
for monitoring and correcting these mistakes. (We 
have to date used rule-based rather than statistical MT 
components, but comparable interactive facilities 
could be supplied for the latter as well. Operational 
prototypes for English<>Japanese and 
English<>German suggest that the techniques can 
also be adapted for languages other than 
English<>Spanish.) Because such interactive tools 
demand some time and attention, we have also put 
into place easily modifiable facilities for instant 
translation of frequent phrases (Translation 
Shortcuts). And finally, since even systems with very 
large lexicons will require specialized lexical items or 
specialized meanings of existing ones, we have 
implemented a quick glossary import facility, so that 
lexical items can be added or updated very easily.  
Our current SLT system, optimized for health 
care, is now in use at a medium-sized hospital in New 
Jersey, with more than twenty machines installed. For 
this paper, we have applied the same system, without 
modifications, to sample utterances from the military, 
emergency service, and law enforcement domains. 
While this exercise has yielded no quantitative results, 
readers can judge whether it demonstrates that users 
can convey mission-critical information with 
acceptable reliability in multiple domains, even in 
advance of any porting efforts. Users do pay a price 
for this flexibility, since time and attention are 
required for monitoring and correcting to achieve 
reliable results. However, when users judge that 
accuracy is not crucial, or when they are unable to 
monitor and correct, they can simply accept the first 
translation attempt as is. (A bilingual transcript of 
each conversation, soon to optionally include the 
back-translation, is always available for later 
inspection.) They can also gain considerable time 
through the use of Translation Shortcuts.  
 
References 
Bouillon, P., Rayner, M., et al 2005. A Generic 
Multi-Lingual Open Source Platform for Limited-
Domain Medical Speech Translation. Presented 
at EAMT 2005, Budapest, Hungary.  
Dillinger, M. and Seligman, M. 2006. Converser? : 
highly interactive speech-to-speech translation for 
health care.  HLT-NAACL 2006: Proceedings of 
the  Workshop on Medical Speech Translation 
(pp.40-43). New York, NY, USA.  
Dillinger, M. and Seligman, M. 2004. System 
description: A highly interactive speech-to-
speech translation system. In:  Robert E. 
Frederking and Kathryn B. Taylor (Eds.), 
46
Machine translation: from real users to research: 
6th conference of the Association for Machine 
Translation in the Americas -- AMTA 2004 (pp. 
58-63). Berlin: Springer Verlag.  
Gao, Y., Liang, G., Zhou, B., Sarikaya, R., et al (2006). 
IBM MASTOR system: multilingual automatic 
speech-to-speech translator. In: HLT-NAACL 
2006: Proceedings of the Workshop on Medical 
Speech Translation (pp.57-60). New York, NY, 
USA. 
Karat, C-M. and Nahamoo, D. 2007. Conversational 
interface technologies. In A. Sears & J. Jacko 
(Eds.), The Human-Computer Interaction 
Handbook: Fundamentals, Evolving 
Technologies, and Emerging Applications. 
Mahwah, NJ: L. Erlbaum.  
Koehn, P. 2008. Statistical Machine Translation. New 
York: Cambridge University Press.  
Seligman, M.. 2000. Nine Issues in Speech 
Translation. Machine Translation, 15, 149-185.  
Seligman, M. and Dillinger, M. 2006. Usability issues 
in an interactive speech-to-speech translation 
system for health care. HLT-NAACL 2006: 
Proceedings of the Workshop on Medical Speech 
Translation (pp. 1-8). New York, NY, USA.  
Zong, C. and Seligman, M. 2005. Toward Practical 
Spoken Language Translation. Machine Transla-
tion, 19, 113-137. 
47
