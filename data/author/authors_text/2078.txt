Generating and Visualizing a Soccer Knowledge Base
Paul Buitelaar, Thomas Eigner, Greg Gul-
rajani, Alexander Schutz, Melanie Siegel,
Nicolas Weber
Language Technology Lab, DFKI GmbH
Saarbr?cken, Germany
{paulb,siegel}@dfki.de
Philipp Cimiano, G?nter Ladwig,
Matthias Mantel, Honggang Zhu
Institute AIFB, University of Karlsruhe
Karlsruhe, Germany
cimiano@aifb.uni-karlsruhe.de
Abstract
This demo abstract describes the SmartWeb
Ontology-based Annotation system (SOBA).
A key feature of SOBA is that all informa-
tion is extracted and stored with respect to
the SmartWeb Integrated Ontology
(SWIntO). In this way, other components of
the systems, which use the same ontology,
can access this information in a straightfor-
ward way. We will show how information
extracted by SOBA is visualized within its
original context, thus enhancing the browsing
experience of the end user.
1 Introduction
SmartWeb1 is a multi-modal dialog system,
which derives answers from unstructured re-
sources such as the Web, from automatically ac-
quired knowledge bases and from web services.
In this paper we describe the current status of
the SmartWeb Ontology-Based Annotation
(SOBA) system. SOBA automatically populates
a knowledge base by information extraction from
soccer match reports as available on the web.
The extracted information is defined with respect
to SWIntO, the underlying SmartWeb Integrated
Ontology (Oberle et al, in preparation) in order
to be smoothly integrated into the system.
The ability to extract information and describe
it ontologically is a basic requirement for more
complex processing tasks such as reasoning and
discourse analysis (for related work on ontology-
based information extraction see e.g. Maedche et
al., 2002; Lopez and Motta, 2004; M?ller et al,
2004; Nirenburg and Raskin, 2004).
1 http://www.smartweb-projekt.de/start_en.html
2 System Overview
The SOBA system consists of a web crawler,
linguistic annotation components and a compo-
nent for the transformation of linguistic annota-
tions into an ontology-based representation.
The web crawler acts as a monitor on relevant
web domains (i.e. the FIFA2 and UEFA3 web
sites), automatically downloads relevant
documents from them and sends them to a
linguistic annotation web service.
Linguistic annotation and information
extraction is based on the Heart-of-Gold (HoG)
architecture (Callmeier et al 2004), which
provides a uniform and flexible infrastructure for
building multilingual applications that use
semantics- and XML-based natural language
processing components.
The linguistically annotated documents are
further processed by the transformation
component, which generates a knowledge base
of soccer-related entities (players, teams, etc.)
and events (matches, goals, etc.) by mapping
annotated entities or events to ontology classes
and their properties.
Finally, an automatic hyperlinking component
is used for the visualization of extracted entities
and events. This component is based on the
VieWs system, which was developed
independently of SmartWeb (Buitelaar et al,
2005). In what follows we describe the different
components of the system in detail.
2.1 Web Crawler
The crawler enables the automatic creation of a
football corpus, which is kept up-to-date on a
daily basis. The crawler data is compiled from
texts, semi-structured data and copies of original
2 http://fifaworldcup.yahoo.com/
3 http://www.uefa.com/
123
HTML documents. For each football match, the
data source contains a sheet of semi-structured
data with tables of players, goals, referees, etc.
Textual data comprise of match reports as well as
news articles.
The crawler is able to extract data from two
different sources: FIFA and UEFA. Semi-
structured data, news articles and match reports
covering the WorldCup2006 are identified and
collected from the FIFA website. Match reports
and news articles are extracted from the UEFA
website. The extracted data are labeled by IDs
that match the filename. The IDs are derived
from the corresponding URL and are thus
unique.
The crawler is invoked continuously each day
with the same configuration, extracting only data
which is not yet contained in the corpus. In order
to distinguish between available new data and
data already present in the corpus, the URLs of
all available data from the website are matched
against the IDs of the already extracted data.
2.2 Linguistic Annotation and Information
Extraction
As mentioned before, linguistic annotation in the
system is based on the HoG architecture, which
provides a uniform and flexible infrastructure for
building multilingual applications that use
semantics- and XML-based natural language
processing components.
For the annotation of soccer game reports, we
extended the rule set of the SProUT (Drozdzyn-
ski et al 2004) named-entity recognition compo-
nent in HoG with gazetteers, part-of-speech and
morphological information. SProUT combines
finite-state techniques and unification-based al-
gorithms. Structures to be extracted are ordered
in a type hierarchy, which we extended with soc-
cer-specific rules and output types.
SProUT has basic grammars for the annotation
of persons, locations, numerals and date and time
expressions. On top of this, we implemented
rules for soccer-specific entities, such as actors in
soccer (trainer, player, referee ?), teams, games
and tournaments. Using these, we further imple-
mented rules for soccer-specific events, such as
player activities (shots, headers ?), game events
(goal, card ?) and game results. A soccer-
specific gazetteer contains soccer-specific enti-
ties and names and is supplemented to the gen-
eral named-entity gazetteer.
As an example, consider the linguistic annota-
tion for the following German sentence from one
of the soccer game reports:
Guido Buchwald wurde 1990 in Italien Welt-
meister (Guido Buchwald became world cham-
pion in 1990 in Italy)
<FS type="player_action">
<F name="GAME_EVENT">
<FS type="world champion"/>
<F name="ACTION_TIME">
<FS type="1990"/>
<F name="ACTION_LOCATION">
<FS type="Italy"/>
<F name="AGENT">
<FS type="player">
<F name="SURNAME">
<FS type="Buchwald"/>
<F name="GIVEN_NAME">
<FS type="Guido"/>
2.3 Knowledge Base Generation
The SmartWeb SportEventOntology (a subset of
SWIntO) contains about 400 direct classes onto
which named-entities and other, more complex
structures are mapped. The mapping is repre-
sented in a declarative fashion specifying how
the feature-based structures produced by SProUT
are mapped into structures which are compatible
with the underlying ontology. Further, the newly
extracted information is also interpreted in the
context of additional information about the
match in question.
This additional information is obtained by
wrapping the semi-structured data on relevant
soccer matches, which is also mapped to the on-
tology. The information obtained in this way
about the match in question can then be used as
contextual background with respect to which the
newly extracted information is interpreted.
The feature structure for player as displayed
above will be translated into the following F-
Logic (Kifer et al 1995) statements, which are
then automatically translated to RDF and fed to
the visualization component:
soba#player124:sportevent#FootballPlayer
[sportevent#impersonatedBy ->
soba#Guido_BUCHWALD].
soba#Guido_BUCHWALD:dolce#"natural-person"
[dolce#"HAS-DENOMINATION" ->
soba#Guido_BUCHWALD_Denomination].
soba#Guido_BUCHWALD_Denomination":dolce#"
natural-person-denomination"
[dolce#LASTNAME -> "Buchwald";
dolce#FIRSTNAME -> "Guido"].
124
2.4 Knowledge Base Visualization
The generated knowledge base is visualized by
way of automatically inserted hyperlink menus
for soccer-related named-entities such as players
and teams. The visualization component is based
on the VIeWs4 system. VIeWs allows the user to
simply browse a web site as usual, but is addi-
tionally supported by the automatic hyperlinking
system that adds additional information from a
(generated) knowledge base.
For some examples of this see the included
figures below, which show extracted information
for the Panama team (i.e. all of the football play-
ers in this team in Figure 1) and for the player
Roberto Brown (i.e. his team and events in which
he participated in Figure 2).
3 Implementation
All components are implemented in Java 1.5 and
are installed as web applications on a Tomcat
web server. SOAP web services are used for
communication between components so that the
system can be installed in a centralized as well as
decentralized manner. Data communication is
handled by XML-based exchange formats. Due
to a high degree of flexibility of components,
only a simple configuration over environment
variables is needed.
4 Conclusions and Future Work
We presented an ontology-based approach to
information extraction in the soccer domain that
aims at the automatic generation of a knowledge
base from match reports and the subsequent
visualization of the extracted information
through automatic hyperlinking. We argue that
such an approach is innovative and enhances the
user experience.
Future work includes the extraction of more
complex events, for which deep linguistic analy-
sis and/or semantic inference over the ontology
and knowledge base is required. For this purpose
we will use an HPSG-based parser that is avail-
able within the HoG architecture (Callmeier,
2000) and combine this with a semantic infer-
ence approach based on discourse analysis
(Cimiano et al, 2005).
4 http://views.dfki.de
Acknowledgements
This research has been supported by grants for
the projects SmartWeb (by the German Ministry
of Education and Research: 01 IMD01 A) and
VIeWs (by the Saarland Ministry of Economic
Affairs).
References
Paul Buitelaar, Thomas Eigner, Stefania Racioppa
Semantic Navigation with VIeWs In: Proc. of the
Workshop on User Aspects of the Semantic Web at
the European Semantic Web Conference, Herak-
lion, Greece, May 2005.
Callmeier, Ulrich (2000). PET ? A platform for ex-
perimentation with efficient HPSG processing
techniques. In: Natural Language Engineering, 6
(1) UK: Cambridge University Press pp. 99?108.
Callmeier, Ulrich, Eisele, Andreas, Sch?fer, Ulrich
and Melanie Siegel. 2004. The DeepThought Core
Architecture Framework In Proceedings of LREC
04, Lisbon, Portugal, pages 1205-1208.
Cimiano, Philipp, Saric, Jasmin and Uwe Reyle.
2005. Ontology-driven discourse analysis for in-
formation extraction, Data Knowledge Engineering
55(1).
Drozdzynski, Witold, Hans-Ulrich Krieger, Jakub
Piskorski, Ulrich Sch?fer, and Feiyu Xu. 2004.
Shallow processing with unification and typed fea-
ture structures ? foundations and applications.
K?nstliche Intelligenz, 1:17-23.
Kifer, M., Lausen, G. and J.Wu. 1995. Logical Foun-
dations of Object-Oriented and Frame-Based Lan-
guages. Journal of the ACM 42, pp. 741-843.
Lopez, V. and E. Motta. 2004. Ontology-driven Ques-
tion Answering in AquaLog In Proceedings of 9th
International Conference on applications of natural
language to information systems.
Maedche, Alexander, G?nter Neumann and Steffen
Staab. 2002. Bootstrapping an Ontology-Based In-
formation Extraction System. In: Studies in Fuzzi-
ness and Soft Computing, editor J. Kacprzyk. Intel-
ligent Exploration of the Web, Springer.
M?ller HM, Kenny EE and PW Sternberg. 2004.
Textpresso: An ontology-based information re-
trieval and extraction system for biological litera-
ture. PLoS Biol 2: e309.
Nirenburg, Sergei and Viktor Raskin. 2004. Ontologi-
cal Semantics. MIT Press.
Oberle et al The SmartWeb Integrated Ontology
SWIntO, in preparation.
125
Figure 2: Generated hyperlink on ?Roberto Brown? with extracted information on his
team and events in which he participated
Figure 1: Generated hyperlink on ?Panama? with extracted information on this team
126
Proceedings of the 8th International Conference on Computational Semantics, pages 351?354,
Tilburg, January 2009. c?2009 International Conference on Computational Semantics
Identifying the Epistemic Value of Discourse
Segments in Biology Texts
Anita de Waard
(1)
Paul Buitelaar
(2)
Thomas Eigner
(3)
(1) Elsevier & Universiteit Utrecht, the Netherlands (anita@cs.uu.nl)
(2) DERI - NLP Unit, Galway, Ireland (paulb@deri.org)
(3) DFKI, Saarbrcken, Germany (teigner@dfki.de)
1 Introduction
To manage the flood of information that threatens to engulf (life-)scientists,
an abundance of computer-aided tools are being developed. These tools aim
to provide access to the knowledge conveyed within a collection of research
papers, without actually having to read the papers. Many of these tools
focus on text mining, by looking for specific named-entities that have scien-
tific meaning, and relationships between these. An overview of the current
state of the art is given in Rebholz-Schuhmann et al (2005) and Couto
et al (2003). Typically, these tools identify a list of sentences containing
relationships between two specific named-entities that can be found using
rules or a thesaurus of synonyms. These sentences represent an overview of
the interactions that are known with a specific entity, thus precluding the
need for an exhaustive literature study. For example, the following are a
few sentences that have been found using a typical text mining tool for the
relationship ?p53 activates *?:
1. The p53 tumor suppressor protein exerts most of its anti-tumorigenic
activity by transcriptionally activating several pro-apoptotic genes.
2. We found that p53 ... activates[,] the promoter of the myosin VI gene.
However, in order to be able to use these statements and to draw conclu-
sions about its subject (?Which entities does p53 activate??) we still need
to read the article that they appeared in, identify the experimental context
and the epistemic (?truth?) value of each statement. For instance, 1. does
not seem to represent an experimental finding that is arrived at in the paper
351
that the sentence is taken from; instead, it seems to be a citation. So, to be
able to evaluate its epistemic value (?How true is this??) we need to read
the paper that contained the sentence and paper(s) where the statement
was first experimentally motivated. In the case of 2., a clear statement is
given on what the authors of the paper have found. But ?How did they
find it??, ?What experimental setup and control experiments were used??,
?What were their assumptions?? Biologists will need to check these and
other issues before accepting 2. as a fact. Our research therefore concerns
the classification of sentences in biology texts by ?epistemic segment type?,
with the purpose of enabling a better way to summarize, mine and compare
statements within biology texts. The current paper describes a first venture
into doing this in a computational way.
2 Epistemic Segment Types for Biology Texts
As motivated elsewhere we have identified seven epistemic segment types
(De Waard, 2007):
? Fact: statement presumed to be accepted as true by the commu-
nity, e.g. Cellular transformation requires the expression of oncogenic
RASV12.
? Hypothesis: possible explanation for a set of phenomena, e.g. This
suggests possible roles for APC in G1 and G0 phases of the cell cycle.
? Implication: interpretation of results, e.g. These results indicate that
our procedure is sensitive enough to detect mild growth differences.
? Method: ways in which the experiment was performed, e.g. We
inserted 500 bp fragments ... in a modified pMSCV-Blasticidin vector.
? Problem: discrepancies or unknown aspects of the known fact corpus,
e.g. The small number of miRNAs with a known function stresses
the need for a systematic screening approach to identify more miRNA
functions.
? Goal: implicit hypothesis and problem, e.g. identify miRNAs that
can interfere with this process and ... contribute to the development of
tumor cells
? Result: a summary of the results of measurements, e.g. we observed
an approximately 4-fold increase in miR-311 signal
352
For example, Fact segments are taken from another source of knowledge
(explicitly referred to or presumed to be known) and therefore not experi-
mentally ascertained in the article, whereas Result segments are obtained
by measurements discussed in the paper itself. For the sentences in the pre-
vious section, we therefore see that 1. is a Fact and 2. is a typical Result
segment. To classify the segments (manually first), we have used several
linguistic clues, as well as an understanding of the context of a segment.
Important linguistic clues are the verb tense of the segment and specific
markers used to identify a segment transition, e.g. the transition between a
Result and an Implication segment is usually indicated by a phrase such as
?These results suggest that?. The segment types and selected specific mark-
ers that we used in our research here are as follows (using regular expressions
to shorten notation):
? Hypothesis: results indicate, suggest, suggesting that
? Implication: data?results demonstrate?suggest?indicate, data?results
show
? Method: by cloning?using, using additionally, we activated?constructed
? Goal: to examine?identify?investigate?mimic?shed light?start to
? Result: as expected?predicted, resulting in, shows that, this confirms
3 Automatic Identification of Epistemic Segment
Types
To investigate if we could use this set of markers for the automatic iden-
tification of segment type, we applied them to an independently developed
data set of 1721 biomedical abstracts on ?mantle cell lymphoma? that we
downloaded from PubMed. We randomly selected 100 sentences, in which
a marker was identified, and to which one out of five segment types (Hy-
pothesis, Implication, Method, Goal, Result) was assigned by a sim-
ple automatic procedure, i.e. we matched the markers to a part-of-speech
enriched version of the PubMed corpus. One or more segment types were
assigned in case of a match. The resulting assignments were then evaluated
by the first author of this paper. Results were encouraging as only 30 out of
100 assignments were incorrect. Most of these (12) were between Hypoth-
esis, Implication, which is not surprising as their markers are overlapping
353
and therefore ambiguous. Others that were somewhat frequent were: Hy-
pothesis instead of Fact (3), Result instead of Fact (3), Result instead
of Method (2), Goal instead of Method (2), Goal instead of Problem
(2). Of these however, Fact and Problem were not covered by our set of
segment specific markers and could therefore not be recognized.
4 Conclusions and Future Work
As a first conclusion, results are encouraging enough to merit further re-
search. We have identified several follow-up steps that can help improve our
results. First, we plan to segment the sentences into smaller discourse units.
For instance, sentences such as the following are quite clearly divided into
two parts: a Goal and a Method:
? Goal: To examine miRNA expression from the miR-Vec system,
? Method: a miR-24 minigene-containing virus was transduced into
human cells.
Such sentences are quite common, as are sentences containing Method,
Result and Result, Implication segments; this clearly indicates that this
move order is logical and occurs often. Secondly, there is a clear correlation
between segment type and verb tense. Method, Result are overwhelm-
ingly stated in the past tense, whereas Fact, Implication are given in the
present tense. Using verb tense as a marker could further improve classi-
fication scores. Lastly, we are interested in applying our epistemic values
to augment and improve bioinformatics tools, and investigating the value of
these categories with users. We are actively pursuing collaborations in this
area.
References
Rebholz-Schuhmann, D., H.Kirsch & F. Couto (2005) Facts from text - is text
mining ready to deliver? PLoS Biology 3(2).
Couto, F., M.J. Silva & P. Coutinho (2003) Improving information extraction
through biological correlation. In Proc. European Workshop on Data Mining
and Text Mining, Dubrovnik.
Waard, A. de (2007) The pragmatic research article. In Proc. 2nd International
Conference on the Pragmatic Web, Tilburg.
354
