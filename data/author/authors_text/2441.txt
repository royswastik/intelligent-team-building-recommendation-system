Multi-Agent Explanation Strategies in Real-Time Domains
Kumiko Tanaka-Ishii
University of Tokyo,
7-3-1 Hongo Bunkyo-ku
Tokyo 113-8656
Japan
kumiko@ipl.t.u-tokyo.ac.jp
Ian Frank
Electrotechnical Laboratory
1-1-4 Umezono, Tsukuba
Ibaraki 305-0085
Japan
ianf@etl.go.jp
Abstract
We examine the benets of using multi-
ple agents to produce explanations. In
particular, we identify the ability to con-
struct prior plans as a key issue con-
straining the eectiveness of a single-
agent approach. We describe an imple-
mented system that uses multiple agents
to tackle a problem for which prior plan-
ning is particularly impractical: real-
time soccer commentary. Our commen-
tary system demonstrates a number of
the advantages of decomposing an expla-
nation task among several agents. Most
notably, it shows how individual agents
can benet from following dierent dis-
course strategies. Further, it illustrates
that discourse issues such as controlling
interruption, abbreviation, and main-
taining consistency can also be decom-
posed: rather than considering them at
the single level of one linear explana-
tion they can also be tackled separately
within each individual agent. We evalu-
ate our system's output, and show that
it closely compares to the speaking pat-
terns of a human commentary team.
1 Introduction
This paper deals with the issue of high-level vs
low-level explanation strategies. How should an
explanation nd a balance between describing the
overall, high-level properties of the discourse sub-
ject, and the low-level, procedural details? In par-
ticular, we look at the di?culties presented by do-
mains that change in real-time. For such domains,
the balance between reacting to the domain events
as they occur and maintaining the overall, high-
level consistency is critical.
We argue that it is benecial to decompose the
overall explanation task so that it is carried out by
more than one agent. This allows a single agent
to deal with the tracking of the low-level develop-
ments in the domain, leaving the others to con-
centrate on the high-level picture. The task of
each individual agent is simplied, since they only
have to maintain consistency for a single discourse
strategy. Further, discourse issues such as control-
ling interruption, abbreviation, and maintaining
consistency can also be decomposed: rather than
considering them at the single level of one linear
explanation they can be tackled separately within
each individual agent and then also at the level of
inter-agent cooperation.
We look at real-world examples of explanation
tasks that are carried out by multiple agents, and
also give a more detailed protocol analysis of one
of these examples: World Cup soccer commen-
tary by TV announcers. We then describe an
actual implementation of an explanation system
that produces multi-agent commentary in real-
time for a game of simulated soccer. In this sys-
tem, each of the agents selects their discourse con-
tent on the basis of importance scores attached to
events in the domain. The interaction between
the agents is controlled to maximise the impor-
tance score of the uttered comments.
Although our work focuses on real-time do-
mains such as soccer, our discussion in x2 puts
our contribution in a wider context and iden-
ties a number of the general benets of using
multiple agents for explanation tasks. We chose
the game of soccer for our research primarily be-
cause it is a multi-agent game in which various
events happen simultaneously on the eld. Thus,
it is an excellent domain to study real-time con-
tent selection among many heterogeneous facts.
A second reason for choosing soccer is that de-
tailed, high-quality logs of simulated soccer games
are available on a real-time basis from Soccer
Server, the o?cial soccer simulation system for
the `RoboCup' Robotic Soccer World Cup initia-
tive (Kitano et al, 1997).
Ease of making prior plans 
difficult possible easy
  sports
commentary
 mind
games
commentary
   car
navigation
systems
panel
discussion
live
lecture
lecture(TV)  business
presentation
Figure 1: Common explanation tasks categorised according to the ease of planning them in advance
2 Explanation Strategies
In this paper, we use the term explanation in its
broadest possible sense, covering the entire spec-
trum from planned lectures to commentating on
sports events. Any such explanation task is af-
fected by many considerations, including the level
of knowledge assumed of the listeners and the
available explanation time. However, the issue we
mainly concentrate on here has not previously re-
ceived signicant attention: the benets of split-
ting an explanation task between multiple agents.
2.1 Explanations and Multi-Agency
The general task of producing explanations with
multiple agents has not been studied in depth
in the literature. Even for the `naturally' multi-
agent task of soccer commentary, the systems de-
scribed in the recent AI Magazine special issue on
RoboCup (Andre et al, 2000) are all single-agent.
However, one general issue that has been studied
at the level of single agents is the trade-o be-
tween low-level and high-level explanations. For
example, in tutoring systems (Cawsey, 1991) has
described a system that handles real-time interac-
tions with a user by separating the control of the
content planning and dialogue planning.
We believe that the key issue constraining the
use of high-level and low-level explanations in a
discourse is the ability to construct prior plans .
For example, researchers in the eld of discourse
analysis, (e.g., (Sinclair and Coulthard, 1975))
have found that relatively formal types of di-
alogues follow a regular hierarchical structure.
When it is possible to nd these kinds of a priori
plans for a discourse to follow, approaches such as
those cited above for tutoring are very eective.
However, if prior plans are hard to specify, a sin-
gle agent may simply nd it becomes overloaded.
Typically there will be two conicting goals: deal
with and explain each individual (unplanned) do-
main event as it occurs, or build up and explain
a more abstract picture that conveys the overall
nature of the explanation topic.
Thus, for any changing domain in which it is
hard to plan the overall discourse, it can be bene-
cial to divide the explanation task between mul-
tiple agents. Especially for real-time domains, the
primary benet of decomposing the explanation
task in this way is that it allows each agent to
use a dierent discourse strategy to explain dif-
ferent aspects of the domain (typically, high-level
or low-level). However, we can see from Figure 1
that even some activities that are highly planned
are sometimes carried out by multiple agents. For
example, business presentations are often carried
out by a team of people, each of which is an expert
in some particular area. Clearly, there are other
benets that come from decomposing the explana-
tion task between more than one agent. We can
give a partial list of these here:
 Agents may start with dierent abilities. For
example, in a panel session, one panellist may
be an expert on Etruscan vases, while another
may be an expert on Byzantian art.
 It can take time to observe high-level pat-
terns in a domain, and to explain them co-
herently. Having a dedicated agent for com-
menting on the low-level changes increases
the chance that higher-level agents have a
chance to carry out analysis.
 A team of agents can converse together.
In particular, they can make explanations
to each other instead of directly explaining
things to the listeners. This can be a more
comfortable psychological position for the lis-
tener to accept new information.
 The simple label of \expert" adds weight to
the words of a speaker, as shown convincingly
by the research of (Reeves and Nass, 1996).
The use of multiple agents actually gives a
chance to describe individual agents as \ex-
perts" on specic topics.
 Even a single agent speaking in isolation
could describe itself as an expert on various
topics. However, (Reeves and Nass, 1996)
also show that self-praise has far less impact
than the same praise from another source.
Rather than describing themselves as experts,
a multi-agent framework allows agents to de-
scribe the other agents as experts.
To illustrate the dierent roles that can be
taken by multiple agents in an explanation task,
we carried out a simple protocol analysis of an ex-
ample from the far left of our scale of Figure 1:
soccer commentary.
2.2 Soccer Protocol Analysis
We analysed the video of the NHK coverage of the
rst half 1998 World Cup nal. This commentary
was carried out by a team of two people who we
call the `announcer' and the `expert'. The gures
in Table 1 demonstrate that there are clear dier-
ences between the roles assumed by this commen-
tary team. Although both use some background
knowledge to ll out their portions of the commen-
tary, the announcer mostly comments on low-level
events, whilst the expert mostly gives higher-level,
state-based information. Further, we can see that
the announcer asked questions of the expert with
a high frequency.
Overall, there is a clear indication that one
agent follows the low-level events and that the
other follows the high-level nature of the game.
Accordingly, their discourse strategies are also dif-
ferent: the announcer tends to speak in shorter
phrases, whereas the expert produces longer anal-
yses of any given subject. The commentary team
collaborates so that the consistency between high-
level, low-level, and background comments is bal-
anced within the content spoken by each individ-
ual, and also within the overall commentary.
2.3 A First Implementation
As a rst step towards a multi-agent explanation
system based on the above observations, the fol-
lowing sections describe how we implemented a
commentary system for a game of simulated soc-
cer. Our experience with this system reected
the discussion above in that we found it was very
di?cult to consistently manage all the possible
discourse topics within a single-agent framework.
When changing to a multi-agent system, however,
we found that a small number of simple rules for
inter-agent interaction produced a far more man-
ageable system. We also found that the system
was behaviourally very similar to the protocol of
Table 1.
3 An Architecture For Multi-
Agent Soccer Commentary
Figure 2 shows the basic architecture of our soc-
cer commentator system. As we mentioned in the
Introduction, this system is designed to produce
live commentary for games played on RoboCup's
Soccer Server. Since the Soccer Server was orig-
inally designed as a testbed for multi-agent sys-
tems (Noda et al, 1998), we call our commenta-
tor Mike (\Multi-agent Interactions Knowledge-
ably Explained"). Typically, Mike is used to add
atmosphere to games played in the RoboCup tour-
naments, so we assume that the people listening
to Mike can also see the game being described.
AnalyserAnnouncer
Soccer Server
Voronoi
Statistics
Basic
TTS
shared 
memory
commentary
Communicator
Figure 2: Mike | a multi-agent commentator
The Soccer Server provides a real-time game log
of a very high quality, sending information on the
positions of the players and the ball to a moni-
toring program every 100msec. Specically, this
information consists of 1) player location and ori-
entation, 2) ball location, and 3) game score and
play modes (throw ins, goal kicks, etc).
This information is placed in Mike's shared
memory, where it is processed by a number of
`Soccer Analyser' modules that analyse higher-
level features of a game. These features include
statistics on player positions, and also `bigrams' of
ball play chains represented as rst order Markov
chains. The Voronoi analyser uses Voronoi dia-
grams to assess game features such as defensive ar-
eas. Note that we do not consider the Soccer Anal-
ysers to be `agents'; they are simply processes that
manipulate the information in the shared mem-
ory. The only true `agents' in the system are the
Announcer and the Analyser, which communicate
both with each other and with the audience.
All information in Mike's shared memory is
represented in the form of commentary fragments
that we call propositions. Each proposition con-
sists of a tag and some attributes. For example,
a pass from player No.5 to No.11 is represented
as (Pass 5 11), where Pass is the tag, and the
Commentary Feature Announcer Expert Note
Background comment
(e.g., on stadium, or team backgrounds)
7% 20% (predened plan)
Event-based comment 82% 3% (low-level)
State-based comment 11% 77% (high-level)
Average length of comment 1.3sec 3.8sec (consistency)
Asks a question to the other 30 0 (new explanation mode)
Interrupts the other 5 0 (priority of roles)
Announcer describes expert as expert 0 n/a (adds weight to expert)
Table 1: Protocol analysis of announcer and expert utterances in professional TV coverage of soccer
Local Global
E Kick ChangeForm
v Pass
e Dribble SideChange
n ShootPredict
t
S Mark TeamPassSuccessRate
t PlayerPassSuccessRate AveragePassDistance
a ProblematicPlayer Score
t PlayerActive Time
e
Table 2: Examples of Mike's proposition tags
numbers 5 and 11 are the attributes. Mike uses
around 80 dierent tags categorised in two ways:
as being local or global and as being state-based
or event-based. Table 2 shows some examples of
categorised proposition tags.
The operation of the Announcer and the Anal-
yser agents is described in detail in the following
section. Basically, they select propositions from
the shared memory (based on their `importance
scores') and process them with inference rules to
produce higher-level chains of explanations. The
discourse control techniques of interruption, rep-
etition, abbreviation, and silence are used to con-
trol both the dialogue strategies of each individual
agent and also the interaction between them.
To produce variety in the commentary, each
possible proposition is associated with several pos-
sible commentary templates (output can be in En-
glish or Japanese). Figure 3 shows the overall
repertoire of Mike's comments. The actual spo-
ken commentary is realised with o-the-shelf text-
to-speech software (Fujitsu's Japanese Synthesiser
for Japanese, and DecTalk for English).
4 Multi-Agent NL Generation
In this section, we describe how Mike uses impor-
tance scores, real-time inferencing, and discourse
control strategies to implement | and control the
interaction between | agents with diering expla-
 Explanation of complex events. Forma-
tion and position changes, advanced plays.
 Evaluation of team plays. Average forma-
tions, formations at a certain moment, play-
ers' locations, indication of active or prob-
lematic players, winning passwork patterns,
wasteful movements.
 Suggestions for improving play. Loose
defence areas, better locations for inactive
players.
 Predictions. Passes, game results, shots.
 Set pieces. Goal kicks, throw ins, kick os,
corner kicks, free kicks.
 Passwork. Tracking of basic passing play.
Figure 3: Mike's repertoire of statements
nation strategies.
To form a single coherent commentary with
multiple agents we extended the single-agent
framework of (Tanaka-Ishii et al, 1998). The ba-
sic principle of this framework is that given a set
of scores that capture the information transmit-
ted by making any utterance, the most eective
dialogue is the one that maximises the total score
of all the propositions that are verbalised. We
therefore created two agents with dierent strate-
gies for content scheduling. One agent acts as an
announcer, following the low-level events on the
eld. This agent's strategy is biased to allow fre-
quent topic change and although it uses inference
rules to look for connections between propositions
in the shared memory, it only uses short chains of
inference. On the other hand, the second agent
acts as an `expert analyst', and is predominantly
state based. The expert's strategy is biased to
have more consistency, and to apply longer chains
of inference rules than the announcer.
4.1 Importance Scores
In Mike, importance scores are designed to cap-
ture the amount of information that any given
proposition will transmit to an audience. They are
not xed values, but are computed from scratch at
every game step (100msec). The importance score
of each proposition depends on three factors: 1)
the elapsed time since the proposition was gener-
ated, 2) for event-based propositions, a compar-
ison of the place associated with the proposition
and the current location of the ball, and 3) the
frequency that the proposition has already been
stated. To keep the number of comments in the
shared memory to a manageable number they are
simply limited in number, with the oldest entries
being removed as new propositions are added.
4.2 Real Time Inference
Mike's commentary propositions are the results
of large amounts of real-time data processing,
but are typically low-level. A commentary based
solely on these propositions would be rather de-
tailed and disconnected. Thus, to analyse the
play more deeply, Mike gives the commentary
agents access to a set of forward-chaining rules
that describe the possible relationships between
the propositions. In total, there are 145 of these
rules, divided into the two classes of logical con-
sequences and second order relations. We give a
representative example from each class here:
 Logical consequence:
(PassSuccessRate player percentage)
(PassPattern player Goal) !
(active player)
 Second order relation:
(PassSuccessRate player percentage)
(PlayerOnVoronoiLine player) !
(Reason @1 @2)
The basic premise of the announcer's dialogue
strategy is to follow the play by repeatedly choos-
ing the proposition with the highest importance
score. Before stating this proposition, however,
the announcer checks any applicable inference
rules in a top down manner, in an attempt to
produce higher-level commentary fragments and
background related information. In contrast to
this, the expert agent has a library of themes (e.g.,
pass statistics, formation, stamina) between which
it chooses based on the propositions selected by
the announcer so far. It then uses inference rules
to try to construct a series of high-level inferences
related to the theme. The expert applies rules
until it succeeds in constructing a single coherent
piece of structured commentary. When it is the
agent's turn to speak it can then send this com-
mentary to the TTS software.
4.3 Discourse Control Strategies
Consider a passage of commentary where the an-
nouncer is speaking and a proposition with a
much larger importance score than the one be-
ing uttered appears in the shared memory. If this
occurs, the total importance score may become
larger if the announcer immediately interrupts the
current utterance and switches to the new one.
As an example, the left of Figure 4 shows (solid
line) the change of the importance score with time
when an interruption takes place (the dotted line
represents the importance score without interrup-
tion). The left part of the solid line is lower than
the dotted, because we assume that the rst utter-
ance conveys less of its importance score when it
is not completely uttered. However, the right part
of the solid line is higher than the dotted line, be-
cause the importance of the second utterance will
be lower by the time it is uttered without inter-
rupting the commentary. Note that after selecting
a proposition to be uttered, its importance score
is assumed to decrease with time (as indicated in
the gure, the decrease is computed dynamically
and will be dierent for each proposition, and of-
ten not even linear). The decision of whether or
not to interrupt is based on a comparison of the
area between the solid or dotted lines and the hor-
izontal axis.
Similarly, it may happen that when the two
most important propositions in shared memory
Importance Score/Time
Ends the
first utterrance
without interruption
An Important
event occurs
with interruption
without interruption
time
<
>
?
Importance Score/Time
But can utter other
important content
with abbreviation
without abbreviation
time
<
>
?
Becomes less comprehensive
      because of abbreviation
Figure 4: Change of importance score on inter-
ruption and abbreviation
Importance Score/Time
Another utterrance
with repetition
without repetition
time
<
>
?
Repeated utterrance have higher 
score by emphasis
Figure 5: Increase in importance scores caused by
emphasis of repeating a proposition
are of similar importance, the amount of com-
municated information can best be maximised by
quickly uttering the most important proposition
and then moving on to the second before it loses
importance due to some development of the game
situation. This is illustrated in the second graph
of Figure 4. Here, the left hand side of the solid
line is lower than that of the dotted because an
abbreviated utterance (which might not be gram-
matically correct, or whose context might not be
fully given) transmits less information than a more
complete utterance. But since the second propo-
sition can be uttered before losing its importance
score, the right hand part of the solid line is higher
than that of the dotted. As before, the benets or
otherwise of this modication should be decided
by comparing the two areas made by the solid and
the dotted line with the horizontal axis.
We originally designed these techniques just to
improve the ability of the announcer agent to
follow the play. With two commentary agents,
however, both interruption and abbreviation can
be adapted to control inter-agent switching. In
Mike, the default operation is for the announcer
to keep talking while the ball is in the nal third
of the eld, or while there are important proposi-
tions to utter. When the announcer has nothing
to say, the expert agent can speak or both agents
can remain silent. If the expert agent chooses to
speak, it may happen that an important event
on the eld makes the announcer wants to speak
again. We model both interruption and abbre-
viation as multi-agent versions of the graphs of
Figure 4: the agent speaking the rst utterance is
the expert and the agent speaking the second is
the announcer.
We use two further discourse control techniques
in Mike: repetition and silence. Repetition is
depicted in Figure 5. Sometimes it can happen
that the remaining un-uttered propositions in the
shared memory have much smaller scores than
any of those that have already been selected. In
this case, we allow individual agents to repeat
things that they have previously said. Also, we
allow them to repeat things that the other agent
has said, to increase the eectiveness of the dia-
logue between them. Finally, we also model si-
lence by adding bonuses to the importance scores
of the propositions uttered by the commentators.
Specically, we add a bonus to the scores of propo-
sitions uttered directly before a period where both
commentators are silent (the longer that a com-
mentary continues uninterrupted, the higher the
silence bonus). This models the benet of giving
listeners time to actually digest the commentary.
Also, a period of silence contributes a bonus to
the importance scores of the immediately follow-
ing propositions. This models the increased em-
phasis of pausing before an important statement.
4.3.1 Communication Templates
To improve the smoothness of the transfer of the
commentary between the two agents we devised a
small number of simple communication templates.
The phrases contained in these templates are spo-
ken by the agents wheneverMike realises that the
commentary is switching between them. For the
purposes of keeping the two agents distinct, the
expert agent is referred to by the announcer as E-
Mike (\Expert Mike"). To pass the commentary
to the Expert, the Announcer can use a number
of phrases such as \E-Mike, over to you", \Any
impressions, E-Mike?", or just \E-Mike?". The
announcer can also pass over control by simply
stopping speaking. If the commentary switches
from Announcer to Expert with a question, the
Expert will start with \Yes..." or \Well...".
The communication templates for passing the
commentary in the other direction (Expert to An-
nouncer) are shown in Table 3. To help listeners
distinguish the dialogue between the Announcer
and Expert better, we also use a female voice for
one agent and a male voice for the other.
5 Evaluation
Mike is robust enough for us to have used it
to produce live commentary at RoboCup events,
and to be distributed on the Internet (it has been
downloaded by groups in Australia and Hungary
and used for public demonstrations). A short ex-
ample of Mike's output is shown in Figure 6.
To evaluate Mike more rigorously we carried
out two questionnaire-based evaluations, and also
a log comparison with the data produced from the
real-world soccer commentary in x2. For the rst
of the questionnaire evaluations, we used as sub-
Question Scale Results
Is the game better with or without commentary? (5=with, 1=without) 4.97
Was the commentary easy to understand? (5=easy, 1=hard) 3.44
Were the commentary contents accurate? (5=correct, 1=incorrect) 3.25
Was the commentary informative? (5=yes, 1=no) 3.53
Did you get tired of the commentary? (5=no, 1=quickly) 3.97
Table 4: Average responses of 20 subjects to rst questionnaire evaluation of (two-agent) Mike
Question Scale 1-agent 2-agent Di
Is the game better with or without...? (5=with, 1=without) 4.45 4.45 0%
Was the commentary easy to understand? (5=easy, 1=hard) 2.95 3.25 +10%
Were the commentary contents accurate? (5=correct, 1=incorrect) 2.65 2.95 +11%
Was the commentary informative? (5=yes, 1=no) 3.15 3.35 +6%
Did you get tired of the commentary? (5=no, 1=quickly) 2.35 3.35 +43%
Table 5: Dierence in response with ten subjects when viewing 1-agent and 2-agent versions of Mike
Announcer interrupts expert
Sorry, E-MIKE.
Have to stop you there E-MIKE.
Oh!...
But look at this!
Announcer speaks when expert stops
Thanks.
That's very true.
Thanks E-MIKE.
Maybe that will change as the game goes on.
OK...
Table 3: Phrases used by announcer when inter-
rupting the expert, or when speaking after the ex-
pert agent has simply stopped (no interruption)
jects twenty of the attendees of a recent RoboCup
Spring camp. All these subjects were familiar with
the RoboCup domain and the Soccer Server en-
vironment. We showed them an entire half of a
RoboCup game commentated by Mike and col-
lated their responses to the questions shown in
Table 4. These results largely show that the lis-
teners found the commentary to be useful and to
contain enough information to maintain their at-
tention. We also included some open-ended ques-
tions on the questionnaire to elicit suggestions
for features that should be strengthened or incor-
porated in future versions of Mike. The most
frequent responses here were requests for more
background information on previous games played
by the teams (possible in RoboCup, but to date
we have only done this thoroughly for individ-
Announcer: yellow 9,in the middle of the
eld,yellow team (a set play happened here). Any
impressions, E-Mike?
Analyser: Well, here are statistics concerning
possessions, left team has slightly smaller value of
possession, it is 43 percent versus 56. right team
has rather higher value of territorial advantage,
Overall, right team is ahead there. (Score is cur-
rently 0-0. E-Mikejudges that red team is doing
better).
Announcer: Really. dribble , yellow 3, on the
left, great long pass made to yellow 1, for red 6,
red 2's pass success rate is 100 percent. E-Mike?
Analyser: Looking at the dribbles and steals, red
team was a little less successful in dribbling, red
team has a lower value of dribble average length,
left is 21 meters whereas right is 11, right team
has a few less players making zero passes, yellow
team has made slightly less stealing,
Announcer: wow (interruption because red 11
made a shot), red 11, goal, red 11, Goal ! It was
red 10, And a pass for red 11 ! The score is 0 1!
Figure 6: Example of Mike's commentary from
RoboCup'98 nal
ual games), more conversation between the agents
(we plan to improve this with more communica-
tion templates), and more emotion in the voices of
the commentators (we have not yet tackled such
surface-level NLG issues). We also asked what the
ideal number of commentators for a game would
be; almost all subjects replied 2, with just two
replying 3 and one replying 1.
The above results are encouraging for Mike,
but to show that the use of multiple agents was
actually one of the reasons for the favourable audi-
ence impression, we carried out a further test. We
Commentary feature Announcer Expert Note
Background comment 16% 22% (predened plan)
Event-based comment 64% 0% (low-level)
State-based comment 20% 78% (high-level)
Average length of comment 1.1sec 2.9sec (consistency)
Asks a question to the other 12.2 0 (new explanation mode)
Interrupts the other 8.6 0 (priority of roles)
Announcer describes expert as expert 0 n/a (adds weight to expert)
Table 6: Breakdown of Mike's agent utterances over ten randomly selected RoboCup half-games
created a single-agent version of Mike by switch-
ing o the male/female voices in the TTS soft-
ware and disabling the communication templates.
This single-agent commentator comments on al-
most exactly the same game content as the multi-
agent version, but with a single voice. We re-
cruited ten volunteers with no prior knowledge of
RoboCup and showed them both the single-agent
and multi-agent versions of Mike commentating
the same game as used in the previous experiment.
We split the subjects into two groups so that one
group watched the multi-agent version rst, and
the other watched the single-agent version rst.
Table 5 shows that the average questionnaire re-
sponses over the two groups were lower than with
the subjects who were familiar with RoboCup, but
that the multi-agent version was more highly eval-
uated than the single-agent version. Thus, even
the supercially small modication of removing
the agent dialogue has a measurable eect on the
commentary.
Finally, we analysed Mike's commentary us-
ing the same criteria as our protocol analysis of
human soccer commentary in x2.2. We selected
ten half-games at random from the 1998 RoboCup
and compiled statistics on Mike's output with an
automatic script. The results of this analysis (Ta-
ble 6) show a marked similarity to those of the
human commentators. This initial result is a very
encouraging sign for further work in this area.
6 Conclusions
We have argued for superiority of producing
explanations with multiple, rather than single,
agents. In particular, we identied the di?culty of
producing prior plans as the key issue constrain-
ing the ability of a single agent to switch between
high-level and low-level discourse strategies.
As a rst step towards a multi-agent explana-
tion system with solid theoretical underpinnings,
we described the explanation strategies used by
our live soccer commentary system, Mike. We
showed how a set of importance scores and infer-
ence rules can be used as the basis for agents with
dierent discourse strategies, and how the dis-
course control techniques of interruption, abbrevi-
ation, repetition and silence can be used not just
to moderate the discourse of an individual agent,
but also the interaction between agents. We eval-
uated Mike's output through listener surveys,
showing that it represents an advance over exist-
ing commentary programs, which are all single-
agent. We also found that the discourse strategies
of Mike's agents closely resembled those revealed
by the protocol analysis of a team of real-life soc-
cer commentators.
References
E. Andre, K. Binsted, K. Tanaka-Ishii, S. Luke,
G. Herzog, and T. Rist. 2000. Three RoboCup
simulation league commentator systems. AI
Magazine, 21(1):57{66, Spring.
A.J. Cawsey. 1991. Generating intreractive expla-
nations. In Proceedings of the Ninth National
Conference on Articial Intelligence (AAAI-
91), pages 86{91.
H. Kitano, M. Asada, Y. Kuniyoshi, I. Noda,
E. Osawa, and H. Matsubara. 1997. RoboCup:
A challenge problem for AI. AI Magazine,
pages 73{85, Spring.
I. Noda, H. Matsubara, K. Hiraki, and I. Frank.
1998. Soccer Server: a tool for research on
multi-agent systems. Applied Articial Intelli-
gence, 12(2{3):233{251.
B. Reeves and C. Nass. 1996. The Media Equa-
tion. CSLI Publications.
J. Sinclair and R. Coulthard. 1975. Towards
an Analysis of Discourse: The English Used by
Teachers and Pupils. Oxford University Press.
K. Tanaka-Ishii, K. Hasida, and I. Noda. 1998.
Reactive content selection in the generation of
real-time soccer commentary. In Proceedings of
COLING-ACL'98, pages 1282{1288, Montreal.
