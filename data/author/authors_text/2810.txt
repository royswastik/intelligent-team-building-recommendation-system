Multilingual interactive experiments with Flickr
Paul Clough
Department of
Information Studies
University of Sheffield
Sheffield, UK
p.d.clough@sheffield.ac.uk
Julio Gonzalo
Departamento de Lenguajes
y Sistemas Informa?ticos
UNED
Madrid, Spain
julio@lsi.uned.es
Jussi Karlgren
Swedish Institute of
Computer Science
Stockholm
Sweden
jussi@sics.se
Abstract
This paper presents a proposal for iCLEF
2006, the interactive track of the CLEF
cross-language evaluation campaign. In
the past, iCLEF has addressed applications
such as information retrieval and ques-
tion answering. However, for 2006 the
focus has turned to text-based image re-
trieval from Flickr. We describe Flickr, the
challenges this kind of collection presents
to cross-language researchers, and suggest
initial iCLEF tasks.
1 Information Retrieval Evaluation by
User Experiment
Information retrieval systems, especially text re-
trieval systems, have benefited greatly from a
fairly strict and straight-laced evaluation scheme,
which enables system designers to run tests on
versions of their system using a test collection of
pre-assessed data. These relevance-oriented ex-
periments shed light on comparative system per-
formance and enable both introduction of new al-
gorithms and incremental optimization. However,
batch-oriented system evaluation based on large
amounts of data, abstracted away from situational
constraints, variation in usage, and interactiveness
issues only addresses some of the bottlenecks to
build a successful system.
The CLEF1 Interactive Track (iCLEF2) is de-
voted to the comparative study of user inclusive
cross-language search strategies. Over the past
5 years, iCLEF has studied three cross-language
search tasks: retrieval of documents, answers and
1http://www.clef-campaign.org/
2http://nlp.uned.es/iCLEF/
annotated images (Gonzalo and Oard, 2002; Gon-
zalo et al, 2005). All tasks involve the user in-
teracting with information systems in a language
different from that of the document collection.
Although iCLEF experiments continue produc-
ing interesting research results, which may have
a substantial impact on the way effective cross-
language search assistants are built, participation
in this track has remained low across the five years
of existence of the track. Interactive studies, how-
ever, remain as a recognized necessity in most
CLEF tracks.
Therefore, to encourage greater participation in
2006 our focus has turned to FLICKR3, a large-
scale, web-based image database with the poten-
tial for offering both challenging and realistic mul-
tilingual search tasks for interactive experiments.
Our aim in selecting a primarily non-textual tar-
get to study textual retrieval is based on some of
the multi-lingual and dynamic characteristics of
FLICKR. We will outline them below.
2 The Flickr system
The majority of Web image search is text-based
and the success of such approaches often de-
pends on reliably identifying relevant text associ-
ated with a particular image. FLICKR is an on-
line tool for managing and sharing personal pho-
tographs and currently contains over five million
freely accessible images. These are available via
the web, updated daily by a large number of users
and available to all web users (users can access
FLICKR for free, although limited to the upload of
20MB of photos per month).
3http://www.flickr.com/
70
2.1 Photographs in the collection
It is estimated that the complete FLICKR database
contains 37 million photos with approximately
200,000 images added daily by 1.2 million mem-
bers4. FLICKR provides both private and pub-
lic image storage, and photos which are shared
(around 5 million) can be protected under a Cre-
ative Commons (CC) licensing5 agreement (an al-
ternative to full copyright). Images from a wide
variety of topics can be accessed through FLICKR,
including people, places, landscapes, objects, ani-
mals and events. This makes the collection a rich
resource for image retrieval research.
2.2 Annotations
In FLICKR, photos are annotated by authors with
freely chosen keywords in a naturally multilingual
manner: most authors use keywords in their native
language; some combine more than one language.
In addition, photographs have titles, descriptions,
collaborative annotations, and comments in many
languages. Figure 5 provides an example photo
with multilingual annotations; Figure 5 shows
what the query ?cats? retrieves from the database,
compared with what the query ?chats? retrieves.
Annotations are used by the authors to organize
their images, and by any user to search on. Key-
words assigned to the images can include place
names and subject matter, and photos can also
be submitted to online discussion groups. This
provides additional metadata to the image which
can also be used for retrieval. An explore util-
ity provided by FLICKR makes use of this user-
generated data (plus other information such as
Clickthroughs) to define an ?interestingness? view
of images6.
3 Flickr at iCLEF 2006
Many images are accompanied by text, enabling
the use of both text and visual features for image
retrieval and its evaluation (Mu?ller et al, 2006,
see e.g.). Images are naturally language indepen-
dent and often successfully retrieved with asso-
ciated texts. This has been explored as part of
ImageCLEF (Clough et al, 2005) for areas such
as information access to medical images and his-
toric photographs. The way in which users search
4These figures are accurate as of October 2005:
http://www.wired.com/news/ebiz/0,1272,68654,00.html
5http://creativecommons.org/image/flickr,
http://flickr.com/creativecommons/
6http://www.flickr.com/explore/interesting
for images provides an interesting application for
user-centered design and evaluation. As an iCLEF
task, searching for images from FLICKR presents
a new multilingual challenge which, to date, has
not been explored. Challenges include:
? Different types of associated text, e.g. key-
words, titles, comments and description
fields.
? Collective classification and annotation us-
ing freely selected keywords (known as folk-
sonomies) resulting in non-uniform and sub-
jective categorization of images.
? Annotations in multiple languages.
Given the multilingual nature of the FLICKR
annotations, translating the user?s search request
would provide the opportunity of increasing the
number of images found and make more of the
collection accessible to a wider range of users
regardless of their language skills. The aim of
iCLEF using FLICKR will be to determine how
cross-language technologies could enhance ac-
cess, and explore the user interaction resulting
from this.
4 Proposed tasks
For iCLEF, participants to this evaluation cam-
paign will be provided with the following:
? A subset of the Flickr collection including an-
notations and photographs7.
? Example (realistic) search tasks. Ideally
these search tasks will reflect real user needs
which could be derived from log files, studies
or similar retrieval tasks.
? A framework in which to run an evaluation.
5 Summary
Flickr will allow us to create an extremely in-
teresting interactive task based on truly hetero-
geneous annotations (that will in turn hopefully
attract more participants). Using images from
within a Web environment is a realistic and con-
temporary search challenge and allows many im-
portant research questions to be addressed from
7We are currently in negotiations with Yahoo! (owners
of Flickr) and Flickr to provide researchers with legitimate
access to a subset of the collection.
71
a quickly developing field. User-centered studies
are required within both text and image retrieval,
but are often neglected as they require more effort
and time from participating groups than a system-
centered comparison that can often be run with-
out human intervention. Still, user-centered eval-
uation cannot be replaced and the influence of the
user on the results is in general stronger than the
influence of the system itself.
References
Paul Clough, Henning Mu?ller, and Mark Sanderson.
2005. The clef 2004 cross language image retrieval
track. In Carol Peters, Paul Clough, Julio Gon-
zalo, Gareth Jones, Michael Kluck, and Bernardo
Magnini, editors, Multilingual Information Access
for Text, Speech and Images: Results of the Fifth
CLEF Evaluation Campaign, number 3491/2005 in
Lecture Notes in Computer Science, pages 597?613.
Springer, Heidelberg, Germany.
Julio Gonzalo and Doug Oard. 2002. The clef
2002 interactive track. In Advances in Cross-
Language Information Retrieval, number 2785 in
Lecture Notes in Computer Science. Springer-
Verlag, Berlin-Heidelberg-New York.
Julio Gonzalo, Paul Clough, and A Vallin. 2005.
Overview of the clef 2005 interactive track. In
Working notes of the CLEF workshop, Vienna, Aus-
tria, September.
Henning Mu?ller, Paul Clough, William Hersh, Thomas
Deselaers, Thomas Lehmann, and Antoine Geiss-
buhler. 2006. Using heterogeneous annotation and
visual information for the benchmarking of image
retrieval systems. In SPIE conference Photonics
West, Electronic Imaging, special session on bench-
marking image retrieval systems, San Diego, Febru-
ary.
72
Figure 1: Example multilingual annotations in Flickr.
Figure 2: Retrieval of ?cats? (left) and ?chats? (right).
73
