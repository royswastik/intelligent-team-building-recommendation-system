Proceedings of the Workshop on Textual Entailment and Paraphrasing, pages 131?136,
Prague, June 2007. c?2007 Association for Computational Linguistics
Semantic Inference at the Lexical-Syntactic Level for Textual Entailment
Recognition
Roy Bar-Haim?,Ido Dagan?, Iddo Greental?, Idan Szpektor? and Moshe Friedman?
?Computer Science Department, Bar-Ilan University, Ramat-Gan 52900, Israel
?Linguistics Department, Tel Aviv University, Ramat Aviv 69978, Israel
{barhair,dagan}@cs.biu.ac.il,greenta@post.tau.ac.il,
{szpekti,friedmm}@cs.biu.ac.il
Abstract
We present a new framework for textual en-
tailment, which provides a modular integra-
tion between knowledge-based exact infer-
ence and cost-based approximate matching.
Diverse types of knowledge are uniformly
represented as entailment rules, which were
acquired both manually and automatically.
Our proof system operates directly on parse
trees, and infers new trees by applying en-
tailment rules, aiming to strictly generate the
target hypothesis from the source text. In or-
der to cope with inevitable knowledge gaps,
a cost function is used to measure the re-
maining ?distance? from the hypothesis.
1 Introduction
According to the traditional formal semantics ap-
proach, inference is conducted at the logical level.
However, practical text understanding systems usu-
ally employ shallower lexical and lexical-syntactic
representations, augmented with partial semantic
annotations. Such practices are typically partial and
quite ad-hoc, and lack a clear formalism that speci-
fies how inference knowledge should be represented
and applied. The current paper proposes a step to-
wards filling this gap, by defining a principled se-
mantic inference mechanism over parse-based rep-
resentations.
Within the textual entailment setting a system is
required to recognize whether a hypothesized state-
ment h can be inferred from an asserted text t.
Some inferences can be based on available knowl-
edge, such as information about synonyms and para-
phrases. However, some gaps usually arise and it
is often not possible to derive a complete ?proof?
based on available inference knowledge. Such sit-
uations are typically handled through approximate
matching methods.
This paper focuses on knowledge-based infer-
ence, while employing rather basic methods for ap-
proximate matching. We define a proof system
that operates over syntactic parse trees. New trees
are derived using entailment rules, which provide a
principled and uniform mechanism for incorporat-
ing a wide variety of manually and automatically-
acquired inference knowledge. Interpretation into
stipulated semantic representations, which is often
difficult to obtain, is circumvented altogether. Our
research goal is to explore how far we can get with
such an inference approach, and identify the scope
in which semantic interpretation may not be needed.
For a detailed discussion of our approach and related
work, see (Bar-Haim et al, 2007).
2 Inference Framework
The main contribution of the current work is a prin-
cipled semantic inference mechanism, that aims to
generate a target text from a source text using en-
tailment rules, analogously to logic-based proof sys-
tems. Given two parsed text fragments, termed
text (t) and hypothesis (h), the inference system (or
prover) determines whether t entails h. The prover
applies entailment rules that aim to transform t into
h through a sequence of intermediate parse trees.
For each generated tree p, a heuristic cost function is
employed to measure the likelihood of p entailing h.
131
ROOT
i 
rain VERB
expletive
ssfff
ff
ff
ff
f wha
++XX
XX
XX
XX
XX
it OTHER when PREP
i 
see VERB
obj
qqcccccc
cccc
cccc
cccc
cc
bessff
ff
ff
ff
ff
by

mod
++XX
XX
XX
XX
XX
Mary NOUN
mod 
be VERB by PREP
pcomp?n

yesterday NOUN
beautiful ADJ John NOUN
ROOT
i 
rain VERB
expletive
rreeee
eee
eee
e wha
,,YYY
YYY
YYY
YY
it OTHER when PREP
i 
see VERB
subj
rreeee
eee
eee
e
obj

mod
,,YYY
YYY
YYY
YY
John NOUN Mary NOUN
mod 
yesterday NOUN
beautiful ADJ
Source: it rained when beautiful Mary was seen by John yester-
day
Derived: it rained when John saw beautiful Mary yesterday
(a) Application of passive to active transformation
L
V VERB
obj
ssfff
ff
ff
ff
f
be 
by
++XX
XX
XX
XX
XX
R
V VERB
subj
ssfff
ff
ff
ff
f obj
++XX
XX
XX
XX
XX
N1 NOUN be VERB by PREP
pcomp?n

N2 NOUN N1 NOUN
N2 NOUN
(b) Passive to active transformation (substitution rule). The dotted arc represents alignment.
Figure 1: Application of inference rules. POS and relation labels are based on Minipar (Lin, 1998b)
If a complete proof is found (h was generated), the
prover concludes that entailment holds. Otherwise,
entailment is determined by comparing the minimal
cost found during the proof search to some threshold
?.
3 Proof System
Like logic-based systems, our proof system consists
of propositions (t, h, and intermediate premises),
and inference (entailment) rules, which derive new
propositions from previously established ones.
3.1 Propositions
Propositions are represented as dependency trees,
where nodes represent words, and hold a set of fea-
tures and their values. In our representation these
features include the word lemma and part-of-speech,
and additional features that may be added during the
proof process. Edges are annotated with dependency
relations.
3.2 Inference Rules
At each step of the proof an inference rule gener-
ates a derived tree d from a source tree s. A rule
is primarily composed of two templates, termed left-
hand-side (L), and right-hand-side (R). Templates
are dependency subtrees which may contain vari-
ables. Figure 1(b) shows an inference rule, where
V , N1 and N2 are common variables. L specifies
the subtree of s to be modified, and R specifies the
new generated subtree. Rule application consists of
the following steps:
L matching The prover first tries to match L in s.
L is matched in s if there exists a one-to-one node
mapping function f from L to s, such that: (i) For
each node u, f(u) has the same features and feature
values as u. Variables match any lemma value in
f(u). (ii) For each edge u ? v in L, there is an
edge f(u) ? f(v) in s, with the same dependency
relation. If matching fails, the rule is not applicable
to s. Otherwise, successful matching induces vari-
132
LROOT
i 
R
ROOT
i 
V1 VERB
wha 
V2 VERB
when ADJ
i 
V2 VERB
Figure 2: Temporal clausal modifier extraction (in-
troduction rule)
able binding b(X), for each variableX in L, defined
as the full subtree rooted in f(X) if X is a leaf, or
f(X) alone otherwise. We denote by l the subtree
in s to which L was mapped (as illustrated in bold
in Figure 1(a), left tree).
R instantiation An instantiation of R, which we
denote r, is generated in two steps: (i) creating a
copy of R; (ii) replacing each variable X with a
copy of its binding b(X) (as set during L matching).
In our example this results in the subtree John saw
beautiful Mary.
Alignment copying the alignment relation be-
tween pairs of nodes in L and R specifies which
modifiers in l that are not part of the rule structure
need to be copied to the generated tree r. Formally,
for any two nodes u in l and v in r whose matching
nodes in L and R are aligned, we copy the daugh-
ter subtrees of u in s, which are not already part of
l, to become daughter subtrees of v in r. The bold
nodes in the right part of Figure 1(b) correspond to
r after alignment. yesterday was copied to r due to
the alignment of its parent verb node.
Derived tree generation by rule type Our for-
malism has two methods for generating the derived
tree: substitution and introduction, as specified by
the rule type. With substitution rules, the derived
tree d is obtained by making a local modification to
the source tree s. Except for this modification s and
d are identical (a typical example is a lexical rule,
such as buy ? purchase). For this type, d is formed
by copying s while replacing l (and the descendants
of l?s nodes) with r. This is the case for the passive
rule. The right part of Figure 1(a) shows the derived
tree for the passive rule application. By contrast, in-
troduction rules are used to make inferences from a
subtree of s, while the other parts of s are ignored
and do not affect d. A typical example is inference
of a proposition embedded as a relative clause in s.
In this case the derived tree d is simply taken to be
r. Figure 2 presents such a rule that derives propo-
sitions embedded within temporal modifiers. Note
that the derived tree does not depend on the main
clause. Applying this rule to the right part of Figure
1(b) yields the proposition John saw beautiful Mary
yesterday.
3.3 Annotation Rules
Annotation rules add features to parse tree nodes,
and are used in our system to annotate negation and
modality. Annotation rules do not have an R. In-
stead, nodes of L may contain annotation features.
If L is matched in a tree then the annotations are
copied to the matched nodes. Annotation rules are
applied to t and to each inferred premise prior to
any entailment rule application and these features
may block inappropriate subsequent rule applica-
tions, such as for negated predicates.
4 Rules for Generic Linguistic Structures
Based on the above framework we have manually
created a rule base for generic linguistic phenomena.
4.1 Syntactic-Based Rules
These rules capture entailment inferences associ-
ated with common syntactic structures. They have
three major functions: (i) simplification and canon-
ization of the source tree (categories 6 and 7 in Ta-
ble 1); (ii) extracting embedded propositions (cate-
gories 1, 2, 3); (iii) inferring propositions from non-
propositional subtrees (category 4).
4.2 Polarity-Based Rules
Consider the following two examples:
John knows that Mary is here?Mary is here.
John believes that Mary is here;Mary is here.
Valid inference of propositions embedded as verb
complements depends on the verb properties, and
the polarity of the context in which the verb appears
(positive, negative, or unknown) (Nairn et al, 2006).
We extracted from the polarity lexicon of Nairn et
al. a list of verbs for which inference is allowed in
positive polarity context, and generated entailment
133
# Category Example: source Example: derived
1 Conjunctions Helena?s very experienced and has played a long
time on the tour.
? Helena has played a long time on the tour.
2 Clausal modi-
fiers
But celebrations were muted as many Iranians ob-
served a Shi?ite mourning month.
? Many Iranians observed a Shi?ite mourning
month.
3 Relative
clauses
The assailants fired six bullets at the car, which car-
ried Vladimir Skobtsov.
? The car carried Vladimir Skobtsov.
4 Appositives Frank Robinson, a one-time manager of the Indians,
has the distinction for the NL.
? Frank Robinson is a one-time manager of the
Indians.
5 Determiners The plaintiffs filed their lawsuit last year in U.S.
District Court in Miami.
? The plaintiffs filed a lawsuit last year in U.S.
District Court in Miami.
6 Passive We have been approached by the investment banker. ? The investment banker approached us.
7 Genitive
modifier
Malaysia?s crude palm oil output is estimated to
have risen by up to six percent.
? The crude palm oil output of Malasia is esti-
mated to have risen by up to six percent.
8 Polarity Yadav was forced to resign. ? Yadav resigned.
9 Negation,
modality
What we?ve never seen is actual costs come
down.
What we?ve never seen is actual costs come down.
(;What we?ve seen is actual costs come down.)
Table 1: Summary of rule base for generic linguistic structures.
rules for these verbs (category 8). The list was com-
plemented with a few reporting verbs, such as say
and announce, assuming that in the news domain the
speaker is usually considered reliable.
4.3 Negation and Modality Annotation Rules
We use annotation rules to mark negation and
modality of predicates (mainly verbs), based on their
descendent modifiers. Category 9 in Table 1 illus-
trates a negation rule, annotating the verb seen for
negation due to the presence of never.
4.4 Generic Default Rules
Generic default rules are used to define default be-
havior in situations where no case-by-case rules are
available. We used one default rule that allows re-
moval of any modifiers from nodes.
5 Lexical-based Rules
These rules have open class lexical components, and
consequently are numerous compared to the generic
rules described in section 4. Such rules are acquired
either lexicographically or automatically.
The rules described in the section 4 are applied
whenever their L template is matched in the source
premise. For high fan-out rules such as lexical-based
rules (e.g. words with many possible synonyms),
this may drastically increase the size of the search
space. Therefore, the rules described below are ap-
plied only if L is matched in the source premise p
and R is matched in h.
5.1 Lexical Rules
Lexical entailment rules, such as ?steal ? take? and
?Britain ? UK? were created based on WordNet
(Fellbaum, 1998). Given p and h, a lexical rule
lemmap ? lemmah may be applied if lemmap
and lemmah are lemmas of open-class words ap-
pearing in p and h respectively, and there is a path
from lemmah to lemmap in the WordNet ontology,
through synonym and hyponym relations.
5.2 Lexical-Syntactic Rules
In order to find lexical-syntactic paraphrases and en-
tailment rules, such as ?X strike Y ? X hit Y ? and
?X buy Y ?X own Y ? that would bridge between p
and h, we applied the DIRT algorithm (Lin and Pan-
tel, 2001) to the first CD of the Reuters RCV1 cor-
pus1. DIRT does not identify the entailment direc-
tion, hence we assumed bi-directional entailment.
We calculate off-line only the feature vector of ev-
ery template found in the corpus, where each path
between head nouns is considered a template in-
stance. Then, given a premise p, we first mark all
lexical noun alignments between p and h. Next, for
every pair of alignments we extract the path between
the two nouns in p, labeled pathp, and the corre-
sponding path between the aligned nouns in h, la-
beled pathh. We then on-the-fly test whether there
is a rule ?pathp ? pathh? by extracting the stored
feature vectors of pathp and pathh and measuring
1http://about.reuters.com/researchandstandards/corpus/
134
their similarity. If the score exceeds a given thresh-
old2, we apply the rule to p.
Another enhancement that we added to DIRT is
template canonization. At learning time, we trans-
form every template identified in the corpus into
its canonized form3 using a set of morpho-syntactic
rules, similar to the ones described in Section 4. In
addition, we apply nominalization rules such as ?ac-
quisition of Y by X ? X acquire Y ?, which trans-
form a nominal template into its related verbal form.
We automatically generate these rules (Ron, 2006),
based on Nomlex (Macleod et al, 1998).
At inference time, before retrieving feature vec-
tors, we canonize pathp into pathcp and pathh into
pathch. We then assess the rule ?path
c
p ? path
c
h?,
and if valid, we apply the rule ?pathp ? pathh? to
p. In order to ensure the validity of the implicature
?pathp ? pathcp ? path
c
h ? pathh?, we canonize
pathp using the same rule set used at learning time,
but we apply only bi-directional rules to pathh (e.g.
conjunct heads are not removed from pathh).
6 Approximate Matching
As mentioned in section 2, approximate matching
is incorporated into our system via a cost function,
which estimates the likelihood of h being entailed
from a given premise p. Our cost function C(p, h) is
a linear combination of two measures: lexical cost,
Clex(p, h) and lexical-syntactic cost ClexSyn(p, h):
C(p, h) = ?ClexSyn(p, h)+ (1??)Clex(p, h) (1)
Let m?() be a (possibly partial) 1-1 mapping of the
nodes of h to the nodes of p, where each node
is mapped to a node with the same lemma, such
that the number of matched edges is maximized.
An edge u ? v in h is matched in p if m?(u)
and m?(v) are both defined, and there is an edge
m?(u) ? m?(v) in p, with the same dependency rela-
tion. ClexSyn(p, h) is then defined as the percentage
of unmatched edges in h.
Similarly, Clex(p, h) is the percentage of un-
matched lemmas in h, considering only open-class
words, defined as:
Clex(p, h) = 1?
?
l?h Score(l)
#OpenClassWords(h)
(2)
2We set the threshold to 0.01
3The active verbal form with direct modifiers
where Score(l) is 1 if it appears in p, or if it is
a derivation of a word in p (according to Word-
Net). Otherwise, Score(l) is the maximal Lin
dependency-based similarity score between l and the
lemmas of p (Lin, 1998a) (synonyms and hyper-
nyms/hyponyms are handled by the lexical rules).
7 System Implementation
Deriving the initial propositions t and h from the in-
put text fragments consists of the following steps:
(i) Anaphora resolution, using the MARS system
(Mitkov et al, 2002). Each anaphor was replaced by
its antecedent. (ii) Sentence splitting, using mxter-
minator (Reynar and Ratnaparkhi, 1997). (iii) De-
pendency parsing, using Minipar (Lin, 1998b).
The proof search is implemented as a depth-first
search, with maximal depth (i.e. proof length) of
4. If the text contains more than one sentence, the
prover aims to prove h from each of the parsed sen-
tences, and entailment is determined based on the
minimal cost. Thus, the only cross-sentence infor-
mation that is considered is via anaphora resolution.
8 Evaluation
Full (run1) Lexical (run2)
Dataset Task Acc. Avg.P Acc. Avg.P
Test IE 0.4950 0.5021 0.5000 0.5379
Official IR 0.6600 0.6174 0.6450 0.6539
Results QA 0.7050 0.8085 0.6600 0.8075
SUM 0.5850 0.6200 0.5300 0.5927
All 0.6112 0.6118 0.5837 0.6093
Dev. All 0.6443 0.6699 0.6143 0.6559
Table 2: Empirical evaluation - results.
The results for our submitted runs are listed in Ta-
ble 2, including per-task scores. run1 is our full sys-
tem, denoted F . It was tuned on a random sample
of 100 sentences from the development set, result-
ing in ? = 0.6 and ? = 0.6242 (entailment thresh-
old). run2 is a lexical configuration, denoted L, in
which ? = 0 (lexical cost only), ? = 0.2375 and
the only inference rules used were WordNet Lexical
rules. We found that the higher accuracy achieved
by F as compared to L might have been merely due
to a lucky choice of threshold. Setting the threshold
to its optimal value with respect to the test set re-
sulted in an accuracy of 62.4% for F , and 62.9% for
135
L. This is also hinted by the very close average pre-
cision scores for both systems, which do not depend
on the threshold. The last row in the table shows
the results obtained for 7/8 of the development set
that was not used for tuning, denoted Dev, using the
same parameter settings. Again, F performs bet-
ter than L. F is still better when using an optimal
threshold (which increases accuracy up to 65.3% for
F and 63.9% for L. Overall, F does not show yet a
consistent significant improvement over L.
Initial analysis of the results (based on Dev) sug-
gests that the coverage of the current rules is still
rather low. Without approximate matching (h must
be fully proved using the entailment rules) the re-
call is only 4.3%, although the precision (92%) is
encouraging. Lexical-syntactic rules were applied
in about 3% of the attempted proofs, and in most
cases involved only morpho-syntactic canonization,
with no lexical variation. As a result, entailment was
determined mainly by the cost function. Entailment
rules managed to reduce the cost in about 30% of the
attempted proofs.
We have qualitatively analyzed a subset of false
negative cases, to determine whether failure to com-
plete the proof is due to deficient components of
the system or due to higher linguistic and knowl-
edge levels. For each pair, we assessed the reasoning
steps a successful derivation of h from t would take.
We classified each pair according to the most de-
manding type of reasoning step it would require. We
allowed rules that are presently unavailable in our
system, as long as they are similar in power to those
that are currently available. We found that while
the single dominant cause for proof failure is lack
of world knowledge, e.g. the king?s son is a mem-
ber of the royal family, the combination of miss-
ing lexical-syntactic rules and parser failures equally
contributed to proof failure.
9 Conclusion
We defined a novel framework for semantic infer-
ence at the lexical-syntactic level, which allows a
unified representation of a wide variety of inference
knowledge. In order to reach reasonable recall on
RTE data, we found that we must scale our rule ac-
quisition, mainly by improving methods for auto-
matic rule learning.
Acknowledgments
We are grateful to Cleo Condoravdi for making the
polarity lexicon developed at PARC available for
this research. We also wish to thank Ruslan Mitkov,
Richard Evans, and Viktor Pekar from University of
Wolverhampton for running the MARS system for
us. This work was partially supported by ISF grant
1095/05, the IST Programme of the European Com-
munity under the PASCAL Network of Excellence
IST-2002-506778, the Israel Internet Association
(ISOC-IL) grant 9022 and the ITC-irst/University of
Haifa collaboration.
References
Roy Bar-Haim, Ido Dagan, Iddo Greental, and Eyal
Shnarch. 2007. Semantic inference at the lexical-
syntactic level. In AAAI (to appear).
Christiane Fellbaum, editor. 1998. WordNet: An Elec-
tronic Lexical Database. Language, Speech and Com-
munication. MIT Press.
Dekang Lin and Patrik Pantel. 2001. Discovery of infer-
ence rules for question answering. Natural Language
Engineering, 4(7):343?360.
Dekang Lin. 1998a. Automatic retrieval and clustering
of similar words. In Proceedings of COLING/ACL.
Dekang Lin. 1998b. Dependency-based evaluation of
minipar. In Proceedings of the Workshop on Evalua-
tion of Parsing Systems at LREC.
C. Macleod, R. Grishman, A. Meyers, L. Barrett, and
R. Reeves. 1998. Nomlex: A lexicon of nominal-
izations. In EURALEX.
Ruslan Mitkov, Richard Evans, and Constantin Orasan.
2002. A new, fully automatic version of Mitkov?s
knowledge-poor pronoun resolution method. In Pro-
ceedings of CICLing.
Rowan Nairn, Cleo Condoravdi, and Lauri Karttunen.
2006. Computing relative polarity for textual infer-
ence. In Proceedings of ICoS-5.
Jeffrey C. Reynar and Adwait Ratnaparkhi. 1997. A
maximum entropy approach to identifying sentence
boundaries. In Proceedings of ANLP.
Tal Ron. 2006. Generating entailment rules based on
online lexical resources. Master?s thesis, Computer
Science Department, Bar-Ilan University, Ramat-Gan,
Israel.
136
