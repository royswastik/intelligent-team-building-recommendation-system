Semi-Automatic Generation of Dialogue Applications
in the GEMINI Project ?
Stefan W. Hamerich, Volker Schubert, Volker Schless
TEMIC Speech Dialog Systems, Ulm, Germany
{stefan.hamerich|volker.schubert|volker.schless}@temic-sds.com
Ricardo de Co?rdoba, Jose? M. Pardo, Luis F. d?Haro
Grupo de Tecnolog??a del Habla, Universidad Polite?cnica de Madrid, Madrid, Spain
{cordoba|pardo|lfdharo}@die.upm.es
Basilis Kladis, Otilia Kocsis
Knowledge S.A. (LogicDIS group), Patras, Greece
{bkladis|okocsis}@logicdis.gr
Stefan Igel
Forschungsinstitut fu?r anwendungsorientierte Wissensverarbeitung (FAW), Ulm, Germany
sigel@faw.uni-ulm.de
Abstract
GEMINI (Generic Environment for Multilin-
gual Interactive Natural Interfaces) is an EC
funded research project, which has two main
objectives: First, the development of a flexible
platform able to produce user-friendly interac-
tive multilingual and multi-modal dialogue in-
terfaces to databases with a minimum of hu-
man effort, and, second, the demonstration of
the platform?s efficiency through the develop-
ment of two different applications based on this
platform: EG-Banking, a voice-portal for high-
quality interactions for bank customers, and
CitizenCare, an e-government platform frame-
work for citizen-to-administration interaction
which are available for spoken and web-based
user interaction.
1 Introduction
GEMINI1 exploits experience gained from previous
projects (see e.g. (Ehrlich et al, 1997; Lehtinen et al,
2000)) and from real-world use of similar systems, to
create a generic platform for the development of user-
friendly, natural, high quality, intuitive, platform in-
dependent and multi-modal interactive interfaces to a
wide area of databases employed by information service
providers.
?This work was partly supported by the European Com-
mission?s Information Society Technologies Programme under
contract no. IST-2001-32343. The authors are solely responsi-
ble for the contents of this publication.
1Refer to the GEMINI Project Homepage on
www.gemini-project.org for further details.
The main idea of GEMINI is that, given a database, a
description of its structure and how to access the data as
well as a list of the kinds of requests the user may make,
the system should be able to automatically generate the
necessary dialogue scripts to run the service. In a sense,
this is exactly what a human call center agent does when
being trained for the job. Within the project we strive to
get as close as possible to this ideal.
Specifically, the application generation platform of the
GEMINI project contains generic dialogue components
available for adaptation to new services and languages.
Thus, generation of multilingual and multi-modal inter-
faces is achieved by incorporating the lexical and se-
mantic relations of the databases contents, reducing the
development time and facilitating the system?s mainte-
nance and transportability to different applications and
languages. Furthermore, the platform enables a high de-
gree of personalisation (i.e. user modelling, speaker ver-
ification, etc.).
This paper is organised as follows: First we describe
the application generation platform (AGP) of the GEM-
INI project. Afterwards we introduce the two pilot appli-
cations developed with our platform. Next we compare
our approach with other proposals made by different re-
search groups. Finally we conclude our major findings.
2 Application Generation Platform
The main target of the GEMINI project is the develop-
ment of a platform for generating interactive, multilin-
gual and multi-modal dialogue interfaces to databases
with a minimum of cost and human effort. The AGP is
an integrated set of assistants to generate multi-modal di-
alogue applications in a semi-automatic way. Its open
and modular architecture simplifies the adaptability of
applications designed with the AGP to different use cases.
Connecting to a different database, adding a new modal-
ity or changing a scripting language can be achieved by
adding or replacing the appropriate component without
touching the other aspects of dialogue design again.
The AGP consists of assistants, which are tools (partly
with a GUI) producing models. All these models gen-
erated within the AGP are described in GDialogXML
(GEMINI Dialog XML), which is an object-oriented ab-
stract dialogue modelling language. It was created during
GEMINI for use with the AGP. See Figure 1 for an exam-
ple of the GDialogXML syntax. For a detailed descrip-
tion of GDialogXML refer to (Hamerich et al, 2003).
<Var id = "xPersonName">
<xType><Type refr = "String"/></xType>
</Var>
<Var id = "xPersonList">
<xType><Type refr = "List">
<xItemType>
<Type refr = "ObjEmbed"/>
<xClass><Class refr = "Person"/></xClass>
</xItemType></Type>
</xType>
</Var>
Figure 1: Definition of variables in GDialogXML
All models in the AGP may be saved as libraries for
future applications.
As shown in Figure 2 the AGP is not supposed to com-
plete its task without any human interaction. This is be-
cause there will always be different ways for retrieving
specific information. Consequently, the designer of dia-
logue applications has to select the preferred flow of dia-
logue manually by confirming the proposals of the AGP
components. Most of these operations are simply drag
& drop actions between various windows that contain all
relevant fields, which are automatically created from the
previous tools of the platform.
2.1 AGP Architecture
All components of the AGP are integrated into one frame-
work. This eases the use of the platform and enables the
designer to switch back and forward to different tools in
case she or he wants to add or modify certain dialogues.
In Figure 2 the architecture of the AGP is illustrated.
The whole AGP consists of three layers. These layers are
described in more detail in the following sections.
2.1.1 Framework Layer
The framework layer is the first layer of the AGP (refer
to Figure 2). It includes the application description as-
sistant (ADA), the data modelling assistant (DMA), and
the data connector modelling assistant (DCMA). As indi-
	
	 
		




		



	
Proceedings of the 9th SIGdial Workshop on Discourse and Dialogue, pages 92?95,
Columbus, June 2008. c?2008 Association for Computational Linguistics
From GEMINI to DiaGen:
Improving Development of Speech Dialogues
for Embedded Systems
Stefan W. Hamerich
University of Hamburg Harman/Becker Automotive Systems
Department of Informatics CoC Speech & Connectivity
Natural Language Systems Division Speech Services
Hamburg ? Germany Ulm ? Germany
shamerich@harmanbecker.com
Abstract
In this paper DiaGen is presented, a tool that
provides support in generating code for em-
bedded dialogue applications. By aid of it, the
dialogue development process is speeded up
considerably. At the same time it is guaran-
teed that only well-formed and well-defined
constructs are used. Having had its roots in
the EU-funded project GEMINI, fundamen-
tal changes were necessary to adopt it to the
requirements of the application environment.
Additionally within this paper the basics of
embedded speech dialogue systems are cov-
ered.
1 Introduction
The EU funded research project GEMINI (Generic
Environment for Multilingual Interactive Natural In-
terfaces) aimed at the development of an Applica-
tion Generation Platform (AGP) to semiautomati-
cally generate multimodal dialogue applications for
database access (Hamerich et al, 2004a). At the end
of the project, two telephony applications had been
successfully deployed: a banking application for a
Greek bank, and a citizen care application for a Ger-
man city. The former has been used by several thou-
sand customers (Hamerich et al, 2004b).
Based on the ideas and concepts of GEMINI a
new tool named DiaGen has been developed, which
improves the development process for dialogue ap-
plications with regard to certain aspects.
This paper is structured as follows: First the basic
ideas of the GEMINI AGP are introduced. Next the
characteristics and peculiarities of embedded speech
applications are explained. This is followed by a
description of the concepts of GEMINI which had
been a starting point for the development of DiaGen.
The core of this paper follows: a detailled descrip-
tion of the DiaGen tool. Finally the conclusion and
outlook are presented.
2 The GEMINI AGP
The GEMINI AGP provided support for the semi-
automatic creation of phone-based dialogue applica-
tions. The development process had several layers.
Through the different phases of a layer the applica-
tion developer was guided by a wizard and had to
use specialised assistants for each phase.
The first starting point was a rough abstract dia-
logue model, which has been enriched step by step
through all phases until finally dialogue model was
completed. All models are completely written in
a language specifically developed for the purposes
of GEMINI covering both, dialogue description and
data modelling (Hamerich et al, 2003; Schubert and
Hamerich, 2005).
Originally the GEMINI AGP was designed for
phone-based or web-based applications. Therefore
the final outcome of the AGP was VoiceXML or
xHTML, according to the initial selection of the ap-
plication developer.
The three layers of the platform are described in
depth in (d?Haro et al, 2006).
3 Automotive Speech Dialogues
Speech dialogues for cars are embedded solutions
running under real-time operating systems with very
92
low memory and CPU power (Hamerich, 2005).1
Next to these hardware requirements customers
from automotive industry demand very explicit
specifications to understand the complete dialogue
flow and see its connections to the graphical/haptical
HMI (human machine interface) in a car. Therefore
special algorithms and tools are used, to develop and
run speech dialogues on such embedded systems. In
consequence Harman/Becker has a proprietary dia-
logue description language developed especially for
being used on embedded environments (Hamerich
and Hanrieder, 2004). The Generic Dialogue Mod-
elling Language (GDML) is designed as a compiled
language to save memory and CPU resources. This
makes sense, since dialogues within a car are still
closed applications.
Speech control for cars is available to the end
customer since 1996 (Heisterkamp, 2001). Today
many car manufacturers offer speech control sys-
tems. Typical applications in a car are voice con-
trol of telephone, tuner and navigation system. Di-
rect control of media files using their meta-data
(e.g. ID3-Tags) by saying e.g. ?play title ?Bad? by
?Michael Jackson?? is a feature currently under de-
velopment (Wang and Hamerich, 2008).
In spite of several tools and libraries, dialogue de-
velopment for automotive applications is mainly still
manual work.
4 Porting Ideas from GEMINI to DiaGen
Since the GEMINI AGP showed that advanced
speech dialogue applications can be created fast and
easy it was straightforward to attempt to transfer at
least some of the possibilities from the AGP into the
world of embedded speech dialogues. However the
following features need to be changed for the new
tool:
? Speech dialogues in cars do not access a
database; instead the devices are controlled di-
rectly by the speech dialogue. Therefore Dia-
Gen does not need a database interface but
should instead offer a flexible way to integrate
access to external devices.
1Generally embedded systems comprise other highly inte-
grated systems as well. Since the approach for embedding
speech dialogue systems described here can work on such sys-
tems as well, the term ?embedded? is used as a generalisation.
? When starting development with the AGP first
a rough dialogue specification has to be pro-
vided, which for every new application needs
to be given again (except the library approach
is used, which makes only sense for very sim-
ilar applications). It would make sense to pro-
vide a sample dialogue at the start of dialogue
development for embedded applications, con-
taining the most common interfaces and allow-
ing faster creation of new applications from this
starting point.
? When using the AGP for dialogue develop-
ment, there was no consistency check for
speech grammars and their connection to the
dialogue. This should be improved with Dia-
Gen.
? Since highly customised applications are de-
manded, code is still written by hand. Never-
theless dialogue designers are supported with
several tools and libraries. Therefore the new
tool should fit into the existing tool chain,
but should also allow for manual editing or
at least fine-tuning of the code. Since it
was experienced from GEMINI that generat-
ing VoiceXML from the models coded in the
GEMINI modelling language was hard work,
it was decided to directly work on the runtime
language for the new tool. This minimises ef-
forts for the generation components and on the
other hand allows for easy editing of code files.
That means for the new tool no generator com-
ponent is needed. Instead the compiler needed
for the embedded dialogue descriptions should
be added to DiaGen, to allow for integrated de-
velopment.
? Since the creation of a phone-based dialogue
system requires specialised handling for differ-
ent situations (e.g. for database access, output
generation, etc.) several specialised wizards
have been created forming the AGP. Since de-
velopment for a speech control system is quite
different it does not make sense, to have several
assistants. Therefore DiaGen integrates all the
needed functionality into one tool.
93
5 DiaGen
As already described above, DiaGen was developed
as a new tool, based on the experiences made within
the GEMINI project. The key idea of DiaGen is to
ease development of speech dialogues for automo-
tive applications. The main point here is not only
to speed up coding of dialogue scripts but addition-
ally to support the development of correct, consis-
tent, and user-friendly dialogue applications.
The main differences between DiaGen and the
GEMINI AGP are already described above. In this
section the most outstanding properties of the final
tool are discussed in detail.
5.1 Modelling Language
Since effort for generating runtime code from de-
velopment models was a big issuee within GEMINI
and it is often required to change code details even in
a late phase of development, it was decided for Dia-
Gen to work directly on GDML. This allows DiaGen
to offer manual editing at any development stage.
5.2 Integration
For a GDML developer, there are daily tools to work
with. These are the grammar and dialogue compiler
and a testing and debugging tool. These tools all
have been integrated into DiaGen. For each tool,
DiaGen allows to set configuration parameters as
well as to compile and debug directly in the envi-
ronment.
5.3 Project Model
One of the main features of DiaGen is a complete
project model, which contains all project files and
runtime configuration settings. Loading this model
into DiaGen allows easy compiling, testing and edit-
ing of the complete application.
The model can be extended by editing the con-
tained files using DiaGen. Additionally DiaGen also
offers the possibility to add predefined routines or
methods to the model, allowing for a library usage.
Another advantage of the model is the complete
coverage of variables, functions, prompts, etc. This
speeds up the development process quite a lot, since
the tool automatically proposes allowed argument
values for a function call. And if a variable has not
been defined in the current context, this can just be
done by a simple click on the respective button. This
feature was already available in parts with the GEM-
INI AGP.
5.4 Sample Application
As already mentioned in section 4 development for
a new application with DiaGen starts with a sample
application. This saves time since setting up a new
running application with correct configuration set-
tings by hand can be a lengthy process. If instead
a complete running system is copied and stripped
down, this costs time as well. Starting with a small
sample application therefore is much more efficient.
The sample application can easily be updated and
maintained, therefore even new configuration set-
tings or techniques can be adopted.
5.5 Device Interface
To control devices by speech, their interface must be
accessible for the dialogue. This in GDML generally
is done with the concept of system calls for details
see (Hamerich and Hanrieder, 2004). New system
calls can be created using DiaGen or just be added
to an existing DiaGen project. When a system call
is needed, it can just be selected from a list, saving
time for lookup. Of course all the advantages of the
project model (sec. 5.3) apply for system calls and
their arguments and results as well.
5.6 Grammar Tag Consistency
GDML (like VoiceXML) uses semantic grammar
tags to identify user utterances. These tags are even
independent of the used language making GDML di-
alogues complete language independent. This gives
bigger flexibility and minimises efforts for porting a
dialogue application to another language.
To initiate a dialogue reaction, a specified tag
has to be delivered from the parser. For each tag
a dialogue action inside the dialogue code itself is
needed. In this case consistency of these tags in
grammar and dialogue script is of highest impor-
tance. As already mentioned the GEMINI AGP did
not ensure this consistency automatically. This led
to high efforts when developing an application with
the AGP. To minimise these efforts and disable po-
tential errors the consistency shall be ensured auto-
matically by DiaGen.
94
To do so DiaGen offers a special view of the
grammar. For each grammar rule or combination of
rules all possible grammar tags are shown. Selecting
a tag automatically constructs a complete switch-
case statement for all possible alternatives and en-
sures consistency between grammar and dialogue.
5.7 Usage of DiaGen
DiaGen has been developed to allow fast creation
of flexible speech dialogues for automotive applica-
tions. See Figure 1 for possibilities of its context
menu. It was used successfully for a proactive dy-
namic traffic information application based on Traf-
fic Message Channel (TMC) messages. This ap-
plication has already been described in (Hamerich,
2007). Since the tool is still in its testing phase, it is
currently used for prototypical development only.
Figure 1: Context menu of DiaGen within GDML dialog
step.
6 Conclusion
In this paper DiaGen was presented. A tool to im-
prove the development process of embedded speech
dialogues as used for automotive systems. Ma-
jor improvements offered by usage of DiaGen are
speed-up of coding and verified code consistency.
DiaGen results partly from the experiences collected
within the GEMINI project. But since GEMINI con-
centrated on phone-based and multimodal applica-
tions, several changes have been necessary for em-
bedded dialogues, which have been described.
7 Future Work
As pointed out the tool is currently used to develop
a pilot application. As feedback from the work on
the pilot application, DiaGen is constantly being up-
dated. At a later development stage of DiaGen it will
be evaluated to be used for product development as
well.
References
L.F. d?Haro, R. de Co?rdoba, J. Ferreiros, S.W. Hamerich,
V. Schless, B. Kladis, V. Schubert, O. Kocsis, S. Igel,
and J.M. Pardo. 2006. An Advanced Platform to
Speed up the Design of Multilingual Dialog Applica-
tions for Multiple Modalities. Speech Communication,
48(6):863?887.
S.W. Hamerich and G. Hanrieder. 2004. Modelling
Generic Dialog Applications for Embedded Systems.
In Proc. ICSLP, pages 237?240, Jeju, Korea.
S.W. Hamerich, Y.-F. H. Wang, V. Schubert, V. Schless,
and S. Igel. 2003. XML-Based Dialogue Descriptions
in the GEMINI Project. In Proc. ?Berliner XML-Tage
2003?, pages 404?412, Berlin, Germany.
S.W. Hamerich, R. de Co?rdoba, V. Schless, L.F. d?Haro,
B. Kladis, V. Schubert, O. Kocsis, S. Igel, and J.M.
Pardo. 2004a. The GEMINI Platform: Semi-
Automatic Generation of Dialogue Applications. In
Proc. ICSLP, pages 2629?2632, Jeju, Korea.
S.W. Hamerich, V. Schubert, V. Schless, R. de Co?rdoba,
J. M. Pardo, L. F. d?Haro, B. Kladis, O. Kocsis, and
S. Igel. 2004b. Semi-Automatic Generation of Dia-
logue Applications in the GEMINI Project. In Proc.
SIGdial, pages 31?34, Cambridge, USA.
S.W. Hamerich. 2005. Speech Dialogue Systems for
Cars - an Overview. SDV ? Sprache und Datenver-
arbeitung, 29(2):107?118.
S.W. Hamerich. 2007. Towards Advanced Speech
Driven Navigation Systems for Cars. In Proc. IE,
pages 247?250, Ulm, Germany.
P. Heisterkamp. 2001. Linguatronic ? Product-Level
Speech System for Mercedes-Benz Cars. In Proc.
HLT, pages 1?2, San Diego, USA.
V. Schubert and S.W. Hamerich. 2005. The Dialog Ap-
plication Metalanguage GDialogXML. In Proc. EU-
ROSPEECH, pages 789?792, Lisbon, Portugal.
Y.-F.H. Wang and S.W. Hamerich, 2008. Dybkj?r, L. and
Minker, W. (Ed.): Recent Trends in Discourse and Di-
alogue, chapter Designing Speech-Controlled Media
File Selection for Automotive Systems, pages 25?43.
Springer, Dordrecht, Netherlands.
95
