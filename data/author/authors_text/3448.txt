R. Dale et al (Eds.): IJCNLP 2005, LNAI 3651, pp. 1 ? 9, 2005. 
? Springer-Verlag Berlin Heidelberg 2005 
A New Method for Sentiment Classification  
in Text Retrieval 
Yi Hu1, Jianyong Duan1, Xiaoming Chen1,2, Bingzhen Pei1,2, and Ruzhan Lu1 
1 Department of Computer Science and Engineering, 
Shanghai Jiao Tong University, Shanghai, China, 200030 
2 School of Computer Science and Engineering, 
Guizhou University, Guiyang, China, 550025 
{huyi, duan_jy, chen-xm, peibz, rz-lu}@cs.sjtu.edu.cn 
Abstract. Traditional text categorization is usually a topic-based task, but a 
subtle demand on information retrieval is to distinguish between positive and 
negative view on text topic. In this paper, a new method is explored to solve 
this problem. Firstly, a batch of Concerned Concepts in the researched domain 
is predefined. Secondly, the special knowledge representing the positive or 
negative context of these concepts within sentences is built up. At last, an 
evaluating function based on the knowledge is defined for sentiment classifica-
tion of free text. We introduce some linguistic knowledge in these procedures to 
make our method effective. As a result, the new method proves better compared 
with SVM when experimenting on Chinese texts about a certain topic. 
1   Introduction 
Classical technology in text categorization pays much attention to determining 
whether a text is related to a given topic [1], such as sports and finance. However, as 
research goes on, a subtle problem focuses on how to classify the semantic orientation 
of the text. For instance, texts can be for or against ?racism?, and not all the texts are 
bad. There exist two possible semantic orientations: positive and negative (the neutral 
view is not considered in this paper). Labeling texts by their semantic orientation 
would provide readers succinct summaries and be great useful in intelligent retrieval 
of information system. 
Traditional text categorization algorithms, including Na?ve Bayes, ANN, SVM, etc, 
depend on a feature vector representing a text. They usually utilize words or n-grams 
as features and construct the weightiness according to their presence/absence or fre-
quencies. It is a convenient way to formalize the text for calculation. On the other 
hand, employing one vector may be unsuitable for sentiment classification. See the 
following simple sentence in English: 
? Seen from the history, the great segregation is a pioneering work. 
Here, ?segregation? is very helpful to determine that the text is about the topic of 
racism, but the terms ?great? and ?pioneering work? may just be the important hints 
for semantic orientation (support the racism). These two terms probably contribute 
2 Y. Hu et al 
less to sentiment classification if they are dispersed into the text vector because the 
relations between them and ?segregation? are lost. Intuitively, these terms can provide 
more contribution if they are considered as a whole within the sentence. We explore a 
new idea for sentiment classification by focusing on sentences rather than entire text. 
?Segregation? is called as Concerned Concept in our work. These Concerned 
Concepts are always the sensitive nouns or noun phrases in the researched domain 
such as ?race riot?, ?color line? and ?government?. If the sentiment classifying 
knowledge about how to comment on these concepts can be acquired, it will be 
helpful for sentiment classification when meeting these concepts in free texts again. 
In other words, the task of sentiment classification of entire text has changed into 
recognizing the semantic orientation of the context of all Concerned Concepts.  
We attempt to build up this kind of knowledge to describe different sentiment 
context by integrating extended part of speech (EPOS), modified triggered bi-grams 
and position information within sentences. At last, we experiment on Chinese texts 
about ?racism? and draw some conclusions. 
2    Previous Work 
A lot of past work has been done about text categorization besides topic-based clas-
sification. Biber [2] concentrated on sorting texts in terms of their source or source 
style with stylistic variation such as author, publisher, and native-language  
background. 
Some other related work focused on classifying the semantic orientation of indi-
vidual words or phrases by employing linguistic heuristics [3][4]. Hatzivassiloglou 
et alworked on predicting the semantic orientation of adjectives rather than phrases 
containing adjectives and they noted that there are linguistic constraints on these 
orientations of adjectives in conjunctions.   
Past work on sentiment-based categorization of entire texts often involved using 
cognitive linguistics [5][11] or manually constructing discriminated lexicons 
[7][12]. All these work enlightened us on the research on Concerned Concepts in 
given domain.  
Turney?s work [9] applied an unsupervised learning algorithm based on the mu-
tual information between phrases and the both words ?excellent? and ?poor?. The 
mutual information was computed using statistics gathered by a search engine and 
simple to be dealt with, which encourage further work with sentiment classification.  
Pang et al[10] utilized several prior-knowledge-free supervised machine learning 
methods in the sentiment classification task in the domain of movie review, and 
they also analyzed the problem to understand better how difficult it is. They ex-
perimented with three standard algorithms: Na?ve Bayes, Maximum Entropy and 
Support Vector Machines, then compared the results. Their work showed that, gen-
erally, these algorithms were not able to achieve accuracies on the sentiment  
classification problem comparable to those reported for standard topic-based  
categorization. 
 A New Method for Sentiment Classification in Text Retrieval 3 
3   Our Work 
3.1   Basic Idea 
As mentioned above, terms in a text vector are usually separated from the Concerned 
Concepts (CC for short), which means no relations between these terms and CCs. To 
avoid the coarse granularity of text vector to sentiment classification, the context of 
each CC is researched on. We attempt to determine the semantic orientation of a free 
text by evaluating context of CCs contained in sentences. Our work is based on the 
two following hypothesizes: 
? H1.  A sentence holds its own sentiment context and it is the processing 
unit for sentiment classification. 
? H2.  A sentence with obvious semantic orientation contains at least one 
Concerned Concept. 
H1 allows us to research the classification task within sentences and H2 means that a 
sentence with the value of being learnt or evaluated should contain at least one de-
scribed CC. A sentence can be formed as: 
                         
( 1) 1 1 ( 1)... ...m m i n nword word word CC word word word? ? ? ? ?
 .                  (1) 
CCi (given as an example in this paper) is a noun or noun phrase occupying the po-
sition 0 in sentence that is automatically tagged with extended part of speech (EPOS 
for short)(see section 3.2). A word and its tagged EPOS combine to make a 2-tuple, 
and all these 2-tuples on both sides of CCi can form a sequence as follows: 
??
???
???
???
?
?????
???
???
???
?
?????
???
?
??
???
?
?
?
?
?
??
??
?
?
n
n
n
ni
m
m
m
m
epos
word
epos
word
epos
wordCC
epos
word
epos
word
epos
word
)1(
)1(
1
1
1
1
)1(
)1(
.        (2) 
All the words and corresponding EPOSes are divided into two parts: m 2-tuples on 
the left side of CCi (from ?m to -1) and n 2-tuples on the right (from 1 to n). These 2-
tuples construct the context of the Concerned Concept CCi.  
The sentiment classifying knowledge (see sections 3.3 and 3.4) is the contribution 
of all the 2-tuples to sentiment classification. That is to say, if a 2-tuple often co-
occurs with CCi in training corpus with positive view, it contributes more to positive 
orientation than negative one. On the other hand, if the 2-tuple often co-occurs with 
CCi in training corpus with negative view, it contributes more to negative orientation. 
This kind of knowledge can be acquired by statistic technology from corpus.  
When judging a free text, the context of CCi met in a sentence is respectively com-
pared with the positive and negative sentiment classifying knowledge of the same CCi 
trained from corpus. Thus, an evaluating function E (see section 3.5) is defined to 
evaluate the semantic orientation of the free text. 
3.2   Extended Part of Speech 
Usual part of speech (POS) carries less sentiment information, so it cannot distinguish 
the semantic orientation between positive and negative. For example, ?hearty? and 
?felonious? are both tagged as ?adjective?, but for the sentiment classification, only 
4 Y. Hu et al 
the tag ?adjective? cannot classify their sentiment. This means different adjective has 
different effect on sentiment classification. So we try to extend words? POS (EPOS) 
according to its semantic orientation. 
Generally speaking, empty words only have structural function without sentiment 
meaning. Therefore, we just consider substantives in context, which mainly include 
nouns/noun phrases, verbs, adjectives and adverbs. We give a subtler manner to de-
fine EPOS of substantives. Their EPOSes are classified to be positive orientation 
(PosO) or negative orientation (NegO). Thus, ?hearty? is labeled with ?pos-adj?, 
which means PosO of adjective; ?felonious? is labeled with ?neg-adje?, which means 
NegO of adjective. Similarly, nouns, verbs and adverbs tagged with their EPOS con-
struct a new word list. In our work, 12,743  Chinese entries in machine readable dic-
tionary are extended by the following principles: 
? To nouns, their PosO or NegO is labeled according to their semantic ori-
entation to the entities or events they denote (pos-n or neg-n).  
? To adjectives, their common syntax structure is {Adj.+Noun*}. If adjec-
tives are favor of or oppose to their headwords (Noun*), they will be de-
fined as PosO or NegO (pos-adj or neg-adj). 
? To adverbs, their common syntax structure is {Adv.+Verb*/Adj*.}, and 
Verb*/Adj*. is headword. Their PosO or NegO are analyzed in the same 
way of adjective (pos-adv or neg-adv).  
? To transitive verb, their common syntax structure is {TVerb+Object*}, 
and Object* is headword. Their PosO or NegO are analyzed in the same 
way of adjective (pos-tv or neg-tv). 
? To intransitive verb, their common syntax structure is {Sub-
ject*+InTVerb}, and Subject* is headword. Their PosO or NegO are ana-
lyzed in the same way of adjective (pos-iv or neg-iv). 
3.3   Sentiment Classifying Knowledge Framework 
Sentiment classifying knowledge is defined as the importance of all 2-tuples <word, 
epos> that compose the context of CCi (given as an example) to sentiment classifica-
tion and every Concerned Concept like CCi has its own positive and negative senti-
ment classifying knowledge that
 
can be formalized as a 3-tuple K: 
: ( , , )pos negK CC S S=  .                                              (3) 
To CCi, its Sipos has concrete form that is described as a set of 5-tuples: 
{ }: ( , , , , , )pos left rightiS word epos wordval eposval? ? ? ? ? ?? ?= < >  .              (4) 
Where Sipos represents the positive sentiment classifying knowledge of CCi, and it is a 
data set about all 2-tuples <word, epos> appearing in the sentences containing CCi in 
training texts with positive view. In contrast, Sineg is acquired from the training texts 
with negative view. In other words, Sipos and Sineg respectively reserve the features for 
positive and negative classification to CCi in corpus. 
In terms of Sipos, the importance of ,word epos? ?< > is divided into wordval?  and 
eposval?  (see section 4.1) which is estimated by modified triggered bi-grams to fit the 
 A New Method for Sentiment Classification in Text Retrieval 5 
long distance dependence. If ,word epos? ?< > appears on the left side of CCi, the 
?side? adjusting factor is lefti? ; if it appears on the right, the ?side? adjusting factor is 
right
i? . We also define another factor ?  (see section 4.3) that denotes dynamic ?posi-
tional? adjusting information during processing a sentence in free text. 
3.4   Contribution of <word, epos>  
If a <word, epos> often co-occurs with CCi in sentences in training corpus with posi-
tive view, which may means it contribute more to positive orientation than negative 
one, and if it often co-occurs with CCi in negative corpus, it may contribute more to 
negative orientation.  
We modify the classical bi-grams language model to introduce long distance trig-
gered mechanism of ,iCC word epos?< > . Generally to describe, the contribution c of 
each 2-tuple in a positive or negative context (denoted by Pos_Neg) is calculated by 
(5). This is an analyzing measure of using multi-feature resources.  
( )( , | , _ ) : exp Pr( , | , _ ) , 0i ic word epos CC Pos Neg word epos CC Pos Neg?? ? ?< > = < > >  .   (5) 
The value represents the contribution of <word, epos> to sentiment classification in 
the sentence containing CCi. Obviously, when ? and ?  are fixed, the bigger 
Pr(<word, epos>|CCi, Pos_Neg>) is, the bigger contribution c of the 2-tuple <word, 
epos> to the semantic orientation Pos_Neg (one of {positive, negative} view) is. 
It has been mentioned that ? and ? are adjusting factor to the sentiment contribu-
tion of pair <word, epos>. ?  rectifies the effect of the 2-tuple according to its ap-
pearance on which side of CCi, and ?  rectifies the effect of the 2-tuple according to 
its distance from CCi. They embody the effect of ?side? and ?position?. Thus, it can 
be inferred that even the same <word, epos> will contribute differently because of its 
side and position. 
3.5   Evaluation Function E 
We propose a function E (equation (6)) to evaluate a free text by comparing the con-
text of every appearing CC with the two sorts of sentiment context of the same CC 
trained from corpus respectively.  
                              ( )' '
1
(1/ ) ( , ) ( , )
N
pos neg
i i i i
i
E N Sim S S Sim S S
=
= ?? .                           (6) 
N is the number of total Concerned Concepts in the free text, and i denotes certain 
CCi. E is the semantic orientation of the whole text. Obviously, if 0?E , the text is to 
be regarded as positive, otherwise, negative. 
To clearly explain the function E, we just give the similarity between the context 
of CCi (Si?) in free text and the positive sentiment context of the same CCi trained 
from corpus. The function Sim is defined as follows: 
6 Y. Hu et al 
'
11
11
( , ) exp Pr( , | , )
exp Pr( , | , )
m m
pos left left
i i i
n n
right right
i
Sim S S word epos CC positive
word epos CC positive
? ? ? ?
??
? ? ? ?
??
? ?
? ?
? ?
=?=?
==
? ? ? ?
= < >? ? ? ?? ?? ?
? ? ? ?
+ < >? ? ? ?? ?? ?
??
??
.           (7) 
11
exp Pr( , | , )
m m
left left
iword epos CC positive? ? ? ?
??
? ?
? ?
=?=?
? ? ? ?
< >? ? ? ?? ?? ? ??
 is the positive orientation of the left 
context of CCi, and 
11
exp Pr( , | , )
n n
right right
iword epos CC positive? ? ? ?
??
? ?
==
? ? ? ?
< >? ? ? ?? ?? ? ??
 is the right one. 
Equation (7) means that the sentiment contribution c of each <word, epos> calculated 
by (5) in the context of CCi within a sentence in free text, which is Si?, construct the 
overall semantic orientation of the sentence together. On the other hand, '( , )negi iSim S S  
can be thought about in the same way. 
4   Parameter Estimation 
4.1  Estimating Wordval and Eposval 
In terms of CCi, its sentiment classifying knowledge is depicted by (3) and (4), and 
the parameters wordval and eposval need to be leant from corpus. Every calculation 
of Pr(<word, epos>|CCi, Pos_Neg) is divided into two parts like (8) according to 
statistic theory: 
Pr( , | , _ ) Pr( | , _ ) Pr( | , _ , )i i iword epos CC Pos Neg epos CC Pos Neg word CC Pos Neg epos? ? ? ? ?< > = ? .(8) 
eposval := Pr( | , _ )iepos CC Pos Neg?  and wordval := Pr( | , _ , )iword CC Pos Neg epos? ? .  
The ?eposval? is the probability of epos? appearing on both sides of the CCi and is 
estimated by Maximum Likelihood Estimation (MLE). Thus, 
#( , ) 1
Pr( | , _ )
#( , )
i
i
i
epos
epos CC
epos CC Pos Neg
epos CC EPOS?
? +
=
+?
.                 (9) 
The numerator in (9) is the co-occurring frequency between epos? and CCi within 
sentence in training texts with Pos_Neg (certain one of {positive, negative}) view and 
the denominator is the frequency of co-occurrence between all EPOSes appearing in 
CCi ?s context with Pos_Neg view.  
The ?wordval?is the conditional probability of ?word  given CCi and epos?  which 
can also be estimated by MLE: 
#( , , ) 1
Pr( , _ , )
#( , , ) 1
i
i
i
word word
word epos CC
word CC Pos Neg epos
word epos CC
? ?
? ?
?
+
=
+? ? .        (10) 
 A New Method for Sentiment Classification in Text Retrieval 7 
The numerator in (10) is the frequency of co-occurrence between < ?word , epos? > 
and CCi , and the denominator is the frequency of co-occurrence between all possible 
words  corresponding to epos?  appearing in CCi ?s context with Pos_Neg view. 
For smoothing, we adopt add?one method in (9) and (10). 
4.2   Estimating ?  
The ??  is the adjusting factor representing the different effect of the ,word epos? ?< >  
to CCi in texts with Pos_Neg view according to the side it appears, which means dif-
ferent side has different contribution.
 
So, it includes left??  and right?? : 
i
i
# of ,  appearing on the left side of CC
# of ,  appearing on both sides of CC
left word epos  
word epos
? ?
?
? ?
?
< >
=
< >
,          (11) 
           
i
i
# of ,  appearing on the right side of CC
# of ,  appearing on both sides of CC
right word epos
word epos
? ?
?
? ?
?
< >
=
< >
.      (12) 
4.3   Calculating ?  
?  is positional adjusting factor, which means different position to some CC will be 
assigned different weight. This is based on the linguistic hypothesis that the further a 
word get away from a researched word, the looser their relation is. That is to say, ?  
ought to satisfy an inverse proportion relationship with position.  
Unlike wordval, eposval and ? which are all private knowledge to some CC, ?  is 
a dynamic positional factor which is independent of semantic orientation of training 
texts and it is only depend on the position from CC. To the example CCi, ?  of 
,word epos? ?< > occupying the 
th?  position on its left side is left?? , which can be de-
fined as:             
| | 1 1 1(1 2) (2 (1 2) )left m??? ? ? ?= ?   1 ~ m? = ? ? .                      (13) 
?  of ,word epos? ?< > occupying  the th? position on the right side of CCi is right?? , 
which can be defined as: 
1 1 1(1 2) (2 (1 2) )right n??? ? ? ?= ?    1 ~ n? = .                          (14) 
5   Test and Conclusions 
Our research topic is about ?Racism? in Chinese texts. The training corpus is built up 
from Chinese web pages and emails. As mentioned above, all these extracted texts in 
corpus have obvious semantic orientations to racism: be favor of or oppose to. There are 
1137 texts with positive view and 1085 texts with negative view. All the Chinese texts 
are segmented and tagged with defined EPOS in advance. They are also marked posi-
8 Y. Hu et al 
tive/negative for supervised learning. The two sorts of texts with different view are 
respectively divided into 10 folds. 9 of them are trained and the left one is used for test. 
For the special domain, there is no relative result that can be consulted. So, we com-
pare the new method with a traditional classification algorithm, i.e. the popular SVM 
that uses bi-grams as features. Our experiment includes two parts: a part experiments on 
the relatively ?long? texts that contain more than 15 sentences and the other part ex-
periments on the ?short? texts that contain less than 15 sentences. We choose ?15? as 
the threshold to distinguish long or short texts because it is the mathematic expectation 
of ?length? variable of text in our testing corpus. The recall, precision and F1-score are 
listed in the following Experiment Result Table. 
Table. Experiment Result 
 
Texts with Positive View 
(more than 15 sentences) 
Texts with Negative View 
(more than 15 sentences) 
 SVM Our Method SVM Our Method 
Recall(%) 80.6 73.2 68.4 76.1 
Precision(%) 74.1 75.3 75.6 73.8 
F1-score(%) 77.2 74.2 71.82 74.9 
 
Texts with Positive View 
(less than 15 sentences) 
Texts with Negative View 
(less than 15 sentences) 
 SVM Our Method SVM Our Method 
Recall(%) 62.1 63.0 62.1 69.5 
Precision(%) 65.1 70.1 59.0 62.3 
F1-score(%) 63.6 66.4 60.5 65.7 
The experiment shows that our method is useful for sentiment classifica-
tion?especially for short texts. Seen from the table, when evaluating texts that have 
more than 15 sentences, for enough features, SVM has better result, while ours is aver-
agely close to it. However, when evaluating the texts containing less than 15 sentences, 
our method is obviously superior to SVM in either positive or negative view. That 
means our method has more potential value to sentiment classification of short texts, 
such as emails, short news, etc.  
The better result owes to the fine description within sentences and introducing lin-
guistic knowledge to sentiment classification (such as EPOS, ?  and ? ), which proved 
the two hypothesizes may be reasonable. We use modified triggered bi-grams to de-
scribe the importance among features ({<word, epos>}) and Concerned Concepts, then 
construct sentiment classifying knowledge rather than depend on statistic algorithm 
only.  
To sum up, we draw the following conclusions from our work: 
? Introducing more linguistic knowledge is helpful for improving statistic 
sentiment classification. 
 A New Method for Sentiment Classification in Text Retrieval 9 
? Sentiment classification is a hard task, and it needs subtly describing capa-
bility of language model. Maybe the intensional logic of words will be help-
ful in this field in future. 
? Chinese is a language of concept combination and the usage of words is 
more flexible than Indo-European language, which makes it more difficult 
to acquire statistic information than English [10]. 
? We assume an independent condition among sentences yet. We should in-
troduce a suitable mathematic model to group the close sentences. 
Our experiment also shows that the algorithm will become weak when no CC ap-
pears in sentences, but this method is still deserved to explore further. In future, we 
will integrate more linguistic knowledge and expand our method to a suitable sen-
tence group to improve its performance. Constructing a larger sentiment area may 
balance the capability of our method between long and short text sentiment  
classification. 
Acknowledgement. This work is supported by NSFC Major Research Program 
60496326: Basic Theory and Core Techniques of Non Canonical Knowledge and also 
supported by National 863 Project (No. 2001AA114210-11). 
References 
1. Hearst, M.A.: Direction-based text interpretation as an information access refinement. In 
P. Jacobs (Ed.), Text-Based Intelligent Systems: Current Research and Practice in Infor-
mation Extraction and Retrieval. Mahwah, NJ: Lawrence Erlbaum Associates (1992) 
2. Douglas Biber: Variation across Speech and Writing. Cambridge University Press (1988) 
3. Vasileios Hatzivassiloglou and Kathleen McKeown: Predicting the semantic orientation of 
adjectives. In Proc. of the 35th ACL/8th EACL (1997) 174-181 
4. Peter D. Turney and Michael L. Littman: Unsupervised learning of semantic orientation 
from a hundred-billion-word corpus. Technical Report EGB-1094, National Research 
Council Canada (2002) 
5. Marti Hearst: Direction-based text interpretation as an information access refinement. In 
Paul Jacobs, editor, Text-Based Intelligent Systems. Lawrence Erlbaum Associates (1992) 
6. Bo Pang and Lillian Lee: A Sentimental Education: Sentiment Analysis Using Subjectivity 
Summarization Based on Minimum Cuts. Proceedings of the 42nd ACL (2004) 271--278 
7. Sanjiv Das and Mike Chen: Yahoo! for Amazon: Extracting market sentiment from stock 
message boards. In Proc. of the 8th Asia Pacific Finance Association Annual Conference 
(2001) 
8. Vasileios Hatzivassiloglou, Janyce Wiebe: Effects of Adjective Orientation and Gradabil-
ity on Sentence Subjectivity. COLING (2000) 299-305 
9. Peter Turney: Thumbs up or thumbs down? Semantic orientation applied to unsupervised 
classication of reviews. In Proc. of the ACL (2002) 
10. Bo Pang, Lillian Lee and Shivakumar Vaithyanathan: Thumbs up? Sentiment Classifica-
tion using Machine Learning Techniques. In Proc. Conf. on EMNLP (2002) 
11. Warren Sack: On the computation of point of view. In Proc. of the Twelfth AAAI, page 
1488. Student abstract (1994) 
12. Richard M. Tong: An operational system for detecting and tracking opinions in on-line 
discussion. Workshop note, SIGIR Workshop on Operational Text Classification (2001) 
 
Proceedings of the COLING/ACL 2006 Main Conference Poster Sessions, pages 176?182,
Sydney, July 2006. c?2006 Association for Computational Linguistics
A Bio-inspired Approach for Multi-Word Expression Extraction
Jianyong Duan, Ruzhan Lu
Weilin Wu, Yi Hu
Department of Computer Science
Shanghai Jiao Tong University
Shanghai, 200240, P.R. China
duanjy@hotmail.com
{lu-rz,wl-wu,huyi}@cs.sjtu.edu.cn
Yan Tian
School of Foreign Languages
Department of Computer Science
Shanghai Jiao Tong University
Shanghai, 200240, P.R. China
tianyan@sjtu.edu.cn
Abstract
This paper proposes a new approach for
Multi-word Expression (MWE)extraction
on the motivation of gene sequence align-
ment because textual sequence is simi-
lar to gene sequence in pattern analy-
sis. Theory of Longest Common Subse-
quence (LCS) originates from computer
science and has been established as affine
gap model in Bioinformatics. We per-
form this developed LCS technique com-
bined with linguistic criteria in MWE ex-
traction. In comparison with traditional
n-gram method, which is the major tech-
nique for MWE extraction, LCS approach
is applied with great efficiency and per-
formance guarantee. Experimental results
show that LCS-based approach achieves
better results than n-gram.
1 Introduction
Language is under continuous development. Peo-
ple enlarge vocabulary and let words carry more
meanings. Meanwhile the language also devel-
ops larger lexical units to carry specific meanings;
specifically MWE?s, which include compounds,
phrases, technical terms, idioms and collocations,
etc. The MWE has relatively fixed pattern because
every MWE denotes a whole concept. In compu-
tational view, the MWE repeats itself constantly in
corpus(Taneli,2003).
The extraction of MWE plays an important role
in several areas, such as machine translation (Pas-
cale,1997), information extraction (Kalliopi,2000)
etc. On the other hand, there is also a need
for MWE extraction in a much more widespread
scenario namely that of human translation and
technical writing. Many efforts have been de-
voted to the study of MWE extraction (Beat-
rice,2003; Ivan,2002; Jordi,2001). These statis-
tical methods detect MWE by frequency of can-
didate patterns. Linguistic information as a filter-
ing strategy is also performed to improve precision
by ranking their candidates (Violeta,2003; Ste-
fan,2004; Arantza,2002). Some measures based
on advance statistical methods are also used,
such as mutual expectation with single statis-
tic model (Paul,2005),C-value/NC-value method
(Katerina,2000),etc.
Frequent information is the original data for
further MWE extraction. Most approaches adopt
n-gram technique(Daniel,1977; Satanjeev,2003;
Makoto,1994). n-gram concerns about one se-
quence for each time. Every sequence can be
cut into some segments with varied lengths be-
cause any length of segment has the possibility to
become candidate MWE. The larger the context
window is, the more difficulty its parameters ac-
quire. Thus data sparseness problem deteriorates.
Another problem arises from the flexible MWE
which can be separated by an arbitrary number of
blanks, for instance, ?make. . . . . . decision?. These
models cannot effectively distinguish all kinds of
variations in flexible MWE.
On the consideration of relations between tex-
tual sequence and gene sequence, we propose a
new bio-inspired approach for MWE identifica-
tion. Both statistical and linguistic information are
incorporated into this model.
2 Multi-word Expression
Multi-word Expression( in general, term) as the
linguistic representation of concepts, also has
some special statistical features. The component
words of terms co-occur in the same context fre-
176
quently. MWE extraction can be viewed as a prob-
lem of pattern extraction. It has two major phases.
The first phase is to search the candidateMWEs by
their frequent occurrence in the corpus. The sec-
ond phase is to filter true MWEs from noise candi-
dates. Filtering process involves linguistic knowl-
edge and some intelligent observations.
MWE can be classified into strict patterns and
flexible patterns by structures of their component
words(Joaquim,1999). For example, a textual se-
quence s = w1w2 ? ? ?wi ? ? ?wn, may contain two
kinds of patterns:
Strict pattern: pi = wiwi+1wi+2
Flexible pattern: pj = wiunionsqwi+2unionsqwi+4, pk =
wi unionsq unionsqwi+3wi+4
where unionsq denotes the variational or active ele-
ment in pattern. The flexible pattern extraction is
always a bottleneck for MWE extraction for lack
of good knowledge of global solution.
3 Algorithms for MWE Extraction
3.1 Pure Mathematical Method
Although sequence alignment algorithm has been
well-developed in bioinformatics (Michael,2003),
(Knut,2000), (Hans,1999), it was rarely reported
in MWE extraction. In fact, it also applies to
MWE extraction especially for complex struc-
tures.
Algorithm.1.
1. Input:tokenlized textual sequences Q =
{s1, s2, ? ? ? , sn}
2. Initionalization : pool, ? = {?k},?
3. Computation:
I. Pairwise sequence alignment
for all si, sj ? Q, si 6= sj
Similarity(si, sj)
Align(si, sj)
path(li,lj)?? {li, lj , ck}
pool ? pool ? {(li, ck), (lj , ck)}
? ? ? ? ck
II. Creation of consistent set
for all ck ? ?, (li, ck) ? pool
?k ? ?k + {li}
pool ? pool ? (li, ck)
III. Multiple sequence alignment
for all ?k
star align(?k) ? MWU ? ?
? ?MWU
4. Output: ?
Our approach is directly inspired by gene se-
quence alignment as algorithm. 1. showed. The
textual sequence should be preprocessed before in-
put. For example, plurals recognition is a rela-
tively simple task for computers which just need
to check if the word accord with the general rule
including rule (+s) and some alternative rules (-y +
ies), etc. A set of tense forms, such as past, present
and future forms, are also transformed into origi-
nal forms. These tokenlized sequences will im-
prove extraction quality.
Pairwise sequence alignment is a crucial step.
Our algorithm uses local alignment for textual se-
quences. The similarity score between s[1 . . . i]
and t[1 . . . i] can be computed by three arrays
G[i, j], E[i, j] ,F[i, j] and zero, where entry ?(x, y)
means word x matches with word y; V[i, j] de-
notes the best score of entry ?(x, y); G[i, j] de-
notes s[i] matched with t[j]:?(s[i], t[j]); E[i, j]
denotes a blank of string s matched with t[j] :
?(unionsq, t[j]); F [i, j] denotes s[i] matched with a
blank of string t : ?(s[i],unionsq).
Initialization:
V [0, 0] = 0; V [i, 0] = E[i, 0] = 0; 1 ? i ?
m. V [0, j] = F [0, j] = 0; 1 ? j ? n.
A dynamic programming solution:
V [i, j] = max{G[i, j], E[i, j], G[i, j], 0};
G[i, j] = ?(i, j) + max
?
?
?
?
?
?
?
?
?
G[i? 1, j ? 1]
E[i? 1, j ? 1]
F [i? 1, j ? 1]
0
E[i, j] = max
?
?
?
?
?
?
?
?
?
?(h + g) + G[i, j ? 1]
? g + E[i, j ? 1]
?(h + g) + F [i, j ? 1]
0
F [i, j] = max
?
?
?
?
?
?
?
?
?
?(h + g) + G[i? 1, j]
?(h + g) + E[i? 1, j]
? g + F [i? 1, j]
0
Here we explain the meaning of these arrays:
I. G[i, j] includes the entry ?(i, j), it denotes
the sum score is the last row plus the max-
imal score between prefix s[1 . . . i ? 1] and
t[1 . . . j ? 1].
177
II. Otherwise the related prefixes s[1 . . . i] and
t[1 . . . j ? 1] are needed1. They are used to
check the first blank or additional blank in or-
der to give appropriate penalty.
a. ForG[i, j?1] and F [i, j?1], they don?t
end with a blank in string s. The blank
s[i] is the first blank. Its score isG[i, j?
1] (or F [i, j ? 1]) minus (h + g).
b. For E[i, j ? 1],The blank is the addi-
tional blank which should be only sub-
tracted g.
In the maximum entry, it records the best score
of optimum local alignment. This entry can be
viewed as the started point of alignment. Then
we backtrack entries by checking arrays which are
generated from dynamic programming algorithm.
When the score decrease to zero, alignment exten-
sion terminates. Finally, the similarity and align-
ment results are easily acquired.
Lots of aligned segments are extracted from
pairwise alignment. Those segments with com-
mon component words (ck) will be collected into
the same set. It is called as consistent set for
further multiple sequence alignment. These con-
sistent sets collect similar sequences with score
greater than certain threshold.
We perform star-alignment in multiple se-
quence alignment. The center sequence in the con-
sistent set which has the highest score in com-
parison with others, is picked out from this set.
Then all the other sequences gather to the cen-
ter sequence with the technique of ?once a blank,
always a blank?. These aligned sequences form
common regions with n-column or a column. Ev-
ery column contains one or more words. Calcula-
tion of dot-matrices is a widespread tool for com-
mon region analysis. Dot-plot agreement is de-
veloped to identify common patterns and reliably
aligned regions in a set of related sequences. If
several plots calculate consistently in a sequence
set, it displays the similarity among them. It in-
creases credibility of extracted pattern in this con-
sistent set. Finally MWE with detailed pattern
emerges from this aligned sequence set.
1Analysis approaches for F [i, j] and E[i, j] are the same,
here only E[i, j] is given its detailed explanation.
3.2 Linguistic Knowledge Combination
3.2.1 Heuristic Knowledge
Original candidate set is noise. Many meaning-
less patterns are extracted from corpus. Some lin-
guistic rules (Argamon,1999) are introduced into
our model. It is observed that candidate pattern
should contain content words. Some patterns are
only organized by pure function words, such as the
most frequent patterns ?the to?, ?of the?. These
patterns should be moved out from the candidate
set. Filter table with certain words is also per-
formed. For example, some words, like ?then?,
cannot occur in the beginning position of MWE.
These filters will reduce the number of noise pat-
terns in great extent.
3.2.2 Embedded Base Phrase detection
Short textual sequence is apt to produce frag-
ments of MWE because local alignment ends pat-
tern extension when similarity score reduces to
zero. The matched component words increase
similarity score while unmatched words decrease
it. The similarity scores of candidates in textual
sequences are lower for lack of matched compo-
nent words. Without accumulation of higher sim-
ilarity score, pattern extension terminates quickly.
Pattern extension becomes especially sensitive to
unmatched words. Some isolated fragments are
generated in this circumstance. One solution is to
give higher scores for matched component words.
It strengthens pattern extension ability at the ex-
pense of introducing noise.
We propose Embedded base phrase(EBP) de-
tection as algorithm.2. It improves pattern ex-
traction by giving lower penalty for longer base
phrase. EBP is the base phrase in a gap (Changn-
ing,2000). It does not contain other phrase recur-
sively. Good quality of MWE should avoid irrela-
tive unit in its gap. The penalty function discerns
the true EBP and irrelative unit in a gap only by
length information. Longer gap means more irrel-
ative unit. It builds a rough penalty model for lack
of semantic information. We improve this model
by POS information. POS tagged textual sequence
is convenient to grammatical analysis. True EBP2
gives comparatively lower penalty.
Algorithm.2.
1. Input: LCS of sl, sk
2The performance of our EBP tagger is 95% accuracy for
base noun phrase and 90% accuracy for general use.
178
2. Check breakpoint in LCS
i. Anchor neighbored common words and
denote gaps
for all ws = wp, wt = wq
if ws ? ls, wt ? lt, ls 6= lt
denote gst, gpq
ii. Detect EBP in gaps
gst
EBP?? g?st, gpq
EBP?? g?pq
iii. Compute new similariy matrix in gaps
similarity(g?st, g?pq)
3. Link broken segment
if path(g?st, g?pq)
lst = ls + lt, lpq = lp + lq
For textual sequence: w1w2 ? ? ?wn, and its
corresponding POS tagged sequence: t1t2 ? ? ? tn,
we suppose [wi ? ? ?wj ] is a gap from wi to wj
in sequence ? ? ? wi?1 [wi ? ? ?wj ]wj ? ? ? . The
corresponding tag sequence is [ti ? ? ? tj ] . We
only focus on EBP analysis in a gap instead of
global sequence. Context Free Grammar (CFG)
is employed in EBP detection. CFG rules follow
this form:
(1)EBP ? adj. + noun
(2)EBP ? noun + ?of? + noun
(3)EBP ? adv. + adj.
(4)EBP ? art. + adj. + noun
? ? ?
The sequences inside breakpoint of LCS are an-
alyzed by EBP detection. True base phrase will
be given lower penalty. When the gap penalty for
breakpoint is lower than threshold, the broken seg-
ment reunites. Based on experience knowledge,
when the length of a gap is less than four words,
EBP detection using CFG can gain good results.
Lower penalty for true EBP will help MWE to
emerge from noise pattern easily.
4 Experiments
4.1 Resources
A large amount of free texts are collected in order
to meet the need of MWE extraction. These texts
are downloaded from internet with various aspects
including art, entertainment, military, business,
etc. Our corpus size is 200, 000 sentences. The
average sentence length is 15 words in corpus.
In addition, result evaluation is a hard job. Its
difficulty comes from two aspects. Firstly, MWE
identification for test corpus is a kind of labor-
intensive business. The judgment of MWEs re-
quires great efforts of domain expert. It is hard and
boring to make a standard test corpus for MWE
identification use. It is a bottleneck for large scales
use. Secondly it relates to human cognition in psy-
chological world. It is proved by experience that
various opinions cannot simply be judged true or
false. As a compromise way, gold standard set
can be established by some accepted resources, for
example, WordNet, as an online lexical reference
system, including many compounds and phrases.
Some terms extracted from dictionaries are also
employed in our experiments. There are nearly
70,000 MWEs in our list.
4.2 Results and Discussion
4.2.1 Close Test
We created a closed test set of 8,000 sen-
tences. MWEs in corpus are extracted by man-
ual work. Every measure in both n-gram and LCS
approaches complies with the same threshold, for
example threshold for frequency is five times.Two
conclusions are drawn from Tab.1.
Firstly, LCS has higher recall than n-gram but
lower precision on the contrary. In close test set,
LCS recall is higher than n-gram. LCS unifies all
the cases of flexible patterns by GAM. However
n-gram only considers limited flexible patterns be-
cause of model limitation. LCS nearly includes
all the n-gram results. Higher recall decreases its
precision to a certain extent because some flexible
patterns are noisier than strict patterns. Flexible
patterns tend to be more irrelevant than strict pat-
terns. The GAM just provides a wiser choice for
all flexible patterns by its gap penalty function. N-
gram gives up analysis on many flexible patterns
without further ado. N-gram ensures its precision
by taking risk of MWE loss .
Secondly, advanced evaluation criterion can
place more MWEs in the front rank of candi-
date list. Evaluation metrics for extracted pat-
terns play an important role in MWE extraction.
Many criteria, which are reported with better per-
formances, are tested. MWE identification is sim-
ilar to IR task. These measures have their own
advantages to move interested patterns forward
in the candidate list. For example, Frequency
data contains much noise. True mutual infor-
179
Table 1: Close Test for N-gram and LCS Approaches
Measure N-Gram LCS
Precision Recall F-Measure Precision Recall F-Measure
(%) (%) (%) (%) (%) (%)
Frequency 35.2 38.0 36.0 32.1 48.2 38.4
TMI 44.7 56.2 49.1 43.2 62.1 51.4
ME 51.6 52.6 51.2 44.7 65.2 52.0
Rankratio 62.1 61.5 61.1 57.0 83.1 68.5
mation (TMI) concerns mutual information with
logarithm(Manning,1999). Mutual expectation
(ME) takes into account the relative probability of
each word compared to the phrase(Joaquim,1999).
Rankratio performs the best on both n-gram and
LCS approaches because it provides all the con-
texts which associated with each word in the cor-
pus and ranks them(Paul,2005). With the help of
advanced statistic measures, the scores of MWEs
are high enough to be detected from noisy pat-
terns.
4.2.2 Open Test
In open test, we just show the extracted MWE
numbers in different given corpus sizes. Two phe-
nomena are observed in Fig.1.








FRUSXVVL]H
0:8
QX
PEH
U
      