Proceedings of ACL-08: HLT, pages 496?504,
Columbus, Ohio, USA, June 2008. c?2008 Association for Computational Linguistics
Combining EM Training and the MDL Principle for an
Automatic Verb Classification incorporating Selectional Preferences
Sabine Schulte im Walde, Christian Hying, Christian Scheible, Helmut Schmid
Institute for Natural Language Processing
University of Stuttgart, Germany
{schulte,hyingcn,scheibcn,schmid}@ims.uni-stuttgart.de
Abstract
This paper presents an innovative, complex
approach to semantic verb classification that
relies on selectional preferences as verb prop-
erties. The probabilistic verb class model un-
derlying the semantic classes is trained by
a combination of the EM algorithm and the
MDL principle, providing soft clusters with
two dimensions (verb senses and subcategori-
sation frames with selectional preferences) as
a result. A language-model-based evaluation
shows that after 10 training iterations the verb
class model results are above the baseline re-
sults.
1 Introduction
In recent years, the computational linguistics com-
munity has developed an impressive number of se-
mantic verb classifications, i.e., classifications that
generalise over verbs according to their semantic
properties. Intuitive examples of such classifica-
tions are the MOTION WITH A VEHICLE class, in-
cluding verbs such as drive, fly, row, etc., or the
BREAK A SOLID SURFACE WITH AN INSTRUMENT
class, including verbs such as break, crush, frac-
ture, smash, etc. Semantic verb classifications are
of great interest to computational linguistics, specifi-
cally regarding the pervasive problem of data sparse-
ness in the processing of natural language. Up to
now, such classifications have been used in applica-
tions such as word sense disambiguation (Dorr and
Jones, 1996; Kohomban and Lee, 2005), machine
translation (Prescher et al, 2000; Koehn and Hoang,
2007), document classification (Klavans and Kan,
1998), and in statistical lexical acquisition in gen-
eral (Rooth et al, 1999; Merlo and Stevenson, 2001;
Korhonen, 2002; Schulte im Walde, 2006).
Given that the creation of semantic verb classi-
fications is not an end task in itself, but depends
on the application scenario of the classification, we
find various approaches to an automatic induction of
semantic verb classifications. For example, Siegel
and McKeown (2000) used several machine learn-
ing algorithms to perform an automatic aspectual
classification of English verbs into event and sta-
tive verbs. Merlo and Stevenson (2001) presented
an automatic classification of three types of English
intransitive verbs, based on argument structure and
heuristics to thematic relations. Pereira et al (1993)
and Rooth et al (1999) relied on the Expectation-
Maximisation algorithm to induce soft clusters of
verbs, based on the verbs? direct object nouns. Sim-
ilarly, Korhonen et al (2003) relied on the Informa-
tion Bottleneck (Tishby et al, 1999) and subcate-
gorisation frame types to induce soft verb clusters.
This paper presents an innovative, complex ap-
proach to semantic verb classes that relies on se-
lectional preferences as verb properties. The un-
derlying linguistic assumption for this verb class
model is that verbs which agree on their selec-
tional preferences belong to a common seman-
tic class. The model is implemented as a soft-
clustering approach, in order to capture the poly-
semy of the verbs. The training procedure uses the
Expectation-Maximisation (EM) algorithm (Baum,
1972) to iteratively improve the probabilistic param-
eters of the model, and applies the Minimum De-
scription Length (MDL) principle (Rissanen, 1978)
to induce WordNet-based selectional preferences for
arguments within subcategorisation frames. Our
model is potentially useful for lexical induction
(e.g., verb senses, subcategorisation and selectional
preferences, collocations, and verb alternations),
496
and for NLP applications in sparse data situations.
In this paper, we provide an evaluation based on a
language model.
The remainder of the paper is organised as fol-
lows. Section 2 introduces our probabilistic verb
class model, the EM training, and how we incor-
porate the MDL principle. Section 3 describes the
clustering experiments, including the experimental
setup, the evaluation, and the results. Section 4 re-
ports on related work, before we close with a sum-
mary and outlook in Section 5.
2 Verb Class Model
2.1 Probabilistic Model
This paper suggests a probabilistic model of verb
classes that groups verbs into clusters with simi-
lar subcategorisation frames and selectional prefer-
ences. Verbs may be assigned to several clusters
(soft clustering) which allows the model to describe
the subcategorisation properties of several verb read-
ings separately. The number of clusters is defined
in advance, but the assignment of the verbs to the
clusters is learnt during training. It is assumed that
all verb readings belonging to one cluster have simi-
lar subcategorisation and selectional properties. The
selectional preferences are expressed in terms of se-
mantic concepts from WordNet, rather than a set of
individual words. Finally, the model assumes that
the different arguments are mutually independent for
all subcategorisation frames of a cluster. From the
last assumption, it follows that any statistical depen-
dency between the arguments of a verb has to be ex-
plained by multiple readings.
The statistical model is characterised by the fol-
lowing equation which defines the probability of a
verb v with a subcategorisation frame f and argu-
ments a1, ..., anf :
p(v, f, a1, ..., anf ) =
?
c
p(c) p(v|c) p(f |c) ?
nf
?
i=1
?
r?R
p(r|c, f, i) p(ai|r)
The model describes a stochastic process which gen-
erates a verb-argument tuple like ?speak, subj-pp.to,
professor, audience? by
1. selecting some cluster c, e.g. c3 (which might
correspond to a set of communication verbs),
with probability p(c3),
2. selecting a verb v, here the verb speak, from
cluster c3 with probability p(speak|c3),
3. selecting a subcategorisation frame f , here
subj-pp.to, with probability p(subj-pp.to|c3);
note that the frame probability only depends on
the cluster, and not on the verb,
4. selecting a WordNet concept r for each argu-
ment slot, e.g. person for the first slot with
probability p(person|c3, subj-pp.to, 1) and so-
cial group for the second slot with probability
p(social group|c3, subj-pp.to, 2),
5. selecting a word ai to instantiate each con-
cept as argument i; in our example, we
might choose professor for person with
probability p(professor|person) and au-
dience for social group with probability
p(audience|social group).
The model contains two hidden variables, namely
the clusters c and the selectional preferences r. In or-
der to obtain the overall probability of a given verb-
argument tuple, we have to sum over all possible val-
ues of these hidden variables.
The assumption that the arguments are indepen-
dent of the verb given the cluster is essential for ob-
taining a clustering algorithm because it forces the
EM algorithm to make the verbs within a cluster as
similar as possible.1 The assumption that the differ-
ent arguments of a verb are mutually independent is
important to reduce the parameter set to a tractable
size
The fact that verbs select for concepts rather than
individual words also reduces the number of param-
eters and helps to avoid sparse data problems. The
application of the MDL principle guarantees that no
important information is lost.
The probabilities p(r|c, f, i) and p(a|r) men-
tioned above are not represented as atomic enti-
ties. Instead, we follow an approach by Abney
1The EM algorithm adjusts the model parameters in such a
way that the probability assigned to the training tuples is max-
imised. Given the model constraints, the data probability can
only be maximised by making the verbs within a cluster as sim-
ilar to each other as possible, regarding the required arguments.
497
and Light (1999) and turn WordNet into a Hidden
Markov model (HMM). We create a new pseudo-
concept for each WordNet noun and add it as a hy-
ponym to each synset containing this word. In ad-
dition, we assign a probability to each hypernymy?
hyponymy transition, such that the probabilities of
the hyponymy links of a synset sum up to 1. The
pseudo-concept nodes emit the respective word with
a probability of 1, whereas the regular concept nodes
are non-emitting nodes. The probability of a path
in this (a priori) WordNet HMM is the product of
the probabilities of the transitions within the path.
The probability p(a|r) is then defined as the sum
of the probabilities of all paths from the concept r
to the word a. Similarly, we create a partial Word-
Net HMM for each argument slot ?c, f, i? which en-
codes the selectional preferences. It contains only
the WordNet concepts that the slot selects for, ac-
cording to the MDL principle (cf. Section 2.3), and
the dominating concepts. The probability p(r|c, f, i)
is the total probability of all paths from the top-most
WordNet concept entity to the terminal node r.
2.2 EM Training
The model is trained on verb-argument tuples of
the form described above, i.e., consisting of a verb
and a subcategorisation frame, plus the nominal2
heads of the arguments. The tuples may be ex-
tracted from parsed data, or from a treebank. Be-
cause of the hidden variables, the model is trained
iteratively with the Expectation-Maximisation algo-
rithm (Baum, 1972). The parameters are randomly
initialised and then re-estimated with the Inside-
Outside algorithm (Lari and Young, 1990) which is
an instance of the EM algorithm for training Proba-
bilistic Context-Free Grammars (PCFGs).
The PCFG training algorithm is applicable here
because we can define a PCFG for each of our mod-
els which generates the same verb-argument tuples
with the same probability. The PCFG is defined as
follows:
(1) The start symbol is TOP.
(2) For each cluster c, we add a rule TOP ? Vc Ac
whose probability is p(c).
2Arguments with lexical heads other than nouns (e.g., sub-
categorised clauses) are not included in the selectional prefer-
ence induction.
(3) For each verb v in cluster c, we add a rule
Vc ? v with probability p(v|c).
(4) For each subcategorisation frame f of cluster c
with length n, we add a rule Ac ? f Rc,f,1,entity
... Rc,f,n,entity with probability p(f |c).
(5) For each transition from a node r to a node r?
in the selectional preference model for slot i of
the subcategorisation frame f of cluster c, we
add a rule Rc,f,i,r ? Rc,f,i,r? whose probability
is the transition probability from r to r? in the
respective WordNet-HMM.
(6) For each terminal node r in the selectional pref-
erence model, we add a rule Rc,f,i,r ? Rr whose
probability is 1. With this rule, we ?jump? from
the selectional restriction model to the corre-
sponding node in the a priori model.
(7) For each transition from a node r to a node r?
in the a priori model, we add a rule Rr ? Rr?
whose probability is the transition probability
from r to r? in the a priori WordNet-HMM.
(8) For each word node a in the a priori model, we
add a rule Ra ? a whose probability is 1.
Based on the above definitions, a partial ?parse? for
?speak subj-pp.to professor audience?, referring to
cluster 3 and one possible WordNet path, is shown in
Figure 1. The connections within R3 (R3,...,entity?
R3,...,person/group) and within R (Rperson/group?
Rprofessor/audience) refer to sequential applications
of rule types (5) and (7), respectively.
TOP
V3
speak
A3
subj-pp.to R3,subj?pp.to,1,entity
R3,subj?pp.to,1,person
Rperson
Rprofessor
professor
R3,subj?pp.to,2,entity
R3,subj?pp.to,2,group
Rgroup
Raudience
audience
Figure 1: Example parse tree.
The EM training algorithm maximises the likelihood
of the training data.
498
2.3 MDL Principle
A model with a large number of fine-grained con-
cepts as selectional preferences assigns a higher
likelihood to the data than a model with a small num-
ber of general concepts, because in general a larger
number of parameters is better in describing train-
ing data. Consequently, the EM algorithm a pri-
ori prefers fine-grained concepts but ? due to sparse
data problems ? tends to overfit the training data. In
order to find selectional preferences with an appro-
priate granularity, we apply the Minimum Descrip-
tion Length principle, an approach from Information
Theory. According to the MDL principle, the model
with minimal description length should be chosen.
The description length itself is the sum of the model
length and the data length, with the model length
defined as the number of bits needed to encode the
model and its parameters, and the data length de-
fined as the number of bits required to encode the
training data with the given model. According to
coding theory, an optimal encoding uses ?log2p
bits, on average, to encode data whose probability
is p. Usually, the model length increases and the
data length decreases as more parameters are added
to a model. The MDL principle finds a compromise
between the size of the model and the accuracy of
the data description.
Our selectional preference model relies on Li and
Abe (1998), applying the MDL principle to deter-
mine selectional preferences of verbs and their argu-
ments, by means of a concept hierarchy ordered by
hypernym/hyponym relations. Given a set of nouns
within a specific argument slot as a sample, the ap-
proach finds the cut3 in a concept hierarchy which
minimises the sum of encoding both the model and
the data. The model length (ML) is defined as
ML = k2 ? log2 |S|,
with k the number of concepts in the partial hierar-
chy between the top concept and the concepts in the
cut, and |S| the sample size, i.e., the total frequency
of the data set. The data length (DL) is defined as
DL = ?
?
n?S
log2 p(n).
3A cut is defined as a set of concepts in the concept hier-
archy that defines a partition of the ?leaf? concepts (the lowest
concepts in the hierarchy), viewing each concept in the cut as
representing the set of all leaf concepts it dominates.
The probability of a noun p(n) is determined by di-
viding the total probability of the concept class the
noun belongs to, p(concept), by the size of that
class, |concept|, i.e., the number of nouns that are
dominated by that concept:
p(n) = p(concept)|concept| .
The higher the concept within the hierarchy, the
more nouns receive an equal probability, and the
greater is the data length.
The probability of the concept class in turn is de-
termined by dividing the frequency of the concept
class f(concept) by the sample size:
p(concept) = f(concept)|S| ,
where f(concept) is calculated by upward propaga-
tion of the frequencies of the nominal lexemes from
the data sample through the hierarchy. For exam-
ple, if the nouns coffee, tea, milk appeared with fre-
quencies 25, 50, 3, respectively, within a specific ar-
gument slot, then their hypernym concept beverage
would be assigned a frequency of 78, and these 78
would be propagated further upwards to the next hy-
pernyms, etc. As a result, each concept class is as-
signed a fraction of the frequency of the whole data
set (and the top concept receives the total frequency
of the data set). For calculating p(concept) (and the
overall data length), though, only the concept classes
within the cut through the hierarchy are relevant.
Our model uses WordNet 3.0 as the concept hier-
archy, and comprises one (complete) a priori Word-
Net model for the lexical head probabilities p(a|r)
and one (partial) model for each selectional proba-
bility distribution p(r|c, f, i), cf. Section 2.1.
2.4 Combining EM and MDL
The training procedure that combines the EM train-
ing with the MDL principle can be summarised as
follows.
1. The probabilities of a verb class model with c
classes and a pre-defined set of verbs and frames
are initialised randomly. The selectional preference
models start out with the most general WordNet con-
cept only, i.e., the partial WordNet hierarchies un-
derlying the probabilities p(r|c, f, i) initially only
contain the concept r for entity.
499
2. The model is trained for a pre-defined num-
ber of iterations. In each iteration, not only the
model probabilities are re-estimated and maximised
(as done by EM), but also the cuts through the con-
cept hierarchies that represent the various selectional
preference models are re-assessed. In each iteration,
the following steps are performed.
(a) The partial WordNet hierarchies that represent
the selectional preference models are expanded to
include the hyponyms of the respective leaf con-
cepts of the partial hierarchies. I.e., in the first itera-
tion, all models are expanded towards the hyponyms
of entity, and in subsequent iterations each selec-
tional preference model is expanded to include the
hyponyms of the leaf nodes in the partial hierarchies
resulting from the previous iteration. This expansion
step allows the selection models to become more and
more detailed, as the training proceeds and the verb
clusters (and their selectional restrictions) become
increasingly specific.
(b) The training tuples are processed: For each tu-
ple, a PCFG parse forest as indicated by Figure 1
is done, and the Inside-Outside algorithm is applied
to estimate the frequencies of the ?parse tree rules?,
given the current model probabilities.
(c) The MDL principle is applied to each selectional
preference model: Starting from the respective leaf
concepts in the partial hierarchies, MDL is calcu-
lated to compare each set of hyponym concepts that
share a hypernym with the respective hypernym con-
cept. If the MDL is lower for the set of hyponyms
than the hypernym, the hyponyms are left in the par-
tial hierarchy. Otherwise the expansion of the hyper-
nym towards the hyponyms is undone and we con-
tinue recursively upwards the hierarchy, calculating
MDL to compare the former hypernym and its co-
hyponyms with the next upper hypernym, etc. The
recursion allows the training algorithm to remove
nodes which were added in earlier iterations and are
no longer relevant. It stops if the MDL is lower for
the hyponyms than for the hypernym.
This step results in selectional preference models
that minimally contain the top concept entity, and
maximally contain the partial WordNet hierarchy
between entity and the concept classes that have
been expanded within this iteration.
(d) The probabilities of the verb class model are
maximised based on the frequency estimates ob-
tained in step (b).
3 Experiments
The model is generally applicable to all languages
for which WordNet exists, and for which the Word-
Net functions provided by Princeton University are
available. For the purposes of this paper, we choose
English as a case study.
3.1 Experimental Setup
The input data for training the verb class mod-
els were derived from Viterbi parses of the whole
British National Corpus, using the lexicalised PCFG
for English by Carroll and Rooth (1998). We took
only active clauses into account, and disregarded
auxiliary and modal verbs as well as particle verbs,
leaving a total of 4,852,371 Viterbi parses. Those in-
put tuples were then divided into 90% training data
and 10% test data, providing 4,367,130 training tu-
ples (over 2,769,804 types), and 485,241 test tuples
(over 368,103 types).
As we wanted to train and assess our verb class
model under various conditions, we used different
fractions of the training data in different training
regimes. Because of time and memory constraints,
we only used training tuples that appeared at least
twice. (For the sake of comparison, we also trained
one model on all tuples.) Furthermore, we dis-
regarded tuples with personal pronoun arguments;
they are not represented in WordNet, and even if
they are added (e.g. to general concepts such as
person, entity) they have a rather destructive ef-
fect. We considered two subsets of the subcate-
gorisation frames with 10 and 20 elements, which
were chosen according to their overall frequency in
the training data; for example, the 10 most frequent
frame types were subj:obj, subj, subj:ap, subj:to,
subj:obj:obj2, subj:obj:pp-in, subj:adv, subj:pp-in,
subj:vbase, subj:that.4 When relying on theses
10/20 subcategorisation frames, plus including the
above restrictions, we were left with 39,773/158,134
and 42,826/166,303 training tuple types/tokens, re-
spectively. The overall number of training tuples
4A frame lists its arguments, separated by ?:?. Most argu-
ments within the frame types should be self-explanatory. ap is
an adjectival phrase.
500
was therefore much smaller than the generally avail-
able data. The corresponding numbers including tu-
ples with a frequency of one were 478,717/597,078
and 577,755/701,232.
The number of clusters in the experiments was ei-
ther 20 or 50, and we used up to 50 iterations over
the training tuples. The model probabilities were
output after each 5th iteration. The output comprises
all model probabilities introduced in Section 2.1.
The following sections describe the evaluation of the
experiments, and the results.
3.2 Evaluation
One of the goals in the development of the presented
verb class model was to obtain an accurate statistical
model of verb-argument tuples, i.e. a model which
precisely predicts the tuple probabilities. In order
to evaluate the performance of the model in this re-
spect, we conducted an evaluation experiment, in
which we computed the probability which the verb
class model assigns to our test tuples and compared
it to the corresponding probability assigned by a
baseline model. The model with the higher proba-
bility is judged the better model.
We expected that the verb class model would
perform better than the baseline model on tuples
where one or more of the arguments were not ob-
served with the respective verb, because either the
argument itself or a semantically similar argument
(according to the selectional preferences) was ob-
served with verbs belonging to the same cluster. We
also expected that the verb class model assigns a
lower probability than the baseline model to test tu-
ples which frequently occurred in the training data,
since the verb class model fails to describe precisely
the idiosyncratic properties of verbs which are not
shared by the other verbs of its cluster.
The Baseline Model The baseline model decom-
poses the probability of a verb-argument tuple into a
product of conditional probabilities:5
p(v, f, anf1 ) = p(v) p(f |v)
nf
?
i=1
p(ai|ai?11 , ?v, f?, fi)
5fi is the label of the ith slot. The verb and the subcategori-
sation frame are enclosed in angle brackets because they are
treated as a unit during smoothing.
The probability of our example tuple ?speak,
subj-pp.to, professor, audience? in the base-
line model is then p(speak) p(subj-pp.to|speak)
p(professor|?speak, subj-pp.to?, subj) p(audience|
professor, ?speak, subj-pp.to?, pp.to).
The model contains no hidden variables. Thus the
parameters can be directly estimated from the train-
ing data with relative frequencies. The parameter
estimates are smoothed with modified Kneser-Ney
smoothing (Chen and Goodman, 1998), such that
the probability of each tuple is positive.
Smoothing of the Verb Class Model Although
the verb class model has a built-in smoothing capac-
ity, it needs additional smoothing for two reasons:
Firstly, some of the nouns in the test data did not
occur in the training data. The verb class model
assigns a zero probability to such nouns. Hence
we smoothed the concept instantiation probabilities
p(noun|concept) with Witten-Bell smoothing (Chen
and Goodman, 1998). Secondly, we smoothed the
probabilities of the concepts in the selectional pref-
erence models where zero probabilities may occur.
The smoothing ensures that the verb class model
assigns a positive probability to each verb-argument
tuple with a known verb, a known subcategorisation
frame, and arguments which are in WordNet. Other
tuples were excluded from the evaluation because
the verb class model cannot deal with them.
3.3 Results
The evaluation results of our classification experi-
ments are presented in Table 1, for 20 and 50 clus-
ters, with 10 and 20 subcategorisation frame types.
The table cells provide the loge of the probabilities
per tuple token. The probabilities increase with the
number of iterations, flattening out after approx. 25
iterations, as illustrated by Figure 2. Both for 10
and 20 frames, the results are better for 50 than for
20 clusters, with small differences between 10 and
20 frames. The results vary between -11.850 and
-10.620 (for 5-50 iterations), in comparison to base-
line values of -11.546 and -11.770 for 10 and 20
frames, respectively. The results thus show that our
verb class model results are above the baseline re-
sults after 10 iterations; this means that our statis-
tical model then assigns higher probabilities to the
test tuples than the baseline model.
501
No. of Iteration
Clusters 5 10 15 20 25 30 35 40 45 50
10 frames
20 -11.770 -11.408 -10.978 -10.900 -10.853 -10.841 -10.831 -10.823 -10.817 -10.812
50 -11.850 -11.452 -11.061 -10.904 -10.730 -10.690 -10.668 -10.628 -10.625 -10.620
20 frames
20 -11.769 -11.430 -11.186 -10.971 -10.921 -10.899 -10.886 -10.875 -10.873 -10.869
50 -11.841 -11.472 -11.018 -10.850 -10.737 -10.728 -10.706 -10.680 -10.662 -10.648
Table 1: Clustering results ? BNC tuples.
Figure 2: Illustration of clustering results.
Including input tuples with a frequency of one in
the training data with 10 subcategorisation frames
(as mentioned in Section 3.1) decreases the loge per
tuple to between -13.151 and -12.498 (for 5-50 it-
erations), with similar training behaviour as in Fig-
ure 2, and in comparsion to a baseline of -17.988.
The differences in the result indicate that the mod-
els including the hapax legomena are worse than the
models that excluded the sparse events; at the same
time, the differences between baseline and cluster-
ing model are larger.
In order to get an intuition about the qualitative
results of the clusterings, we select two example
clusters that illustrate that the idea of the verb class
model has been realised within the clusters. Ac-
cording to our own intuition, the clusters are over-
all semantically impressive, beyond the examples.
Future work will assess by semantics-based eval-
uations of the clusters (such as pseudo-word dis-
ambiguation, or a comparison against existing verb
classifications), whether this intuition is justified,
whether it transfers to the majority of verbs within
the cluster analyses, and whether the clusters cap-
ture polysemic verbs appropriately.
The two examples are taken from the 10 frame/50
cluster verb class model, with probabilities of 0.05
and 0.04. The ten most probable verbs in the first
cluster are show, suggest, indicate, reveal, find, im-
ply, conclude, demonstrate, state, mean, with the
two most probable frame types subj and subj:that,
i.e., the intransitive frame, and a frame that subcat-
egorises a that clause. As selectional preferences
within the intransitive frame (and quite similarly
in the subj:that frame), the most probable concept
classes6 are study, report, survey, name, research,
result, evidence. The underlined nouns represent
specific concept classes, because they are leaf nodes
in the selectional preference hierarchy, thus refer-
ring to very specific selectional preferences, which
are potentially useful for collocation induction. The
ten most probable verbs in the second cluster are
arise, remain, exist, continue, need, occur, change,
improve, begin, become, with the intransitive frame
being most probable. The most probable concept
classes are problem, condition, question, natural
phenomenon, situation. The two examples illustrate
that the verbs within a cluster are semantically re-
lated, and that they share obvious subcategorisation
frames with intuitively plausible selectional prefer-
ences.
4 Related Work
Our model is an extension of and thus most closely
related to the latent semantic clustering (LSC) model
(Rooth et al, 1999) for verb-argument pairs ?v, a?
which defines their probability as follows:
p(v, a) =
?
c
p(c) p(v|c) p(a|c)
In comparison to our model, the LSC model only
considers a single argument (such as direct objects),
6For readability, we only list one noun per WordNet concept.
502
or a fixed number of arguments from one particu-
lar subcategorisation frame, whereas our model de-
fines a probability distribution over all subcategori-
sation frames. Furthermore, our model specifies se-
lectional preferences in terms of general WordNet
concepts rather than sets of individual words.
In a similar vein, our model is both similar and
distinct in comparison to the soft clustering ap-
proaches by Pereira et al (1993) and Korhonen et
al. (2003). Pereira et al (1993) suggested determin-
istic annealing to cluster verb-argument pairs into
classes of verbs and nouns. On the one hand, their
model is asymmetric, thus not giving the same in-
terpretation power to verbs and arguments; on the
other hand, the model provides a more fine-grained
clustering for nouns, in the form of an additional hi-
erarchical structure of the noun clusters. Korhonen
et al (2003) used verb-frame pairs (instead of verb-
argument pairs) to cluster verbs relying on the Infor-
mation Bottleneck (Tishby et al, 1999). They had
a focus on the interpretation of verbal polysemy as
represented by the soft clusters. The main difference
of our model in comparison to the above two models
is, again, that we incorporate selectional preferences
(rather than individual words, or subcategorisation
frames).
In addition to the above soft-clustering models,
various approaches towards semantic verb classifi-
cation have relied on hard-clustering models, thus
simplifying the notion of verbal polysemy. Two
large-scale approaches of this kind are Schulte im
Walde (2006), who used k-Means on verb subcat-
egorisation frames and verbal arguments to cluster
verbs semantically, and Joanis et al (2008), who ap-
plied Support Vector Machines to a variety of verb
features, including subcategorisation slots, tense,
voice, and an approximation to animacy. To the
best of our knowledge, Schulte im Walde (2006) is
the only hard-clustering approach that previously in-
corporated selectional preferences as verb features.
However, her model was not soft-clustering, and
she only used a simple approach to represent selec-
tional preferences by WordNet?s top-level concepts,
instead of making use of the whole hierarchy and
more sophisticated methods, as in the current paper.
Last but not least, there are other models of se-
lectional preferences than the MDL model we used
in our paper. Most such models also rely on the
WordNet hierarchy (Resnik, 1997; Abney and Light,
1999; Ciaramita and Johnson, 2000; Clark and Weir,
2002). Brockmann and Lapata (2003) compared
some of the models against human judgements on
the acceptability of sentences, and demonstrated that
the models were significantly correlated with human
ratings, and that no model performed best; rather,
the different methods are suited for different argu-
ment relations.
5 Summary and Outlook
This paper presented an innovative, complex ap-
proach to semantic verb classes that relies on se-
lectional preferences as verb properties. The prob-
abilistic verb class model underlying the semantic
classes was trained by a combination of the EM al-
gorithm and the MDL principle, providing soft clus-
ters with two dimensions (verb senses and subcate-
gorisation frames with selectional preferences) as a
result. A language model-based evaluation showed
that after 10 training iterations the verb class model
results are above the baseline results.
We plan to improve the verb class model with re-
spect to (i) a concept-wise (instead of a cut-wise)
implementation of the MDL principle, to operate on
concepts instead of combinations of concepts; and
(ii) variations of the concept hierarchy, using e.g. the
sense-clustered WordNets from the Stanford Word-
Net Project (Snow et al, 2007), or a WordNet ver-
sion improved by concepts from DOLCE (Gangemi
et al, 2003), to check on the influence of concep-
tual details on the clustering results. Furthermore,
we aim to use the verb class model in NLP tasks, (i)
as resource for lexical induction of verb senses, verb
alternations, and collocations, and (ii) as a lexical
resource for the statistical disambiguation of parse
trees.
References
Steven Abney and Marc Light. 1999. Hiding a Seman-
tic Class Hierarchy in a Markow Model. In Proceed-
ings of the ACL Workshop on Unsupervised Learning
in Natural Language Processing, pages 1?8, College
Park, MD.
Leonard E. Baum. 1972. An Inequality and Associated
Maximization Technique in Statistical Estimation for
Probabilistic Functions of Markov Processes. Inequal-
ities, III:1?8.
503
Carsten Brockmann and Mirella Lapata. 2003. Evaluat-
ing and Combining Approaches to Selectional Prefer-
ence Acquisition. In Proceedings of the 10th Confer-
ence of the European Chapter of the Association for
Computational Linguistics, pages 27?34, Budapest,
Hungary.
Glenn Carroll and Mats Rooth. 1998. Valence Induction
with a Head-Lexicalized PCFG. In Proceedings of the
3rd Conference on Empirical Methods in Natural Lan-
guage Processing, Granada, Spain.
Stanley Chen and Joshua Goodman. 1998. An Empirical
Study of Smoothing Techniques for Language Model-
ing. Technical Report TR-10-98, Center for Research
in Computing Technology, Harvard University.
Massimiliano Ciaramita and Mark Johnson. 2000. Ex-
plaining away Ambiguity: Learning Verb Selectional
Preference with Bayesian Networks. In Proceedings
of the 18th International Conference on Computa-
tional Linguistics, pages 187?193, Saarbru?cken, Ger-
many.
Stephen Clark and David Weir. 2002. Class-Based Prob-
ability Estimation using a Semantic Hierarchy. Com-
putational Linguistics, 28(2):187?206.
Bonnie J. Dorr and Doug Jones. 1996. Role of Word
Sense Disambiguation in Lexical Acquisition: Predict-
ing Semantics from Syntactic Cues. In Proceedings of
the 16th International Conference on Computational
Linguistics, pages 322?327, Copenhagen, Denmark.
Aldo Gangemi, Nicola Guarino, Claudio Masolo, and
Alessandro Oltramari. 2003. Sweetening WordNet
with DOLCE. AI Magazine, 24(3):13?24.
Eric Joanis, Suzanne Stevenson, and David James. 2008?
A General Feature Space for Automatic Verb Classifi-
cation. Natural Language Engineering. To appear.
Judith L. Klavans and Min-Yen Kan. 1998. The Role
of Verbs in Document Analysis. In Proceedings of
the 17th International Conference on Computational
Linguistics and the 36th Annual Meeting of the Asso-
ciation for Computational Linguistics, pages 680?686,
Montreal, Canada.
Philipp Koehn and Hieu Hoang. 2007. Factored Trans-
lation Models. In Proceedings of the Joint Conference
on Empirical Methods in Natural Language Process-
ing and Computational Natural Language Learning,
pages 868?876, Prague, Czech Republic.
Upali S. Kohomban and Wee Sun Lee. 2005. Learning
Semantic Classes for Word Sense Disambiguation. In
Proceedings of the 43rd Annual Meeting on Associa-
tion for Computational Linguistics, pages 34?41, Ann
Arbor, MI.
Anna Korhonen, Yuval Krymolowski, and Zvika Marx.
2003. Clustering Polysemic Subcategorization Frame
Distributions Semantically. In Proceedings of the 41st
Annual Meeting of the Association for Computational
Linguistics, pages 64?71, Sapporo, Japan.
Anna Korhonen. 2002. Subcategorization Acquisition.
Ph.D. thesis, University of Cambridge, Computer Lab-
oratory. Technical Report UCAM-CL-TR-530.
Karim Lari and Steve J. Young. 1990. The Estimation of
Stochastic Context-Free Grammars using the Inside-
Outside Algorithm. Computer Speech and Language,
4:35?56.
Hang Li and Naoki Abe. 1998. Generalizing Case
Frames Using a Thesaurus and the MDL Principle.
Computational Linguistics, 24(2):217?244.
Paola Merlo and Suzanne Stevenson. 2001. Automatic
Verb Classification Based on Statistical Distributions
of Argument Structure. Computational Linguistics,
27(3):373?408.
Fernando Pereira, Naftali Tishby, and Lillian Lee. 1993.
Distributional Clustering of English Words. In Pro-
ceedings of the 31st Annual Meeting of the Associ-
ation for Computational Linguistics, pages 183?190,
Columbus, OH.
Detlef Prescher, Stefan Riezler, and Mats Rooth. 2000.
Using a Probabilistic Class-Based Lexicon for Lexical
Ambiguity Resolution. In Proceedings of the 18th In-
ternational Conference on Computational Linguistics.
Philip Resnik. 1997. Selectional Preference and Sense
Disambiguation. In Proceedings of the ACL SIGLEX
Workshop on Tagging Text with Lexical Semantics:
Why, What, and How?, Washington, DC.
Jorma Rissanen. 1978. Modeling by Shortest Data De-
scription. Automatica, 14:465?471.
Mats Rooth, Stefan Riezler, Detlef Prescher, Glenn Car-
roll, and Franz Beil. 1999. Inducing a Semantically
Annotated Lexicon via EM-Based Clustering. In Pro-
ceedings of the 37th Annual Meeting of the Association
for Computational Linguistics, Maryland, MD.
Sabine Schulte im Walde. 2006. Experiments on the Au-
tomatic Induction of German Semantic Verb Classes.
Computational Linguistics, 32(2):159?194.
Eric V. Siegel and Kathleen R. McKeown. 2000.
Learning Methods to Combine Linguistic Indica-
tors: Improving Aspectual Classification and Reveal-
ing Linguistic Insights. Computational Linguistics,
26(4):595?628.
Rion Snow, Sushant Prakash, Daniel Jurafsky, and An-
drew Y. Ng. 2007. Learning to Merge Word Senses.
In Proceedings of the joint Conference on Empirical
Methods in Natural Language Processing and Com-
putational Natural Language Learning, Prague, Czech
Republic.
Naftali Tishby, Fernando Pereira, and William Bialek.
1999. The Information Bottleneck Method. In Pro-
ceedings of the 37th Annual Conference on Communi-
cation, Control, and Computing, Monticello, IL.
504
Proceedings of the 4th ACL-SIGSEM Workshop on Prepositions, pages 1?8,
Prague, Czech Republic, June 2007. c?2007 Association for Computational Linguistics
A Corpus-based Analysis of Geometric Constraints on Projective
Prepositions
Christian Hying
IMS, Universita?t Stuttgart
Azenbergstr. 12
70174 Stuttgart
Germany
christian.hying@ims.uni-stuttgart.de
Abstract
This paper presents a corpus-based method
for automatic evaluation of geometric con-
straints on projective prepositions. The
method is used to find an appropriate
model of geometric constraints for a two-
dimensional domain. Two simple models
are evaluated against the uses of projective
prepositions in a corpus of natural language
dialogues to find the best parameters of these
models. Both models cover more than 96%
of the data correctly. An extra treatment of
negative uses of projective prepositions (e.g.
A is not above B) improves both models get-
ting close to full coverage.
1 Introduction
This paper describes an empirical approach to find-
ing an appropriate model of geometric constraints of
projective prepositions with respect to a domain that
is implicitly given by a corpus. We examine uses
of the projective prepositions above, below, to the
right of, to the left of and other projective preposi-
tions whose orientation is aligned with one of the
former, when they describe the location of an object
relative to another object in two-dimensional space,
see for example (1) and (2) relating to Figure 1:
(1) The circle is to the right of the rectangle.
(2) The circle is not to the left of the rectangle.
Henceforth, the term located object (LO) will be
used to refer to the object whose location is speci-
fied and the term reference object (RO) to refer to
the object relative to which the location is specified.
Figure 1: Example of a spatial scene.
In the examples, the located object is the circle in
Figure 1 and the reference object is the rectangle.
The notion projective term refers to the word of a
projective preposition that determines the direction,
e.g. the word right for the projective preposition to
the right of. Let us call the use of the projective
prepositions positive use when it is used in default
context as in (1) and negative use when it is embed-
ded under negation as in (2).
Geometric constraints that are associated with
projective prepositions need to be such that they are
met by positive uses such as (1) and violated by neg-
ative uses such as (2). Given that these sentences
are appropriate uses to describe Figure 1, the spatial
scene should meet the constraints that are associated
with to the right of and violate the constraints of to
the left of. It is obvious that this dual question of true
or false invokes the issue of vagueness: We may find
utterances describing a particular spatial scene and
also their negations describing the same scene. For
example, the following positive use of above may
be appropriate to describe the spatial scene above ?
The circle is above the rectangle ? but also the cor-
responding negative use in the sentence The circle is
not above the rectangle.
We collect empirical evidence of uses of projec-
tive prepositions from the HCRC Map Task corpus
(Anderson et al, 1991) ? a corpus of human-human
1
dialogues. In contrast to other approaches that report
empirical studies on geometric conditions of projec-
tive prepositions (Kelleher, 2003; Crawford et al,
2000; Logan and Sadler, 1996; Gapp, 1995; Abella,
1995) the resource used in this paper enables us to
study their use in conversation.
This paper presents a new method for automatic
evaluation of geometric constraints on projective
prepositions with corpus data. We use this method
to study the use of projective prepositions in human-
human conversations and apply it to two models of
geometric constraints with different parameters in
order to evaluate the coverage for each parameter.
A detailed analysis of incorrect cases leads us to a
separate treatment of negative uses.
2 Related Work
This section introduces two types of spatial orienta-
tion relations that we are going to use as geometric
constraints for projective prepositions in Section 4.
Orientation relations are defined with respect to a
frame of reference that defines the actual alignment
of directions (Levinson, 2003). The present study
is carried out under the assumption of a fixed frame
of reference such that the maps that are used as spa-
tial data define the reference directions for above,
below, right, and left. Although projective preposi-
tions are in general sensitive to extra-geometric in-
fluences, e.g. dynamic LOs and ROs and functional
relations between LO and RO (Coventry and Gar-
rod, 2004), we do not expect that such effects play a
role in the data, because the domain is static and it
hardly contains any pairs of objects with a functional
relationship.
In the literature, we find two paradigms for
defining spatial orientation relations: the orthogo-
nal projection paradigm and the angular deviation
paradigm. For each paradigm we review a simple
model and define different levels of granularity. The
limitations of these simple models have been dis-
cussed at length, and more complex models have
been proposed (Kelleher, 2003; Schmidtke, 2001;
Crawford et al, 2000; Matsakis and Wendling,
1999; Fuhr et al, 1995; Abella and Kender, 1993;
Wazinski, 1992). Nonetheless, it will turn out that
RO
N
S
NENW
W E
SESW
(a) Orthogonal pro-
jection model.
E
W
N
S
(b) Angular devia-
tion model.
Figure 2: Definition of directions.
we can find for each simple model a level of granu-
larity which covers more than 96% of the data.
Orthogonal projection. Orthogonal projection
models define conditions on intervals that are
the result of projecting two-dimensional or three-
dimensional objects onto reference axes. (Papadias
and Sellis, 1994), for example, define an orthogo-
nal projection model with a horizontal and a verti-
cal axis. Objects are represented by their projection
onto these axes or, more illustrative, by bounding
boxes. A bounding box of an object is the mini-
mal rectangle with vertical and horizontal sides that
contains the object. Lines which are defined by
the sides of the bounding box of the reference ob-
ject divide the space into nine regions. We refer
to the regions around the bounding box of the ref-
erence object by means of the cardinal directions
(N,S,E,W,NW,NE,SW,SE) as shown in Figure 2(a).
Let us define two relations OV and INC for ex-
pressing overlap and complete inclusion. A region
A overlaps with a region B if and only if their in-
tersection is not empty. A region A is completely
included in B if and only if their intersection yields
A:
(3) OV (A,B) ? A ?B 6= ? (overlap)
INC(A,B) ? A ?B = A (inclusion)
The spatial orientation relations between LO
and RO presented below are defined in terms of
overlap and complete inclusion of LO with the
nine regions around RO defined by the model. We
exemplify the specification for the direction north
using the auxiliary regions NHP and NXHP, where
NHP = NW?N?NE is the half-plane consisting of
all northern regions and NXHP = NHP?W ?RO?E
is the (extended) half-plane which consists of all
2
but the southern regions. For each orientation we
define different levels of granularity ? increasing
index indicates wider interpretation. The idea is
that relations on OP0 are as strict as possible and on
OP7 as wide as possible. On granularity level OP0,
the relation north0op(LO,RO) is true if LO is com-
pletely included in the N -region. The predicate on
the next granularity level is true if LO overlaps with
the given N -region and is included in the northern
half-plane NHP. Granularity level OP2 only requires
inclusion in NHP. OP3 requires overlap with NHP
and inclusion in the extended half-plane NXHP. On
level OP4 the relation is true if LO is included in the
extended half-plane NXHP. Relations on OP5 require
overlap of LO with NXHP and LO must not overlap
with S. On OP6 north6op(LO,RO) is true if the LO
does not overlap with S and on OP7 it is true if LO
is not completely included in S. The same patterns
apply to the relations southnop, westnop, and eastnop.
OP0: north0op(LO, RO) ? INC(LO, N)
OP1: north1op(LO, RO) ? OV (LO, N) ? INC(LO, NHP)
OP2: north2op(LO, RO) ? INC(LO, NHP)
OP3: north3op(LO, RO) ?
OV (LO, NHP) ? INC(LO, NXHP)
OP4: north4op(LO, RO) ? INC(LO, NXHP)
OP5: north5op(LO, RO) ?
OV (LO, NXHP) ? INC(LO, NXHP ? SW ? SE)
OP6: north6op(LO, RO) ? INC(LO, NXHP ? SW ? SE)
OP7: north7op(LO, RO) ? OV (LO, NXHP ? SW ? SE)
Note, that on granularity levels OP0 to OP3 oppo-
site relations such as north and south are disjoint.
Their extensions overlap on levels OP4 to OP7.
Angular deviation. Angular deviation models de-
fine conditions on one or more angles that repre-
sent how much LO deviates from a reference direc-
tion from the perspective of RO. In two-dimensional
space there are four reference directions correspond-
ing to the cardinal directions: ~N , ~S, ~E, and ~W .
They are aligned with the vertical axis and the hor-
izontal axis, respectively, as shown in Figure 2(b).
Like the models presented in (Hernandez, 1994;
Gapp, 1994) we use centroids to determine one sin-
gle angle between RO and LO. Let the function c(?)
return the centroid of its argument and let ~o be a vec-
tor from the centroid of the reference object to the
centroid of the located object.
(4) ~o = ??????????c(RO)c(LO)
The angle between two vectors ~a and ~b is repre-
sented as 6 (~a,~b) and the angular deviation of ~a from
the direction given by~b is represented as |6 (~a,~b)|.
Orientation relations are defined via inequality
conditions specifying that the deviation of the an-
gle ~o from the corresponding reference direction is
below or equal to a threshold. The threshold is de-
fined as the granularity level multiplied by 10 de-
grees. We define 19 granularity levels ADn from
n=0 to n=18 according to the pattern shown in (5).
The same patterns with the reference directions ~S,
~W , and ~E apply to the relations southnad, westnad,
and eastnad, respectively.
(5) ADn: northnad(LO, RO) ? |6 ( ~N,~o)| ? (n ? 10?)
Note, that opposite relations such as north and
south are disjoint on the levels from AD0 to AD8
and overlap from AD9 to AD18.
3 Data
This section describes the data that is used for the
analysis of the semantics of projective prepositions.
The data is an exhaustive collection of uses of pro-
jective prepositions occurring in the HCRC Map
Task corpus (Anderson et al, 1991) where the speak-
ers describe the location of a two-dimensional ob-
ject relative to another two-dimensional object. The
HCRC Map Task corpus is a collection of route de-
scription dialogues where one participant tries to ex-
plain a route printed on a map to another partic-
ipant. It contains transcriptions of 128 dialogues
which were recorded with 32 subjects. The maps are
schematic maps containing line drawings of objects,
so called landmarks. Examples of sections of the
maps are shown in Section 5. The participants can-
not see each other?s maps so that the task can be ac-
complished only by means of what the participants
say to one another. The two maps that are used for
one dialogue are not exactly identical because not all
landmarks have an identical counterpart on the other
map. Therefore, the participants align their infor-
mation about the maps by describing the location of
landmarks.
3
TERM Frequency
above 87
left 86
below 77
right 65
underneath 52
beneath 7
bottom 7
top 7
down 5
TERM Frequency
under 5
up 5
west 3
north 2
south 2
east 1
upwards 1
over 1
Table 1: Frequency of projective terms.
The present study selects those descriptions from
the corpus that satisfy the following requirements:
Requirements:
(i) The description describes the location of one
landmark relative to exactly one other landmark.
(ii) The description contains a projective preposition
that is associated with one of the four cardinal
directions from Figure 2(b).
(iii) The description does not contain any modifiers.
After having removed duplicates of descriptions
occurring in the same dialogue, the set of data con-
sists of 734 different uses of projective prepositions.
324 uses are filtered out by condition (iii) because
they contain modifiers such as hedges (e.g. just), di-
rection modifiers (e.g. straight), and distance modi-
fiers (e.g. 2 cm). The remaining set of data consists
of 410 different uses of unmodified projective prepo-
sitions which further divides into 389 positive uses
and 21 negative uses. Table 1 shows all projective
terms ordered by frequency.
Spatial data. The corpus is supplemented by elec-
tronic copies of the maps that the participants have
used. We created geometric representations of each
map by redrawing the shape of each landmark and
representing it as a closed polygon at the same lo-
cation as the original landmark. All polygons are
associated with unique identifiers. Let us define a
function polygon that yields the polygon definition
for each landmark. Given that l is an identifier of
a landmark and m an identifier of a map, the ex-
pression polygon(l,m) returns the definition of the
corresponding polygon.
Annotations. We identify all descriptions in the
corpus that satisfy the requirements specified above.
Then we mark the corresponding projective preposi-
tions in the corpus and annotate them with the fol-
lowing type of information:
(6)
2
6
6
6
6
6
6
6
6
4
TERM : Projective Term
DIAL : Dialogue Identifier
MAP : Map Identifier
LO : Landmark Identifier
RO : Landmark Identifier
INT : (pos | neg)
3
7
7
7
7
7
7
7
7
5
The feature TERM denotes the projective term. The
feature DIAL holds a symbol that uniquely identifies
the dialogue which the corresponding utterance oc-
curs in. The feature MAP specifies the map which the
corresponding utterance describes a part of. The fea-
tures LO for located object and RO for reference ob-
ject hold symbols that uniquely identify landmarks.
Finally, the feature INT determines the way how to
interpret the whole feature structure. It accepts one
of the values pos and neg. The value pos indi-
cates positive use of the projective preposition in the
given utterance from the corpus: The feature struc-
ture is interpreted as the statement that the partici-
pant of dialogue DIAL who has map MAP produced
utterances where the location of LO relative to RO on
map MAP can be described correctly by the preposi-
tion in question. The value neg indicates a negative
use of the preposition: The feature structure is in-
terpreted as the statement that the participant of dia-
logue DIAL who has map MAP produced utterances
where the negation of the preposition used is appro-
priate to describe the location of LO relative to RO
on map MAP. In the corpus we find cases of explicit
and implicit negation. The following two examples
show cases of explicit negation.
(7) X is not below Y .
(8) A: Is X below Y ?
B: No.
In the first example, the speaker makes a statement
and uses a negated prepositional phrase. In the sec-
ond example, the negation is triggered by a negative
response to a question.
Implicit negations are triggered by rejections of
alternatives. In the following example, participant A
asks B about the truth of alternatives. If B chooses
one alternative the others are rejected as incorrect:
4
(9) A: Is X above or below Y ?
B: It?s above.
Participant B states that the first alternative X is
above Y is correct and thereby implicitly rejects the
other alternative X is below Y.
4 Automatic Evaluation of Geometric
Constraints on Projective Prepositions
This section describes a method of automatic evalu-
ation of geometric constraints on projective preposi-
tions with respect to the data described in the previ-
ous section.
For each level of granularity of the spatial ori-
entation relations defined in Section 2 we define
a model-theoretic semantics that maps projective
prepositions onto truth conditions that are expressed
in terms of these spatial orientation relations. In gen-
eral, truth conditions determine the truth of a natu-
ral language expression with respect to a particular
model of a situation. Applied to data used in this
study this means that the truth conditions determine
the applicability of projective prepositions with re-
spect to a pair of landmarks that appear on the same
map.
Semantics. For each projective preposition we
define as many meanings as we have defined
levels of granularity of spatial orientation relations
in Section 2. We define a semantics on feature
structure representations (6). Given the model
? and the granularity level n we map a feature
structure f onto the truth condition shown in (a) if
f.INT=pos and onto (b) otherwise:
Let f be a feature structure of type (6),
?lo = polygon(f.LO, f.MAP ), and
?ro = polygon(f.RO, f.MAP )), then
(a) ?f.TERM?n?(?lo, ?ro) if f.INT=pos;
(b) ??f.TERM?n?(?lo, ?ro) if f.INT=neg.
As said above, the function polygon(?, ?) yields a
geometric representation of the landmark specified
by a landmark identifer and a map identifier. The
term ?f.TERM?n? denotes the mapping of a projec-
tive term from Table 1 onto a spatial relation with the
account ? and the granularity level n. For example,
the projective terms above, top, up, upwards, over,
level +pos -pos +neg -neg corr
OP0 79 310 21 0 100
OP1 249 140 21 0 270
OP2 346 43 19 2 365
OP3 376 13 16 5 392
OP4 385 4 11 10 396
OP5 386 3 7 14 393
OP6 387 2 2 19 389
OP7 389 0 0 21 389
Table 2: Results of the orthogonal projection mod-
els.
and north are all mapped onto northn?-relations.1 For
example, if we evaluate the account using orthog-
onal projection and granularity level 0 the feature
structure shown in (10) is mapped onto the formula
?north0op(?1, ?2) where ?1 and ?2 are the polygons
determined by LO and RO, respectively.
(10)
2
6
6
6
6
6
6
6
6
4
TERM = above
DIAL = d0
MAP = m2f
LO = m2 manned fort
RO = m2 rapids
INT = neg
3
7
7
7
7
7
7
7
7
5
Automatic evaluation. We evaluate a semantics
of projective prepositions by automatically comput-
ing truth conditions for each feature structure in the
data and evaluating it with the corresponding geo-
metric representations of RO and LO. If the truth
value is true and the feature structure specifies pos-
itive use (i.e. INT = pos), then in this case the
semantics is correct. Likewise, if the truth value
is false and the data specifies negative use (INT =
neg) the semantics is correct. In all other cases
there is a mismatch between the semantics and the
feature structure, so that the corresponding use of
a projective preposition provides negative empirical
evidence against the semantics.
5 Results and Discussion
The results of the evaluation are shown in Table 2
and Table 3. It comprises the evaluation of 27 se-
mantic accounts corresponding to 8 levels of gran-
ularity of the orthogonal projection model (OP0 to
1(O?Keefe, 1996) suggests that distinct projective preposi-
tions can be associated with different levels of granularity, for
example, above and up. For the present study the data is too
sparse to compare such differences.
5
level +pos -pos +neg -neg corr
AD0 0 389 21 0 21
AD1 116 273 21 0 137
AD2 179 210 21 0 200
AD3 250 139 21 0 271
AD4 291 98 21 0 312
AD5 320 69 21 0 341
AD6 347 42 20 1 367
AD7 370 19 18 3 388
AD8 382 7 17 4 399
AD9 385 4 14 7 399
AD10 386 3 12 9 398
AD11 386 3 10 11 396
AD12 386 3 7 14 393
AD13 386 3 5 16 391
AD14 387 2 5 16 392
AD15 388 1 4 17 392
AD16 388 1 3 18 391
AD17 388 1 1 20 389
AD18 389 0 0 21 389
Table 3: Results of the angular deviation models.
OP7) and 19 levels of granularity of the angular
deviation model with thresholds from 0? (AD0) to
180? (AD18). The first column specifies the gran-
ularity level used. The evaluation of positive uses
of projective prepositions is listed in the second and
third column, the results for negative uses in the
fourth and fifth column. The columns +pos and
+neg report the number of correct cases in which
the truth conditions are consistent with the value of
the INT feature. The number of all correct cases is
the sum of +pos and +neg and is printed in the last
column with the label corr. The remaining columns
-pos and -neg report incorrect truth conditions for
positive and negative uses, respectively.
Orthogonal projection. Over all orthogonal pro-
jection models OP4 (included in extended half-
plane) correctly covers a maximum number of 396
cases (96.6%).
For a more detailed analysis aiming at full cover-
age we take a closer look at the errors: there are 4
positive uses for which OP4 provides an incorrect
semantics. The corpus reveals that three of these
uses are not covered by OP4 because the speakers
confused left and right. This confusion is apparent
either because it is corrected by the speaker at a later
point in the dialogue or because the use is obviously
wrong. The remaining case is given by the following
part of the corpus relating to Figure 3:
(11) dialogue q4ec3, utterance 174f
Figure 3: Pebbled shore, crane bay, and boat house.
Figure 4: Disused warehouse and giraffes.
G: have you got anything below pebbled
shore
F: washed stones and flag ship ... and bay
Note, that Figure 3 does not display the landmarks
washed stones and flag ship. The participant F says
that crane bay is below pebbled shore. This case
is not captured by OP4 but by OP5 (overlap with
extended half-plane).
All negative uses are correctly rejected by OP0
and OP1. The next level OP2 (i.e. completely in-
cluded in half-plane) does not reject the following
two cases:
(12) dialogue q4nc2, utterance 264f
G: i don?t have a disused warehouse on
mine
F: oh right. well it?s just parallel to it ...
like ... just ehm ... ... well not under-
neath the giraffes ... you know ...
(13) dialogue q3nc7, utterance 66f
G: is totem pole below the trout farm?
F: no i?, well, it?s kind of opposite it
These uses are explicit negations. In (12) F says
6
Figure 5: Totem pole and trout farm.
that the warehouse in Figure 4 is not underneath the
giraffes. And in (13) F indicates that the totem pole
is not below the trout farm in Figure 5. As said
before, OP1 is the most general model that rejects
these cases.
To summarise, a semantics that aims at covering
all of the good data employs OP5 for positive uses
and OP1 for negative uses. 2 On level OP5 and to a
lesser extent on OP4, the extensions of opposite re-
lations such as above and below overlap, because all
objects that are included in the union of the regions
W , RO, and E are both above and below relative
to the reference object. Since on OP4 the overlap is
smaller than on OP5 it is better to use OP4 instead.
A combination of OP4 for positive uses and OP1 for
negative uses still covers almost all of the good data
(99.8%).
Angular deviation. Over all angular deviation
models AD8 and AD9 correctly cover a maximum
number of 399 cases (97.3%).
On level AD9 there are 4 positive uses with an
incorrect semantics. Again the same three uses as
above are due to confusion of left and right. The
remaining use is the following utterance, which re-
lates to the part of a map depicted in Figure 3. The
narrowest model that covers this use is AD13:
(14) dialogue q4ec3, utterance 332
my boat house is ... down below crane bay
All negative uses are correctly rejected by all
models from AD0 to AD5. Model AD6 does not
predict rejection of the case which has already been
described above in (12). AD7 additionally produces
two further errors in the following two cases which
describe Figure 6(a) and Figure 6(b), respectively.
2Good data means all data excluding the cases where left
and right was confused.
(a) Tribal settlement and
rope bridge.
(b) Highest viewpoint and
overgrown gully
Figure 6: Section of maps 13 and 10.
(15) dialogue q4ec1, utterance 10f
F: is it underneath the rope bridge or to
the left?
G: it?s underneath the rope bridge
(16) dialogue q4ec8, utterance 41f
G: and eh to the ... left or right of highest
viewpoint
F: ... it?s beneath it
These examples show implicit negative uses. The
utterances in (15) give rise to the interpretation that
the tribal settlement is not to the left rope bridge.
And the utterances in (16) imply that the overgrown
gully is neither to the left nor to the right of the high-
est viewpoint. These three negative uses and again
the localisation of the totem pole in (13) have not
been modelled correctly by the semantics that em-
ploys AD8.
To summarise, a semantics aiming to cover all of
the good data uses AD13 for positive uses and AD5
for negative uses. Considering that the extensions
of the opposite relations in AD13 overlap to a great
extent, it is better to use a combination of AD9 for
positive uses and AD5 for negative uses which still
covers all of the good data except one case (99.8%).
If we compare the angular deviation model
(AD9/AD5) with the orthogonal projection model
(OP4/OP1), the angular deviation model is superior,
because in AD9 the extensions of opposite relations
such as above and below only have a very small
overlap, namely when the angular deviation is ex-
actly 90?, while in OP4 the overlap is much more
significant.
7
6 Summary and Conclusion
This paper described a method to evaluate geometric
constraints on projective prepositions with empirical
data extracted from a corpus of human-human con-
versations. The key feature of the approach is the an-
notation of projective prepositions in the corpus with
links to geometric representations of the objects that
the arguments of the prepositions refer to. The data
is used to automatically apply and evaluate differ-
ent granularity levels of a semantics building upon
a simple orthogonal projection model and a simple
angular deviation model. Both models cover more
than 96% of the data correctly. Further refinement
shows that the angular deviation model covers the
data almost perfectly (99.8%) if we provide an extra
treatment for negative uses, so that positive uses are
accepted when the angular deviation is below 90?
and negative uses are accepted when the angular de-
viation is greater than 50?.
References
Alicia Abella and John R. Kender. 1993. Qualita-
tively describing objects using spatial prepositions. In
National Conference on Artificial Intelligence, pages
536?540.
Alicia Abella. 1995. From imagery to salience: locative
expressions in context. Ph.D. thesis, Computer Sci-
ence Department, Columbia Universtity, New York,
NY.
A. Anderson, M. Bader, E. Bard, E. Boyle, G. M. Do-
herty, S. Garrod, S. Isard, J. Kowtko, J. McAllister,
J. Miller, C. Sotillo, H. S. Thompson, and R. Weinert.
1991. The HCRC Map Task Corpus. Language and
Speech, 34(4):351?366.
Kenny Coventry and Simon Garrod. 2004. Towards
a classification of extra-geometric influences on the
comprehension of spatial prepositions. In Functional
Features in Language and Space.
L. Elizabeth Crawford, Terry Regier, and Janellen Hut-
tenlocher. 2000. Linguistic and non-linguistic spatial
categorization. Cognition, 75(3):209?235.
T. Fuhr, G. Socher, C. Scheering, and G. Sagerer. 1995.
A three-dimensional spatial model for the interpreta-
tion of image data. In IJCAI-95 Workshop on Repre-
sentation and Processing of Spatial Expressions, Mon-
treal, Canada.
Klaus-Peter Gapp. 1994. Basic meanings of spatial re-
lations: computation and evaluation in 3d space. In
AAAI?94: Proceedings of the twelfth national confer-
ence on Artificial intelligence (vol. 2), pages 1393?
1398, Menlo Park, CA, USA. American Association
for Artificial Intelligence.
K.-P. Gapp. 1995. An empirically validated model
for computing spatial relations. In I. Wachsmuth,
C.-R. Rollinger, and W. Brauer, editors, KI-95: Ad-
vances in Artificial Intelligence. 19th German Annual
Conference on Artificial Intelligence, pages 245?256.
Springer, Berlin, Heidelberg.
Daniel Hernandez. 1994. Qualitative Representation of
Spatial Knowledge. Springer-Verlag New York, Inc.
John Kelleher. 2003. A Perceptually Based Compu-
tational Framework for the Interpretation of Spatial
Language in 3D Simulated Environments. Ph.D. the-
sis, Dublin City University, Dublin.
Stephen C. Levinson. 2003. Space in Language and
Cognition. Cambridge University Press.
Gordon D. Logan and Daniel D. Sadler. 1996. A com-
putational analysis of the apprehension of spatial rela-
tions. In Paul Bloom, Mary A. Peterson, Lynn Nadel,
and Merril G. Garrett, editors, Language and Space.
MIT Press.
Pascal Matsakis and Laurent Wendling. 1999. A new
way to represent the relative position between areal
objects. IEEE Transactions on Pattern Analysis and
Machine Intelligence, 21(7):634?643.
John O?Keefe. 1996. The spatial prepositions in English,
vector grammar, and the cognitive map theory. In Paul
Bloom, Mary A. Peterson, Lynn Nadel, and Merril G.
Garrett, editors, Language and Space. MIT Press.
Dimitris Papadias and Timos K. Sellis. 1994. Qual-
itative representation of spatial knowledge in two-
dimensional space. VLDB Journal: Very Large Data
Bases, 3(4):479?516.
Hedda R. Schmidtke. 2001. The house is north of
the river: Relative localization of extended objects.
In D.R. Montello, editor, COSIT 2001, LNCS 2205,
pages 415?430.
Peter Wazinski. 1992. Generating spatial descriptions
for cross-modal references. In Proceedings of the third
conference on Applied natural language processing,
pages 56?63. Association for Computational Linguis-
tics.
8
