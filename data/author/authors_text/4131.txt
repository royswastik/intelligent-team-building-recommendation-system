A spoken dialogue interface for TV operations based on             
data collected by using WOZ method 
Jun  
Goto 
NHK STRL 
Human Science 
Tokyo 157-8510 
Japan 
goto.j-fw 
@nhk.or.jp 
Yeun-Bae 
 Kim 
NHK STRL 
Human Science 
Tokyo 157-8510 
Japan 
kimu.y-go 
@nhk.or.jp 
Masaru  
Miyazaki 
NHK STRL 
Human Science 
Tokyo 157-8510 
Japan 
miyazaki.m-fk
@nhk.or.jp 
Kazuteru  
Komine 
NHK STRL 
Human Science 
Tokyo 157-8510 
Japan 
komine.k-cy 
@nhk.or.jp 
Noriyoshi 
Uratani 
NHK STRL 
Human Science 
Tokyo 157-8510 
Japan 
uratani.n-fc
@nhk.or.jp 
 
Abstract 
The development of multi-channel digital 
broadcasting has generated a demand not 
only for new services but also for smart 
and highly functional capabilities in all 
broadcast-related devices. This is espe-
cially true of the television receivers on 
the viewer's side. With the aim of achiev-
ing a friendly interface that anybody can 
use with ease, we built a prototype inter-
face system that operates a television 
through voice interactions using natural 
language. At the current stage of our re-
search, we are using this system to inves-
tigate the usefulness and problem areas of 
the spoken dialogue interface for televi-
sion operations. 
1 Introduction 
In Japan, the television reception environment has 
become quite diverse in recent years. In addition to 
analog broadcasts, BS (Broadcast Satellite) digital 
television and data broadcasts have been operating 
since 2000. At the same time, TV operations for 
receiving such broadcasts are becoming increas-
ingly complex, and an ever increasing variety of 
peripheral devices such as video tape recorders, 
disk recorders, DVD players, and game consoles 
are now being connected to televisions, and operat-
ing such devices with different kinds of interfaces 
is becoming troublesome not only for the elderly 
but for general users as well (Komine et al, 2000). 
Recently we conducted a usability test targeting 
data broadcasts in BS digital broadcasting. The 
results of the test revealed that many subjects had 
trouble accessing hierarchically arranged data. 
This finding revealed the need for an easy 
means of accessing desired programs. One such 
means is a spoken natural language dialogue (here-
after spoken dialogue) interface for TV operations. 
If spoken dialogue could be used to select and 
search for programs, to operate peripheral devices, 
and to give information in reply to system queries, 
we can envisage such an interface as being ex-
tremely valuable in a multi-channel and multi-
service function viewing environment. With this in 
mind, we have set out to build an interface system 
that could operate a television via spoken dialogue 
in place of manual operations. 
2 Collecting dialogue data for TV opera-
tions 
Assuming that a television is intelligent enough to 
understand the words spoken by a human, what 
kind of language expressions would a user use to 
give commands to that television? In other words, 
it is important that the words spoken by a user in 
such a situation be carefully examined when de-
signing a television interface using spoken dia-
logues. Therefore first we built an experimental 
environment that would enable us to collect dia-
logue data based on WOZ (Wizard of OZ) method. 
2.1 Wizard of OZ 
We set up a television-operation environment ac-
cording to the WOZ framework in which the sub-
jects were instructed that ?the character appearing 
on the television screen can understand anything 
you say, and that the character will operate the 
television for you.?  
The number of channels that could be selected 
was 19, and screens displaying Electronic Program 
Guide (EPG) and user interface for program 
searching were presented as needed (Komine et al, 
2002). 
This WOZ environment required two operators, 
one in charge of voice responses and the other of 
user interface operations. The voice-response op-
erator returns a voice response to the subject by a 
speech synthesizer after selecting a reply from 
about 50 previously prepared statements or input-
ting replies directly from a keyboard. If the subject 
happens to be silent, the operator returns a re-
sponse that introduces new services or prompts the 
subject to say something. The user interface opera-
tor first determines what the subject wants, and 
then manipulates user interface or EPG and per-
forms basic television operations such as changing 
channels. 
The subjects selected for data collection con-
sisted of 10 men and 10 women ranging in age 
from 24 to 31 (average age: 28.7), and each was 
allowed to speak freely with the television for 5 
minutes under an assumption that the ?television 
has a certain amount of intelligence.? 
2.2 Results of data analysis 
Figure 1 shows an example of dialogue data re-
corded during a WOZ session. On analyzing col-
lected utterances made by the subjects  (1,268 
utterances in total), it was found that 83% of user 
utterances concerned requests made to the televi-
sion, and that 89% of those requests included 
words belonging to specific categories such as 
program title, genre, performer, station, time, and 
TV operation commands. The remaining 17% of 
utterances did not concern the system but were 
rather a result of subjects talking or muttering to 
themselves for self-confirmation and the like.  
Here, we consider the following reason why 
most utterances belonged to specific categories 
despite the fact that a variety of request could be 
made. In this system, TV program- and operation-
related information is displayed on the television 
screen, and based on this information, subjects 
tended to underestimate television capability and to 
omit utterances not dealing with service functions 
they saw as possible. It is also thought that the 
conventional image of television inside subjects? 
minds served to restrict user utterances. 
As a part of this WOZ experiment, we also had 
the subjects fill out a questionnaire with regards to 
television operations by using spoken dialogue 
interface. When asked to give an opinion on oper-
ating a television by voice, more than half replied 
?Yes, I would like to? therefore apparently indicat-
ing a high demand for the spoken dialogue inter-
face. On the other hand, most subjects that replied 
?No, I would not like to? gave simple embarrass-
ment at speaking out loud as one reason and a re-
luctance to vocalize commands when watching 
television together with their families as another. 
In this regard, we think that embarrassment could 
probably be reduced through user experience and 
appropriate environment configuration. 
3 Spoken dialogue interface system for 
TV operations 
Based on the results of the data analysis, we built a 
prototype system that enables television operations 
via spoken dialogue. Figure 2 shows the configura-
tion of this system. The system allows users to se-
lect real-time broadcast programs from 19 channels. 
It also enables the presentation of program in-
00:27:08 Subject     Well, I?m looking for a program. 
00:30:23 WOZ    You can also choose by genre.  
 Would you like to see the list of  
 programs by genre?  
00:36:25 Subject  Yes. 
00:38:00 WOZ  All right. 
00:47:02 Subject     Ah!  
00:47:02 WOZ        Please select a genre.  
00:50:04 Subject     Well, let?s see.  
 How about ?Variety??  
00:55:11 WOZ       OK!  
01:02:06 Subject    I see.  
01:03:29    WOZ     Please select the program you  
 would like to see.  
01:08:27 Subject    Well, I would like see more at the  
 bottom of the screen. 
01:12:09 WOZ       OK, I will do it. 
01:15:23 Subject  Um, Just a little bit more.  
01:17:27 WOZ       OK, how?s that? 
Figure 1: Example of dialogue data 
formation obtained from the Internet or overlaid 
data in digital broadcasts; the scheduling of pro-
gram recording; and the browsing of program-
related information from Internet. All of these 
functions can be operated through spoken natural 
language interactions. The main processing mod-
ules of the system are described below. 
3.1 Robot interface 
The user makes operation requests to interface ro-
bot (IFR) as shown in Figure 3, and the IFR oper-
ates the television accordingly for the user. The 
IFR is equipped with a super-unidirectional micro-
phone and a speaker, and communicates and acti-
vates the speech recognition and voice synthesis, 
and dialogue processing of the system. The IFR 
has been given the appearance of a stuffed animal. 
One advantage of this IFR is that it can be directly 
touched and manipulated to create a feeling of 
warmth and closeness. 
On hearing a greeting or being called by its 
name, the IFR opens its eyes and enters a state that 
can perform various operations. For example, the 
IFR can assist the user search for a program, can 
present information about any program on the tele-
vision screen, and can return voice responses.  
3.2 Speech recognition 
The speech recognition module uses an algorithm 
that can finalize recognition results in a sequential 
manner for a real-time operation and a high speech 
recognition rate. When applying this module to a 
news program, a speech recognition rate of about 
95% can be obtained (Imai, 2000).  
In speech that occurs during television opera-
tions, the words such as program titles, names of 
broadcast stations, names of entertainers and etc. 
have a high probability of occurring and are also 
updated frequently. For this reason, newly acquired 
word-lists are automatically registered in a diction-
ary on a daily basis. In addition, as program titles 
often consist of multiple words, it is necessary to 
register them as a single word in order to improve 
the recognition rate. 
Despite several additional forms of tuning, it is 
still difficult to achieve perfect results with current 
speech recognition technology. To enable feedback 
to be given to the user at the time of erroneous rec-
ognition, results of recognition are always dis-
played on the lower left corner of the television 
screen. 
3.3 Dialogue processing  
In dialogue processing, it is generally difficult to 
understand intent by performing only a lexical 
analysis of speech. If we limit tasks to dialogue 
used in television operation, the words spoken by a 
user have a high probability of falling into specific 
categories such as program name, as indicated by 
the results of the data analysis described in 2.2. As 
a consequence, user intent can be inferred from a 
combination of specific categories and predicates. 
From the viewpoint of processing speed, process-
ing can be performed in real time if we use pattern-
base approach. This approach is also used in other 
dialogue systems such as PC-based agent televi-
sion systems in the (FACTS) project and (Sumiyo-
shi et al, 2002). 
The dialogue processing module performs real-
time morphological analysis of input statements 
from the speech recognition module. A statement 
is then identified by pattern matching in units of 
morphemes and the meaning ascribed beforehand 
to that statement is obtained. An example of such 
pattern is shown in Figure 4 using the meta-
characters listed in Table 1: 
 
 
User 
Internet
Individual profile  
management program 
Program retrieval  Profile search 
TV program 
database 
Dialog processing 
Speech recognition 
Voice synthesis 
Machine 
control  
Presentation
 
Digital 
broadcasting
Operation 
request 
Figure 3: Interface robot and an operation scene Figure 2: Configuration of interface system 
 Table 1: Meta-characters used in pattern 
 
 
In the pattern matching process, categories im-
portant to television operations are stored as slots. 
Table 2 lists these category-slots and examples of 
their members. The words stored in these slots are 
then used as a basis for generating television op-
eration commands and search expressions to access 
the TV program database. Response statements to 
input statements may take various forms depending 
on the patterns and current circumstances, and they 
are here generated by taking into account slot in-
formation, response history, results of searching 
for program information. 
 
Table 2: Content of category-slots 
4 Conclusion 
We have built a spoken dialogue system based on 
the results of a WOZ experiment with the aim of 
achieving a television operation interface easy 
enough for anybody to use.  
In the preliminary system operation test, 5 sub-
jects were asked to give some examples of TV pro-
grams that they watch at home, and to use this 
system to see whether they could obtain informa-
tion in relation to those programs. Results of this 
test showed that all subjects could access informa-
tion on desired programs. In a subsequent ques-
tionnaire, moreover, all subjects stated that 
?program selection was easy, and particularly there 
was no need to know about hierarchical structure 
of program information.? 
On the other hand, the test also revealed that 
some issues remain to be addressed in speech rec-
ognition but that a favorable evaluation could be 
obtained from all subjects with regard to television 
operations via spoken dialogue. We are currently 
conducting even more detailed experiments to 
demonstrate the usefulness of a spoken dialogue 
interface for television control and to examine 
problem areas. 
References 
FACTS (FIPA Agent Communication Technologies and 
Services) A1 Work Package. Available at 
http://sharon.cselt.it/projects/facts-a1/. 
Hideki Sumiyoshi, Ichiro Yamada, and Nobuyuki Yagi. 
2002. Multimedia Education System for Interactive 
Educational Services. Proceedings of IEEE Interna-
tional Conference on Multimedia and Expo, CD-
ROM. 
Kazuteru Komine, Nobuyuki Hiruma, Tatsuya Ishihara, 
Eiji Makino, Takao Tsuda, Takayuki Ito, and Haruo 
Isono. 2000. Usability Evaluation of Remote Con-
trollers for Digital Television receivers. Proceedings 
of SPIE, Human Vision and Electronic Imaging 5, 
Vol. 3959:458-467. 
Kazuteru Komine, Toshiya Morita, Jun Goto, and Nori-
yoshi Uratani. 2002. Analysis of Speech Utterances 
in TV Program Selection Operations using a Spoken 
Dialogue Interface. Proceeding of Human Interface 
Symposium, No.3231:631-634. (in Japanese). 
Toru Imai. 2000. Progressive 2-pass Decoder for real-
time Broadcast news captioning. Proceedings of 
ICASSP-2000, Vol.3:1559-1562. 
Meta-character Description 
* any number of any words 
+ one word 
! non-matching word 
{} optional 
[] mandatory  
() any order 
@ slots 
| or 
, delimiter 
Slot Examples 
@Moviename Blade Runner, My Fair Lady etc 
@Performer?s 
name 
Harrison Ford, Chizuru Ikewaki  
Norika Fujiwara, etc 
@Genre Drama, Animation, News, etc 
@Time 10:20, Tomorrow, Tonight, etc 
@Broadcast 
station name 
NHK, TBS, WOWOW, etc 
@Direct opera-
tion 
Volume, Channel, etc 
@Action Search, Watch, Turn up, etc 
Input statement 
I?d like to watch Blade Runner tonight 
 
Pattern 
* [watch|search] * @Moviename * @Time 
Figure 4:  Example of pattern matching 
Question-Answering Based on Virtually Integrated Lexical  
Knowledge Base 
Key-Sun Choi 
KAIST,Korterm 
Daejeon  
305-701 Korea 
kschoi@cs.ka
ist.ac.kr 
Jae-Ho Kim 
KAIST,Korterm
Daejeon 
305-701 Korea
jjaeh@world.
kaist.ac.kr
Masaru 
Miyazaki 
NHK STRL 
Tokyo 157-8510
Japan 
miyazaki.m-
fk@nhk.or.jp
Jun Goto 
NHK STRL 
Human Science 
Tokyo 157-8510 
Japan 
 goto.j-
fw@nhk.or.jp 
Yeun-Bae Kim
NHK STRL 
Human Science
Tokyo 157-8510
Japan 
 kimu.y-
go@nhk.or.jp
 
Abstract 
This paper proposes an algorithm for cau-
sality inference based on a set of lexical 
knowledge bases that contain information 
about such items as event role, is-a hier-
archy, relevant relation, antonymy, and 
other features. These lexical knowledge 
bases have mainly made use of lexical 
features and symbols in HowNet. Several 
types of questions are experimented to 
test the effectiveness of the algorithm here 
proposed. Particularly in this paper, the 
question form of ?why? is dealt with to 
show how causality inference works. 
1 Introduction 
A virtually linked knowledge base is designed to 
utilize a pre-constructed knowledge base in a dy-
namic mode when it is in actual use. 
An open-domain question answering architec-
ture must consist of various components and 
processes (Pas?a, 2001) that include WordNet-
like resources, part of speech tagging, parsing, 
named entity recognition, question processing, 
passage retrieval, answer extraction, and answer 
justification. Consider a question like the follow-
ing: ?Why do doctors cure patients?? 
The answer may be obtained by commonsense 
knowledge as follows: 
1. A patient suffered from a 
disease. 
2. A doctor cures the disease. 
3. The doctor cures at hospi-
tal. 
4. Doctor is an occupation. 
5. So the doctor cures the 
patient. 
These sentences are transformed into proposi-
tional forms, as illustrated below: 
6. sufferFrom(patient,disease) 
7. cure(doctor,disease) 
8. cure(doctor,at-hospital) 
9. occupation(doctor) 
10. cure(doctor,patient) 
Linguistic knowledge bases like WordNet 
(Miller, 1995), EDR dictionary (Yokoi, 1995) and 
HowNet (Dong, 1999) have been used to interpret 
these sentences. 
Moldovan et al (2002) generated lexical chains 
from WordNet in order to trace these topically re-
lated paths and thereby to search for causal expla-
nations. A conceptual word Cj inside of a gloss 
under a synset Ci is linked to the synset Cj.  
HowNet (Dong et al 1999) is a linguistic 
knowledge base that is designed to have the defini-
tion of words and concepts as well as event role 
and role-filling entities. Commonsense knowledge 
like naive physics is also built up through event 
role relation like the relation of sufferFrom requir-
ing cure. 
HowNet is modularized into separate knowl-
edge spaces for entity hierarchy, event hierarchy, 
antonymy, syntax, attributes, etc. Relations be-
tween various concepts (e.g., part-of, relevance, 
location) are defined implicitly in the definition of 
each concept. 
This paper will focus on building an algorithm 
that allows for searching for some topical paths in 
order to find causal explanations for questions like 
?Why do doctors cure patients?? or ?Why do pa-
tients pay money?? as illustrated in Figure 1. 
patient doctor occupation money
$cure *cure earn $earn
#occupation
converse
agent=patient
possession=money
target=?
agent=?
possession=money
source=patient
entity
syn
event
*pay $pay
give take
(1)
(2) (3)
(4)
(5)
(6)(7)
(8)
(9)  
Figure 1: A Snapshot of a virtually integrated 
knowledge base for the question: ?Why do patients 
pay money to doctors?? 
 
In the following sections, issues on the virtual in-
tegration of knowledge bases, their algorithms and 
experimentations are presented.  
2 Underlined Knowledge Bases and Vir-
tual Integration 
In Figure 1, each marked numbering has the fol-
lowing meaning: 
(1) Entity hierarchy: entity is the top node in 
the hierarchy of entities. 
(2) entity is the hypernym of patient, doctor, 
occupation, and money in the line (3). 
(3) Concepts or word entries are listed in this 
line. All concepts and word entries repre-
sent their definition by a list of concepts 
and marked pointers. 
(4) A concept (or word) in (3) features defini-
tional relations to a list of concepts. For 
example, a doctor definition is composed 
of two concepts and their marking point-
ers: #occupation and *cure. Pointers in 
HowNet represent relations between two 
concepts or word entries, e.g., ?#? means 
?relevant? and ?*? does ?agent?. 
(5) syn refers to the syntactic relation in the 
question ?Why do patients pay money to 
doctors?? 
(6) converse refers to the converse relation be-
tween events, e.g., give and take. 
(7) Event hierarchy: For example, the hy-
pernym for pay is give and the hypernym 
of give is event. 
(8) Event role: Now, event roles are partially 
filled with entities, e.g., patient and 
money. 
(9) Event role shift: The agent of give is 
equalized to the source of take. 
An overview of each component of the knowl-
edge base is in Figure 2, where three word entries 
why, patient, and money are in the dictionary. 
The four concept facets of entity, role, event, and 
converse are described in this example, mainly as 
part of linguistic knowledge. 
 
pay
give take
agent=
possession=
target=
agent=
possession=
source=
Alter-possession
patient
doctor occupation money
cure
*cure earn $earn
#occupation
entity
give take
converse
event
earn
human
pay
why
role
question
cause
dictionary Conceptfacets
 
Figure 2: HowNet Architecture in Example. 
 
Some issues on ontology integration have been 
discussed from various points of view. Pinto et al 
(1999) classified the notions of ontology integra-
tion into three types: integration, merging and 
use/application. The term virtually integrated 
means the view of ontology-based use/application. 
This paper presents issues on and arguments for 
linguistic knowledge base and commonsense 
knowledge in (Lenat, Miller and Yokoi, 1995). 
One of the arguments was whether linguistic 
knowledge could be separated from commonsense 
knowledge, but it was agreed that both types of 
knowledge were essentially required for natural 
language processing. 
This paper was motivated by the desire to make 
inferences using a lexical knowledge base, thus 
successfully carrying out a kind of commonsense 
reasoning. 
3 Interpretation of Lexical Knowledge 
Consider the following three sentences: 
11. Doctors cure patients. 
12. Doctors earn money. 
13. Patients pay money. 
One major concern is finding connectability 
among words and concepts. As shown in Figure 2, 
the following facts are derived: 
14. Doctor is relevant to oc-
cupation. 
15. Occupation allows you to 
earn money. 
Because there exists a converse relation be-
tween give and take, their hyponyms earn and pay 
also fall under converse relation. It is something 
like the following social commonsense as shown in 
Figure 2: ?If someone X pays money to the other Y, 
Y earns money from X.? 
We humans now understand the reason for 
?why patients pay money.? The answer is that 
?doctors cure patients as their occupation allowing 
them to earn money.? 
The following is a valid syllogism where Y is 
being instantiated to doctor: 
 
If ?X pays money to Y? is 
equivalent to ?Y earns money 
from X?1, and ?a doctor earns 
money from X?, then ?X pays 
money to the doctor?. 
 
Consider the next syllogism: If ?a doctor 
cures X? and ?doctor is an occupa-
tion? and Axiom 1, then ?the doc-
tor earns money from X?. 
Axiom 1 is needed to make such a syllogism 
that ?If Y cures X and Y is an occu-
pation, then Y earns money from 
X.? Then our challenge is to find out this Axiom 
1 from the lexical knowledge bases. It is a com-
monsense and thus there is a gap in the lexical 
knowledge base. 
The following is a list of questions derived 
from the three sentences of 11, 12 and 13 which 
are designed to discover such axioms (or rules) 
from a set of lexical knowledge bases: ?Why do 
                                                           
1 It is a converse relation. 
doctors cure patient??, ?Why do doctors earn 
money??, and ?Why do patients pay money to doc-
tors?? 
4 Connectability: Similarity Measure  
Consider the query ?Why do doctors cure pa-
tients?? Tracing Figure 2 back through Figure 1 
leads to obtaining logical forms from 6 through 10. 
The best connectable path is planned from the first 
word of the question. 
For each pair of words, the function called 
"similar(*,*)" will be estimated to choose the next 
best tracing concepts (or words).  similar's mis-
sions are summarized as (1) checking the connect-
ability between two nodes2, (2) selecting the best 
sense of the node,3 (3) selecting the best tracing 
candidate node in the next step. Finally, following 
the guidance by similar allows us to explain the 
question. 
4.1 Observation and Evidence of Topical Re-
latedness 
Let's try to follow the steps 6-10 given in the logi-
cal forms. In the question ?Why do doctors cure 
patient?? that focuses on three words doctor, cure, 
and patient, we can trace some key words given in 
example sentences as follows: patient ~ disease ~ 
cure ~ doctor ~ occupation ~ earn ~ pay ~ pa-
tient. 
What kind of lexical relations are relevant to 
each pair of words or concepts? Their observation 
can be summarized as follows: 
A) The relation between patient ~ disease is a 
role relation of ?sufferFrom(patient, dis-
ease)?. 
B) A sequence of cure ~ doctor ~ occupation 
~ earn lets us infer the relation among 
cure ~ earn, which are closely linked by 
their relevance relation to occupation. 
Furthermore, earn and cure shares a 
common subject of these two events. 
C) The sequence of earn ~ pay is the result of 
a converse event relation between earn 
and pay. 
D) pay ~ patient: The agent of pay is a ge-
neric human. In other words, pay is a hy-
                                                           
2 A node means either concept or word. 
3 It is similar with word sense disambiguation. 
ponym for the act of human, one of whose 
hyponym is patient. 
Consider again the match between the tracing 
sequences of concepts and the knowledge base. 
Going into more details, notations with footnotes 
will be given to each example. At this point, we 
will give names and formalization based on the 
observed characteristics. 
A) Feature comparison: To find the role re-
lation among patient ~ disease, search the 
definition of entities (referring to patient 
and disease) in ways that two entities share 
the same event concept (referring to 
cure):4 
patient ? human?$cure ?*sufferFrom. 
disease ?  medical?$cure ? undesired. 
B) Interrelation: To find the event interrela-
tion among cure ~ earn, two possible 
paths are presented as follows. 
? First, inverse interrelation: Two event's 
role entities can be found by searching all of 
entities using *earn ~ *cure that share the 
same subject, and using *earn ~ $cure 
where the subject of earn is the object of 
cure. 
? Second, sister interrelation: The following 
logical form can be derived from Figure 2:5 
doctor ? *cure ? #occupation. 
occupation ? earn. 
Because cure and occupation is in the defi-
nition of doctor, a probable logical implica-
tion can be derived as follows:6 
*cure ? ~#occupation. 
C) Converse/antonymy: earn and pay have 
their respective hypernyms take and give. 
There exists a converse relation between 
these two hypernyms. 
                                                           
4 According to HowNet convention, ?$? represents patient, 
target, possession, or content of an event, and ?*? represents 
agent, experiencer, or instrument. ??? means implies or has 
features. 
5 ?#? means ?relevant?. 
6 ?~? means ?very probable?. 
D) Inheritance: The relation among pay ~ 
patient is represented as follows:7 
humanpatient
acthuman
actpay
p
p
*?  
4.2 Rationale of Connectability 
In the former section, we summarized four charac-
teristics8 of causality (relatedness)-based path find-
ing: feature comparison, interrelation, 
converse/antonymy in their hypernym?s level, and 
inheritance. Among search spaces available, it is 
necessary to find out a measure of guiding the op-
timal9 path tracing. 
We will call such a measure similar which will 
be defined according to the four characteristics just 
mentioned. Further details about the calculation 
formula will be presented again later. 
A) For ?feature comparison?, the measure fea-
ture similar(X,Y) defines the notion of 
similarity between the features in X and Y.  
B) There are two interrelations in the last sec-
tion. 
? For ?inverse interrelation?', inverse simi-
lar(X,Y) calculates how much similarity ex-
ists between X? and Y? in a manner that X? 
= {Z | Z ? ?X}, where ?X is an abstraction 
of role-marked concepts like *X, $X, #X, 
etc. Thus inverse similar(X,Y) = simi-
lar(X?,Y?). 
? For ?sister interrelation?, the measure sister 
similar(X,Y) means the following two situa-
tions: First, X and Y are features to define 
one concept (say, W). Second, one of them, 
say, Y's definitional feature concepts (refer-
ring to Z) are similar with X such that X and 
Z are similar if W ? X ?Y and Y ? Z. 
C) Converse or antonymy: The converse re-
lation converse(X,Y) can be found by the 
measure feature similar. converse(X,Y) is 
formulated by X ? ?Y and Y ? ?X where 
? = converse. 
                                                           
7 ? YX p ? means ?Y is hypernym of X?.  
8 Their exhaustiveness should be discussed later. 
9 ?optimal? will not be discussed. 
D) Using inheritance property in the concept 
hierarchy, relations between hypernym of 
concepts X and Y are inherited to X and Y 
in a way that X and Y is similar if there 
exist X? and Z such that 'XX p , Z ? ?X?, 
and ZY p  where ? is a pointer or null. 
This inheritance tracing can be determined 
by how much similar X and Y are in terms 
of their path upward based on the relation 
of hypernym. We will define path similar. 
But tracing the path upward following hy-
pernym links is to be described later ac-
cording to the algorithm. 
A measure called similar will be defined based 
on the discussion in this section. Then an algorithm 
is introduced through this measure with an exam-
ple. 
5 Measures 
In the last section, we discussed four kinds of the 
measure similar. 
? path similar, 
? feature similar, 
? inverse similar, 
? sister similar. 
For feature, inverse, and sister similar func-
tions, path similar is used as a basis of calculation. 
They are different with respect to both their search 
method and the depth of expanding features. fea-
ture similar finds similar features by using path 
similar. inverse similar(X,Y) searches for entries 
that contain X and Y as features and then use the 
path similar. In the same way, sister similar finds 
sister concepts, expands them, and finally meas-
ures using the path similar. 
Since path similar plays a key role in all these 
search and measure processes, its role will be ex-
plained in the next subsection. Other measures are 
only dealt with as part of the algorithm. 
5.1 Similarity Based on Hierarchy and Fea-
ture 
The mission of the measuring function simi-
lar(X,Y) is to calculate their relevancy between 
two concepts or words whether they are of type 
entity, event, or of some other type. 
If X and Y belong to different types of knowl-
edge plane (e.g., entity and event), it is hard to 
compare their hypernym path upward to the top 
concept. However, if different types of concepts 
have any relevance to (connect) causality, we will 
use feature similar or inverse similar after find-
ing the same type of concepts to calculate the path 
similar. Now we will explain the above by using 
two pairs of concept type: entity-entity and entity-
event, without loss of generality. 
First, pathsimilar(entity X, entity Y) is de-
fined as follows: 
)()(
)()(2
),(
YpathXpath
YpathXpath
YXrpathsimila
++
++
+
??=  
where path+(X) is the ordered list of hypernym for 
X by descending order from the top concept. For 
example, 
path+(doctor)  
= [entity...animate...human.doctor] 
path+(patient)  
= [entity...animate...human.patient] 
Because |path+(X)| counts the number of nodes on 
the path, pathsimilar(doctor,patient) = 2? 
6/(7+7)=0.857. 
Second, pathsimilar(entity N, event V) is de-
fined as follows: 
pathsimilar(N,V)  
= Max pathsimilar(N.feature,V) 
where N.feature means the feature list in the defi-
nition of N. The following is an illustrative exam-
ple for the definition: 
money ? $earn,*buy,#sell, $setAside, 
it is equivalent to the following:  
money.feature=[$earn,*buy,#sell,$setAside]. 
So pathsimilar(money,earn)=pathsimilar(earn,earn) 
=1. According to this Max function, the selection 
priorities for the path can be specified. 
Third, pathsimilar(event V, entity N) is de-
fined by inverse similar as follows: pathsimi-
lar(V,N) = Max pathsimilar(V.inverse, N).  For 
example, pathsimilar(cure, doctor) = Max path-
similar(cure.inverse, doctor) = Max pathsimi-
lar({doctor, medical worker, medicine, patient}, 
doctor). 
Fourth, pathsimilar(event X, event Y) shares 
the same formula with pathsimilar(entity X, en-
tity Y) shown before. But, we can give another 
inverse pathsimilar(event X, event Y) = Max 
pathsimilar(X.inverse, Y.inverse). 
5.2 Logical Implication and Expansion Depth 
All of the relations in Figure 2 are translated into 
logical form (see below). As shown in ?Interpreta-
tion as Abduction? (Hobbs et al 1988), ?abductive 
inference is inference to the best explanation?. 
These relations showed ?the interpretation of a text 
is the minimal explanation of why the text would 
be true? based on the abductive inference. By the 
same token, ?the interpretation of a question is the 
minimal explanation of why the question would be 
true? based on a set of lexical knowledge bases. 
Before proceeding to our algorithm, an example 
will be applied to abductive inference briefly as a 
set of logical forms as well as a diagram in Figure 
3. 
16. doctor ? human, #occupation, 
*cure, medical. 
17. medicine ? *cure. 
18. disease ? $cure. 
19. cure ? medical, 
{agent,patient,content}. 
20. medical ? #cure. 
21. converse(pay,earn) ? 
agent=source,  
target=agent. 
22. patient ? human,$cure. 
23. occupation ? affairs, earn. 
24. cause(cure,sufferFrom) ? 
patient=experiencer, 
content=content. 
25. possibleConsequence(cure, 
beRecovered) ?  
patient=experiencer,  
content=stateIni. 
 
While pursuing the path tracing enabling mini-
mal explanation, now we are going to propose       
a connectability measure similar such as 
?weighted abduction? (Hobbs et al 1988). As 
?likelihood estimation? is useful to consider a 
?bounded conditioning? (Russell & Norvig, 1995) 
in a belief network, the ?expansion depth? of simi-
lar will be useful for the explanation path tracing 
for the purpose of the minimal explanation of the 
question. 
commercial
$earn
*buy
#sell
$setAside
patient pay moneywhy
human
*sufferFrom
$cure
agent
content
source
payer*
money 
advanced$
doctor
give
hypernym
take
hypernym
occupation affirs
earn
human
#occupation
*cure
medical
inverse
converse
 
Figure 3: Virtual Linking for Causality 
 
The ?expansion depth level? of similar has two 
kinds of utilities: one is to find the minimal expla-
nation, and the other is to be dynamically adapt-
able to the level of interaction. This level of 
similar is defined as a function simi-
lar(Level)(X,Y) for X and Y, concepts or words in 
the following manner: 
? similar(0)=pathsimilar: they use only them-
selves and their hypernym path from X and 
Y.  
? similar(1)=feature_similar: they use their 
features that are expanded one more than 
similar(0). 
? similar(2)=inverse_similar 
? similar(3)=sister_similar 
=inverse_similar?feature_similar. 
Depending on what level of similar is chosen, 
the search paths may be changed. A snapshot up to 
similar(2) is given in Figure 4. 
 
 
Figure 4: Snapshot for similar(2). 
human
* sufferFrom
$cure 
doctorcure patient why
human
#occupation
*cure
medical
agent 
patient 
content 
medical 
medicine* 
disease& 
medical# 
 ne* 
se$ 
l# 
6 Tracing Algorithms 
6.1 Algorithm Crossover 
The overall algorithm 10  flow depends on simi-
lar(Level) as in the next program. 
Algorithm Crossover 
For Level=0...N until stopping 
condition is satisfied: 
   Expand the trace  
by similar(Level) 
For example, when Level=1, the algorithm cross-
over finds a very primitive answer to the question 
?Why do doctors cure patients?? We will expand 
other features of doctor except for cure because 
cure has a syntactic relation between doctor and 
patient. 
As shown in the logical forms (16~24) intro-
duced in the previous section, this algorithm in 
Level=1 can find the following concepts as a re-
sult: medical, human, cure ($cure, *cure). 
When Level=2, the algorithm crossover will 
seek higher-order relations (like the hypothesis) 
from the concept (by inverse_similar), con-
verse/antonymy relations (by feature_similar), 
and    event relations (if any, for use in knowing 
the cause or consequence relation). Consider again 
our example "Why do doctors cure patients?" by 
using the previous section's logical forms. The re-
sults are as follows: 
*cure = {doctor, medicine} 
$cure = {patient, disease} 
*sufferFrom = {patient} 
$sufferFrom = {disease} 
Its generated meaning may be ?If a doctor cures a 
patient, the patient is recovered from disease.            
Because patients suffer from diseases, doctors cure 
the patients. Patients are recovered after getting 
cured.? 
6.2 Stopping Condition 
Stopping conditions for the algorithm crossover 
are as follows: 
(1) Event roles are filled up. 
(2) If no event is found in the feature defini-
tion, increase similar level. 
                                                           
10 This algorithm will be called ?crossover?. 
(3) [weak stopping condition] When there is 
no event, one of the other features is com-
monly shared between two concepts. For 
example, medical is a common feature be-
tween doctor and cure. 
6.3 Hypernym Climbing 
In section 4.2, inheritance was discussed for the 
purpose of finding a relation among pay ~ patient. 
After trying to make Level=2 in section 5.2, we 
have been motivated to find the interrelation be-
tween hypernyms. The algorithm crossover is up-
dated. 
Algorithm Crossover+ 
For Level=0..N until stopping 
condition is satisfied: 
Expand the trace  
by similar(Level) 
If Level >= 2, then 
repeat climb up hypernym 
until it matches with  
the higher relation. 
6.4 Algorithm Crossover++ 
Consider again the question "Why do patients pay 
money to doctors?" As shown in Figure 1, the best 
trace is $cure ~ *cure ~ *earn ~ $pay. It provides 
an explanation for the statement that ?patients are 
cured by doctors ~ doctors earn money ~ patients 
pay money to doctors?. This minimal explanation 
is observed by switching over the role pointers ? 
whenever tracing is performed. For example, 
$cure was switched over to *cure. This extended 
version of algorithm is called Crossover++. 
7 Evaluation 
By the algorithm Crossover?s, the behavior of 
?why?-type questions are investigated by extract-
ing the answer paths as follows. 
Q: Why does patient pay money?  
Path: patient ~ $cure ~ doctor ~ #occupation ~ 
$earn ~ money 
Q: Why does researcher read textbook? 
Path: researcher ~ #knowledge ~ #information ~ 
readings ~ textbook 
Paths between two concepts can now be found 
by simply checking the presence of a path among 
the concepts reached from an initial concept. Table 
1 and Table 2 show examples of the number of 
paths as a function of path size.  
 
Reached concepts path size Source 
concept 1 2 3 
cure 275 593 24854 
eat 268 605 24903 
study 276 358 23172 
food 532 650 18066 
human 6713 3686 51171 
money 328 1312 19827 
Table 1: Examples of destination concepts reached 
starting from one source concept  
 
Paths number length Concept1 Concept2 1 2 3 
cure human 0 78 26 
pay money 0 7 3 
human money 0 3 7 
food human 0 0 28 
read write 0 4 6 
earn pay 0 0 7 
Table 2: The number of paths between pairs of 
concepts 
8 Discussion 
HowNet (Dong et al 1999-2003) has already de-
fined the words and concepts using the features of 
concepts. Each event role is also defined under the 
notion of feature. On the other hand, WordNet 
(Miller, 1995) consists of synsets and their glosses. 
Moldovan et al (2002) showed a lexical chain to 
use words in glosses in order to trace the topically 
related paths.  
Their search boundary is restricted to the 
shapes: V, W, VW, and WW. In this paper, cross-
over* is shown to be flexible and search for a more 
probable explanation. 
9 Conclusion 
In this paper, we have attempted to show how to 
link pre-existing lexical knowledge bases to one 
another. The major issue was to generate a path to 
give explanation paths for answering the ?why?-
type question. While observing the causality path 
behavior, we proposed the measure similar and 
also the algorithm crossover. It is compared with 
the ?weighted abduction? (Hobbs et al 1988) and 
?lexical chain? (Moldovan et al 2002). 
With the ability to provide explanations de-
pending on the level of the measure similar, our 
proposed algorithm adapts itself to the user knowl-
edge level and well as to the type of interactive 
questions to enable more detailed level of ques-
tion-answering.  
References 
Zhen Dong and Q. Dong.  1999-2003. Hownet, 
http://www.keenage.com/ 
Jerry R. Hobbs, Mark Stickel, Douglas Appelt and 
Paul Martin. 1988. Interpretation as Abduction, 
Proceedings of the Conference on 26th Annual 
Meeting of the Assocation for Computational Lin-
guistics. 
Doug Lenat, George Miller, and Toshio Yokoi. 1995. 
CYC, WordNet, and EDR: Critiques and Re-
sponses, Communications of the ACM, 38(11):45-
48. 
Bernardo Magnini and Manuela Speranza. 2002. 
Merging Global and Specialized Linguistic On-
tologies, Proceedings of Ontolex 2002 (Workshop 
held in conjunction with LREC-2002), Las Palmas. 
George Miller. 1995. WordNet: a lexical database. 
Communications of the ACM, 38(11):39-41. 
Dan Moldovan and Adrian Novischi. 2002. Lexical 
Chains for Question Answering, Proceedings of 
COLING 2002, Taipei. 
Takanoa Ogino and Masahiro Kobayashi. 2000. Verb 
Patterns extracted from EDR Concept Description, 
IPSJ SIGNotes Natural Language Abstract, 
No.138 ? 006:39-46. 
Alexandru Marius Pas?a. 2001. High-Performance, 
Open-Domain Question Answering from Large 
Text Collections. Ph.D Dissertation, Southern 
Methodist University. 
H. Sofia Pinto, Asunci?n G?mez-P?rez and Jo?o P. 
Martins. 1999. Some Issues on Ontology Integra-
tion, Proceedings of the IJCAI-99 workshop on 
Ontologies and Problem-Solving Methods (KRR5), 
Stockholm. 
Stuart Russell and Peter Norvig. 1995. Artificial 
Intelligence: A Modern Approach. Prentice-Hall. 
Toshio Yokoi. 1995. The EDR Electronic Dictionary. 
Communications of the ACM, 38(11). 
