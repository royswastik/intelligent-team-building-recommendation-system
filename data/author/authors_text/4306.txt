Using Argumentation Strategies in Automated Argument 
Generation 
I ngr id  Zukerman,  R ichard  McConachy  and  Kev in  B .  Korb  
School  o f  Computer  Science and  Sof tware  Engineer ing 
Monash  Un ivers i ty  
C layton ,  V ic tor ia  3800, AUSTRAL IA  
emai l :  { ingr id ,  r i cky ,  korb}@csse ,  monash,  edu .  au 
Abst ract  
During argumentation, people persuade their au- 
dience using a variety of strategies, e.g., hypo- 
thetical reasoning, reasoning by cases and ordinary 
premise-to-goal rguments. In this paper, we of- 
fer an operational definition of the conditions for 
pursuing these strategies, and incorporate into a 
Bayesian argument-generation system a mechanism 
for proposing applicable argumentation strategies, 
generating specific arguments based on these strat- 
egies, and selecting a final argument. 
1 In t roduct ion  
During argumentation, people persuade their audi- 
ence using a variety of strategies, e.g., hypothetical 
reasoning, reasoning by cases and premise to goal. 
Although the use of different strategies i common in 
human argumentation, the argumentation and dis- 
course planning systems developed to date offer little 
insight into the problem of proposing different argu- 
mentation strategies and selecting among them. 
In this paper, we extend our previous work on 
argument generation (Zukerman et al, 1998; Zuker- 
man et al, 1999) to address this problem. In this 
extension, we provide an operational definition of 
promising conditions for pursuing different argumen- 
tation strategies, and incorporate the procedure for 
selecting an argumentation strategy into the content 
planning process. The integration of strategy selec- 
tion and content planning is necessary due to the 
interplay between argumentation strategy and con- 
tent: the strategy influences the content hat is rele- 
vant to an argument, while the information gathered 
early in the content planning process determines the 
applicability of the different strategies. 
The argumentation strategies discussed in this 
paper are premise to goal,.~hypothetiddl ~red~ctio" .... 
ad absurdum and inference to the best explanation) 
and reasoning by cases (exclusive and non-exclusive) 
(Figure 1). Premise to goal starts from believed 
premises and proceeds to the goal. Reductio ad ab- 
surdum assumes the negation of the goal, leading to 
an argulnent which results in a contradiction with 
a believed premise and requires the assertion of the 
Premise to goal: Corrective lenses are re- 
quired. 
"Being unable to see far objects is evidence for 
myopia, which indicates that corrective lenses 
are required." 
Reduct io  ad absurdum:  There has always 
been matter. 
"There could never have been a time when 
nothing existed, for, if there were \[hypotheti- 
cal assumption\], then nothing would exist now, 
since from nothing comes nothing." (from St. 
Thomas Aquinas) 
In ference  to the best  exp lanat ion:  Patient 
has the flu. 
"If she had the flu \[hypothetical assumption\], 
she would be tired, achy. and feverish, which 
are all true. Hence, she probably has the flu" 
Reason ing  by cases (exclusive):  There can- 
not be a utopian society. 
"Having checks on procreation leads to misery 
and vice, which in turn results in a non-utopian 
society. 
Having no checks on procreation leads to a pop- 
ulation explosion, which in turn leads to star- 
vation. This also results in a non-utopian soci- 
ety." (from Malthus, 1798) 
Reason ing  by cases (non-exclusive):  Fail- 
ing a test. 
"I don't know whether he is stupid or lazy. But 
either way, he is likely to fail the test." 
Figure 1: Examples of Argumentation Strategies 
goal to resolve this contradiction. Inference to the 
.best. explanation (Lipton,, 1991) assumes&he goal, 
leading to an argument hat supports a believed 
premise (which would be disbelieved in the absence 
~,of ,thia, assmnption)~ ~Reasoning,,by casesmnumerates 
a set of exhaustive conditions and establishes that a 
desired conclusion would follow regardless of which 
case is true. ~ In particular, we consider two types 
of reasoning-by-cases trategies: exclusive and non- 
1 Reasoning by cases is not related to case-based reasoning, 
which involves problem solving based upon some stereotypical 
case-  
55 
exclusive. The exclusive strategy is applicable to sit- choice, on argument persuasiveness. The mecha- 
uations where the belief in a proposition is unknown nisms developed by these researchers, which are ap- 
or not agreed upon by the conversational partners, plicable after an argumentation strategy has been 
In this case, two separate arguments for the goal are selected, are expected to complement our future in- 
generated, one assuming the truth of this proposi- vestigation on modeling the effect of rhetorical fac- 
tion and the other assuming its falsity. 2 The non- tots on an addressee's beliefs. 
exclusive strategy applies to situations where at least 
one of several propositions i  known to be true, but 3 The  Argument  Generat ion  Process  
it is not known which. This strategy produces epa- 
rate arguments in support o f  the goal, each of which The platform for our investigation is the argumenta- 
assumes the truth of one of these propositions, tion system NAG (Nice Argument Generator) (Zuk- 
In the following sectiiSfi,~we " discuss r~l~ged-"~~: ...... ~erma~:~ec.~etl.,.~.1998i..Zukermar~,.et. aL~A-999:)..NAG ... . . .  
search. Next, we present an overview of NAG's argu- generates nice arguments, that is, arguments that 
are both normatively correct and persuasive for a ment generation process. We then describe our pro- 
cedure for proposing argumentation strategies, and target audience. To this effect, it tests the effects 
for generating and selecting specific arguments. Fi- of prospective arguments on two models: (1) a nor- 
nally, we illustrate the operation of our mechanism mative model, which represents NAG's beliefs, and 
with an example, discuss results from our prelimi- (2) a user model, which represents a user's presumed 
beliefs. Each model incorporates a Bayesian net- nary evaluation and present concluding remarks. work (BN) (Pearl, 1988) as its main representation 
2 Re la ted  Research  formalism (BNs were chosen because of their abil- 
ity to represent normatively correct reasoning un- 
A general introduction to hypothetical reasoning, in- der uncertainty). An argument is represented as an 
cluding a discussion of counterfactual reasoning and Argument Graph, which is a network of nodes that 
modality, may be found in (Rescher, 1964). The represent propositions, and links that represent the 
use of suppositions in hypothetical reasoning to cre- inferences connecting these propositions. This Ar- 
ate reductio ad absurdum arguments i described in gument Graph is obtained from the structural in- 
(Freeman, 1991), and their use in the analysis of tersection of relevant portions of the normative and 
such arguments is discussed in (Fisher, 1988). Fis- user BNs. By considering the Argument Graph rel- 
cher also illustrates how suppositions can lead to ar- ative to both models we are able to assess both its 
guments that explain observed outcomes, a weaker normative correctness and its persuasiveness. 
version of inference to the best explanation. Condi- NAG receives as input a goal proposition to be 
tional argumentation, a weaker form of reasoning by argued for, an initial argument context, and a tar- 
cases, where not all the cases must be examined and get range for the belief to be achieved in the goal 
the beginning of each case does not have to be proven (as a result of the argument) in the user model BN 
within the argument i self, is described in Freeman's and the normative model BN. Initially, the context is 
work. These works provide theoretical insights into composed of the goal proposition and salient propo- 
the field of dialectics. However, they do not present sitions and concepts mentioned in the preceding dis- 
implementable computational mechanisms, cussion. During argument generation, the context is 
In the area of discourse planning, few systems expanded to include the current Argument Graph. 
deal with the selection of argumentation strategies. Figure 2 shows the main modules of NAG (the 
Cerbah (1992) considers three discourse strategies: modules in double boxes contain the new argulnen- 
CausaIChain, which is a special case of our premise tation strategy mechanisms). After receiving a goal 
to goal strategy'; Parallel, which assigns a paral- proposition, the Strategist activates a sequence of 
lel structure to part of the text.; and Concessive. focusing-generation-analysis cycles as follows. First: 
These strategies reflect specific patterns of argumen- the Attentional Mechanism is invoked to focus on 
ration which may be incorporated in our higher level parts of the normative and user BNs that are likely 
strategies. Elhadad (1995) considers the use of at- to be useful in the argument. This is performed by 
gumentative features at several stages of the dis- spreading activation from the initial context. This 
course planning process, but none of his stages deals process generates an initial Argument Graph, and in 
with high-level argumentation.st.mtegies...Reed and . . tater~ cycles extends-the exist ing ArgumentGraph.  
Long (1997) use ordering heuristics to model the el- The Strategist hen calls the Generator to continue 
fect of presentation order on argument persnasive- the argument building process by finding additional 
ness, and Mareu (1996) considers the effect of vari- information to incorporate in the Argument Graph 
ous stylistic factors, including ordering and lexical (Zukerman et al, 1998). The extended Argument 
2The generalization of this strategy to N propositions re- Graph is returned to the Strategist,  which invokes 
quires the presentation of 2 \" cases: in the current implemen- the Analyzer to deternfine the beliefs in the uodes 
tation, only individual proposit.ions are considered, in the Argnnlent Graph under a variety of condi- 
56 
Argument 1 H Argu~ 
Generator | , ~....A.m,al,yzer 
- - ' - ' -~- ' -~  Argument ~ Argument 
? ~ Goal Analysis ~ a  . . . . . . .  ~",.....~A n aly sis 
Argument ~"'-,.,,,,P ro p osi t ion s / /  ~k~u-,y,~ ~ 
, Mechanism, 
Figure 2: System Architecture 
tions (Section 4.1). The Analyzer uses a constrained 
Bayesian propagation scheme on the normative and 
user BNs, limiting the updates to the subnetworks 
represented in the Argument Graph. For the pur- 
poses of Bayesian updating, propositions which are 
provided in the preamble are treated as "observa- 
tions"; that is, their degrees of belief are used as 
sources during Bayesian propagation. Based c,n the 
beliefs resulting from the Bayesian propagation, the 
Strategist determines which argumentation strate- 
gies are worth pursuing (Sections 4.2 and 4.3). If no 
strategy ields a nice enough argument, i.e., the be- 
lief in the goal is outside the target range in one or 
both models, the context is expanded, and another 
generation-analysis cycle is performed: the Strate- 
gist re-activates the focusing mechanism, followed 
by the re-activation of the Generator and then the 
Analyzer. This process iterates until a successful 
Argument Graph is built, or NAG is unable to con- 
tinue, e.g., because it failed to find further evidence. 
If one or more strategies yield a nice enough ar- 
gument, the Strategist selects one of the more con- 
cise arguments (Section 4.4). The corresponding Ar- 
gument Graph and an ordering of the nodes to be 
presented are then passed to the Presenter, which 
removes easily inferred propositions from the argu- 
ment. After each removal, the Presenter activates 
the Analyzer to check whether the argument remains 
nice enough, and the Attentional Mechanism to de- 
termine whether the argument can still be followed 
by the user. After the Presenter determines that no 
more propositions can be removed from the argu- 
ment, it extracts Bayesian reasoning patterns from 
the final Argument Graph and passes them to the in- 
terface, which renders the argument in English (Zuk- 
erman et al, 1999). 
This procedure is implemented by the following 
algorithm, which is executed by the Strategist) 
aA previous version of this procedure which generates only 
premise-to-goal arguments is described in (Zukerman et al, 
1998). In this paper, we focus on Steps 4 and 5, which have 
been modified to support the consideration of different argu- 
mentation strategies during the content planning process. 
Generat ion -Ana lys i s  A lgor i thm 
1. Perform spreading activation starting from the 
items in the current context. 
2. Identify new subgoals in the current Argument 
Graph. 
3. Pass the subgoals identified in Step 2 to the 
Generator, which adds to the current Argument 
Graph new information related to these sub- 
goals. 
4. Pass the Argument Graph generated in Step 3 
to the Analyzer for evaluation under different 
conditions. 
5. If (based on the Analyzer's report) some of the 
argumentation strategies eem promising then 
(a) Inspect specific arguments based on these 
strategies, and 
(b) Pass to the Presenter the portion of the Ar- 
gument Graph corresponding to a concise 
argument which achieves the intended be- 
lief in the goal. 
6. Otherwise, add to the current context new 
nodes that were connected to the goal or be- 
came salient during this cycle, and go to Step 1. 
4 Us ing  Argumentat ion  S t ra teg ies  
During the argument generation process, the Strat- 
egist performs the following actions: (1) determine 
the potential applicabihty of the different .argumen- 
tation strategies based on the beliefs in the nodes 
in the Argument Graph, (2) propose specific candi- 
dates for each apphcable.strategy, and. (3) select a 
concise argument among these candidates. 
4.1 Ant ic ipat ing  the effect  o f  a node  
The Strategist selects an argumentation strategy 
based on the Analyzer's assessment of the effect of 
the nodes in the Argmnent Graph on the goal propo- 
sition (and vice versa). This effect is determined by 
means of a constrained Bayesian propagation scheme 
57 
2" 
in both the user model BN and the normative model 
BN. Specifically, for each node a t  the '!edge" of the 
Argument Graph, each new node (i.e., one added 
in the last generation step), and each previous node 
to which new links were added in the last step, the 
Analyzer calculates its positive and negative ffect 
on the goal, and the positive and negative ffect of 
the goal on this node. 4 The positive~negative effect 
of a node X on a node Y is the hypothetical be- 
lief in node Y after propagating a high/low belief in 
node X (which represents a true/false belief in the 
corresponding proposition). TheTositive/negative 
effect of a node on the goal is required to generate 
arguments by cases, and the positive/negative effect 
of the goal on a node is required to generate hy- 
pothetical arguments, viz reductio ad absurdum and 
inference to the best explanation. When computing 
positive/negative effects for a particular node, the 
Bayesian propagation process uses the prior beliefs 
of the other nodes in the Argument Graph. 
4.2 Determin ing  app l i cab le  a rgumentat ion  
s t ra teg ies  
After receiving the Analyzer's report, the Strategist 
checks the following conditions to determine the po- 
tential applicability of each argumentation strategy. 5 
Reductio ad absurdum - The negation of the goal 
G undermines a proposition Q which is firmly 
believed independently of the goal (i.e., P(Q) = 
High, where Q is a premise or inferred from 
premises). Hence, P(QI~G) = Low (where Q is 
temporari ly treated as if it were not a premise, 
so that its value may change when the goal is 
negated). 
Inference to the best explanation - The assertion 
of the goal G supports a proposition Q which 
is firmly believed (i.e., P(Q) = High, where 
Q is a premise or inferred from premises), but 
which would be unexplained (improbable) with- 
out supposing the truth of the goal. Hence, 
whereas P(Q\[G) = High, in the absence of in- 
formation about G, the belief in Q is low (where 
Q is temporarily treated as if it were not a 
premise). 
Reasoning by cases (exclusive) - A proposition Q 
satisfies one of the following conditions: (1) it 
has-an indeterminate l vel of belief in both the 
normative and user models (i.e., its probability 
is within an interval \[0:5=t:O\]); or (2)it has highly 
4Previous nodes with new links are reconsidered because 
their effect on the goal node (and tile goal node's effect on 
them) is more likely to have changed ue to these links than 
the effects of nodes with an unchanged local topology. 
5For clarity of presentation, these conditions and the sub- 
sequent discussion assume apositive bias, i.e., the proposition 
under consideration is believed: for a negative bias some ex- 
pressions will be altered accordingly. 
divergent levels of belief in the user model and 
the normative model.,: For either condition, the 
belief in the goal must be high both when a high 
level of belief is ascribed to Q and when a low 
level of belief is ascribed. 
Reasoning by cases (non-exclusive) - There ex- 
ists a set of propositions {Q1,..-,Q,~}, each 
of which leads to a strong belief in the goal 
(i.e., P(GIQi ) = High for i = 1 , . . . ,n ) ,  and 
the disjunction of these propositions i strongly 
bel ieved (i.e., P(Vi  Qi) :--High) "6 . . . . . . . . .  
Premise to goal- This is the default strategy and 
requires only that given the current beliefs in 
the premises, the belief in the goal will be in 
the target range in both the normative and user 
BNs. 
Since the conditions for the reasoning by cases 
strategies consider nodes in the Argument Graph 
separately, they do not guarantee that all opportu- 
nities to argue by cases will be found. For instance, 
two particular nodes may not satisfy the conditions 
for the exclusive strategy when considered separately 
(because when a node is ascribed a high or low level 
of belief, the prior beliefs of the other nodes are used 
for Bayesian propagation). However, when consid- 
ered jointly, the four permutations ofextreme beliefs 
in these nodes, viz high-high, high-low, low-high and 
low-low, may satisfy the applicability conditions of 
the exclusive strategy. At present, these opportuni- 
ties are missed by NAG. However, this may be an 
appropriate outcome, since such complex arguments 
by cases are quite rare. 
4.3 P ropos ing  specif ic a rguments  for each 
s t ra tegy  
In this step, the Strategist considers the propositions 
or sets of propositions that satisfy the conditions for 
each applicable argumentation strategy, and gener- 
ates a specific argument based on each of these prop- 
ositions (or sets of propositions). This is done as 
follows for each argumentation strategy. 
Reduct io  ad absurdum and In ference to the  
best  exp lanat ion .  For each proposition Q which 
satisfies the conditions for reductio ad absurdum, the 
Strategist extracts from the Argument Graph the 
? subgraph whicbcorresponds to the line of reasoning 
going from the goal node (which was ascribed a low 
level of belief) to Q (which has been contradicted 
6This situation may be generalized so that any Qi consists 
of a subset of propositions which lead to the goal. However, 
in the current implementation, each Qi consists of one propo- 
sition only. Further, owing to practicality considerations, at
present NAG implements a limited version of the applicability 
conditions for the non-exclusive strategy whereby only pairs 
of nodes that are relatively close to tile goal and to observable 
nodes are inspected. This last requirement is necessary inor- 
der to determine which combinations of beliefs are possible 
for the inspected pairs of nodes. 
58 
as a result of this line of reasoning). Each line of When choosing its final argument, the Strate- 
reasoning is obtained by  treating themegation of;the: .: ~. gis.t considers;only~=ice arguments, i.e., those that 
goal as a premise and ~Q as a goal. 
A similar process is applied for the inference to the 
best explanation strategy, but the goal is ascribed a 
high level of belief, and Q is expected to achieve a 
high level of belief as a result of the argument. In 
general, when using the reductio ad absurdum strat- 
egy, people identify only one target proposition to 
be contradicted when the goal is negated. In con- 
trast, for inference to the best explanation, the goal 
is often used to explain several propositions. In the 
current implementation, only one target proposition 
is being considered for both strategies. 
Reason ing  by cases (exclus ive) .  If proposition 
Q satisfies the conditions for the exclusive strategy, 
then a copy of the Argument Graph is made for the 
case where a high belief is ascribed to Q and another 
copy is made for the case where a low belief is as- 
cribed to Q. Both copies have the same structure, 
but the propagated values are different. The argu- 
ment by cases consists of a pair of Argument Graphs, 
one graph for each case. These graphs do not re- 
quire further analysis, since the results of propagat- 
ing these beliefs through the Argument Graph were 
previously returned by the Analyzer (Section 4.1), 
and according to the applicability conditions for the 
exclusive strategy, the argument for each case is suf- 
ficiently nice. 
Reasoning by cases (non-exc lus ive) .  If a set 
of nodes {Q1,---,  Qn } satisfies the applicability con- 
ditions of the non-exclusive strategy, an Argument 
Graph is generated for each of the n cases by ascrib- 
ing a high level of belief to each Qi in turn (the rest of 
the nodes retain their existing degrees of belief). If 
the Analyzer reports that the argument correspond- 
ing to each graph is sufficiently nice, an argument by 
cases is constructed by listing each graph in turn. 
Premise to goal. Finally, the Strategist considers 
a premise to goal argument by inspecting the belief 
in the goal in both the normative and user models 
after propagation from the premises (this belief was 
computed by the Analyzer). If the argument is nice 
enough, then it is retained as a possible candidate. 
If upon completion of this process, none of these 
argumentation strategies has yielded a nice enough 
argument, the reasoning context is updated with 
nodes that were connected to the goal or became 
salient during the current cycle. The Strategist then 
re-invokes the spreading activation process, and re- 
activates the Generator to expand the Argument 
Graph (Section 3). After expansion, the analysis 
and strategy proposal processes are repeated. If one 
or more candidate argunmnts were generated, the 
Strategist selects a concise argument as described in 
the next section. 
achieve a degree of belief in the goal which lies in- 
side the target range in both the user model and the 
normative model. However, we do not have a direct 
means for determining the belief in the goal in the 
user model as a result of a hypothetical rgument or 
an argument by cases. This is because the rhetori- 
cal force of these strategies affects the user's beliefs 
in a manner that deviates from the effect modeled 
by means of  Bayesian propagation, as illustrated by 
the sample arguments in Section 5. The problem of 
incorporating a model of the rhetorical force of an 
argument into a Bayesian propagation scheme is yet 
to be addressed. Nonetheless, in order to test the op- 
eration of our mechanism, we currently approximate 
the effect of an argument (regardless of its strategy) 
on the user's beliefs by performing Bayesian propa- 
gation in the user model BN. In the future, as a first 
step in modeling rhetorical factors, we intend to in- 
vestigate how the beliefs in our user models deviate 
from users' actual (reported) beliefs. 
4.4 Selecting a concise argument 
Here the Strategist removes long arguments, o that 
a final selection is made among (shorter) arguments 
of similar length. 7 NAG does not simply select the 
most concise argument, because as shown in Sec- 
tion 6, the choice of strategy has a greater influence 
on the addressee's beliefs than any (small) remaining 
differences in argument length. 
The Strategist initially performs coarse pruning 
on the Argument Graphs that were generated by the 
premise to goal or reasoning by cases trategies. This 
coarse-grained pruning examines eparately the im- 
pact of each individual line of reasoning contribut- 
ing to the belief in the goal, removing entire lines 
that are not strictly necessary to achieve a belief in 
the goal that falls inside the target range (the ar- 
guments generated using the reductio ad absurdum 
and inference to the best explanation strategies are 
not coarsely pruned, since those arguments already 
comprise a single line of reasoning). Sometimes, the 
impact of certain lines of reasoning cannot, be as- 
sessed in isolation, since two or more lines may con- 
tribute jointly towards the belief in a proposition in a 
mutually dependent manner. Often however, some 
of the contributing lines of reasoning are indepen- 
dent or nearly so, and coarse pruning can proceed. 
Next, the Strategist drops from consideration the 
arguments that a re  significa~ntly longer than the 
shortest argument (where length is measured in 
number of nodes),8 and selects one of the remaining 
7Other factors, such as the structural complexity of the 
arguments, will be considered in the future. 
SAlthough an Argument Graph is further pruned before 
presenting its corresponding argument to the user (Section 3), 
it is reasonable toconsider lhe length of each candidate graph 
59 
(A benevolent and omnipotent) God exists j< , , \  . . . . .  
God is benevolent God is omnipotent 
(2) (3) 
1 1 
God wants to prevent evil God can prevent evil 
(4) (5) 
S 
? There- is evit~in'the~world . . . . . .  - ' 
(6) 
Figure 3: Argument Graph for the Problem of Evil 
arguments according to the following order of prefer- 
ence: reasoning by cases, premise to goal, inference 
to the best explanation and reductio ad absurdum. 
This ordering is consistent with the results of our 
evaluation (Section 6). 
5 Example  - The  Prob lem o f  Ev i l  
We now illustrate our argumentation mechanism 
with "The Problem of Evil". Given a preamble 
that establishes that there is evil in the world, and 
the goal to prove that there is no God, NAG ob- 
tains the Argument Graph in Figure 3 after one 
focusing-generation cycle, and produces the Argu- 
ment Graphs corresponding to the arguments in Fig- 
ure 4 (the adverbs that indicate level of belief and 
the conjunctive xpressions are italicized in the ar- 
guments for ease of comparison).9 These arguments 
are based on a definition of God that requires God 
to be both omnipotent and benevolent. 
P remise  to goal. Bayesian propagation of the be- 
lief in node 6 results in the denial of the combination 
of nodes 4 and 5, but yields a moderate probability 
for each of these nodes and for their respective par- 
ents, node 2 and node 3. Still, the probability of 
node 1 is quite low (i.e., there is a high belief in its 
negation). 
Reduct io  ad absurdum.  The conditions for re- 
ductio ad absurdum are also met by this Argument 
Graph. That is, the negation of the goal undermines 
the belief in the premise (the existence of evil). 
Reason ing  by cases (exclusive) .  The condi- 
tions for exclusive reasoning by cases are met by 
both node 4 and node 5, since they obtain mid- 
dling degrees of belief duringpropagation. We 'illus- ' - 
trate here only the argument which hinges on node 4 
(the argument which hinges on node 5 is symmetri- 
cal). The two cases in the generated argument are: 
at this stage, because it is indicative of the length of the 
argument  obtained after finer pruning. 
9The English versions of these arguments  were hand gen- 
erated from NAG's output.  
node 4 is true or node 4 is false. The case which 
......... assumes.:the.negation.ofr~ode 4 leads:to a.straight~ 
forward argument hat achieves the goal. The case 
which asserts node 4 achieves the goal through an 
explain away relationship which involves nodes 4, 5 
and 6 (Pearl, 1988). This relationship requires that ? 
P(61-~4) > P(6) and P(61-~5) > P(6), which means 
that the negation of nodes 4 and 5 are potential ex- 
planations for node 6, and that P(416 & 5) < P(416) 
and P(516 & 4) < P(516), which means that given 
node 6, node 5 explains away node 4 and vice versa 
(Zukerman et al; "'1999)':" -'Tl~at is~ ~ ~'sei~ir/g':'the " 
proposition in node 5 in light of node 6 greatly weak- 
ens the belief in node 4. 
Reason ing  by cases (non-exc lus ive) .  The 
Strategist identifies nodes 4 and 5 as possible sources 
for a non-exclusive argument by cases, since the 
negation of each of these nodes leads to a strong 
belief in the goal, and P(-~4 V-~5) is high (because 
of their relation to node 6). The cases in the gen- 
erated argument are: node 4 is false or node 5 is 
false. 
Since all these arguments are nice, the Strategist 
retains all of them for further processing. As stated 
in Section 4.4, the arguments that are substantially 
longer than the shortest argument (in number of 
nodes) are dropped from consideration. In our ex- 
ample, the premise to goal argument is the short- 
est, as it threads a path through the 6 nodes in the 
Argument Graph; the exclusive reasoning by cases 
argument is the longest, requiring 9 nodes (3 for 
the case where node 4 is false, 5 for the case where 
node 4 is true, and 1 for stating the conclusion); the 
non-exclusive reasoning by cases argument requires 
8 nodes (3 for each case, 1 for node 6, which in- 
troduces the cases, and 1 for the conclusion); and 
the reductio ad absurdum argument requires 7 nodes 
(the 6 nodes in the Argument Graph plus 1 node for 
stating the conclusion). The exclusive reasoning by 
cases argument is dropped from consideration since 
it is 1.5 times longer than the shortest argument, 
and the non-exclusive argument is select.ed among 
the remaining arguments by applying our preference 
ordering. 
6 P re l iminary  Eva luat ion  
In order to determine the users' preferences Yor dif- 
ferent argumentation strategies, we performed a pre- 
liminary evaluation where we presented two sets 
of arguments to subjects.  One set contained the 
premise to goal and reasoning by cases arguments 
for the problem of evil shown in Figure 4. The sec- 
ond set contained a preamble which presented some 
background information, and a premise to goal, a 
reductio ad absurdum and an inference to the best 
explanation argument for a large asteroid striking 
Earth 65 million years BC (Figure 5). The argu- 
60 
Premise to goal: I 
"Evil in the world (6) implies.that God may not want to prevent evil (-~4) and that GQd:maynot ........ I 
be able to preveiat- egil (-45). God possibly not wantingto prevent evil (-~)t) im~liesthdl~ God ?ndb, 
not be benevolent (-~2). God possibly not being able to prevent evil (--,5) implies that God may 
not be omnipotent (-~3). The fact that God may not be benevolent (-~2) and ,that God may not 
be omnipotent (-~3) implies that it is very likely that God does not exist (-,1).' 
Reductio ad absurdum: 
"Assume that God exists (1). This implies that God is benevolent (2) and that God is omnipotent 
(3). God being benevolent (2) implies that God wants to prevent evil (4). God being omnipotent 
(3) implies that God can prevent evil (5).  The fact that Godwants  to prevent evil (4) and that 
God can prevent evil (5) implies that there is no evil in the world (-~6). But there is evil in the 
world (6): ,Therefore~.Go:d:doesmot exist." 
Reasoning by cases  (exclusive): 
"Consider the following cases: God wants to prevent evil (4), and God does not want to prevent 
evil (--14). 
God wants to prevent evil (4). This, together with the existence of evil (6) implies that God is 
not able to prevent evil (~5), which in turn implies that God is not omnipotent (-~3). This implies 
that God does not exist (~1). 
God does not want to prevent evil (~4). This implies that God is not benevolent (-~2), which in 
turn implies that God does not exist (~1). 
Either way, God does not exist (-~1)." 
Reasoning by cases (non-exclusive}: 
"Since there is evil in the world (6), God does not want to prevent evil (-~4) or God cannot prevent 
evil (-~5). 
God does not want to prevent evil (-,4). This implies that God is not benevolent (~2), which in 
turn implies that God does not exist (~1). 
God cannot prevent evil (-~5). This implies that God is not omnipotent (-~3), which in turn implies 
that God does not exist (-11). 
Either way, God does not exist (--1)." 
Figure 4: Arguments 
ments in each set were presented in two different 
orders. 40 subjects read the 'problem of evil' ar- 
guments, and 35 the 'asteroid' arguments. In the 
former set, the distribution of preferences was uni- 
form among the three strategies. In the latter set, 
premise to goal was preferred, followed by inference 
to the best explanation and then reductio ad absur- 
dum (these results, which were not affected by the 
order of presentation, were supported by X 2 tests 
which were significant at the 0.01 level). 
At first glance it appears that premise to goal 
is the preferred argmnentation strategy. However, 
the participants' comments indicate that further ex- 
periments are required to determine the conditions 
under which different argumentation strategies are 
appropriate. For exarnple,several participants in: 
dicated that reductio ad absurdum arguments are 
appropriate when the ensuing contradiction is com- 
pelling, which tile3" did not find to be the case in the 
asteroid example. Further. they stated that they 
liked the premise to goal argument because it con- 
tained inorc information than the other argunmnts 
(which have one line of reasoning only). However. 
for the Problem of Evil 
this additional information may be less appealing 
for arguments that are longer than one paragraph. 
7 Conc lus ion  
We have offered an operational definition of the 
conditions for pursuing three types of argumenta- 
tion strategies: hypothetical, reasoning by cases and 
premise to goal. We have also presented a mecha- 
nism that proposes applicable argumentation strate- 
gies based on these conditions, and generates specific 
arguments based on these strategies. This mecha- 
nism has been implemented in a Bayesian argument- 
generation system. Our evaluation also brings to 
notice tile need to investigate additional aspects of 
argumentation strategies. 
8 ? ~ :Acknowledgments  
This work was supported in part bv Australian Re- 
search Council grant A49531227. 
References  
Cerbah, F. (1992). Generating causal explana- 
tions: From qualitative models to natural lan- 
guage texts. In ECAI92 - Proceedings of the 
61 
Preamble :  
"Approximately 65 million years BC the dinosaurs, large reptiles that dominated the Earth for 
many millions ofwears,~becameextinct. At aboutthe sametime,-the-nnmber:of giant Sequoias in 
California greatly increased." 
P r ~  to goaT: 
"65 million years ago, dinosaurs became xtinctand giant sequoias proliferated. These events may 
have been caused by a cooling of the Earth, which in turn may have been caused by material 
obstructing the sun. 
Lots of 65 million year old iridium deposits have been found. This may have been caused by 
widespread iridium being deposited 65 million years ago, which together with the material ob- 
structing the sun may have been caused by an explosion which threw up material. This explosion 
may have been:caused.b~.a tar.ge.iridium~rich~astexoid~.~trikiag~.E~.th~65,,million.~years BC.'~ ... ...... 
\ [ ' ~ r o i d  had not struck Earth 65 million years BC, there wouldn't be a 
I large explosion that up throws material. Therefore, iridium would not have spread around, and 
I widespread 65 million year old iridium deposits would not have been found. 
I However, widespread 65 million year old iridium deposits were found. Therefore, a large iridium- 
I rich asteroid struck Earth about 65 million years BC." 
In fe rence  to the  best  exp lanat ion :  
"If an iridium-rich asteroid had struck Earth 65 million years BC, there would have been an 
explosion that throws up material, hence widespread iridium would have been deposited. Therefore, 
lots of 65 million year old iridium deposits would be found. 
Since widespread 65 million year old iridium deposits were found, then an iridium-rich asteroid 
struck Earth 65 million years BC." 
Figure 5: Arguments for an Asteroid Striking Earth 65 Million Years BC 
Tenth European Conference on Artificial Intelli- 
gence, pages 490-494, Vienna, Austria. 
Elhadad, M. (1995). Using argumentation i text 
generation. Journal of Pragmatics, 24:189-200. 
Fisher, A. (1988). The logic of real arguments. Cam- 
bridge University Press, Cambridge: England. 
Freeman, J. (1991). Dialectics and the macrostruc- 
ture of arguments: a theory of argument structure. 
Foris Publications, Berlin. 
Lipton, P. (1991). Inference to the best explanation. 
Routledge, London; New York. 
Malthus, T. (1798). Essay on the Principle of Pop- 
ulation as it affects the Future Improvement of 
Society with Remarks on the Speculations of Mr. 
Godwin, Mr. Condorcet and other Writers. 
Marcu, D. (1996). The conceptual and linguistic 
facets of persuasive arguments. In Proceedings of 
ECAI-96 Workshop - Gaps and Bridges: New Di- 
rections in Planning and NLG, pages 43-46, Bu- 
dapest, Hungary. 
Pearl, J. (1988). ~ Probabilistic .Reasoning in Intelli- 
gent Systems. Morgan Kauflnann Publishers, San 
Mateo, California. 
Reed, C. and Long, D. (1997). Content ordering 
in the generation of persuasive discourse. In IJ- 
CAI97 - Proceedings of the Fifteenth Interna- 
tional Joint Conference on Artificial Intelligence. 
pages 1022-1027, Nagoya, Japan. 
Rescher, N. (1964). Hypothetical reasoning. North 
Holland, Amsterdam. 
Zukerman, I., McConachy, R., and Korb, K. B. 
(1998). Bayesian reasoning in an abductive mech- 
anism for argument generation and analysis. In 
AAAI98 - Proceedings of the Fifteenth National 
Conference on Artificial Intelligence, pages 833- 
838, Madison, Wisconsin. 
Zukerman, I., McConachy, R., Korb, K. B., and 
Pickett, D. A. (1999). Exploratory interaction 
with a Bayesian argumentation system. In IJ- 
CAI99 - Proceedings of the Sixteenth Interna- 
tional Joint Conference on Artificial Intelligence, 
pages 1294-1299, Stockholm, Sweden. 
62 
