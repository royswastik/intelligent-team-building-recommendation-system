Proceedings of the Human Language Technology Conference of the North American Chapter of the ACL, pages 77?80,
New York, June 2006. c?2006 Association for Computational Linguistics
Evaluation of Utility of LSA for Word Sense Discrimination 
 
Esther Levin Mehrbod Sharifi Jerry Ball 
 Dept. of  Computer Science Dept. of  Computer Science Air Force Research Laboratory 
City College of New York City College of New York 6030 S Kent Street 
NY, NY 10031 NY, NY 10031 Mesa, AZ 85212-6061 
esther@cs.ccny.cuny
.edu 
mehrbod@yahoo.com Jerry.Ball@mesa.afmc.af.m
il 
 
 
 
Abstract 
The goal of the on-going project de-
scribed in this paper is evaluation of the 
utility of Latent Semantic Analysis (LSA) 
for unsupervised word sense discrimina-
tion. The hypothesis is that LSA can be 
used to compute context vectors for am-
biguous words that can be clustered to-
gether ? with each cluster corresponding 
to a different sense of the word. In this 
paper we report first experimental result 
on tightness, separation and purity of 
sense-based clusters as a function of vec-
tor space dimensionality and using differ-
ent distance metrics. 
1 Introduction 
Latent semantic analysis (LSA) is a mathematical 
technique used in natural language processing for 
finding complex and hidden relations of meaning 
among words and the various contexts in which 
they are found (Landauer and Dumais, 1997; Lan-
dauer et al 1998). LSA is based on the idea of as-
sociation of elements (words) with contexts and 
similarity in word meaning is defined by similarity 
in shared contexts. 
The starting point for LSA is the construction of a 
co-occurrence matrix, where the columns represent 
the different contexts in the corpus, and the rows 
the different word tokens.  An entry ij in the matrix 
corresponds to the count of the number of times 
the word token i appeared in context j.  Often the 
co-occurrence matrix is normalized for document 
length and word entropy (Dumais, 1994). 
The critical step of the LSA algorithm is to com-
pute the singular value decomposition (SVD) of 
the normalized co-occurrence matrix. If the matri-
ces comprising the SVD are permuted such that the 
singular values are in decreasing order, they can be 
truncated to a much lower rank. According to Lan-
dauer and Dumais (1997), it is this dimensionality 
reduction step, the combining of surface informa-
tion into a deeper abstraction that captures the mu-
tual implications of words and passages and 
uncovers important structural aspects of a problem 
while filtering out noise. The singular vectors re-
flect principal components, or axes of greatest 
variance in the data, constituting the hidden ab-
stract concepts of the semantic space, and each 
word and each document is represented as a linear 
combination of these concepts.  
Within the LSA framework   discreet entities such 
as words and documents are mapped into the same 
continuous low-dimensional parameter space, re-
vealing the underlying semantic structure of these 
entities and making it especially efficient for vari-
ety of machine-learning algorithms.  Following 
successful application of LSA to information re-
trieval other areas of application of the same meth-
odology have been explored, including language 
modeling, word and document clustering, call rout-
ing and semantic inference for spoken interface 
control (Bellegarda, 2005). 
The ultimate goal of the project described here is 
to explore the use of LSA for unsupervised identi-
fication of word senses and for estimating word 
sense frequencies from application relevant cor-
pora following Sch?tze?s (1998) context-group 
discrimination paradigm. In this paper we describe 
a first set of experiments investigating the tight-
ness, separation and purity properties of sense-
based clusters.    
77
2 Experimental Setup 
The basic idea of the context-group discrimination 
paradigm adopted in this investigation is to induce 
senses of ambiguous word from their contextual 
similarity. The occurrences of an ambiguous word 
represented by their context vectors are grouped 
into clusters, where clusters consist of contextually 
similar occurrences. The context vectors in our 
experiments are LSA-based representation of the 
documents in which the ambiguous word appears.  
Context vectors from the training portion of the 
corpus are grouped into clusters and the centroid of 
the cluster?the sense vector?is computed.  Am-
biguous words from the test portion of the corpus 
are disambiguated by finding the closest sense vec-
tor (cluster centroid) to its context vector represen-
tation. If sense labels are available for the 
ambiguous words in the corpus, sense vectors are 
given a label that corresponds to the majority sense 
in their cluster, and sense discrimination accuracy 
can be evaluated by computing the percentage of 
ambiguous words from the test portion that were 
mapped to the sense vector whose label corre-
sponds to the ambiguous word?s sense label.  
Our goal is to investigate how well the different 
senses of ambiguous words are separated in the 
LSA-based vector space. With an ideal representa-
tion the clusters of context vectors would be tight 
(the vectors in the cluster close to each other and 
close to centroid of the cluster), and far away from 
each other, and each cluster would  be pure, i.e., 
consisting of  vectors corresponding to words with 
the same sense. Since we don?t want the evaluation 
of the LSA-based representation to be influenced 
by the choice of clustering algorithm,  or the algo-
rithm?s initialization and its parameter settings that 
determine the resulting grouping, we took an or-
thogonal approach to the problem: Instead of 
evaluating the purity of the clusters based on geo-
metrical position of vectors, we evaluate how well-
formed the clusters based on sense labels are,  how 
separated from each other  and tight they are. As 
will be discussed below, performance evaluation of 
such sense-based clusters results in an upper bound 
on  the performance that can be obtained by clus-
tering algorithms such as EM or  K-means.  
3 Results 
We used the line-hard-serve-interest cor-
pus(Leacock et al 1993), with 1151 instances for 3 
noun senses of word ?Line?: cord - 373,  division - 
374, and text - 404;  752 instances for 2 adjective 
senses of word ?Hard?: difficult ? 376, not yield-
ing to pressure or easily penetrated ? 376; 1292 
instances for 2 verb senses of word ?Serve?: serv-
ing a purpose, role or function or acting as ? 853,  
and providing service 439; and 2113 instances for 
3 noun senses of word ?Interest?: readiness to give 
attention - 361, a share in a company or business ? 
500, money paid for the use of money -1252.  
For all instances of an ambiguous word in the cor-
pus   we computed the corresponding LSA context 
vectors, and grouped them into clusters according 
to the sense label given in the corpus. To evaluate 
the inter-cluster tightness and intra-cluster separa-
tion for variable-dimensionality LSA representa-
tion we used the following measures:  
1. Sense discrimination accuracy. To compute 
sense discrimination accuracy the centroid of each 
sense cluster was computed using 90% of the data. 
We evaluated the sense discrimination accuracy 
using the remaining 10% of the data reserved for 
testing by computing for each test context vector 
the closest cluster centroid and comparing their 
sense labels.  To increase the robustness of this 
evaluation we repeated this computation 10 times, 
each time using a different 10% chunk for test 
data, round-robin style. The sense discrimination 
accuracy estimated in this way constitutes an upper 
bound on the sense discrimination performance of 
unsupervised clustering such as K-means or EM: 
The sense-based centroids, by definition, are the 
points with minimal average distance to all the 
same-sense points in the training set, while the 
centroids found by unsupervised clustering are 
based on geometric properties of all context vec-
tors, regardless of their sense label.      
2. Average Silhouette Value. The silhouette value 
(Rousseeuw, 1987) for each point is a measure of 
how similar that   point is to points in its own clus-
ter vs. points in other clusters. This measure ranges 
from +1, indicating points that are very distant 
from neighboring clusters, through 0, indicating 
points that are not distinctly in one cluster or 
another, to -1, indicating points that are probably 
assigned to the wrong cluster. To construct the sil-
houette value for each vector i, S(i), the following 
formula is used:  
78
)}(),(max{
))()(()(
ibia
iaibiS ?= , 
where a(i)  is an average distance  of i-object to all 
other objects in the same cluster and b(i) is a 
minimum of average distance of i-object to all ob-
jects in other cluster (in  other words,  it is the av-
erage distance to the points in closest cluster 
among the other clusters). The overall average sil-
houette value is simply the average of the S(i) for 
all points in the whole dataset.  
 
 
Figure 1: Average discrimination accuracy 
 
Figure 1 plots the average discrimination accuracy 
as a function of LSA dimensionality for different 
distance/similarity measures, namely L2, L1 and 
cosine, for the 4 ambiguous words in the corpus. 
Note that the distance measure choice affects not 
only the classification of a point to the cluster, but 
also the computation of cluster centroid. For L2 
and cosine measures the centroid is simply the av-
erage of vectors in the cluster, while for L1 it is the 
median, i.e., the value of i-th dimension of the 
cluster centroid vector is the median of values of 
the i-th dimension of all the vectors in the cluster.  
As can be seen from the sense discrimination re-
sults in Fig. 1, cosine distance, the most frequently 
used distance measure in LSA applications, has the 
best performance in for 3 out of 4 words in the 
corpus. Only for ?Hard? does L1 outperforms co-
sine for low values of LSA dimension. As to the 
influence of dimensionality reduction on sense dis-
crimination accuracy, our results show that (at least 
for the cosine distance) the accuracy does not peak 
at any reduced dimension, rather it increases 
monotonically, first rapidly and then reaching satu-
ration as the dimension is increased from its lowest 
value (50 in our experiments) to the full dimension 
that corresponds to the number of contexts in the 
corpus.  
 These results suggest that the value of dimension-
ality reduction is not in increasing the sense dis-
crimination power of LSA representation, but in 
making the subsequent computations more effi-
cient and perhaps enabling working with much 
larger corpora. For every number of dimensions 
examined, the average sense discrimination accu-
racy is significantly better than the baseline that 
was computed as the relative percentage of the 
most frequent sense of each ambiguous word in the 
corpus.  
Figure 2 shows the average silhouette values for 
the sense-based clusters as a function of the dimen-
sionality of the underlying LSA?based vector rep-
resentation for the 3 different distance metrics and 
for the 4 words in the corpus. The average silhou-
ette value is close to zero, not varying significantly 
for the different number of dimensions and dis-
tance measures. Although the measured silhouette 
values indicate that the sense-based clusters are not 
very tight, the sense-discrimination accuracy re-
sults suggest that    they are sufficiently far from 
each other to guarantee relatively high accuracy.  
4 Summary and Discussion 
In this paper we reported on the first in a series of 
experiments aimed at examining the sense dis-
crimination utility of LSA-based vector representa-
tion of ambiguous words? contexts. Our evaluation 
of average silhouette values indicates that sense-
79
based clusters in the latent semantic space are not 
very tight (their silhouette values are mostly posi-
tive, but close to zero). However, they are sepa-
rated enough to result in sense discrimination 
accuracy significantly higher than the baseline. We 
also found that the cosine distance measure outper-
forms L1 and L2, and that dimensionality reduc-
tion for sense-based clusters does not improve the 
sense discrimination accuracy. 
 
 
Figure2: Average silhouette values 
 
The clustering  examined in this paper is based on 
pre-established word sense labels, and the meas-
ured accuracy  constitutes an upper bound on a 
sense discrimination accuracy that can be obtained 
by unsupervised clustering such as EM or segmen-
tal K-means. In the next phase of this investigation 
we plan to do a similar evaluation for clustering 
obtained without supervision by running K-means 
algorithm on the same corpus. Since such cluster-
ing is based on geometric properties of word vec-
tors, we expect it to have a better tightness as 
measured by average silhouette value, but, at the 
same time, lower sense discrimination accuracy.  
The experiments reported here are based on LSA 
representation computed using the whole docu-
ment as a context for the ambiguous word. In the 
future we plan to investigate the influence of the 
context size on sense discrimination performance.  
Acknowledgements 
The project described above is supported by grant 
?Using LSA to Compute Word Sense Frequencies? 
from Air Force Research Lab. Its contents are 
solely the responsibility of the authors and do not 
necessarily represent the official views of the 
AFRL. 
5 References 
J.R. Bellegarda. 2005. Latent Semantic Mapping, 
IEEE Signal Processing Magazine, 22(5):70-80. 
 
S.T. Dumais. 1994. Latent Semantic Indexing (LSI) 
and TREC-2, in Proc Second Text Retrieval Conf. 
(TREC-2),  pp 104-105. 
 
T.K. Landauer, S.T. Dumais. 1997. A solution to 
Plato's problem: The latent semantic analysis the-
ory of acquisition, induction and representation of 
knowledge, Psychological Review, 104(2):211-
240. 
 
T.K. Landauer, P. Foltz, and  D. Laham.  1998. 
Introduction to Latent Semantic Analysis. 
Discourse Processes, 25, 259-284. 
 
C. Leacock, G. Towel, E. Voorhees. 1993. Corpus-
Based Statistical Sense Resolution, Proceedings of 
the ARPA Workshop on Human Language Tech-
nology. 
 
P.J. Rousseeuw. 1987.  Silhouettes: a graphical 
aid to the interpretation and validation of cluster 
analysis. Journal of Computational and Applied 
Mathematics. 20. 53-65.  
 
H. Sch?tze. 1998. Automatic Word Sense Dis-
crimination, Journal of Computational Linguistics, 
Volume 24, Number 2  
80
Bridging the Gap: Academic and Industrial Research in Dialog Technologies Workshop Proceedings, pages 25?31,
NAACL-HLT, Rochester, NY, April 2007. c?2007 Association for Computational Linguistics
Technical Support Dialog Systems: 
Issues, Problems, and Solutions  
 
 
Kate Acomb, Jonathan Bloom, Krishna Dayanidhi, Phillip 
Hunter, Peter Krogh, Esther Levin, Roberto Pieraccini 
SpeechCycle 
535 W 34th Street 
New York, NY 10001 
{kate,jonathanb,krishna,phillip,peter,roberto}@speechcycle.com 
esther@spacegate.com  
 
 
 
 
Abstract 
The goal of this paper is to give a description 
of the state of the art, the issues, the problems, 
and the solutions related to industrial dialog 
systems for the automation of technical sup-
port. After a general description of the evolu-
tion of the spoken dialog industry, and the 
challenges in the development of technical 
support applications, we will discuss two spe-
cific problems through a series of experimental 
results.    The first problem is the identification 
of the call reason, or symptom, from loosely 
constrained user utterances. The second is the 
use of data for the experimental optimization 
of the Voice User Interface (VUI). 
1 Introduction 
Since the beginning of the telephony spoken dialog 
industry, in the mid 1990, we have been witnessing 
the evolution of at least three generations of sys-
tems. What differentiates each generation is not 
only the increase of complexity, but also the dif-
ferent architectures used. Table 1 provides a sum-
mary of the features that distinguish each 
generation. The early first generation systems were 
mostly informational, in that they would require 
some information from the user, and would pro-
vide information in return. Examples of those sys-
tems, mostly developed during the mid and late 
1990s, are package tracking, simple financial ap-
plications, and flight status information. At the 
time there were no standards for developing dialog 
systems, (VoiceXML 1.0 was published as a rec-
ommendation in year 2000) and thus the first gen-
eration dialog applications were implemented on 
proprietary platforms, typically evolutions of exist-
ing touch-tone IVR (Interactive Voice Response) 
architectures.  
 
Since the early developments, spoken dialog sys-
tems were implemented as a graph, called call-
flow. The nodes of the call-flow typically represent 
actions performed by the system and the arcs rep-
resent an enumeration of the possible outcomes. 
Playing a prompt and interpreting the user re-
sponse through a speech recognition grammar is a 
typical action. Dialog modules (Barnard et al, 
1999) were introduced in order to reduce the com-
plexity and increase reusability of call-flows. A 
Dialog Module (or DM) is defined as a call-flow 
object that encapsulates many of the interactions 
needed for getting one piece of information from 
the user, including retries, timeout handling, dis-
ambiguation, etc. Modern commercial dialog sys-
tems use DMs as their active call-flow nodes.  
 
The number of DMs in a call-flow is generally an 
indication of the application complexity. First gen-
eration applications showed a range of complexity 
of a few to tens of DMs, typically spanning a few 
turns of interaction.   
 
The dialog modality is another characterization of 
applications. Early applications supported strict 
directed dialog interaction, meaning that at each 
25
turn the system would direct the user by proposing 
a finite?and typically small?number of choices. 
That would also result in a limited grammar or vo-
cabulary at each turn.  
 
The applications of the second generation were 
typically transactional, in the sense that they could 
perform a transaction on behalf of the user, like 
moving funds between bank accounts, trading 
stocks, or buying tickets. Most of those applica-
tions were developed using the new standards, 
typically as collections of VoiceXML documents. 
The complexity moved to the range of dozens of 
dialog modules, spanning a number of turns of in-
teractions of the order of ten or more. At the same 
time, some of the applications started using a tech-
nology known as Statistical Spoken Language Un-
derstanding, or SSLU (Gorin et al, 1997, Chu-
Carroll et al, 1999, Goel et al 2005), for mapping 
loosely constrained user utterances to a finite num-
ber of pre-defined semantic categories. The natural 
language modality?as opposed to directed dia-
log?was initially used mostly for call-routing, i.e. 
to route calls to the appropriate call center based 
on a more or less lengthy description of the reason 
for the call by the user.  
 
While the model behind the first and second gen-
erations of dialog applications can be described by 
the form-filling paradigm, and the interaction fol-
lows a pre-determined simple script, the systems of 
the third generation have raised to a qualitatively 
different level of complexity. Problem solving ap-
plications, like customer care, help desk, and tech-
nical support, are characterized by a level of 
complexity ranging in the thousands of DMs, for a 
number of turns of dynamic interaction that can 
reach into the dozens. As the sophistication of the 
applications evolved, so did the system architec-
ture by moving the logic from the client 
(VoiceXML browser, or voice-browser) to the 
server (Pieraccini and Huerta, 2005). More and 
more system are today based on generic dialog 
application server which interprets a dialog speci-
fication described by a?typically proprietary?
markup language and serve the voice-browser with 
dynamically generated VoiceXML documents. 
Finally, the interaction modality of the third gen-
eration systems is moving from the strictly directed 
dialog application, to directed dialog, with some 
natural language (SSLU) turns, and some limited 
mixed-initiative (i.e. the possibility for the user to 
change the course of the dialog by making an un-
solicited request).  
2 Technical Support Applications 
Today, automated technical support systems are 
among the most complex types of dialog applica-
tions. The advantage of automation is clear, espe-
cially for high-volume services like broadband-
internet, entertainment (cable or satellite TV), and 
telephony. When something goes wrong with the 
service, the only choice for subscribers is to call a 
technical support center. Unfortunately, staffing a 
call center with enough agents trained to help solve 
even the most common problems results in pro-
hibitive costs for the provider, even when out-
sourcing to less costly locations End users often 
experience long waiting times and poor service 
from untrained agents. With the magnitude of the 
daily increase in the number of subscribers of those 
services, the situation with human agents is bound 
to worsen. Automation and self-service can, and 
does, help reduce the burden constituted by the 
most frequent call reasons, and resort to human 
agents only for the most difficult and less common 
problems.  
GENERATION 
  FIRST SECOND THIRD 
Time Period 1994-2001 2000-2005 2004-today 
Type of Ap-
plication Informational 
Transac-
tional 
Problem 
Solving 
Examples 
Package 
Tracking, 
Flight Status 
Banking, 
Stock 
Trading, 
Train Res-
ervation 
Customer 
Care, 
Technical 
Support, 
Help Desk. 
Architecture Proprietary 
Static 
VoiceXML  
Dynamic 
VoiceXML 
Complexity 
(Number of 
DMs) 10 100 1000 
Interaction 
Turns  few 10 10-100 
Interaction 
Modality directed 
directed + 
natural 
language 
(SSLU) 
directed + 
natural 
language 
(SSLU) + 
limited 
mixed initia-
tive 
 
Table 1: Evolution of spoken dialog systems. 
26
 However, automating technical support is particu-
larly challenging for several reasons. Among them:   
 
- Troubleshooting knowledge is not readily 
available in a form that can be used for 
automation. Most often it is based on the 
idiosyncratic experience of the individual 
agents. 
- End users are typically in a somewhat 
emotionally altered state?something for 
which they paid and that is supposed to 
work is broken. They want it repaired 
quickly by an expert human agent; they 
don?t trust a machine can help them.  
- The description of the problem provided 
by the user can be imprecise, vague, or 
based on a model of the world that may be 
incorrect (e.g. some users of internet can-
not tell their modem from their router). 
- It may be difficult to instruct non-
technically savvy users on how to perform 
a troubleshooting step (e.g. Now renew 
your IP address.) or request technical in-
formation (e.g. Are you using a Voice over 
IP phone service?) 
- Certain events cannot be controlled. For 
instance, the time it would take for a user 
to complete a troubleshooting step, like re-
booting a PC, is often unpredictable.   
- The acoustic environment may be chal-
lenging. Users may be asked to switch 
their TV on, reboot their PC, or check the 
cable connections. All these operations can 
cause noise that can trigger the speech rec-
ognizer and affect the course of the inter-
action. 
 
On the other hand, one can leverage the automated 
diagnosis or troubleshooting tools that are cur-
rently used by human agent and improve the effi-
ciency of the interaction. For instance, if the IP 
address of the digital devices at the user premises 
is available, one can ping them, verify their con-
nectivity, download new firmware, and perform 
automated troubleshooting steps in the background 
without the intervention of the user. However, the 
interplay between automated and interactive op-
erations can raise the complexity of the applica-
tions such as to require higher level development 
abstractions and authoring tools.  
3 High Resolution SSLU 
The identification of the call reason?i.e. the prob-
lem or the symptoms of the problem experienced 
by the caller?is one of the first phases of the in-
teraction in a technical support application. There 
are two possible design choices with today?s spo-
ken language technology: 
 
- Directed dialog. A specific prompt enu-
merates all the possible reasons for a call, 
and the user would choose one of them. 
-  Natural Language: An open prompt asks 
the user to describe the reason for the call. 
The utterance will be automatically 
mapped to one of a number of possible call 
reasons using SSLU technology. 
 
Directed dialog would be the preferred choice in 
terms of accuracy and cost of development. Unfor-
tunately, in most technical support applications, the 
number of call-reasons can be very large, and thus 
prompting the caller through a directed dialog 
menu would be impractical. Besides, even though 
a long menu can be structured hierarchically as a 
cascade of several shorter menus, the terms used 
for indicating the different choices may be mis-
leading or meaningless for some of the users (e.g. 
do you have a problem with hardware, software, or 
networking?).  Natural language with SSLU is 
generally the best choice for problem identifica-
tion.  
 
In practice, users mostly don?t know what the ac-
tual problem with their service is (e.g. modem is 
wrongly configured), but typically they describe 
their observations?or symptoms?which are ob-
servable manifestations of the problem. and not the 
problem itself (e.g. symptom: I can?t connect to the 
Web, problem: modem wrongly configured). Cor-
rectly identifying the symptom expressed in natural 
language by users is the goal of the SSLU module.  
 
SSLU provides a mapping between input utter-
ances and a set of pre-determined categories. 
SSLU has been effectively used in the past to en-
able automatic call-routing. Typically call-routing 
applications have a number of categories, of the 
order of a dozen or so, which are designed based 
on the different routes to which the IVR is sup-
posed to dispatch the callers. So, generally, in call-
27
routing applications, the categories are known and 
determined prior to any data collection.  
 
One could follow the same approach for the prob-
lem identification SSLU, i.e. determine a number 
of a-priori problem categories and then map a col-
lection of training symptom utterances to each one 
of them. There are several issues with this ap-
proach.  
 
First, a complete set of categories?the prob-
lems?may not be known prior to the acquisition 
and analysis of a significant number of utterances. 
Often the introduction of new home devices or ser-
vices (such as DVR, or HDTV) creates new prob-
lems and new symptoms that can be discovered 
only by analyzing large amounts of utterance data.   
 
Then, as we noted above, the relationship between 
the problems?or broad categories of problems?
and the manifestations (i.e. the symptoms) may not 
be obvious to the caller. Thus, confirming a broad 
category in response to a detailed symptom utter-
ance may induce the user to deny it or to give a 
verbose response (e.g. Caller: I cannot get to the 
Web. System: I understand you have a problem 
with your modem configuration, is that right? 
Caller: Hmm?no. I said I cannot get to the Web.). 
 
Finally, caller descriptions have different degrees 
of specificity (e.g. I have a problem with my cable 
service vs. The picture on my TV is pixilated on all 
channels).  Thus, the categories should reflect a 
hierarchy of symptoms, from vague to specific, 
that need to be taken into proper account in the 
design of the interaction.  
 
As a result from the above considerations, SSLU 
for symptom identification needs to be designed in 
order to reflect the high-resolution multitude and 
specificity hierarchy of symptoms that emerge 
from the analysis of a large quantity of utterances. 
Figure 1 shows an excerpt from the hierarchy of 
symptoms for a cable TV troubleshooting applica-
tion derived from the analysis of almost 100,000 
utterance transcriptions.  
 
Each node of the tree partially represented by Fig-
ure 1 is associated with a number of training utter-
ances from users describing that particular 
symptom in their own words. For instance the top-
most node of the hierarchy, ?TV Problem?, corre-
sponds to vague utterances such as I have a 
problem with my TV or My cable TV does not 
work. The? Ordering? node represents requests of 
the type I have a problem with ordering a show, 
which is still a somewhat vague request, since one 
can order ?Pay-per-view? or ?On-demand? events, 
and they correspond to different processes and 
troubleshooting steps. Finally, at the most detailed 
level of the hierarchy, for instance for the node 
?TV Problem-Ordering-On Demand-Error?, one 
finds utterances such as I tried to order a movie on 
demand, but all I get is an error code on the TV. 
 
In the experimental results reported below, we 
trained and tested a hierarchically structured SSLU 
for a cable TV troubleshooting application. A cor-
pus of 97,236 utterances was collected from a de-
ployed application which used a simpler, non 
hierarchical, version of the SSLU. The utterances 
were transcribed and initially annotated based on 
an initial set of symptoms. The annotation was car-
ried out by creating an annotation guide document 
which includes, for each symptom, a detailed ver-
bal description, a few utterance examples, and 
relevant keywords. Human annotators were in-
structed to label each utterance with the correct 
category based on the annotation guide and their 
TV Problem
On Demand
Pay-per-view
Ordering
No Picture
Error
PIN
Other
Error
 
 
Figure 1: Excerpt from the hierarchical symp-
tom description in a cable TV technical support 
application 
 
28
work was monitored systematically by the system 
designer. 
 
After a first initial annotation of the whole corpus, 
the annotation consistency was measured by com-
puting a cluster similarity distance between the 
utterances corresponding to all possible pairs of 
symptoms. When the consistency between a pair of 
symptoms was below a given threshold, the clus-
ters were analyzed, and actions taken by the de-
signer in order to improve the consistency, 
including reassign utterances and, if necessary, 
modifying the annotation guide. The whole process 
was repeated a few times until a satisfactory global 
inter-cluster distance was attained.  
 
Eventually we trained the SSLU on 79 symptoms 
arranged on a hierarchy with a maximum depth of 
3. Table 2 summarizes the results on an independ-
ent test set of 10,332 utterances.  The result shows 
that at the end of the process, a satisfactory batch 
accuracy of 81.43% correct label assignment what 
attained for the utterances which were deemed to 
be in-domain, which constituted 90.22% of the test 
corpus. Also, the system was able to correctly re-
ject 24.56% of out-of-domain utterances. The 
overall accuracy of the system was considered rea-
sonable for the state of the art of commercial 
SSLUs based on current statistical classification 
algorithms. Improvement in the classification per-
formance can result by better language models (i.e. 
some of the errors are due to incorrect word recog-
nition by the ASR) and better classifiers, which 
need to take into account more features of the in-
coming utterances, such as word order1 and con-
textual information. 
                                                          
1
 Current commercial SSLU modules,  as the one used in the 
work described here, use statistical classifiers based only on 
bags of words. Thus the order of the words in the incoming 
utterance is not taken into consideration.  
3.1 Confirmation Effectiveness 
Accuracy is not the only measure to provide an 
assessment of how the symptom described by the 
caller is effectively captured. Since the user re-
sponse needs to be confirmed based on the inter-
pretation returned by the SSLU, the caller always 
has the choice of accepting or denying the hy-
pothesis. If the confirmation prompts are not prop-
erly designed, the user can erroneously deny 
correctly detected symptoms, or erroneously accept 
wrong ones.  
 
The analysis reported below was carried out for a 
deployed system for technical support of Internet 
service. The full symptom identification interac-
tions following the initial open prompt was tran-
scribed and annotated for 895 calls. The SSLU 
used in this application consisted of 36 symptoms 
structured in a hierarchy with a maximum depth of 
3. For each interaction we tracked the following 
events: 
 
- the first user response to the open question 
- successive responses in case of re-
prompting because of speech recognition 
rejection or timeout 
- response to the yes/no confirmation ques-
tion) 
- successive responses to the confirmation 
question in case the recognizer rejected it 
or timed out. 
- Successive responses to the confirmation 
question in case the user denied, and a 
second best hypothesis was offered. 
 
Table 3 summarizes the results of this analysis. 
  
The first row reports the number of calls for which 
the identified symptom was correct (as compared 
with human annotation) and confirmed by the 
caller.  The following rows are the number of calls 
where the identified symptom was wrong and the 
caller still accepted it during confirmation, the 
symptom was correct and the caller denied it, and 
the symptom was wrong and denied, respectively. 
Finally there were 57 calls where the caller did not 
provide any confirmation (e.g. hung up, timed out, 
ASR rejected the confirmation utterance even after 
re-prompting, etc.), and 100 calls in which it was 
not possible to collect the symptom (e.g. rejections 
Utterances 10332 100.00% 
In domain 9322 90.22% 
Correct  in-domain 7591 81.43% 
Out of domain  1010 9.78% 
Correct rejection out-of-
domain 249 24.65% 
 
Table 2: Accuracy results for Hierarchical 
SSLU with 79 symptoms. 
29
of first and second re-prompts, timeouts, etc.) In 
both cases?i.e. no confirmation or no symptom 
collection at all?the call continued with a differ-
ent strategy (e.g. moved to a directed dialog, or 
escalated the call to a human agent). The interest-
ing result from this experiment is that the SSLU 
returned a correct symptom 59.8 + 2.5 = 62.3% of 
the times (considering both in-domain and out-of-
domain utterances), but the actual ?perceived? ac-
curacy (i.e. when the user accepted the result) was 
higher, and precisely 59.8 + 13.2 = 73%. A deeper 
analysis shows that for most of the wrongly ac-
cepted utterances the wrong symptom identified by 
the SSLU was still in the same hierarchical cate-
gory, but with different degree of specificity (e.g. 
Internet-Slow vs. vague Internet) 
 
The difference between the actual and perceived 
accuracy of SSLU has implications for the overall 
performance of the application. One could build a 
high performance SSLU, but a wrongly confirmed 
symptom may put the dialog off course and result 
in reduced automation, even though the perceived 
accuracy is higher. Confirmation of SSLU results 
is definitely an area where new research can poten-
tially impact the performance of the whole system. 
4 Experimental VUI 
Voice User Interface (VUI) is typically considered 
an art. VUI designers acquire their experience by 
analyzing the effect of different prompts on the 
behavior of users, and can often predict whether a 
new prompt can help, confuse, or expedite the in-
teraction. Unfortunately, like all technologies rely-
ing on the anecdotal experience of the designer, in 
VUI it is difficult to make fine adjustments to an 
interface and predict the effect of competing simi-
lar designs before the application is actually de-
ployed. However, in large volume applications, 
and when a global measure of performance is 
available, one can test different non-disruptive de-
sign hypotheses on the field, while the application 
is running. We call this process experimental VUI.  
 
There have been, in the past, several studies aimed 
at using machine learning for the design of dialog 
systems (Levin et al, 2000, Young 2002, Pietquin 
et al 2006). Unfortunately, the problem of full de-
sign of a system based uniquely on machine learn-
ing is a very difficult one, and cannot be fully 
utilized yet for commercial systems. A simpler and 
less ambitious goal is that of finding the optimal 
dialog strategy among a small number of compet-
ing designs, where all the initial designs are work-
ing reasonably well (Walker 2000, Paek et al2004, 
Lewis 2006). Comparing competing designs re-
quires carrying on an exploration based on random 
selection of each design at crucial points of the 
dialog. Once a reward schema is defined, one can 
use it for changing the exploration probability so as 
to maximize a function of the accumulated reward 
using, for instance, one of the algorithms described 
in (Sutton 1998). 
 
Defining many different competing designs at sev-
eral points of the interaction is often impractical 
and costly. Moreover, in a deployed commercial 
application, one needs to be careful about main-
taining a reasonable user experience during explo-
ration. Thus, the competing designs have to be 
chosen carefully and applied to portions of the dia-
log where the choice of the optimal design can 
make a significant difference for the reward meas-
ure in use.  
 
In the experiments described below we selected the 
symptom identification as a point worth exploring. 
in an internet technical support application We 
then defined three prompting schemas 
 
- Schema A: the system plays an open 
prompt 
- Schema B: the system plays an open 
prompt, and then provides some examples 
of requests 
- Schema C: The system plays an open 
prompt, and then suggests a command that 
provides a list of choices. 
 
Accepted correct 535 59.8% 
Accepted wrong 118 13.2% 
Denied correct 22 2.5% 
Denied wrong 63 7.0% 
Unconfirmed 57 6.4% 
No result 100 11.2% 
TOTAL 895 100.0% 
 
Table 3: Result of the confirmation analy-
sis based on the results of 895 calls 
30
The three schemas were implemented on a de-
ployed system for limited time. There was 1/3 
probability for each individual call to go through 
one of the above schemas. The target function cho-
sen for optimization was the average automation 
rate.  
 
Figure 2 shows the effect on the cumulated average 
automation rate for each one of the competing de-
sign. The exploration was carried out until the dif-
ference in the automation rate among the three 
designs reached statistical significance, which was 
after 13 days with a total number of 21,491 calls. 
At that point in time we established that design B 
had superior performance, as compared to A and 
C, with a difference of 0.68 percent points.  
Event though the gain in total automation rate (i.e. 
0.68 percent points) seems to be modest, one has to 
consider that this increase is simply caused only by 
the selection  of the best wording of a single 
prompt in an application with thousands of 
prompts. One can expect to obtain more important 
improvements by at looking to other areas of the 
dialog where experimental VUI can be applied and 
selecting the optimal prompt can have an impact 
on the overall automation rate.  
5 Conclusions 
We started this paper by describing the advances 
achieved in dialog system technology for commer-
cial applications during the past decade. The indus-
try moved from the first generation of systems able 
to handle very structured and simple interactions, 
to a current third generation where the interaction 
is less structured and the goal is to automate com-
plex tasks such as problem solving and technical 
support.We then discussed general issues regarding 
the effective development of a technical support 
application. In particular we focused on two areas: 
the collection of the symptom from natural lan-
guage expressions, and the experimental optimiza-
tion of the VUI strategy. In both cases we 
described how a detailed analysis of live data can 
greatly help optimize the overall performance.  
6 References 
Barnard, E., Halberstadt, A., Kotelly, C., Phillips, M.,  1999 
?A Consistent Approach To Designing Spoken-dialog 
Systems,? Proc. of ASRU99 ? IEEE Workshop, Keystone, 
Colorado, Dec. 1999. 
Gorin, A. L., Riccardi, G.,Wright, J. H.,  1997 Speech Com-
munication, vol. 23, pp. 113-127, 1997. 
Chu-Carroll, J., Carpenter B., 1999. ?Vector-based natural 
language call routing,? Computational Linguistics, 
v.25, n.3, p.361-388, September 1999 
Goel, V., Kuo, H.-K., Deligne, S., Wu S.,  2005 ?Language 
Model Estimation for Optimizing End-to-end Performance 
of a Natural Language Call Routing System,? ICASSP 
2005 
Pieraccini, R., Huerta, J., Where do we go from here? Re-
search and Commercial Spoken Dialog Systems, Proc. of 
6th SIGdial Workshop on Discourse and Dialog, Lisbon, 
Portugal, 2-3 September, 2005. pp. 1-10 
Levin, E., Pieraccini, R., Eckert, W., A Stochastic Model of 
Human-Machine Interaction for Learning Dialog Strate-
gies,  IEEE Trans. on Speech and Audio Processing, Vol. 
8, No. 1, pp. 11-23, January 2000. 
Pietquin, O., Dutoit, T., A Probabilistic Framework for Dialog 
Simulation and Optimal Strategy Learning, In IEEE 
Transactions on Audio, Speech and Language Processing, 
14(2):589-599, 2006 
Young, S., Talking to Machines (Statistically Speaking), Int 
Conf Spoken Language Processing, Denver, Colorado. 
(2002). 
Walker, M., An Application of Reinforcement Learning to 
Dialogue Strategy Selection in a Spoken Dialogue System 
for Email . Journal of Artificial Intelligence Research, 
JAIR, Vol 12., pp. 387-416, 2000 
Paek T., Horvitz E.,. Optimizing automated call routing by 
integrating spoken dialog models with queuing models. 
Proceedings of HLT-NAACL, 2004, pp. 41-48. 
Lewis, C., Di Fabbrizio, G., Prompt Selection with Rein-
forcement Learning in an AT&T Call Routing Applica-
tion, Proc. of Interspeech 2006, Pittsburgh, PA. pp. 1770-
1773, (2006) 
Sutton, R.S., Barto, A.G. (1998). Reinforcement Learning: An 
Introduction. MIT Press. 
 
14.00%
15.00%
16.00%
17.00%
18.00%
19.00%
20.00%
21.00%
1 2 3 4 5 6 7 8 9 10 11 12 13
Time (days)
A
u
to
m
a
tio
n
 
ra
te
A
B
C
Figure 2: Daily average automation rate for com-
peting designs. 
31
