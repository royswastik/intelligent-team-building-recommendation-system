Proceedings of the COLING/ACL 2006 Interactive Presentation Sessions, pages 53?56,
Sydney, July 2006. c?2006 Association for Computational Linguistics
Re-Usable Tools for Precision Machine Translation?
Jan Tore L?nning? and Stephan Oepen??
?Universitetet i Oslo, Computer Science Institute, Boks 1080 Blindern; 0316 Oslo (Norway)
?Center for the Study of Language and Information, Stanford, CA 94305 (USA)
{ jtl@ifi.uio.no |oe@csli.stanford.edu}
Abstract
The LOGON MT demonstrator assembles
independently valuable general-purpose
NLP components into a machine trans-
lation pipeline that capitalizes on output
quality. The demonstrator embodies an in-
teresting combination of hand-built, sym-
bolic resources and stochastic processes.
1 Background
The LOGON projects aims at building an exper-
imental machine translation system from Norwe-
gian to English of texts in the domain of hiking in
the wilderness (Oepen et al, 2004). It is funded
within the Norwegian Research Council program
for building national infrastructure for language
technology (Fenstad et al, 2006). It is the goal
for the program as well as for the project to in-
clude various areas of language technology as well
as various methods, in particular symbolic and
empirical methods. Besides, the project aims at
reusing available resources and, in turn, producing
re-usable technology.
In spite of significant progress in statistical ap-
proaches to machine translation, we doubt the
long-term value of pure statistical (or data-driven)
approaches, both practically and scientifically. To
ensure grammaticality of outputs as well as fe-
licity of the translation both linguistic grammars
and deep semantic analysis are needed. The ar-
chitecture of the LOGON system hence consists of
a symbolic backbone system combined with vari-
ous stochastic components for ranking system hy-
potheses. In a nutshell, a central research question
in LOGON is to what degree state-of-the-art ?deep?
NLP resources can contribute towards a precision
MT system. We hope to engage the conference
audience in some reflection on this question by
means of the interactive presentation.
2 System Design
The backbone of the LOGON prototype imple-
ments a relatively conventional architecture, orga-
?This demonstration reects the work of a large group
of people whose contributions we gratefully acknowledge.
Please see ?http://www.emmtee.net? for background.
?h1,
{ h1:proposition m(h3),
h4:proper q(x5, h6, h7), h8:named(x5,?Bod??),
h9: populate v(e2, , x5), h9: densely r(e2) },
{ h3 =q h9, h6 =q h8 } ?
Figure 1: Simplied MRS representation for the utterance
?Bod? is densely populated.? The core of the structure is a bag
of elementary predications (EPs), using distinguished han-
dles (?hi? variables) and ?=q? (equal modulo quantier inser-
tion) constraints to underspecify scopal relations. Event- and
instance-type variables (?ej? and ?xk?, respectively) capture
semantic linking among EPs, where we assume a small inven-
tory of thematically bleached role labels (ARG0 ... ARGn).
These are abbreviated through order-coding in the example
above (see ? 2 below for details).
nized around in-depth grammatical analysis in the
source language (SL), semantic transfer of logical-
form meaning representations from the source into
the target language (TL), and full, grammar-based
TL tactical generation.
Minimal Recursion Semantics The three core
phases communicate in a uniform semantic in-
terface language, Minimal Recursion Semantics
(MRS; Copestake, Flickinger, Sag, & Pollard,
1999). Broadly speaking, MRS is a flat, event-
based (neo-Davidsonian) framework for computa-
tional semantics. The abstraction from SL and TL
surface properties enforced in our semantic trans-
fer approach facilitates a novel combination of di-
verse grammatical frameworks, viz. LFG for Nor-
wegian analysis and HPSG for English generation.
While an in-depth introduction to MRS (for MT)
is beyond the scope of this project note, Figure 1
presents a simplified example semantics.
Norwegian Analysis Syntactic analysis of Nor-
wegian is based on an existing LFG resource gram-
mar, NorGram (Dyvik, 1999), under development
on the Xerox Linguistic Environment (XLE) since
around 1999. For use in LOGON, the gram-
mar has been modified and extended, and it has
been augmented with a module of Minimal Re-
cursion Semantics representations which are com-
puted from LFG f-structures by co-description.
In Norwegian, compounding is a productive
morphological process, thus presenting the anal-
ysis engine with a steady supply of ?new? words,
e.g. something like klokkeslettuttrykk meaning ap-
53
Norwegian
Analysis
(LFG) ffPVM
-
NorGram
Lexicon?
Norwegian
SEM-I
6
-
LOGON
Controller ffPVM
- English
Generation
(HPSG)
ERG
Lexicon?
English
SEM-I
6
ffNO? ENTransfer
(MRS)
6PVM ?
GUI 6? WWW6?
Figure 2: Schematic system architecture: the three core pro-
cessing components are managed by a central controller that
passes intermediate results (MRSs) through the translation
pipeline. The Parallel Virtual Machine (PVM) layer facilitates
distribution, parallelization, failure detection, and roll-over.
proximately time-of-day expression. The project
uses its own morphological analyzer, compiled
off a comprehesive computational lexicon of Nor-
wegian, prior to syntactic analysis. One impor-
tant feature of this processor is that it decomposes
compounds in such a way that they can be compo-
sitionally translated downstream.
Current analysis coverage (including well-
formed MRSs) on the LOGON corpus (see below)
is approaching 80 per cent (of which 25 per cent
are ?fragmented?, i.e. approximative analyses).
Semantic Transfer Unlike in parsing and gen-
eration, there is less established common wisdom
in terms of (semantic) transfer formalisms and
algorithms. LOGON follows many of the main
Verbmobil ideas?transfer as a resource-sensitive
rewrite process, where rules replace MRS frag-
ments (SL to TL) in a step-wise manner (Wahlster,
2000)?but adds two innovative elements to the
transfer component, viz. (i) the use of typing for
hierarchical organization of transfer rules and (ii)
a chart-like treatment of transfer-level ambiguity.
The general form of MRS transfer rules (MTRs) is
as a quadruple:
[ CONTEXT : ] INPUT [ ! FILTER ] ? OUTPUT
where each of the four components, in turn, is
a partial MRS, i.e. triplet of a top handle, bag of
EPs, and handle constraints. Left-hand side com-
ponents are unified against an input MRS M and,
when successful, trigger the rule application; ele-
ments of M matched by INPUT are replaced with
the OUTPUT component, respecting all variable
bindings established during unification. The op-
tional CONTEXT and FILTER components serve to
condition rule application (on the presence or ab-
sence of specific aspects of M ), establish bindings
for OUTPUT processing, but do not consume el-
ements of M . Although our current focus is on
?lingo/jan-06/jh1/06-01-20/lkb? Generation Profile
total word distinct overall time
Aggregate items string trees coverage (s)
] ? ? % ?
30 ? i-length < 40 21 33.1 241.5 61.9 36.5
20 ? i-length < 30 174 23.0 158.6 80.5 15.7
10 ? i-length < 20 353 14.3 66.7 86.7 4.1
0 ? i-length < 10 495 4.6 6.0 90.1 0.7
Total 1044 11.6 53.50 86.7 4.3
(generated by [incr tsdb()] at 15-mar-2006 (15:51 h))
Table 1: Central measures of generator performance in re-
lation to input ?complexity?. The columns are, from left to
right, the corpus sub-division by input length, total number
of items, and average string length, ambiguity rate, grammat-
ical coverage, and generation time, respectively.
translation into English, MTRs in principle state
translational correspondence relations and, mod-
ulo context conditioning, can be reversed.
Transfer rules use a multiple-inheritance hier-
archy with strong typing and appropriate feature
constraints both for elements of MRSs and MTRs
themselves. In close analogy to constraint-based
grammar, typing facilitates generalizations over
transfer regularities?hierarchies of predicates or
common MTR configurations, for example?and
aids development and debugging.
An important tool in the constructions of the
transfer rules are the semantic interfaces (called
SEM-Is, see below) of the respective grammars.
While we believe that hand-crafted lexical trans-
fer is a necessary component in precision-oriented
MT, it is also a bottleneck for the development
of the LOGON system, with its pre-existing source
and target language grammars. We have therefore
experimented with the acquistion of transfer rules
by analogy from a bi-lingual dictionary, building
on hand-built transfer rules as a seed set of tem-
plates (Nordga?rd, Nygaard, L?nning, & Oepen,
2006).
English Generation Realization of post-transfer
MRSs in LOGON builds on the pre-existing LinGO
English Resource Grammar (ERG; Flickinger,
2000) and LKB generator (Carroll, Copestake,
Flickinger, & Poznanski, 1999). The ERG al-
ready produced MRS outputs with good coverage
in several domains. In LOGON, it has been refined,
adopted to the new domain, and semantic repre-
sentations revised in light of cross-linguistic ex-
periences from MT. Furthermore, chart generation
efficiency and integration with stochastic realiza-
tion have been substantially improved (Carroll &
Oepen, 2005). Table 1 summarizes (exhaustive)
generator performance on a segment of the LOGON
54
temp loc
at p temp in p temp on p temp
temp abstr
afternoon n day n ? ? ? year n
Figure 3: Excerpt from predicate hierarchies provided by English SEM-I. Temporal, directional, and other usages of prepo-
sitions give rise to distinct, but potentially related, semantic predicates. Likewise, the SEM-I incorporates some ontological
information, e.g. a classication of temporal entities, though crucially only to the extent that is actually grammaticized in the
language proper.
development corpus: realizations average at a lit-
tle less than twelve words in length. After addition
of domain-specific vocabulary and a small amount
of fine-tuning, the ERG provides adequate analyses
for close to ninety per cent of the LOGON reference
translations. For about half the test cases, all out-
puts can be generated in less than one cpu second.
End-to-End Coverage The current LOGON sys-
tem will only produce output(s) when all three
processing phases succeed. For the LOGON target
corpus (see below), this is presently the case in 35
per cent of cases. Averaging over actual outputs
only, the system achieves a (respectable) BLEU
score of 0.61; averaging over the entire corpus, i.e.
counting inputs with processing errors as a zero
contribution, the BLEU score drops to 0.21.
3 Stochastic Components
To deal with competing hypotheses at all process-
ing levels, LOGON incorporates various stochastic
processes for disambiguation. In the following, we
present the ones that are best developed to date.
Training Material A corpus of some 50,000
words of edited, running Norwegian text was gath-
ered and translated by three professional transla-
tors. Three quarters of the material are available
for system development and also serve as training
data for machine learning approaches. Using the
discriminant-based Redwoods approach to tree-
banking (Oepen, Flickinger, Toutanova, & Man-
ning, 2004), a first 5,000 English reference transla-
tions were hand-annotated and released to the pub-
lic.1 In on-going work on adapting the Redwoods
approach to (Norwegian) LFG, we are working to
treebank a sizable text segment (Rose?n, Smedt,
Dyvik, & Meurer, 2005; Oepen & L?nning, 2006).
Parse Selection The XLE analyzer includes sup-
port for stochastic parse selection models, assign-
ing likelihood measures to competing analyses
1See ?http://www.delph-in.net/redwoods/?
for the LinGO Redwoods treebank in its latest release,
dubbed Norwegian Growth.
(Riezler et al, 2002). Using a trial LFG treebank
for Norwegian (of less than 100 annotated sen-
tences), we have adapted the tools for the current
LOGON version and are now working to train on
larger data sets and evaluate parse selection perfor-
mance. Despite the very limited amount of train-
ing so far, the model already appears to pick up
on plausible, albeit crude preferences (as regards
topicalization, for example). Furthermore, to re-
duce fan-out in exhaustive processing, we collapse
analyses that project equivalent MRSs, i.e. syntac-
tic distinctions made in the grammar but not re-
flected in the semantics.
Realization Ranking At an average of more
than fifty English realizations per input MRS (see
Table 1), ranking generator outputs is a vital part
of the LOGON pipeline. Based on a notion of au-
tomatically derived symmetric treebanks, we have
trained comprehensive discriminative, log-linear
models that (within the LOGON domain) achieve
up to 75 per cent exact match accuracy in pick-
ing the most likely realization among compet-
ing outputs (Velldal & Oepen, 2005). The best-
performing models make use of configurational
(in terms of tree topology) as well as of string-
level properties (including local word order and
constituent weight), both with varied domains of
locality. In total, there are around 300,000 features
with non-trivial distribution, and we combine the
MaxEnt model with a traditional language model
trained on a much larger corpus (the BNC). The
latter, more standard approach to realization rank-
ing, when used in isolation only achieves around
50 per cent accuracy, however.
4 Implementation
Figure 2 presents the main components of the LO-
GON prototype, where all component communica-
tion is in terms of sets of MRSs and, thus, can easily
be managed in a distributed and (potentially) par-
allel client ? server set-up. Both the analysis and
generation grammars ?publish? their interface to
transfer?i.e. the inventory and synopsis of seman-
55
tic predicates?in the form of a Semantic Inter-
face specification (?SEM-I?; Flickinger, L?nning,
Dyvik, Oepen, & Bond, 2005), such that trans-
fer can operate without knowledge about gram-
mar internals. In practical terms, SEM-Is are
an important development tool (facilitating well-
formedness testing of interface representations at
all levels), but they also have interesting theoret-
ical status with regard to transfer. The SEM-Is
for the Norwegian analysis and English genera-
tion grammars, respectively, provide an exhaus-
tive enumeration of legitimate semantic predicates
(i.e. the transfer vocabulary) and ?terms of use?,
i.e. for each predicate its set of appropriate roles,
corresponding value constraints, and indication of
(semantic) optionality of roles. Furthermore, the
SEM-I provides generalizations over classes of
predicates?e.g. hierarchical relations like those
depicted in Figure 3 below?that play an impor-
tant role in the organization of MRS transfer rules.
5 Open-Source Machine Translation
Despite the recognized need for translation, there
is no widely used open-source machine translation
system. One of the major reasons for this lack of
success is the complexity of the task. By asso-
ciation to the international open-source DELPH-
IN effort2 and with its strong emphasis on re-
usability, LOGON aims to help build a repository of
open-source precision tools. This means that work
on the MT system benefits other projects, and
work on other projects can improve the MT sys-
tem (where EBMT and SMT systems provide re-
sults that are harder to re-use). While the XLE soft-
ware used for Norwegian analysis remains propri-
etary, we have built an open-source bi-directional
Japanese ? English prototype adaptation of the LO-
GON system (Bond, Oepen, Siegel, Copestake, &
Flickinger, 2005). This system will be available
for public download by the summer of 2006.
References
Bond, F., Oepen, S., Siegel, M., Copestake, A., & Flickinger,
D. (2005). Open source machine translation with DELPH-
IN. In Proceedings of the Open-Source Machine Trans-
lation workshop at the 10th Machine Translation Summit
(pp. 15 ? 22). Phuket, Thailand.
Carroll, J., Copestake, A., Flickinger, D., & Poznanski, V.
(1999). An efcient chart generator for (semi-)lexicalist
grammars. In Proceedings of the 7th European Workshop
on Natural Language Generation (pp. 86 ? 95). Toulouse,
France.
2See ?http://www.delph-in.net? for details, in-
cluding the lists of participating sites and already available
resources.
Carroll, J., & Oepen, S. (2005). High-efciency realization
for a wide-coverage unication grammar. In R. Dale &
K.-F. Wong (Eds.), Proceedings of the 2nd International
Joint Conference on Natural Language Processing (Vol.
3651, pp. 165 ? 176). Jeju, Korea: Springer.
Copestake, A., Flickinger, D., Sag, I. A., & Pollard, C.
(1999). Minimal Recursion Semantics. An introduction.
In preparation, CSLI Stanford, Stanford, CA.
Dyvik, H. (1999). The universality of f-structure. Discov-
ery or stipulation? The case of modals. In Proceedings of
the 4th International Lexical Functional Grammar Con-
ference. Manchester, UK.
Fenstad, J.-E., Ahrenberg, L., Kvale, K., Maegaard, B.,
M?uhlenbock, K., & Heid, B.-E. (2006). KUNSTI. Knowl-
edge generation for Norwegian language technology. In
Proceedings of the 5th International Conference on Lan-
guage Resources and Evaluation. Genoa, Italy.
Flickinger, D. (2000). On building a more efcient grammar
by exploiting types. Natural Language Engineering, 6 (1),
15 ? 28.
Flickinger, D., L?nning, J. T., Dyvik, H., Oepen, S., & Bond,
F. (2005). SEM-I rational MT. Enriching deep grammars
with a semantic interface for scalable machine translation.
In Proceedings of the 10th Machine Translation Summit
(pp. 165 ? 172). Phuket, Thailand.
Nordg	ard, T., Nygaard, L., L?nning, J. T., & Oepen, S.
(2006). Using a bi-lingual dictionary in lexical transfer. In
Proceedings of the 11th conference of the European Asoo-
ciation of Machine Translation. Oslo, Norway.
Oepen, S., Dyvik, H., L?nning, J. T., Velldal, E., Beermann,
D., Carroll, J., Flickinger, D., Hellan, L., Johannessen,
J. B., Meurer, P., Nordg	ard, T., & Ros?en, V. (2004). Som
	a kapp-ete med trollet? Towards MRS-based Norwegian ?
English Machine Translation. In Proceedings of the 10th
International Conference on Theoretical and Methodolog-
ical Issues in Machine Translation. Baltimore, MD.
Oepen, S., Flickinger, D., Toutanova, K., & Manning, C. D.
(2004). LinGO Redwoods. A rich and dynamic treebank
for HPSG. Journal of Research on Language and Compu-
tation, 2(4), 575 ? 596.
Oepen, S., & L?nning, J. T. (2006). Discriminant-based MRS
banking. In Proceedings of the 5th International Con-
ference on Language Resources and Evaluation. Genoa,
Italy.
Riezler, S., King, T. H., Kaplan, R. M., Crouch, R., Maxwell,
J. T., & Johnson, M. (2002). Parsing the Wall Street
Journal using a Lexical-Functional Grammar and discrim-
inative estimation techniques. In Proceedings of the 40th
Meeting of the Association for Computational Linguistics.
Philadelphia, PA.
Ros?en, V., Smedt, K. D., Dyvik, H., & Meurer, P. (2005).
TrePil. Developing methods and tools for multilevel tree-
bank construction. In Proceedings of the 4th Workshop
on Treebanks and Linguistic Theories (pp. 161 ? 172).
Barcelona, Spain.
Velldal, E., & Oepen, S. (2005). Maximum entropy models
for realization ranking. In Proceedings of the 10th Ma-
chine Translation Summit (pp. 109 ? 116). Phuket, Thai-
land.
Wahlster, W. (Ed.). (2000). Verbmobil. Foundations of
speech-to-speech translation. Berlin, Germany: Springer.
56
