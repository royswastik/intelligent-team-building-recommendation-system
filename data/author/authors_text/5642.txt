Chart Parsing and Constraint Programming 
Frank Morawietz 
Seminar flit Sprachwissenschaft 
Universifiit Tfibingen 
Wilhehnstr. I 13 
72074 Tfibingen, Germany 
frank@s fs. nphil, uni-tuebingen, de 
Abstract 
In this paper, lmrsing-as-deduction and constraint pro- 
gramming are brought ogether to outline a procedure for 
the speeitication of constraint-based chart parsers. Fob 
lowing the proposal in Shieber et al (1995), we show 
how to directly realize tim inference rules tbr deductive 
parsers as Constraint Handling Rules (Fr{ihwirlh, 1998) 
by viewing lhe items of a chart parser its constraints and 
lhe constraint base as a charl. This allows the direct use 
of constraint resolution to parse sentences. 
1 I n t roduct ion  
The parsing-as-deduction approach proposed in Pereira 
and Warren (1983) and exlended in Shieber et al (1995) 
and the parsing schemala detincd in Sikkel (1997) are 
well established parsing paradigms in computalional lin- 
guistics. Their main slrengths are Iheir llexibility and 
lhe level of abstraction concerning control informal\]o,1 
inherenl in parsing algorithms, lVurlhermore, lhcy are 
easily exlcnsible In more complex formalisms, e.g., at\]g- 
mcntcd phrase struclure rules or the ID/LP formal. 
Constraint Programming (CP) has been used in com- 
putational linguislics in several areas, for example in 
(typed) featut'e-lmsed systems (Smolka, 1995), or condio 
tional constraints (Matiasek, 1994), or adwmccd compi- 
lation techniques (G6tz and Meurcrs, 1997) or special- 
ized constraint solvers (Manandhar, 1994). But none 
of these approaches uses constraint programming tech- 
niques lo implement standard chart parsing algorithnls 
directly in a constraint system. 
In this papel; I will bring these two tmmdigms to- 
gether by showing how to implement algorithn\]s fl'om 
the parsing-as-deduction sctmme by viewing the parsing 
process as constraint propagation. 
The core idea is that the items of a conventional chart 
parser are constraints on labeled links between the words 
and positions of an input string. Then tile inference rules 
allow for the deduction of new constraints, again labeled 
and spanning parts of tim input siring, via constraint 
propagation. The resulting constraint store represents he 
chart which can be accessed to determine whether the 
parse was success fu l  or to reconstruct  a parse tree. 
While this ntay seem a trivial observation, it is not 
.iust another way of implementing deductive parsing in 
yet another language. "file approach allows for a rapid 
and very flexible but at lhe same time uniform method 
of implementation f all kinds of parsing algorithms (for 
constraint-lmsed theories). The goal is not necessarily to 
build tim fastest imrscr, but rather to build - for an ar- 
bitrary algorithm - a parser fast and pcrspict\]ously. For 
example, the advantage of our approach compared to the 
one proposed in Shieber et al (1995) is that we do not 
have to design a special dedt,ction engine and we do not 
have In handle chart and agenda explicitly. Furlhemmre, 
the process can be used in any constrainl-based formal- 
ism which allows for constraint propagation and there- 
fore can bc easily integrated into existing applications. 
The paper proceeds by reviewing Ihc parsing-as- 
deduction approach and a imrticular way of imple- 
menting constraint syslclns, Constraint Handling P, ules 
(CHR) as presented in l~rfihwir/h (1998). Then it shows 
how to implement several parsing algorithms very natu- 
rally with constraint propagation rules before concluding 
with an outlook on how 1o exteml the technique In more 
advanced applications. 
1.1 Pars ing  as Deduction 
Although I assume some familiarity with parsing-as- 
deduction, I will recall some basic delinitions for con- 
venience. The nolations and dm three basic algorithms 
are directly token from Shieber et al (t 995). 
As usual, strings w result from concalcnation o1' sym- 
bols from some alphal~et set ?, i.e., w C- E':. We refer 
t(i tile decomposition of such a siring into its alphabet 
symbols with indices. We lix this notation using w = 
Wl... uS,. Further notational conventions are: i, j E N, n 
for the length of the string to be parsed, A,B,C,... for 
arbilrary formulas or nonterminals, a b,c,.., for termi- 
nals, a for the empty string and o~,\[3,7,.., for strings of 
terminals and nonterminals. Formtflas used in parsing 
will also be called items or edges. A grammatical deduc- 
tion system or, in Sikkel's terminology a pal:ring schema, 
is defined as a set of deduction schemes and a set of ax- 
ioms. These are given with the help of formula schemata 
which contain (syntactic) me\]a-variables which are in- 
s\]an\]tared with concrete terms on application of tim rules. 
A deduction scheme R has t11o general form 
AI - . -  A ,  
( side conditions on A \] . . .  A , ,  C ) 
C 
551 
Table 1: Parsing algorithms as Grammatical Deduction Systems 
Bottom-Up Top-Down Earley 
Items 
Axiom 
Goal 
Scan 
Predict 
Complete 
\[j,c~-\] \[j, ? \[~1 \[i,j,A,o~* ~1 
\[o, ? \] \[o, ? Sl \[o, o, s', ? s\] 
\[,,,s.\] \[,,, .\] \[0,,,,s',s.\] 
\[j, ot * \] \[j, * w.i+l ~\] \[i, j ,a, o~ * w.i+ |\[3\] 
\ [ j+  1,mvj+l "\]' \ [ j+  l, ? \[3\] \[i,j+ I ,A,~wj+I * \[3\] 
~ (B___~ T ) \[i:j,a,o~.B~\] (B__+ T) 
\[j, ? 7\[3\] \[j, j, B, ? 3'\] 
\[k,j,n,Vo\] 
(B ---+ y) \[i,j,A,aB \[3\] \[j, ae  ? \] 
where the Ai and C arc formula schemata. The Ai are 
called antecedents and C the consequence. Note that de- 
duction schemes may refer to string positions, i.e., the 
indices within the input string, in their side conditions. 
Application of these schemata nd derivations of formu- 
las are then detined as in the Shieber et al article. In- 
tuitively, parsing uses the deductive rules - if their an- 
tecedents and the side conditions are met - to infer new 
items from the axioms and already generated items until 
no new ones can be derived. The parse was successful if
a goal item was derived. 
Therefore, all the parsing systems used in this paper 
are delincd by specifying a class of items, a set of ax- 
ioms, a set of inference rules and a subset of the items, 
the goals, For better eadability, I follow Shieber et al in 
using the familiar dotted items for the presentation. The 
three classical example algorithms we will use to illus- 
trate our technique are given in Tab. 1. I assume famil- 
iarity with these algorithms. 
Unless specified differently, we assume that we are 
given a context-free grammar ~ = ( N, Z, S, P ) with non- 
terminals N, terminals Z, start symbol S and set o1' pro- 
ductions P. For Earley's algorithm we also assume a new 
start symbol S' which is not in N. Each production is of 
the form A ----+ o~ with A G N, c~ E (NU Z)*. For examples 
I will use the simple PP-attachmcnt grammar ~ given in 
Fig. 1 with the obvious sets of nonterminals and termi- 
nals, the start symbol S and productions P. It is left to 
the reader to calculate xample derivations for the three 
algorithms t'or a sentence such as John hit the dog with 
the stick. 
1.2 Constraint Handling Rules 
There are several constraint programming environments 
available. The most recent and maybe the most tlexible is 
the Constraint Handling Rules (CHR) package included 
in SICStus Prolog (Friihwirth, 1998). These systems 
S ---+ NPVP V - -}  hit 
VP ----+ V NP \[ V NP PP PN ---+ John 
PP ~ PNP N ---+ dog\]stick 
NP - -+ PN \] Det N I P ---+ with 
NI ----+ N I N1 PP Det ----q the 
Figure 1: Example Grammar: PP-attachment 
maintain a constraint base or store which is continually 
monitored for possible rule applications, i.e., whether 
there is enough information present to successfully use a 
rule to silnplify constraints or to derive new constraints. 
Whereas usually one deals with a tixed constraint domain 
and a specialized solver, CHR is an extension of the Pro- 
log language which allows for the specification of user- 
defined constraints and arbitrary solvers. The strengfl~ of 
the CHR approach lies in the fact that it allows for mul- 
tiple (conjunctively interpreted) heads in rules, that it is 
flexible and that it is tightly and transparently integrated 
into the Prolog engine. 
In CHR constraints are just distinguished sets of 
(atomic) formulas. CHR allow the definition of rule sets 
for constraint solving with three types of rules: Firstly 
simplification rules (<=>)  which replace a number of 
constraints in the store with new constraints; secondly 
propagation rules (==>)  which add new constraints 
to the store in case a number of constraints is already 
present; and thirdly "simpagation" rules (<=> in com- 
bination with a \ in the head of the rule) which replace 
only those constraints with new ones which are to the 
right of the backslash. Rules can have guards. A guard 
(separated from the rest of the body by a I) is a condition 
which has to be met before the rule can be applied. 
We cannot go into the details of the formal seman- 
tics of CHR here. The interested reader is referred to 
Frfihwirth (1998). Since I will refer back to it let us just 
552 
note that logically, simplification rules are cqt, ivalences 
and propagation rules are implications if their gtmrd is 
satislied. Simpagation rules are special cases of simpli- 
fication rules. Soundness and completeness results for 
CHR are available (Abdennadher tal., 1996 Abdennad- 
her, 1998). 
2 Parsing as Constraint Propagation 
The basic observation which turns parsing-as-deduction 
into constraint propagation is simple: items o1' a chart 
parser arc just specM formulas which are used in an in- 
ference process. Since constraints in constraint program- 
ruing are nothing but atomic formulas and c(mslraint han- 
dling rules nothing but inference rules, the connection is
immediate. 
In more detail, I will present in this section how to 
implement the three parsing algorithms given in %b. i in 
CHR and discuss the advantages and drawbacks of this 
approach. Since CHP, are integrated in SICStus Prolog, 
I will present constraints and rules in Prolog notation. 
We use tile following two types of constraints. The 
constraints cor,'esponding to tile items will be called 
edge constraints. They have two arguments in case of 
the two naive algorithms and tive in tile case o1' Ear- 
ley's algorithm, i.e., edge (X, N) means in the case of the 
bottom-up algorithm that we have recognized a list of 
categories X up to position N, in the case of tile top-down 
algorithm that we are looking for a list of categories X 
starting at position N and in tile case of Earlcy's algo- 
rithm edge (A,Alpha,Beta, I , J )  means that we found 
a substring fl'om I to J by recognizing the list of cate- 
gories Alpha, bul we are still looking for a list of cate- 
gories Beta to yield category k. The second constraint, 
werd(Pos,Cat-Word),  is treed in tile scanning steps. 
It avoids using Icxical entries in prediction/completion 
since in gramnmr ules we do not use woIWs but their 
categories. 
For simplicity, a gramnmr is given as Prok/g Ihcts: lex- 
ical items as lex (Word, Category) and gramnmr ules 
as ru le  (RHS, LHS) where RHS is a list of categories rep- 
resenting the right hand side and LHS is a single category 
representing the left hand side of the rule. 
The algorithms are simple to implement by specify- 
ing the inl'erenee rules as constraint propagation rules, 
the axioms and the goal items as constraints. The infer- 
once rules are translated into CHR in the following way: 
The antecedents are transformed into constraints appear- 
ing in the head of the propagation rules, the side condi- 
tions into the guard and the consequence is posted in the 
body. A summarization of the resulting CHR programs 
is presented in Tab. 2. 
We use Earley's algorithm for a closer look at the CHR 
propagation rules. In the scanning step, we can move 
tile head of the list of categories we arc looking for to 
those we already recognized in case we have an appro- 
priately matching edge and word constraint in our con- 
straint store. The result is posted as a new edge constraint 
parse(InList):- 
axiom, 
post eonst(InList, 
report(Length). 
0, Length), 
post_const(\[\], Len, Len). 
post_const(\[Word}Str\], InLen, Len):- 
rAndall(Cat, lex(Word,Cat), Cats), 
post words(Cats, InLen, Word), 
NewLen is InLen + i, 
post const(Str, NewLen, Len). 
Figure 2: Utilities for CHRdmsed deductive parsing 
with tile positional index appropriately increnmnted. 
The prediction step is more complex. There is only 
one head in a rule, namely an edge which is still looking 
tbr s()me category to be found. If one can lind rules with 
a matching LHS, we collect all of them in a lisl and post 
tile approl)riatc fl'esh edge constraints lbr each element of 
that list with the predicate post_ea_edges/3 which posts 
edges of tim lbllowingkind: edge(LHS,\[ J ,RHS, J ,d) .  
The collection of all matching rules in a call to se to f /3  
is necessm 7 since CHR are a committed choice lan- 
guage. One cannot enumerate all solutions via back- 
tracking. If there are no matching rules, i.e., tim list 
of RHSs we found is cmpty, the call to se to f  i, the 
guard will fail and therefore avoid vacuous predictions 
and nontermination f tile predictor. 
Lastly, tile completion step is a pure propagation rule 
which |1"a11s\]alcs literally. The two antecedents are in 
the head and lhe consequence in the body with appro- 
priate instantiations o1' the positional variables and with 
the movement of the category recognized by the passive 
edge from the categories Io be found to those found. 
In the table there is one more type of rule, called an 
absorption rule. It discovers those cases where we posted 
an edge consmtint which is already present in the chart 
and simply absorbs the newly created one. 
Note that we do not have to specify how to insert edges 
into ciflmr chart or agenda. The chart and the agenda re 
represented by the constraint store and therefore built- 
in. Neither do we need a specialized eduction engine 
as was necessary for the implementation described in 
Shieber et al In fact, the utilities needed are extremely 
simple, see Fig. 2. 
All we have to do for parsing (parse / l )  is to post the 
axion? and o~1 traversal of the input stri,g to post the 
word constraints according to the lexicon of the given 
grammar. Then the constraint resolution process witll the 
inference rules will automatically build a complete chart. 
The call to repor t /1  will just determine whether dmre 
is an appropriate edge with the correct length in the chart 
and print that information to the screen. 
Coming back to the issues of chart and agenda: the 
constraint store l'nnetiot~s as chart and agenda t the same 
i axiom/0 just posts Ihe edge(s) delined in Tab. 2. 
553 
Table 2: Parsing systems as CHR programs 
Bottom-Up Top-Down Earley 
I tems edge (X,N) edge  (X,N) 
Ax iom edge ( \[ \] , 0 ) edge  ( \[ s \] , 0 ) 
Goa l  edge( Is\] ,Len) edge( \[\] ,Len) 
edge(A,Alpha,Beta, I,J) 
edge(sprime,\[\],\[s\],0,0) 
edge(sprime,\[s\],\[\],0,Len) 
Scan 
Bottom-Up 
Top-Down 
Earley 
edge(Stack,N), word(N,Cat- Word) :=> 
N1 is N+I, 
edge(\[CatlStack\],Nl). 
edge(\[CatlT\],N), word(N,Cat- Word) ==> 
N1 is N+I, 
edge(T,Nl). 
edge(A,ilpha,\[CatlBeta\],I,J), word(J,Cat- Word) 
Jl is J+l, 
edge(h,\[Catlilpha\],Beta,I,Jl). 
==> 
Predict 
Top-Down 
Earley 
edge(\[LHSIT\],N) ::> 
setof(RHS, rule(RHS,LHS), List) I 
post_td edges(List,T,N). 
edge( A, Alpha,\[Bl Beta\], I,d} ==> 
setof(Gan~a, rule(Gamma,B), List) 
post ea_edges(List,B,J). 
Complete 
Bottom-Up 
Earley 
edge(Stack,N) ::> 
setof(Rest-LHS, split(Stack,Rest,LHS), List) 
post bu_edges(List,N). 
edge(h,ilpha,\[BIBeta\],I,K), edge(B,Gamma,\[\],K,J) ==> 
edge(i,\[Blilpha\],Beta,I,J). 
Absorb 
Bottom-Up edge(L,N) \ edge(L,N) <:> true. 
Top-Down edge(L,N) \ edge(L,N) <=> true. 
Ear ley  edge (A,Alpha, Beta, I, J) \ edge (A,Alpha, Beta, I, J) <:> true. 
time since as soon as a constraint is added all rules are 
tried for applicability. If none apply, the edge will remain 
dormant until another constraint is added which triggers 
a rule together with it. 2 So, the parser works incremen- 
tally by recursively trying all possible inferences for each 
2 Another way to "wake" a constraint is to instanliate any of its vari- 
ables in which case, it will be matched against he rules again. Since all 
our constraints are ground, this does not play a role here, 
constraint added to the store before continuing with the 
posting of new constraints fi'om the post_const/3 pred- 
icate. The way this predicate works is to traverse the 
string fi'om left-to-right. It is trivial to alter tile predicate 
to post the constraints from right-to-left or any arbitrary 
order chosen. This can be used to easily test different 
parsing strategies. 
The testing for applicability of new rules also has a 
554 
I ?- parse(\[john, hit, the, dog, 
with, the, stick\]). 
Input recognized. 
word (0, pn- j ohn) 
word ( I, v-hi t), 
word (2, det- the 
word (3, n-dog) , 
word ( 4, p-wi th) 
word ( 5, det- the ) 
word ( 6, n-stick) 
edge(sprlme, \[\], \[s\],O,O), 
edge(s,\[\],\[np,vp\],O,O), 
edge(np, \[\] , \[det,nbar\], O, O) , 
edge(np, \[\], \[pn\], O, O) , 
edge(np, \[phi, \[\] , O, I) , 
edge(s, \[np\], \[vp\],O,l), 
edge(vp,\[\], \[v,np\],l,l), 
edge(vp, \[\], \[v,np,pp\],l,l), 
edge(s,\[vp,np\],\[\],O,7), 
edge(sprime,\[s\], \[\],0,7) 
Figure 3: A partial CHP. generated chart 
connection with the absorption rules. We absorb tile 
newer edge since we can assume that all possible propa- 
gations have been done with lhe old identical edge con- 
straint so that we can safely throw tile other one away. 
As an example I'OZ" tile resulting chart, part of the out- 
put of an Earley-parse for John hit the dog with the stick 
assuming the grammar fl'om Fig. I is presented in Fig. 3. 
The entire conslrainl stere is prinlcd lo tl~e screen after 
the constraint resolution process tops. Tile order of file 
constraints actually reflects tile order of the construction 
o1' the edges, i.e., the chart constitutes a lrace o1' tile parse 
at the same time. Although the given siring was ambigu- 
ous, only a single solution is visible in lh.e chart. This is 
due to the fact that we only (lid recognition. No explicit 
parse wits built which could have differentiated between 
ihe two solutions. It is an easy exercise to either write a 
predicate to extract all possible parses from the chart or 
to alter the edges in such a way flint an explicit parse tree 
is built dr,ring parsing. 
By using a built-in deduction engine, one gives up con- 
trol of its efficiency. As it turns out, this CHR-based ap- 
proach is slower titan the specialized engine developed 
and provided by Shieber et al by about a factor of 2, e,g., 
for a six word sentence and a simple grammar tile pars- 
ing time increased from 0.01 seconds to 0.02 seconds on 
a LINUX PC (Dual Pentium lI with 400MHz) running 
SICStus Prolog. This factor was preserved under 5 and 
500 repetitions of the same parse. However, speed was 
not the main issue in developing this setup, but rather 
simplicity and ease of implementation. 
qb sunl up this section, tile advantages of the approach 
lie in its flexibility and its availability for rapid prototyp- 
ing of different parsing algorithms. While we used the 
basic examples fl'om the Shieber et al article, one can 
also implement all Iho different deduction schemes from 
Sikkel (1997). This also includes advanced algorithms 
st,ch as left-corner or head-corner parsing, the relined 
Earley-algoriflml proposed by Graham el al. (1980), or 
(unification-based) II)/LP parsing as defined in Moraw- 
ietz (1995), or any improved version of any of these. 
Furthermore, because of the logical semantics of CHP, 
with their soundness and completeness, all eorrecmess 
and so/redness proofs for the algorithms can be directly 
applied to this constraint propagation proposal. The main 
disadvantage of the proposed approach certainly lies in 
its apparent lack of efficiency. One way to address this 
problem is discussed in the next section. 
3 Extensions of the Basic Technique 
The,'e are tw'o directions the extensions of the presented 
technique of CHR imrsing might rake. Firstly, one might 
consider lmrsing of more complicated granmm,'s com- 
pared to tile CF ones which were assumed so far. Fol- 
lowing Shieber et al, one can consider utfification-tmsed 
grammars or tree adjoining grammars. Since I think lha! 
the previous sections howed lhat the Shieber ctal. ap- 
proach is transferable in general, the results they present 
are applicable here as well. 3 Instead, I want to consider 
parsing of minimalist grammars (Chomsky, 1995) as de- 
lined in recent work by Stabler (I 997, 1999). 4
3.1 Minimalist Parsing 
We cannot cover the flleory behind deriwltional minimal- 
ism as presenled in Smbler's papers in any delail. Very 
briefly, lexical items arc combined wilh each other by a 
binary operation meIx'e which is lriggered by the avail- 
ability of an appropriate pair of clashing features, here 
noted as cat: IC) for Smbler's categories c and comp (C) 
for =c. Fttrlhermorc, there is a treaty operation move 
which, again on tile awfilability era  pair of clashing fea- 
tures (e.g., -case, +case), triggers the extraelion era  
(possibly trivial) subtree and its merging in at tile root 
node. On completion of these operations lhe clashing 
feature pairs are removed. The lexical items are of tile 
l'orm o1' linked sequences o1' trees. Accessibility o1' fea- 
lures is detined via a given order on the nodes in this 
chain of trees. A parse is acceptable if all features have 
been checked, apart li'om one category feature which 
spans the length of the string. The actual algorithm 
works naively bottom-up and, since the operations are 
at most binary, the algorithm is CYK-based. 
3Obviously, using unification will inlroduce addilional complexity, 
but no change of the basic melhod isrequired. If lhe tmilicazion can be 
reduced to Prolog unilication, it can stay in the head of the rule(s). If it 
needs dedicated tmilicalion algorilhms, they have to be called explicitly 
it\] the guard. 
4 The code for the original implenlenzalion u derlying the paper was 
kindly provided by Hd Stabler Altar/from Ihe implementation in CHP,, 
all file rest is his work and his ideas. 
555 
Table 3: Part of a CHR-based minimalist parser 
Items 
Axiom 
Goal 
edge(I, J, Chain, Chains) 
edge(I, I, Chain, Chains) 
edge(I, I+l, Chain, Chains) 
edge(J, J, Chain, Chains) 
edge(0, Length, \[cat(C)\], \[\]) 
( \[Chain l Chains \] ----+ e), I a variable 
( \[Chain I Chains\] ----+ Wi+l) 
and there is no -X in \[Chain I Chains\] 
( \[ChainlChains\] - -~  wi+l), J a variable 
and -X, I and I+l  occur in \[ChainlChains\] 
Merge edge(I,J,\[comp(X) IRestHead\],Ch0), edge(K,L,\[cat(X) IRestComp\],Chl) 
eheck(RestHead,NewHead, I,J,K,L,A,B,RestComp,Ch0,Chl,Ch) 1 
edge(A,B,NewHead,Ch). 
==> 
An initial edge or axiom in this minimalist parsing sys- 
tem cannot simply be assumed to cover only the part of 
the string where it was l~und since it could have been the 
result of a move. So the elements of the lexicon which 
will have to be moved (they contain a movement trig- 
ger -X) actually have the positional indices instantiated 
in the last o1' those features appearing. All other move- 
ment triggers and the position it will he base generated 
are assumed to be traces and therefore mpty. Their po- 
sitional markers are identical variables, i.e., they span no 
portion of the string and one does not know their value 
at the moment of the construction of the axioms. They 
have to be instantiated during the minimalist parse. 
Consider the set of items as delined by the axioms, see 
Tab. 3. The general form of the items is such that we 
have the indices first, then we separate the chain of trees 
into the first one and the renmining ones for better access. 
As an example for the actual edges and to illustrate the 
discussion about tile possibly variable string positions in 
the edges, consider the lexical item it (as in believe it): 
lex(it,I,\[(K,K):\[cat(d),-case(I,J)\]\]):- 
J is I+l. 
Since I = 1 in the example the following edge results 
edge(K, K, \ [ ca t (d ) , - case(1 ,2 ) \ ] \ ] ,  \ [ \ ] ) .Weknow 
that it has been moved to cover positions 1 to 2, but we 
do not know (yet) where it was base generated. 
We cannot go into any further detail how the actual 
parser works. Nevertheless, the propagation rule for 
merging complementizers shown in Tab. 3 demonstrates 
how easily one can implement parsers for more advanced 
types of grammars. 5 
5The predicate check implements the checking of the features and 
i,ldices and recomputes the new values for the resulting edge. 
3.2 Compiling the Grammar Rules into the 
Inference Rules 
A proposal for improving tile approach consists in mov- 
ing the test for rule applicability from the guards into 
the heads of the CHR rules. One can translate a given 
context-fi'ee grammar under a given set of inference rules 
into a CHR program which contains constraint propaga- 
tion rules for each grammar rtde, thereby making tile pro- 
cessing more efficient. For simplicity, we discuss only 
tim case of bottom-up arsing. 
For the translation from a CF grammar into a con- 
straint framework we have to distinguish two types of 
rules: those with from those without an empty RHS. We 
treat the trivial case of the conversion first. For each rule 
in the CF grammar with a non-empty RHS we create a 
constraint propagation rule such that each daughter of 
the rule inu'oduces an edge constraint in the head of the 
propagation rule with variable, but appropriately nmtch- 
ink string positions and a tixed label. Tile new, propa- 
gated edge constraint spans tbe entire range of the posi- 
tions ot' the daughters and is labeled with the (nontermi- 
nal) symbol of the LHS of tile CF rule. In our example, 
the resulting propagation rule for S looks as follows: 
edge(I,K, np), edge(K,J,vp) ::> edge(I,J,s) 
The translation is a little bit more complicated for rules 
with empty RHSs. Basically, we create a propagation 
rule for each empty rule, e.g., A ----+ e, such that the head 
is an arbitrary edge, i.e., both positions and the label are 
arbitrary variables, and post new edge constraints with 
the LHS of the CF rule as label, using the positional vari- 
ables and spanning no portion of the string, resulting in 
CHR rules of the following type: 
edge(I,J,_Sym) :=> J is I+l 
edge(l,I,A), edge(J,J,A) 
556 
But obviously rtfles of tiffs type lead to nonlerlnination 
since they would propagate furlhcr constraints on their 
own output which is avoided by inchlding a guard which 
ensures flint empty edges are only propagated for every 
possible string position once by testing whether the edge 
spans a string of length one. Recall that storing and us- 
ing already existing edge conslrairfls is aw)idcd with an 
absorption rule. Since these empty constraints can be 
reused an arbitrary number of times, we get the desired 
effect with.out having to fear nontermination. Allhough 
this is not an elegant solution, it seems lhat other alterna- 
tives such as analyzing and transforming the entire gram- 
mar or posting the empty constraints while traversing the 
input string arc not appealing eflher since they give up 
the one-to-one correspondence b tween the rules of the 
CF grammar and the constraint program which is advan- 
tageous in debugging. 
With this technique, the parsing timcs achieved were 
better by a factor of a third compared to the Shieher et al 
implemenlation. Although now the process of the com- 
pilation obscures the direct com~ection betweet~ parsing- 
as-deduction and constraint propagalion somewhat, the 
increase in speed makes it a worfl~while xercise. 
4 Conclusion 
In the paper, the similarity between parsing-as-deduction 
and constraint propagation is used to propose a llexible 
and simple system which is easy to implement and flmre- 
fore offers itself as a tcstbed for different parsing strate- 
gies (such as top-down or bottom-up), for wu'ying modes 
? of processing (such as left-to-right or right-to-left) or for 
different ypes of grammars (such as for example min- 
imalist grammars). Compared to the Shieber al)proach, 
the pure version see,ns to be lacking in efliciency. This 
can be remedied by providing an automatic compilation 
into more eflicient specialized parsers. 
While the paper has shown that existing constraint 
systems are powerful enough to allow chart parsing, 
more work has to be invested in the realization of such 
a larger system combining these techniques with con- 
straint solvers lbr existing constraint-based natural an- 
guage theories m see whether ft,rther benelils can be got- 
ten from using parsing as constraint propagation. Dt, e to 
the tlexibility of the CHR system, one can now use the 
constraint propagation approach to drive other constraint 
solving or constraint resolution techniques (also imple- 
mented in CHR) resulting in a homogenous environment 
which combines both classical constraint solving with a 
more operational generator. 
Specifically, one can use each created edge to post 
other constraints, for example about he wdl-formedness 
of associated typed feature structures. By posting them, 
they become available for other constraint handling rules. 
In particular, systems directly implementing HPSG seem 
to suffer fi'om the problem how to drive the constraint 
resolution process efficiently. Some systems, as for ex- 
ample ALE (Carpenter and Penn, 1998) use a phrase 
structtH'e backbone to drive tile process. Tile p,oposal 
here would allow to use 111e ID/LP schemata directly as 
constraints, but nevertheless a the driving tbz'ce behind 
lhe other constraint satisfi~ction techniques. However, for 
the moment this remains peculative. 
References 
Abdemmdhcr, S. (1998). Almlyse yon regelbasierten 
Constraintli~sern, PhD thesis, Ludwig-Maximilians- 
Universitfit Mfinchen. 
Abdennadheh S., Frfihwirth, T. and Meuss, H. (1996). 
On conlluence of constraint handling rules, LNCS' 
1118, Springer. 
Carpenter, B. and Penn, G. (1998). ALE: The attribute 
logic engine, version 3.1, User mamtal, Carnegie Mel- 
lon University, Pittsburgh. 
Chomsky, N. (1995). The Minimalist Program, Vol. 28 
of Current Studies in Linguistics, MIT Press. 
Friihwirth, T. (1998). Thcory and practice of constraint 
handling rules, Journal (),/'Logic Pmgtzmlnting 37. 
G6tz, T. and Meurers, D. (1997). Interleaving universal 
principles and relational constraints over typed feature 
logic, A CTJEA CL Collj'erence '97, Madrid, Spain. 
Graham, G., Harrison, M. G. and Ruzzo, W. L. (1980). 
An improved context-li'cc recognizer, ACM 7)wnsac- 
tions on Programming Languages and Systems 2 (3). 
Manandhar, S. (1994). An attributive logic of set descrip- 
tions and set operations, ACL Conference '94. 
Matiasek, J. (1994). PHnciple-Based Processing of Nat- 
ural Language Using CEP Techniques, PhD thesis, TU 
Wien. 
Morawiclz, F. (1995). A Unification-Based ID/LP Pars- 
ing Schema, Proceedings of the 4th IWPT, Prag. 
Pereira, F. C. N. and Warren, D. H. D. (1983). Parsing as 
deduction, ACL Collference ' 83. 
Shieber, S. M., Schabes, Y. and Pereira, F. C. N. (1995). 
Principles and i,nplemenlation of deductive parsing, 
Journal of Logic Pmgtwmming 24(1-2). 
Sikkel, K. (1997). Patwing Schemata: A Framework 
Jbr Specification and Analysis o.f Pa~wing Algorithms, 
ETACS Series, Springer. 
Smolka, G. (1995). The Oz programming model, in 
J. van Leeuwen (ed.), Conqmter Science 7bday, LNCS 
1000, Springer. 
Stabler, E. (1997). Derivational minimalism, in C. Retor6 
(ed.), Logical Aspects of Computational Linguistics, 
LNAI 1328, Springer. 
Stabler, E. (2000). Minimalist grammars and recogni- 
tion, Presented at the Workshop Linguistic Form and 
its" Conqnttation of the SFB 340 in Bad Teinach, Uni- 
versitiit Tiibingen. Draft. 
557 
