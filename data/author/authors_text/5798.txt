An Algorithm for One-page Summarization of a Long Text
Based on Thematic Hierarchy Detection
Yoshio Nakao
Fujitsu Laboratories Ltd.
Kamikodanaka 4-1-1, Nakahara-ku, Kawasaki, Japan, 211-8588
nakao@ab.fujitsu.co.jp
Abstract
This paper presents an algorithm for
text summarization using the the-
matic hierarchy of a text. The algo-
rithm is intended to generate a one-
page summary for the user, thereby
enabling the user to skim large vol-
umes of an electronic book on a
computer display. The algorithm
rst detects the thematic hierarchy
of a source text with lexical cohe-
sion measured by term repetitions.
Then, it identies boundary sen-
tences at which a topic of appropri-
ate grading probably starts. Finally,
it generates a structured summary
indicating the outline of the the-
matic hierarchy. This paper mainly
describes and evaluates the part for
boundary sentence identication in
the algorithm, and then briey dis-
cusses the readability of one-page
summaries.
1 Introduction
This paper presents an algorithm for text
summarization using the thematic hierarchy
of a long text, especially for use by readers
who want to skim an electronic book of sev-
eral dozens of pages on a computer display.
For those who want an outline to quickly
understand important parts of a long text,
a one-page summary is more useful than a
quarter-size summary, such as that gener-
ated by a typical automatic text summa-
rizer. Moreover, a one-page summary helps
users reading a long text online because the
whole summary can appear at one time on
the screen of a computer display.
To make such a highly compressed sum-
mary, topics of appropriate grading must be
extracted according to the size of the sum-
mary to be output, and selected topics must
be condensed as much as possible. The pro-
posed algorithm decomposes a text into an
appropriate number of textual units by their
subtopics, and then generates short extracts
for each unit. For example, if a thirty-
sentence summary is required to contain as
many topics as possible, the proposed algo-
rithm decomposes a source text into approxi-
mately ten textual units, and then generates a
summary composed of two- or three-sentence
extracts of these units.
The proposed algorithm consists of three
stages. In the rst stage, it detects the the-
matic hierarchy of a source text to decom-
pose a source text into an appropriate num-
ber of textual units of approximately the same
size. In the second stage, it adjusts each
boundary between these textual units to iden-
tify a boundary sentence, indicating where a
topic corresponding to a textual unit proba-
bly starts. It then selects a lead sentence that
probably indicates the contents of subsequent
parts in the same textual unit. In the last
stage, it generates a structured summary of
these sentences, thereby providing an outline
of the thematic hierarchy of the source text.
The remainder of this paper includes the
following: an explanation of problems in one-
page summarization that the proposed algo-
rithm is intended to solve; brief explanations
of a previously published algorithm for the-
matic hierarchy detection (Nakao, 1999) and
a problem that must be solved to successfully
realize one-page summarization; a description
and evaluation of the algorithm for boundary
sentence identication; a brief explanation of
an algorithm for structured summary con-
struction; and some points of discussion on
one-page summarization for further research.
2 Problems in one-page
summarization of a long text
This section examines problems in one-page
summarization. The proposed algorithm is
intended to solve three such problems.
The rst problem is related to text decom-
position. Newspaper editorials or technical
papers can be decomposed based on their
rhetorical structures. However, a long ag-
gregated text, such as a long technical sur-
vey report, cannot be decomposed in the
same way, because large textual units, such
as those longer than one section, are usually
constructed with only weak and vague rela-
tionships. Likewise, their arrangement may
seem almost at random if analyzed accord-
ing to their logical or rhetorical relationships.
Thus, a method for detecting such large tex-
tual units is required.
Since a large textual unit often corresponds
to a logical document element, such as a part
or section, rendering features of logical ele-
ments can have an important role in detecting
such a unit. For example, a section header
is distinguishable because it often consists
of a decimal number followed by capitalized
words. However, a method for detecting a
large textual unit by rendering features is not
expected to have wide range of applicability.
In other words, since the process for render-
ing features of logical elements varies accord-
ing to document type, heuristic rules for de-
tection must be prepared for every document
type. That is a problem. Moreover, the log-
ical structure of a text does not always cor-
respond to its thematic hierarchy, especially
if a section consists of an overview clause fol-
lowed by other clauses that can be divided
into several groups by their subtopics.
Since then, based on Hearst's work (1994),
an algorithm for detecting the thematic hi-
erarchy of a text using only lexical cohesion
(Haliday and Hasan, 1976) measured by term
repetitions was developed (Nakao, 1999). In
comparison with some alternatives (Salton et
al., 1996; Yaari, 1998), one of the features
of the algorithm is that it can decompose a
text into thematic textual units of approxi-
mately the same size, ranging from units just
smaller than the entire text to units of about
one paragraph. In this paper, a summariza-
tion algorithm based on this feature is pro-
posed.
The second problem is related to the tex-
tual coherence of a one-page summary itself.
A three-sentence extract of a large text, which
the proposed algorithm is designed to gener-
ate for an appropriate grading topic, tend to
form a collection of unrelated sentences if it is
generated by simple extraction of important
sentences. Furthermore, the summary should
provides new information to a reader, so an
introduction is necessary to help a reader un-
derstand it. Figure 4 shows a summary exam-
ple of a technical survey report consisting of
one hundred thousand characters. It was gen-
erated by extracting sentences with multiple
signicant terms as determined by the like-
lihood ratio test of goodness-of-t for term
frequency distribution. It seems to have sen-
tences with some important concepts (key-
words), but they do not relate much to one
another. Moreover, inferring the contexts in
which they appear is di?cult.
To prevent this problem, the proposed al-
gorithm is designed to extract sentences from
only the lead part of every topic.
The third problem is related to the read-
ability of a summary. A one-page summary
is much shorter than a very long text, such
as a one-hundred-page book, but is too long
to read easily without some breaks indicating
segues of topics. Even for an entire exposi-
tory text, for which a method for displaying
the thematic hierarchy with generated head-
ers was proposed to assist a reader to explore
the content (Yaari, 1998), a good summary is
required to help a user understand quickly.
To improve readability, the proposed algo-
rithm divides every one-page summary into
several parts, each of which consists of a
heading-like sentence followed by some para-
graphs.
3 Text Summarization Algorithm
3.1 Thematic Hierarchy Detection
In the rst stage, the proposed algorithm uses
the previously published algorithm (Nakao,
1999) to detect the thematic hierarchy of a
text based on lexical cohesion measured by
term repetitions. The output of this stage is
a set of lists consisting of thematic boundary
candidate sections (TBCS). The lists corre-
spond individually to every layer of the hier-
archy and are composed of TBCSs that sep-
arate the source text into thematic textual
units of approximately the same size.
3.1.1 Thematic Hierarchy Detection
Algorithm
First, the algorithm calculates a cohesion
score at xed-width intervals in a source text.
According to Hearst's work (1994), a cohesion
score is calculated based on the lexical sim-
ilarity of two adjacent xed-width windows
(which are eight times larger than the interval
width) set at a specic point by the following
formula:
c(b
l
; b
r
) =

t
w
t;b
l
w
t;b
r
q

t
w
2
t;b
l

t
w
2
t;b
r
where b
l
and b
r
are the textual block in the
left and right windows, respectively, and w
t;b
l
is the frequency of term
1
t for b
l
, and w
t;b
r
is the frequency t for b
r
. Hereafter, the point
between the left and right windows is referred
to as the reference point of a cohesion score.
The algorithm then detects thematic
boundaries according to the minimal points of
four-item moving average (arithmetic mean of
four consecutive scores) of the cohesion score
series. After that, it selects the textual area
contributing the most to every minimal value
and identies it as a TBCS.
Figure 1 shows the results of a TBCS de-
tection example, where FC is, Forward Co-
hesion, a series of average values plotted at
1
All content words (i.e., verbs, nouns, and adjec-
tives) extracted by a tokenizer for Japanese sentences.
0
0.1
0.2
0.3
0.4
0.5
0.6
0.7
0.8
10900 11000 11100 11200 11300 11400 11500 11600 11700
C
oh
es
io
n 
S
co
re
Location in Text [words]
(4.4)
(4.4.1)
minimal
FC
minimal
BC
moving average range
EP
FC < BC FC > BC
C
FC
BC
TBCS
Section Boundary
Figure 1: Example of TBCS Detection
the reference point of the rst averaged score,
and BC is, Backward Cohesion, a series of
averaged values plotted at the reference point
of the last averaged score. Since the textual
area just before the point at which FC plotted
is always in the left window when one of the
averaged cohesion scores is calculated, FC in-
dicates the strength of forward (left-to-right)
cohesion at a point. Conversely, BC indicates
the strength of backward cohesion at a point.
In the gure, EP is, Equilibrium Point, the
point at which FC and BC have an identi-
cal value. The algorithm checks for FC and
BC starting from the beginning till the end
of the source text; and it records a TBCS, as
depicted by the rectangle, whenever an equi-
librium point is detected (see (Nakao, 1999)
for more information).
640
B(4)
1280
B(3)
2560
B(2)
5120
B(1)
entire
B(0)
0 2000 4000 6000 8000 10000 12000 14000 16000 18000
W
in
do
w
 W
id
th
 [w
or
ds
]
Location in Text [words]
(4.2)
(4.2.1)
(4.2.2)
(ref)
(4.3)
(4.3.1) (4.3.2)
(4.3.3)
(ref)
(4.4)
(4.4.1)
(4.4.2)
(4.4.3)
(4.4.4)
(ref)
[0]
[0] [1] [2]
[0] [1] [2] [3] [4]
[0] [1] [2] [3] [4] [5] [6] [7] [8] [9] [10]
[6]
TBCS
Section Boundary
Figure 2: Example of Thematic Hierarchy
For a sample text, Figure 2 shows the re-
sulting thematic hierarchy that was detected
Table 1: Accuracy of Thematic Hierarchy Detection
Window Boundary # Original TBCS Unied TBCS
width cor. res. Recall Precision Recall Precision
5120 1 2 100 (22) 50 (11) 100 (0.3) 50 (0.1)
2560 2 4 100 (22) 50 (11) 50 (0.5) 25 (0.3)
1280 3 10 100 (27) 30 (8.1) 67 (1.4) 20 (0.4)
640 30 42 90 (23) 64 (16) 57 (2.3) 40 (1.7)
320 114 163 67 (22) 47 (16) 46 (4.5) 33 (3.2)
160 184 365 70 (22) 35 (11) 51 (9.1) 25 (4.6)
80 322 813 57 (25) 23 (10) 57 (21) 23 (8.2)
40 403 1681 52 (25) 13 (6.2) 71 (42) 17 (10)
The gures in parentheses are the baseline rates.
by the aforementioned procedure using vary-
ing window widths (the ordinates). Each hor-
izontal sequence of rectangles depicts a list
of TBCSs detected using a specic window
width.
To narrow the width of candidate sections,
the algorithm then unies a TBCS with an-
other TBCS in the layer immediate below. It
continued the process until TBCSs in all lay-
ers, from the top to the bottom, are unied.
After that, it outputs the thematic hierarchy
as a set of lists of TBCS data:
i: layer index of the thematic
hierarchy
B(i)[j]: TBCS data containing the
following data members:
ep: equilibrium point
range: thematic boundary
candidate section.
In Figure 2, for example, B(1)[1] is unied
with B(2)[1]; B(3)[4]; B(4)[6]; : : :, and the val-
ues of its data members (ep and range) are
replaced by those of the unied TBCS in the
bottom layer, which has been detected using
the minimum window width (40 words).
3.1.2 Results of Thematic Hierarchy
Detection
Table 1 summarizes the accuracy of the-
matic hierarchy detection in an experiment
using the following three kinds of Japanese
text as test data: a technical survey report
2
that consists of three main sections and con-
tains 17,816 content words; eight series of
2
\Progress Report of Technical Committee on Net-
work Access" in Survey on Natural Language Process-
ing Systems by Japan Electronic Industry Develop-
ment Association, chapter 4, pp. 117{197, Mar. 1997.
newspaper columns
3
, each of which consists of
4 to 24 articles containing about 400 words;
and twelve economic research reports
4
, each
of which consists of about ten articles con-
taining 33 to 2,375 words.
In the table, cor. denotes the number of the
correct data values composed of the starting
points of sections that contain the same num-
ber of words or more than the window width
listed in the same row
5
. In addition, res. de-
notes the number of TBCSs. The original
TBCS columns list the recall and precision
rates of detected TBCSs before TBCS unica-
tion, and the unied TBCS columns list those
rates after TBCS unication. On each layer,
the width of candidate sections for original
TBCS is about half of the window width; and
that of unied TBCS is 25 words (about half
of the minimum window width). The gures
shown in parentheses are the baseline rates
corresponding to random selection. That is,
parts are randomly selected from the source
text whose total size is equal to the total area
size of TBCSs.
As the boundary gures indicate, the pro-
posed algorithm decomposes a text into tex-
tual units of about equivalent window widths.
In addition, the rates of detected TBCSs are
clearly larger than their baselines. Further-
3
Obtained from the Daily Yomiuri On-line
(http://www.yomiuri.co.jp/).
4
Monthly reports written for a Japanese company
by a Japanese professor living in the U.S.A.
5
Only headings and intentional breaks, such as
symbol lines inserted to separate a prologue or epi-
logue from a main body, are used as correct bound-
aries. As a result, the precision rates of using smaller
window widths tend to degrade because of insu?cient
amounts of correct data.
more, for two relatively large series of news-
paper columns, the major boundaries were
detected properly. That is, using larger win-
dow widths, those boundaries were selectively
detected that separate groups of columns by
their subtopics. For example, the starting
point of a set of three consecutive columns
identically entitled \The Great Cultural Rev-
olution" in the \Chinese Revolution" series
was detected using 1,280 word width window,
as well as those of other three sets of consec-
utive columns entitled identically. Thus, the
proposed algorithm is expected to be eec-
tive for arbitrarily selecting the size of tex-
tual units corresponding to dierent grading
topics.
However, there are problems about how to
determine a boundary point in the range de-
ned by a TBCS. Although the previously
published algorithm (Nakao, 1999) deter-
mines a boundary point with minimal points
of cohesion scores for the smallest window
width, the accuracy degrades substantially
(see Table 3). The boundary sentence identi-
cation algorithm given below is a solution to
this problem.
3.2 Boundary Sentence Identication
In the second stage, from sentences in a
TBCS, the algorithm identies a boundary
sentence, indicating where a topic corre-
sponding to a textual unit probably starts,
and selects a lead sentence that probably in-
dicates the contents of subsequent parts in the
same textual unit. Figure 3 shows the algo-
rithm in detail.
3.2.1 Forward/Backward Relevance
Calculation
In steps 2 and 3, boundaries are identied
and lead sentences are selected based on two
kinds of relevance scores for a sentence: for-
ward relevance indicating the sentence rele-
vance to the textual unit immediately after
the sentence, and backward relevance indicat-
ing the sentence relevance to the textual unit
immediately before the sentence. The dier-
ence between the forward and the backward
relevance is referred to as relative forward rel-
1. Assign the target layer as the bottom layer of
the thematic hierarchy: i i
max
.
2. For each TBCS in the target layer, B(i)[j], do
he following:
(a) If i  i
max
, then select and identify
all sentences in B(i)[j]:range as Bound-
ary Sentence Candicates (B.S.C.); oth-
erwise, select and identify the sentences
in B(i)[j]:range located before or identi-
cal to the boundary sentence of B(i+ 1)
as B.S.C.
(b) From the B.S.C., identify a sentence as
a Boundary Sentence (B.S.), whose rel-
ative forward relevance is greater than 0
and has the most increment from that of
the previous sentence.
(c) Among the sentences in the B.S.C. lo-
cated after or identical to the B.S., select
the sentence that has the greatest for-
ward relevance as a Lead Sentence (L.S.).
3. If i > 1, then i i 1, and repeat from step 2.
Figure 3: Boundary Sentence Identication
Algorithm
evance.
Forward or backward relevance is calcu-
lated using the formula below, where every
textual unit is partitioned at the equilibrium
points of two adjacent TBCSs in the target
layer, the equilibrium point of each TBCS is
initially set by the thematic hierarchy detec-
tion algorithm, and the point is replaced by
the location of the boundary sentence after
the boundary sentence is identied (i.e., step
2b is completed).
r
S;u
=
1
jSj
X
t2S
tf
t;u
juj
 log(
jDj
df
t
))
jSj total number of terms in sentence S
juj total number of terms in textual unit u
tf
t;u
frequency of term t in textual unit u
jDj total number of xed-width (80 words)
blocks in the source text
df
t
total number of xed-width blocks
where term t appears
The use of this formula was proposed as
an eective and simple measure for term im-
portance estimation (Nakao, 1998)
6
. It is a
6
An experiment reported in (Nakao, 1998) indi-
Table 2: Example of Boundary Sentence Identication
Relevance Sentence [partially presented]
Location Backward Forward Relative (translation)
O:R:
11122 0 0.017 0.017 [???, 86] ([Yoshimura et. al])
11124 0.021 0.004 -0.017 ?????: "?????????? ", ?, pp.33-40, 1986
(Yoshimura, Kenji ... : Automatic Extraction System of ...)
B:S:
11146 0 0.016 0.016 4.4. ?????? (Search Engine)
L:S:
11148 0.005 0.022 0.017 ??????????????????????????
(This section reports on ... of intelligent information access.)
11170 0.010 0.016 0.006 ???????????????????????
(The key issue of the reports in the following clauses is ... )
modied version of entropy, where informa-
tion bit (log part of the formula) is calcu-
lated by reducing the eect of term repeti-
tions in a short period. The modication was
done to increase the scores for an important
term higher, based on the reported observa-
tion that content bearing words tend to occur
in clumps (Bookstein et al, 1998).
3.2.2 Example of Boundary Sentence
Identication
Table 2 summarizes an example of bound-
ary sentence identication of a TBCS located
just before the 12,000th word in Figure 2. Ev-
ery row in the table except the rst row, which
is marked with O:R:, shows a candidate sen-
tence. The row marked B:S: shows a bound-
ary sentence, which has positive relative for-
ward relevance (0.016 in the fourth column of
the row) and the greatest increment from the
previous value (-0.017). The row marked L:S:
shows a lead sentence, which has the great-
est forward relevance (0.022 in the third col-
umn of the row) among all sentences after the
boundary sentence.
3.2.3 Evaluation of Boundary
Identication
Table 3 shows recall and precision rates of
the boundary identication algorithm in the
same format as Table 1. Compared with the
results obtained using the previous version of
the algorithm (Nakao, 1999), as shown in the
minimal cohesion columns, the proposed al-
gorithm identies more accurate boundaries
cates that heading terms (i.e., terms appeared in head-
ings) are eectively detected by scoring terms with the
part of the formula in the summation operator.
(the boundary sentence columns). In ad-
dition, boundary sentence identication was
successful for 75% of the correct TBCSs, that
is, TBCSs including correct boundaries
7
(see
unied TBCS in Table 1). Thus, the proposed
boundary sentence identication algorithm is
judged to be eective.
Table 3 also summarizes a feature of the
proposed algorithm that it tends to detect
and identify headings as boundary sentences
(the heading rate columns). For the part cor-
responding to larger textual units, which the
proposed algorithm mainly used, the gures
in the overall columns indicate that half of
boundary sentences or more are identical to
headings in the original text; and the gures
in the identication columns indicate that
the proposed algorithm identies headings as
boundary sentences for more than 80% of the
case where TBCSs including headings.
3.3 Summary Construction
In the third and last stage, the algorithm
outputs the boundary and lead sentences of
TBCSs on a layer that probably corresponds
to topics of appropriate grading. Based on the
ratio of source text size to a given summary
size, the algorithm chooses a layer that con-
tains an appropriate number of TBCSs, and
generates a summary with some breaks to in-
dicate thematic changes.
For example, to generate a 1,000-character
summary consisting of several parts of ap-
proximately 200 characters for each topic, a
text decomposition consisting of ve textual
7
For the correct TBCSs, the average number of
boundary sentence candidates is 4.4.
units is appropriate for summarization. Since
the sample text used here was decomposed
into ve textual units on the B(2) layer (see
Figure 2), it outputs the boundary sentences
and lead sentences of all TBCSs in B(2).
4 Discussion
Figure 5 shows a one-page summary of a tech-
nical survey report, where (a) is a part of
the summary automatically generated, and
(b) is its translation. It corresponds to the
part of the source text between B(1)[1] and
B(1)[2] (in Figure 2). It is composed of three
parts corresponding to B(2)[1], B(2)[2], and
B(3)[6]. Each part consists of a boundary sen-
tence, presented as a heading, followed by a
lead sentence.
In comparison with the keyword-based
summary shown in Figure 4, generated in the
process described in Section 2, the one-page
summary gives a good impression as being
easy to understand. In fact, when we in-
formally asked more than ve colleagues to
state their impression of these summaries,
they agreed with this point. As described
in Section 2, one of the reasons for the good
impression should be the dierence in coher-
ence. The relationship among sentences in
the keyword-based summary is not clear; con-
versely, the second sentence of the one-page
summary introduces the outline of the clause,
and it is closely related to the sentences that
follow it. The fact that the one-page sum-
mary provides at least two sentences, includ-
ing a heading, for each topic is also considered
to make coherence strong.
As shown in Table 3, the proposed algo-
rithm is expected to extract headings eec-
tively. However, there is a problem that de-
tected headings do not always correspond to
topics of appropriate grading. For example,
the second boundary sentence in the exam-
ple is not appropriate because it is a heading
of a subclause much smaller than the window
width corresponding to B(2)[2], and its pre-
vious sentence \4.3.2 Technical Trend of IR
Techniques" is more appropriate one.
This example is also related to another lim-
itation of the proposed algorithm. Since there
is no outline description in the subsequent
part of the heading of clause 4.3.2, the pro-
posed algorithm could not generate a coher-
ent extract if it had identied the heading as
a boundary sentence.
It is a future issue to develop more elab-
orated algorithm for summarizing detected
topics especially for the user who wants richer
information than that can be provided in a
extract consisting of two or three sentences.
5 Conclusion
This paper has proposed an algorithm for one-
page summarization to help a user skim a
long text. It has mainly described and re-
ported the eectiveness of the boundary sen-
tence identication part of the algorithm. It
has also discussed the readability of one-page
summaries. The eectiveness of structured
summaries using the thematic hierarchy is an
issue for future evaluation.
References
A. Bookstein, S. T. Klein, and T. Raita. 1998.
Clumping properties of content-bearing words.
Journal of the American Society for Informa-
tion Science, 49(2):102{114.
Michael A.K. Haliday and Ruqaiya Hasan. 1976.
Cohesion in English. Longman, London.
Marti A. Hearst. 1994. Multi-paragraph segmen-
tation of expository text. In Proc. of the 32nd
Annual Meeting of Association for Computa-
tional Linguistics, pages 9{16.
Yoshio Nakao. 1998. Automatic keyword extrac-
tion based on the topic structure of a text. IPSJ
SIG Notes FI-50-1. (in Japanese).
Yoshio Nakao. 1999. Thematic hierarchy detec-
tion of a text using lexical cohesion. Journal of
the Association for Natural Language Process-
ing, 6(6):83{112. (in Japanese).
Gerard Salton, Amit Singhal, Chris Buckley, and
Mandar Mitra. 1996. Automatic text decom-
position using text segments and text themes.
In Proc. of Hypertext '96, pages 53{65. the As-
sociation for Computing Machinery.
Yaakov Yaari. 1998. Texplore { exploring expos-
itory texts via hierarchical representation. In
Proc. of CVIF '98, pages 25{31. Association for
Computational Linguistics.
Table 3: Evaluation of Boundary Sentence Identication
Window Boundary # Minimal cohesion Boundary sentence Heading rate
width cor. res. Recall Precision Recall Precision Overall Identication
5120 1 2 0 (0.1) 0 (.05) 100 (0.1) 50 (.05) 100 (6.6) 100 (29)
2560 2 4 0 (0.2) 0 (0.1) 100 (0.2) 50 (.05) 100 (6.6) 100 (29)
1280 3 10 33 (0.5) 10 (0.2) 67 (0.5) 20 (0.2) 80 (6.6) 80 (30)
640 30 42 27 (1.0) 19 (0.7) 47 (1.0) 33 (0.7) 67 (6.3) 88 (34)
320 114 163 26 (1.8) 18 (1.3) 40 (1.8) 28 (1.3) 54 (5.0) 82 (31)
160 184 365 28 (3.5) 14 (1.8) 43 (3.5) 22 (1.8) 37 (4.8) 77 (28)
80 322 813 29 (7.8) 12 (3.1) 45 (7.8) 18 (3.1) 23 (4.8) 70 (26)
40 403 1681 37 (17) 9 (3.9) 46 (16) 11 (3.9) 12 (4.8) 58 (26)
The gures in parentheses are the baseline rates.
4.3??????????????
?????????????????????????
?????????????????????????
???????????????
?????????????????????????
?????????????????????????
?????????????????????????
???????????
? tf? idf????????????????????
???????????????????? tf????
??????????????????????? idf?
?????????????????????????
? [??, 92]??? ????????????????
?????????????????????????
?????????????????????????
????
ya part of a summary condensed to 1.3% of the
source text
(a) Original
4.3 Internet Services
... They are also enhanced with some techniques,
such as eliminating high frequency words, weighing
a term in document titles and headings, etc., to
achieve high precision. ...
... In addition, since the greatly increasing amount of
pages provided by an Internet service causes a great
increase of average hit number for a query, more
eective automatic text summarization technique
is required for helping a user to nd out required
information quickly. ...
... Tfidf method weighs a term in a document with
a product of the term frequency (tf) in a document
and inverse document frequency (idf), i.e., inverse
of the number of document that the term appears. ...
... [Kawai, 92] A document classication method cal-
culates a score based on 
2
values of not only keyword
frequencies but also semantic frequencies correspond-
ing to occurrences of abstracted semantic category in
target divisions. ...
(b) Translation
Figure 4: Example of Keyword-based Sum-
mary (partially presented)
?????????????? [4.3??]
?????WWW???????????????
????????????????????????
????????????????????????
????????????????????????
????????????????????????
???????????????
??????? [(1)??]
???????????????????? 1???
?????????????
???? [(4)??]
???????????????????????
????????????????????WWW
?????????????????????
ya part of a summary condensed to 1% of the
source text
(a) Original
Internet Services [see 4.3]
This clause surveys internet services, electronic
publishing, and digital libraries, reports on their
features, technical points, and problems observed
in their typical cases, and suggests the desired ser-
vices in the future and the required technology for
their realization based on the investigation of re-
lated research areas. ...
Keyword Extraction [see (1)]
Keyword-based IR is a popular access method for
retrieving document on the networks. ...
Distributed IR Systems [see (4)]
In near future, it will be impossible for a single
IR system storing all resources in a single
database to handle the increasing number of
large WWW text collections. ...
(b) Translation
Figure 5: Example of One-page Summary
(partially presented)
