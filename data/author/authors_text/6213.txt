Reusing an ontology to generate numeral classifiers 
Francis Bond* 
NTT Communication Science Laboratories 
2-4 Hikari-dai, Kyoto 619-0237, JAPAN 
bond@cs lab .kec l  .n t t .  co .  jp  
Kyonghee Paik 
Center for the Study of Language and Information 
Stanford University, CA 94305-2150, USA 
kpa ik@usa ,  net  
Abstract 
In this paper, we present a solution to the prob- 
lem of generating Japanese nmneral classifiers us- 
ing semantic lasses from an ontology. Most nouns 
must take a numeral classifier when they are quan- 
tiffed in languages uch as Chinese, Japanese, Ko- 
rean, Malay and Thai. In order to select an appro- 
priate classifier, we propose an algorithm which as- 
sociates classifiers with semantic lasses and uses 
inheritance to list only those classifiers which have 
to be listed. It generates sortal classifiers with au ac- 
curacy of 81%. We reuse the ontology provided by 
Goi-Taikei - -  a Japanese lexicon, and show that it 
is a reasonable choice for this task, requiring infor- 
mation to be entered for less than 6% of individual 
nouns .  
1 Introduction 
In this paper we consider two questions. The th'st is: 
how to generate numeral classifiers uch as piece in 
2 pieces qfl)aper? To do this we use a semantic hier- 
archy originally developed for a different ask. The 
second is: how far can such a hierarchy be reused? 
In English, uncountable nouns cannot be directly 
modified by numerals, instead the noun nmst be 
embedded in a noun phrase headed by a classi- 
tier. Knowing when to do this is a language Sl0e- 
cific property. For example, French deux renseigne- 
merit must be translated as two pieces of information 
in English. \] Iu many languages, including most 
South-East Asian lauguages, Chinese, Japanese and 
Korean, the majority of nouns are uncountable and 
nmst be quantified by numeral classifier combina- 
tions. These languages typically have many differ- 
ent classifiers. There has been some work on the 
analysis of numeral classifiers in natural language 
processing, particularly for Japanese (Asahioka et 
al., 1990; Kamei and Muraki, 1995; Bond et al, 
* Visiting CSLI, Stanford University (1999-2000). 
I Numeral-classilier combinations are shown in bold, the 
noun phrases they quantify are underlined. 
1996; Bond et al, 1998; Yokoyama and Ochiai, 
1999), but very little on their generation. We could 
only find one paper on generating classifiers in Thai 
(Sornlertlamvanich et al, 1994). One immediate 
application fox the generation of classifiers is ma- 
chine translation, and we shall take examples flom 
there, but it is in fact needed fox" the generation 
of any quantified noun phrase with an uncountable 
head noun. 
The second question we address is: how far can 
an ontology be reused for a difl%rent task to the one 
it was originally designed fox. There are several 
large ontologies now in use (WordNet (Fellb~mm, 
1998); Goi-Taikei (lkehara et al, 1997); Mikrokos- 
rues (Nirenburg, 1989)) and it is impractical to re- 
build one fox" every application. Howevel, there is 
no guarantee that an ontology built fox one task will 
be useful for another. 
The paper is structured as follows. In Section 2, 
we discuss tile properties of numeral classifiers in 
more detail and suggest an ilnproved algorithm fox" 
generating them. Seclion 3 introduces the ontology 
we have chosen, the Goi-Taikei ontology (ikehara ct 
al., 1997). Then we show how to use the ontology to 
generate classifiers in Section 4. Finally, we discuss 
how well it performs in Section 5. 
2 Generating Numeral Classifiers 
In this section we introduce the properties of nu- 
meral classifiers, focusing on Japanese, then give 
an algorithm to generate classiliers. Japanesc was 
chosen because of tile wealth of published ata on 
Japanese classifiers and the availability of a large 
lexicon with semantic lasses marked. 
2.1 What are Numeral Classifiers 
Japanese is a language where most nouns can not 
be directly modified by numerals, instead, nouns 
are modified by a numeral-classifier combinatiou as 
shown in (1).2 
2~Vc use lhe fo l low ing  abbrev ia t ions :  NOM : nominat ive ;  
ACC = accusat ive ;  AI)N = adnomina l ;  CI. = c lass i l ier ;  ARGSTR 
90 
(l) 2-tsfH10 denshimC~ru 
2-(:L-ADN emai\[ 
2 pieces of emai\] 
2 emails 
In Japanese, numeral classifiers arc a subclass o\[ 
nouns. The main properly dislinguishillg them from 
t)rolotypical nouns is thai lhey cannot sland alone. 
Typically they postiix to numerals, forming a quan- 
tilter l)hrase. Japanese also allows them to combine 
with the quantifier st7 "some" or tile interrogative 
nani "what" (2). We will call all such Colnbinations 
ot' a numeral/quantifier/interrogative with a numeral 
classifier a numeral-classitier combination. 
(2) a. 2-hiki"2 animals" (Numeral) 
b. sO-hiki "solne animals" (Quantilier) 
c. nan-biki "how Illauy mfimals" (inlcr- 
rogali ve) 
Classiliers have different l)rOl)erlies del)ending on 
their use. There are live ulajor types: serial which 
classify the kind o1: tile noun phrase tile}, (.\]uan- 
lily (such as -/all "piece"); evenl which arc used 
to quantify events (such as -kai " l i l l lC" ) ;  me i l s l l -  
ral which ~lre used to measure lhc U.IIIOtlllt Of  SOl l le  
property (such its senchi "-cm"), group which refer 
to a collection of melnbers (such as -inure gloup ), 
and taxononfic which force (he noun phrase to be 
inlerpreted as a generic kind (such as -.vim "kind"). 
We propose the l:ollowing basic struclurc for sor- 
tal classiliers (3). The lexical slructtlre we adopt is 
an extension ot' Pustejovsky's (1995) generative l x- 
icon, with tile addition of an explicit quantilication 
relationship (Bond and Paik, 1997). 
\[ \[AR(;I x : numera l+ 
ARGSTR (3) / LD-ARG1 y: 
,,la.,.qlicrLOUANT Cluant:5- f 5.es (x,  y)  
There are two variables in the argument strut- 
lure: the numeral, quantifier or interrogative (repre- 
sented by numera2+) ,  and the noun phrase being 
classilied. Because the noun phrase being classilied 
can be omitted in context, it is a default argun-lent, 
one which participales in tile logical expressions in 
the qualia, but is not necessarily expressed syntacti- 
cally. 
= argunle l l l  s lructurc;  AR(; = argument ;  \[)-AR(; = default  m-gu- 
menl ,  QUANT = quant i l icat ion.  
Serial classiliers differ from each other in tile re- 
strictions they place on the quantilied variable 7V. 
For example tile classilier -nin adds tile restriction 
y :human.  That is, it can only be used to classify 
human referents. 
Japanese has two number systems: a Sine- 
Japanese one based on Chinese for example, ichi 
"Olle",lli "\[wo",s(lll "lhree", etc., and ~tll alternative 
nalive-Jal)anesc ystem, for example, hitotsu "one" 
fitlalsu "two",milsu "three", etc. In Japanese tile lla- 
live system only exists for the numbers from one 
to ten. Most classitiers combine with the Chinese 
lorms, howevm; different classiliers select Sine- 
Japanese for some numerals, for example, ni-hiki 
"two-el", and most classifiers undergo some form 
of sound change (such as -hiki to -biki in (2)). 
Wc will not bc concerned wilh these morllhological 
changes, we refer interested reMers to Backhouse 
(1993, I 1 g-122) for more discussion. 
Numeral classiliers characteristically premodify 
the noun phrases they quantify, linked by an adhere- 
inal case marker, as in (4); or appear 't\]oating' as 
adverbial phrases, lypically to before the verb: (5). 
The choice between pre-nominal and lloming quan- 
lifters is hu'gcly driven by discourse related consid- 
erations (1)owning, 1996). In this paper we concen- 
lrale on (he semantic ontribution of the quantiliers, 
and ignore tile discourse ffects. 
(4) 2-isii-no tegami-o yonda 
2-CI.-AI)N letter-A{:c read 
I read two letters 
(5) tcgami-o 2-tsii yonda 
letter-ACC 2<:L read 
I read two letters 
Quantilier phrases can also function as noun 
l)hrascs on their own, with anaphoric or deictic ref- 
erence, when what is being quantilied is recover- 
able from the context. For example (7) is accept- 
able if the letters have already been referred to, or 
arc clearly visible. 
(6) \[some background with letters salient\] 
(7) 2-tsfi-o yonda (Japanese) 
2-CI,-ACC read 
1 read two letters 
In the pre-nonlinal construction tile relation be- 
tween ihe target noun phrase and quantilier is 
explicit. For muneral-classilier combinations the 
91 
quantification can be of the object denoted by the 
noun phrase itself as in (8); or of a sub-part of it as 
in (9) (see Bond and Pai l  (1997) for a fuller discus- 
sion). 
(8) 3-tsfi-no tegami 
3-CL-ADN letter 
3 letters 
(9) 3-mai-no tegami 
3-CL-ADN letter 
a 3 page letter 
2.2 An Algorithm to Generate Numeral 
Classifiers 
The only published algorithm to generate classifiers 
is that of Sornlertlamvanich et al (1994). They 
propose to generate classifiers in Thai as follows: 
First create a lexicon with default classifiers listed 
for as many nouns as possible. This was done by 
automatically extracting noun classifier pairs from 
a sense-tagged corpus, and taking the classifier that 
appeared most often with each sense of a noun. 3 
Then, the most fiequent classifier is listed for each 
semantic lass. Generation is then simple: if a noun 
has a default classifier in the lexicon, then use it, 
otherwise use the default classifier associated with 
its semantic lass. 
Unfortunately, no detailed results were given as 
to the size of the concept hierarchy, the number of 
nodes in it or the number of nouns for which clas- 
sifiers were found. As the generation procedure 
was not ilnplemented, there was no overall accuracy 
given for the system. 
As a default, Sornlertlamvanich et al's algorithm 
is useful. However, it does not cover several ex- 
ceptional cases, so we have refined it further. The 
extended algorithm is shown in Figure 1. 
Firstly, we have made explicit what to do when 
a noun is a member of more than one semantic 
class or of no semantic lass. In the lexicon we 
used, nouns are, on average, inembers of 2 seman- 
tic classes. Howevm; the semantic lasses are or- 
dered so that the most typical use comes first. For 
example, usagi "rabbit" is marked as both animal 
and meat, with animal coming first (Fignre 3). 
In this case, we would take the classifier associated 
3111 fact, Thai also has a great many group classiliers, much 
like heM, flock and pack in English. Therefore ach noun has 
tWO classifiers, a sortal classifier and a group classifier listed. 
Japanese does not, so we will not discuss the generation of 
group classiliers here. 
with the first semantic lass. However, in the case of 
usagi it is not counted with the default classifier for 
animals -hiki, but with that for birds -wa, this must 
be listed as an exception. 
Secondly, we have added a method for generating 
classifiers that quantify coordinate noun phrases. 
These commonly appear in appositive noun phrases 
such as ABC-to XYC-no 2-sha "the two companies, 
ABC and XYZ". 
1. For a simple noun phrase 
(a) If the head noun has a default classifier in 
the lexicon: 
use the noun's default classifier 
(b) Else if it exists, use the defimlt classifier 
of the head noun's first listed semantic 
class (the class's default classifier) 
(c) Else use the residual classifier -tsu 
2. For a coordinate noun phrase 
generate the classifier for each noun phrase 
use the most frequent classifier 
Figure 1: Algorithm to generate numeral classifiers 
In addition, we investigate to what degree we 
could use inheritance to remove redundancy from 
the lexicon, ff a noun's default classifier is the same 
as the default classifier for its semantic lass, then 
there is no need to list it in the lexicon. This makes 
the lexicon smaller and it is easier to add new en- 
tries. Any display of the lexical item (such as for 
maintenance or if the lexicon is used as a human 
aid), should automatically generate the classifier 
from the semantic lass. Alternatively (and equiv- 
alently), in a lexicon with multiple inheritance and 
defaults, the class's default classifier can be added 
as a defeasible constraint on all lnembers of the se- 
mantic class. 
3 The  Go i -Ta ike i  Onto logy  
We used tim ontology provided by Goi-Taikei - -  A 
Japanese Lexicon (Ikehara et al, 1997). We choose 
it because of its rich ontology, its extensive use in 
many other NLP applications, its wide coverage of 
Japanese, and tile fact that it is being extended to 
other numeral classifier languages, such as Malay. 
The ontology has several hierarchies of concepts: 
92 
with both is-a and has-a rehttionshil)s. 2,710 se- 
mantic classes (12-level t'ee structure) for common 
nouns, 200 chtsses (9-level tree structure) for proper 
nouns and 108 classes for predicates. We show the 
top three levels of the common norm ontology in 
Figure 2. Words can be assigned to semantic lasses 
anywhere in the hierarchy. Not all semantic lasses 
have words assigned to them. 
The semantic classes are used in the Jalmnese 
word semantic dictionary to classify nouns, verbs 
and adjectives. The dictionary inchtdes 100,000 
common nouns, 70,000 technical terms, 200,000 
proper nouns and 30,000 other words: 400,000 
words in all. The semantic lasses al'e also used as 
selectional restrictions on the arguments o1' predi- 
cates in a separate predicate dictionary, with around 
17,000 entries. 
Figure 3 shows an example of one record of the 
Japanese semantic word dictionary, with the addi- 
tion of the new I)I{FAU1\]I" CLASSIFIFA{ lield (under- 
lined for elnphasis). 
Each record has an index form, pronunciation, 
a canonical form, part-of-speech and semantic 
classes. Each word can have up to five common 
iloun classes and ten proper noun chtsses, hi the 
case of usagi "rabbit", there are two common noun 
classes and no proper noun classes. 
4 Maplfing Classiliers to the Onto logy  
In this section we investigate how l'ar the seman- 
tic classes can be used to predict default classiticrs 
for nouns. Because most sortal classifiers select 
for some kind of semantic lass, we thought that 
nouns grouped together under the same senmntic 
class should share the same classifier. 
We associated classifiers with semantic classes 
by hand. This took around two weeks. We found 
that, while some classes were covered by a single 
classifier, around 20% required more than one. For 
example, 1056:song is counted only by -kyoku 
"tune", and 989 :waker  veh icZe  by only by - 
seki "ship", but the class \[961:weapon\] had menl- 
bet's counted by -hen "long thin", -chO "knife", -.fitri 
"swords", -ki "machines" and more. 
We show the most flequeut numeral classifiers in 
Table 1. We ended up with 47 classifiers used as 
semantic lasses' default classifiers. This is in line 
with the fact that most speakers of Japanese know 
and use between 30 and 80 sortal classifiers (l)own- 
ing, 1996). Of course, we expect o add more clas- 
sifters at the noun level. 
801 semantic lasses turned out not to have clas- 
siliers. This included chtsses with no words associ- 
ated with them, and those that only contained nouns 
with referents o abstract we considered them to be 
uncountable, such as greed, lethargy, etc. 
We used the default chtssifiers assigned to the se- 
mantic classes to generate defeasible del'aults for the 
noun entries in the common and technical term dic- 
tionaries (172,506 words in all). We did this in order 
to look at the distribution of classifiers over words in 
the lexicon. In the actual generation this would be 
done dynamically, after the semantic lasses have 
been disambiguated. The distributions of classifiers 
were similar to those of the semantic lasses, al- 
though there was a higher proportion counted with 
the residual classilier -tsu, and the classifier for ma- 
chines -ekti. This may be an artifact of the 70,000 
word technical term dictionary. As further esearch, 
wc would like to calculate the distribution of classi- 
\[iers in some text, althottgh we expect it to depend 
greatly on the genre. 
The mapping we created is not complete because 
some of the semantic lasses have nouns which do 
not share the same classifiers. We have to add lnore 
specific defaults at the noun level. As well as more 
specific sortal classifiers, there are cases where a 
group classifier may be more appropriate. For ex- 
ample, among the nouns counted with -~zi~ there are 
entries such as couple, twins and so on which are 
often counted with -kumi "pair". 
In addition, the choice o1' classilier can depend on 
factors other than just semantic lass, for example, 
hire "people" can be counted by either -nin or -mei, 
the only difference being that -mei is more polite. 
it was difficult to assign default classifiers to 
the semantic lasses that referred to events. These 
chtsses mainly include deverbal nouns (e.g. konomi 
"liking") and nominal verbs (e.g., benkyO "study"). 
These can stand for both the action or the result of 
the action: e.g. kenkyl7 "a study/research". In these 
cases, every application we considered would dis- 
tinguish between event and sortal classification in 
the input, so it was only necessary to choose a clas- 
sifier for the result of the action. 
5 Evaluation and Discuss ion 
The algorithm was tested oil a 3700 sentence tna- 
claine translation test set of Japanese with English 
translatious, although we only used the JapaneseJ 
~The test set is available at www.kec l .n t t . co . jp /  
i c l /mtg / resources .  
93 
1 : noun  
2 : concrete  
3 : 388 : 533 : 
agent  p lace  ob jec t  
i000 : abst rac t  
1001 : 1235 : 2422 : 
abst rac t  th ing  event  re la t ion  
Figure 2: Top three levels of the Goi-Taikei Common Noun Ontology 
;'CCo;'H 
-INDEX FORM 
PRONUNCIATION 
CANONICAL FORM 
PAP.T OF SPEECH 
\])IEFAULT CLASSIFIER 
SEMANTIC CLASSES 
ey +)-:~ (usagi) 
"5 ~ -~"/usagi/ 
~, (usagi) 
noun 
~g~ (-wa) 
COMMON NOUN 537:beast  \] 
843 meat /egg\ ]  
Figure 3: Japanese Lexical Entry for rabbit "usagi" 
We only considered sentences with a noun phrase 
modified by a sortal classifier. Noun phrases modi- 
lied by group classifiers, such as -soku "pair" were 
not evaluated, as we reasoned that the presence of 
such a classifier would be marked in the input to the 
generator. We also did not consider the anaphoric 
use of numeral classifiers. Although there were 
ninny anaphoric examples, resolving them requires 
robust anaphor esolution, which is a separate prob- 
lem. We estimate that we would achieve the same 
accuracy with the anaphoric examples if their ref- 
erents were known, unfortunately the test set did 
not always include the full context, so we could not 
identify the referents and test this. A typical exam- 
ple of anaphoric use is (10). 
(1o) shukka-ga ruiseki-de 500-hon-wo 
shipment-NOM cumulative 500-CL-ACC 
toppa-shita 
roached 
Cumulative shipments reached 500 ?bar- 
rels/rolls/logs/... 
In total, there were 90 noun phrases modified by a 
sortal classilier. Our test of the algoritlml was done 
by hand, as we have no Japanese generator. We as- 
sumed as input only the fact that a classifier was 
required, and the semantic lasses of the head noun 
given in the lexicon. Using only the default classi- 
tiers predicted by the senmntic lass, we were able 
to generate 73 (81%) correctly. A classifier was only 
judged to be correct if it was exactly the stone as 
that in the original test set. This was ahnost double 
the base line of generating the most common clas- 
sifter (-nin) for all noun phrases, which would have 
achieved 41%. The results, with a breakdown of the 
errors, are summarized in Table 2. 
In this small sample, 6 out of 90 (6.7%) of noun 
phrases needed to have tim default classifier marked 
for the nouu. In fact, there were only 4 different 
nouns, as two were repeated. We therefore stinmte 
that fewer than 6% of nouns will need to have their 
own default classifier marked. Had the default clas- 
sifier for these nouns been marked in the lexicon, 
our accuracy would have been 88%, the maxinmm 
achievable for our method. 
94 
CI.ASSIFIER P, eferents class|lied Semantic Class (2,710) Noun (172,506) 
No. % Example No. % 
None Uncountable referents 794 29.3 3 : agent  34,548 20.0 
-kai (IN) events 703 25.9 1699 :v i s i t  35,050 20.3 
-tsu (O) abstract/general objects 565 20.9 2 : concrete  52,921 30.1 
-nin (J,,) person 298 11.0 5 :person 8,545 4.9 
-ko ({\])iI) concrete objecls 124 4.6 854 : ed ib le  f ru i t  14,380 8.3 
-hen (J?) long thin objecls 52 1.9 673 : t ree  3,775 2.1 
-mai (~)  fiat objecls 32 1.2 7 70 : paper  2,807 1.6 
-teki (}l',;~J) liquid 21 0.8 652 : tear  1,219 0.7 
-dai (?i't) lnechanic itclnS/furniture 18 0.7 9 62 : mach inery  5,087 2.9 
-hiki (l;ri) animals 12 0.6 537 :beast  1,361 0.8 
Other 38 classifiers 91 3.4 12,813 7.4 
Table 1 : Japanese Numeral Classiliers and associated Semantic Classes 
P, esult % No. 
Correctly generated 81% 73 
Incorrectly generated 19% 17 
Total 100% 90 
Breakdown o1' En'ors 
Noun needs default classilier - -  6 
Target not in lexicon, bad entry 4 
()ther errors 7 
Table 2: P, esults of atplying the algorilhm 
Looking at it from allolher point of view, the 
Goi-Taikei ontology, although initially designed i'or 
.lapanese analysis, was also useftfl for generating 
Japanese numeral chtssifiers. We consider that it 
would be equally useful for the same task with Ko- 
l'can, or even lhe tmrelaled language Mahty. 
We generated the residual classilier -tsu for nouns 
not in the lexicon, this proved to be a bad choice 
lbr three unknown words. If we had a me(hod o1: 
deducing senlanlic chtsses for tlnknown words wc 
couM have used it to predict the classiiicr more 
successfully. 1;or example, kikan-l&vhika "insti- 
tutional investor ''5 was not in the dictionary, and 
so we used the senmntic class for lOshika "in- 
vestor", which was 175 : investor ,  a sub-type 
of 5 :person .  Had kikan-toshika "institutional 
investor" been marked as a subtype of company, 
or if we had deduced the semantic lass from the 
modifier, then we would have been able to gener- 
5hmlitufional illvcStOl'S are \[inancial institutions tha! invest 
savin~,s of individuals and non-lina.ncial companies in the fi- 
nancial nmrkets. 
ate tho correct classifior -sha. In ono case, wc felt 
lho default ordering of the semantic lasses should 
have been reversed: 673: t ree  was listed before 
854 : ed ib le  f ru i t  for ringo "apple". 
The remaining errors were moro problematic. 
There was one cxamplc, 80,O00-nin-amari-no 
.vl,#nlei "about 80,000 signatures", wlfich could be 
ueated as rel:ercnt tlansfof: shomei "signature" 
was being counted wilh the classifier for people. 
Another l)ossiblc analysis is that the classilier is 
the head of a referential noun phrase with deic- 
tic/almphoric reference, equivalent to the si,qnaluJws 
oJ'ahold SO, 000 people. A COUlJe were quile literary 
in slylc: for example lOnen-no loshi "10 years (Lit: 
10 years of years)", where the loshi "year" lmrt is 
redundant, and would not normally be used. in two 
of the errors the residual classilier was used instead 
of (he more specific default. Shhnoio (1997) prc~ 
dicls flint this will happen in expressions where lhe 
amot ln l  is being emphasized more than what is be- 
ing counted. Intuitively, lifts applied in both cases, 
but we were ul\]able to identify any features we could 
exploit 1o make this judgment autolnatically. 
A more adwmced semantic analysis may be able 
lo dynamically delermine the appropriate semantic 
class for cases of rel'ercnt transfer, unknown words, 
or words whose semantic lass can be restricted by 
context Our algorithm, which ideally generates the 
classifier from this dynamically determined seman- 
tic class allows us to generate the correct classilier 
in context, whereas using a default listed for a noun 
does not. This was our original mot|wit|on 1'oi" gen- 
erating chtssitiers 1?o111 seman(ic lasses, rather than 
using a classifier lis(ed wilh each noun as Sornlert- 
95 
lamvanich et al (1994) do. 
In this paper we have concentrated on solving 
the problem of generating appropriate Japanese nu- 
meral classifiers using an ontology. 11\] future work, 
we would like to investigate in more detail the con- 
ditions under which a classifier needs to be gener- 
ate& 
6 Conclusion 
In this paper, we presented an algorithm to generate 
Japanese numeral classifiers. It was shown to select 
the correct sortal classifier 81% of the time. The al- 
gorithm uses the ontology provided by Goi-Taikei, 
a Japanese lexicon, and shows how accurately se- 
mantic lasses can predict numeral classifiers for the 
nouns they subsume. We also show how we can 
improve the accuracy and efficiency ftmher through 
solving other natural language processing problems, 
in particular, referent ransfer, anaphor esolution 
and word sense disambiguation. 
Acknowledgments 
The authors thank Kentaro Ogura, Timothy Bald- 
win, Virach Sornlertlamvanich and the anonymous 
reviewers for their helpful comments. 
References 
Yoshimi Asahioka, Hideki Hirakawa, and Shin-ya 
Amano. 1990. Semantic lassification and an 
analyzing system of Japanese numerical expres- 
sions. 1PSJ SIG Notes 90-NL-78, 90(64):129- 
136, July. (in Japanese). 
A. E. Backhouse. 1993. The Japatwse Language: 
An h~troduction. Oxford University Press. 
Francis Bond and Kyonghee Paik. 1997. Classify- 
ing correspondence in Japanese and Korean. In 
3rd Pacific Association for Computational Lin- 
guistics Conference: PACLING-97, pages 58-67. 
Meisei University, Tokyo, Japan. 
Francis Bond, Kentaro Ogura, and Satom Ikehara. 
1996. Classifiers in Japanese-to-English machine 
translation. In 16th International Coqference on 
Computational Linguistics: COLING-96, pages 
125-130, Copenhagen, August. (h t tp : / /  
xxx. lanl. gov/abs/cmp- ig/9608014). 
Francis Bond, Daniela Kurz, and Satoshi Shirai. 
1998. Anchoring floating quantifiers in Japanese- 
to-English machine translation. In 36th Anmtal 
Meeting of the Association .for Computational 
Linguistics and 17th hzternational Conference 
on Computational Linguistics: COLING/ACL- 
98, pages 152-159, Montreal, Canada. 
Pamela Downing. 1996. Nunwral Class(tier Sys- 
tems, the case of Japanese. Jolm Benjamins, Am- 
sterdam. 
Christine Fellbamn, editor. 1998. WordNet: An 
Electronic Lexical Database. MIT Press. 
Satoru Ikehara, Masahiro Miyazaki, Satoshi Shirai, 
Akio Yokoo, Hiromi Nakaiwa, Kentaro Ogura, 
Yoshifumi Ooyama, and Yoshihiko Hayashi. 
1997. Goi-Taikei - -  A Japanese Lexicon.. 
Iwanami Shoten, Tokyo. 5 volumes/CDROM. 
Shin-ichiro Kamei and Kazunori Muraki. 1995. An 
analysis of NP-like quantifiers in Japanese. In 
First Natural l_zmguage Processing Pactific Rim 
Symposium: NLPRS-95, volume 1, pages 163- 
167. 
Sergei Nirenburg. 1989. KBMT-89 - -  a 
knowledge-based MT proiect at Carnegie 
Mellon University. pages 141-147, Aug. 16-18. 
James Pusteiovsky. 1995. The Generative Lexicon. 
MIT Press. 
Mitsuaki Shimojo. 1997. The role of the general 
category in the maintenance of numeral classi- 
fier systems: The case of tsu and ko in Japanese. 
Linguistics, 35(4). (h t tp  : / / i f rm.  g locom.  
ac. jp/doc/sOl. 001 .html). 
Virach Sornlertlamvanich, Wantanee Pantachat, 
and Surapant Meknavin. 1994. Classifier 
assignment by corpus-based approach. In 
15th International Conference on Computa- 
tional Linguistics: COLING-94, pages 556- 
561, August. (h t tp : / /xxx .  lan l .gov /  
abs/cmp- ig/9411027). 
Shoichi Yokoyalna and Takeru Ochiai. 1999. 
Aimai-na sfiry6shi-o fukumu meishiku-no 
kaisekih6 \[a method for analysing noun phrases 
with ambiguous quantifiers.\]. In 5th Almual 
Meeting of the Association for Natural Lzmguage 
Processing, pages 550-553. The Association for 
Natural Language Processing. (in Japanese). 
,+a:~--:~,5o NNT ' JZNN,~N~,  q~NN, t3 
7%, 6 %~cr)~l~l ,~Uc  r) b'~Jb~'\[~l~%-5: 
96 
Automatic Construction of a Transfer Dictionary
Considering Directionality
Kyonghee Paik, Satoshi Shirai? and Hiromi Nakaiwa
{kyonghee.paik,hiromi.nakaiwa}@atr.jp * sat@fw.ipsj.or.jp
ATR Spoken Language Translation Laboratories
2-2-2, Keihanna Science City Kyoto, Japan 619-0288
?NTT Advanced Technology Corporation
12-1, Ekimaehoncho, Kawasaki-ku, Kawasaki-shi, Japan 210-0007
Abstract
In this paper, we show how to construct a
transfer dictionary automatically. Dictionary
construction, one of the most difficult tasks
in developing a machine translation system, is
expensive. To avoid this problem, we investi-
gate how we build a dictionary using existing
linguistic resources. Our algorithm can be ap-
plied to any language pairs, but for the present
we focus on building a Korean-to-Japanese
dictionary using English as a pivot. We
attempt three ways of automatic construction
to corroborate the effect of the directionality
of dictionaries. First, we introduce ?one-time
look up?method using a Korean-to-English and
a Japanese-to-English dictionary. Second, we
show a method using ?overlapping constraint?
with a Korean-to-English dictionary and an
English-to-Japanese dictionary. Third, we con-
sider another alternative method rarely used
for building a dictionary: an English-to-Korean
dictionary and English-to-Japanese dictionary.
We found that the first method is the most
effective and the best result can be obtained
from combining the three methods.
1 Introduction
There are many ways of dictionary building.
For machine translation, a bilingual transfer
dictionary is a most important resource. An in-
teresting approach is the Papillon Project that
focuses on building a multilingual lexical data
base to construct large, detailed and principled
dictionaries (Boitet et al, 2002). The main
source of multilingual dictionaries is monolin-
gual dictionaries. Each monolingual dictionary
is connected to interlingual links. To make
this possible, we need many contributors, ex-
? Some of this research was done while at ATR.
perts and the donated data. One of the stud-
ies related to the Papillon Project tried to link
the words using definitions between English and
French, but the method can be extended to
other language pairs (Lafourcade, 2002). Other
research that focuses on the automatic build-
ing of bilingual dictionaries include Tanaka and
Umemura (1994), Shirai and Yamamoto (2001),
Shirai et al (2001), Bond et al (2001), and
Paik et al (2001).
Our main concern is automatically building
a bilingual dictionary, especially with different
combinations of dictionaries. None of the re-
search on building dictionaries seriously consid-
ers the characteristics of dictionaries. A dic-
tionary has a peculiar characteristic according
to its directionality. For example, we use a
Japanese-to-English (henceforth, J?E) dictio-
nary mainly used by Japanese often when they
write or speak in English. Naturally, in this sit-
uation, a Japanese person knows the meaning
of the Japanese word that s/he wants to trans-
late into English. Therefore, an explanation for
the word is not necessary, except for the words
whose concept is hard to translate with a single
word. Part-of-speech (henceforth POS) infor-
mation is also secondary for a Japanese person
when looking up the meaning of the correspond-
ing equivalent to the Japanese word.
On the other hand, an English-to-Japanese
(henceforth E?J) dictionary is basically used
from a Japanese point of view to discover the
meaning of an English word, how it is used and
so on. Therefore, explanatory descriptions, ex-
ample sentences, and such grammatical infor-
mation as POS are all important. As shown in
(2), a long explanation is used to describe the
meaning of tango, its POS and such grammat-
ical information as singular or plural. Also, an
E?J dictionary includes the word in plenty of
examples, comparing to a J?E dictionary. The
following examples clearly show the difference.
(1) J?E:   :  dance  the tango   s 
(2) E?J: tan 	 go /(n. pl    s)
 

 :a. 
