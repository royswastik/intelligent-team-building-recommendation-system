c? 2003 Association for Computational Linguistics
A Model for Matching Semantic Maps
between Languages (French/English,
English/French)
Sabine Ploux? Hyungsuk Ji?
Institut des Sciences Cognitives Institut des Sciences Cognitives
This article describes a spatial model for matching semantic values between two languages, French
and English. Based on semantic similarity links, the model constructs a map that represents a
word in the source language. Then the algorithm projects the map values onto a space in the target
language. The new space abides by the semantic similarity links specific to the second language.
Then the two maps are projected onto the same plane in order to detect overlapping values. For
instructional purposes, the different steps are presented here using a few examples. The entire set
of results is available at the following address: http://dico.isc.cnrs.fr.
1. Goals
This article presents a spatial model that projects the semantic space of a source lan-
guage word onto a semantic space in the chosen target language. Although the study
presented in this article can be described from various angles, we place it within the
framework of artifactual simulations of the translation process, and more specifically,
access to the target language?s lexicon. The model is described as a construction pro-
cess designed to reproduce cognitive functions and their extensions. Future research
will include the study of the psycholinguistic validity of such a spatial representation.
Now let us briefly describe the scientific basis of the study.
? Three major areas are generally distinguished in the study of the
translation process (see Vinay and Darbelnet [1996]), the lexicon (or the
study of notions), sentence generation (putting words together), and the
message (which brings communicative factors into play). The first area
involves choosing the right word, which is usually left up to the
intuition and expertise of the translator. Our model deals with accessing
the lexicon of the target language starting from a notion in the source
language. The utility of this research lies in the fact that different
languages break down reality in different ways.
? Although the translation process has been mastered by a number of
experts, it is usually still dependent upon the utilization of tools like
dictionaries. The model proposed here relies on semantic maps and
offers an alternative method based on the concepts of lexical access and
lexical neighborhood.
? The work by Anderson (1983) and Collins and Loftus (1975) on the
organization of the lexicon is based on priming and the automatic
? UMR 5015 CNRS-Universite? Lyon I, 67 bd Pinel, F-69 675 Bron Cedex. E-mail:{ploux,ji}@isc.cnrs.fr.
156
Computational Linguistics Volume 29, Number 2
spreading of activation to the prime?s neighboring concepts. As an
alternative to these local semantic networks, Masson (1995) proposed a
connectionist model that takes into account the subjects? reaction time
during priming experiments (the correspondence is based on the
assumption that semantic or phonologic proximity and ease of access are
correlated). Rouibah, Ploux, and Ji (2001) showed that experimental data
on interactions between phonology and semantics could be simulated by
distances on lexical maps. One advantage of this proposal is that
experimental and artifactual findings converge; another is its ability to
describe a real lexicon. Although the relevance of our model to the
representation of the mental lexicon will not be discussed in this article
(attempts to gain insight into this correlation are currently underway in
other studies), this point is not unrelated to the suitability of our
approach to modeling translation as a cognitive function.
2. Description of the Model
No two lexicons are related by a one-to-one correspondence (Abplanalp 1998). In
other words, the way words are used to refer to extralinguistic reality varies across
languages. Some examples of this are cross-language differences in color naming and,
borrowing Chuquet and Paillard?s (1989) English-French examples, differences like:
? room: pie`ce, chambre, bureau
(or in an abstract domain)
? esprit: mind, spirit, wit
Certain authors (Abplanalp 1998) insist how impossible it is to translate at the
word level and propose recourse to the conceptual level as a theoretical alternative.
Concepts are thought to depend on human cognitive abilities that are general and
shared by all. Although the correspondence between words and concepts remains a
controversial topic of study (Reboul 2000), the concept/word opposition is neverthe-
less relevant to any model of translation, even an artifactual one like ours. As we shall
see, even when heeding the specific organization and breakdown of each individual
language, the matching operation does not take place at the word level but at the
substrate level (defined below), where the set of meanings of each word ?cuts out? a
form.
First, we will present the model we devised to describe the organization of lan-
guages. Then we will explain the source-to-target spreading method used.
2.1 A Model Based on Semantic Similarity
The model was initially developed on the basis of a semantic similarity: synonymy.
Note, however, that the data and the model are independent, so this same framework
can be used to organize other types of similarity (contextual, phonological [Rouibah,
Ploux, and Ji 2001], etc.). Other authors also organize the lexicon or other kinds of
knowledge on the basis of similarity. For example, in Edelman?s (1998) spatial model
of internal representations of the world?s objects, spatial proximity reflects object simi-
larity. WordNet (Fellbaum 1998) and EuroWordNet (Vossen 1998) organize the lexicon
conceptually as a network of terms, each of which is associated with a partition into
157
Ploux and Ji A Model for Matching Semantic Maps
Synsets (a Synset being a small group of synonyms that label a concept). Our model
differs from Edelman?s in that it deals with lexical semantics, not perceived objects. It
also differs from Miller?s (1990) approach, in three respects:
? the grain of the semantic units
? the lexical structure generation mode
? the resulting geometry and organization
Most models1 use separate units to represent words or concepts (symbols, points in a
space, nodes on a graph, etc.). Relationships between units are expressed as proximity
links (in spatial models) or as arcs between nodes (in networks). Our model is spa-
tial, but it differs from local models in that each term is represented by a region in the
space, part of which it shares with other terms. This region is constructed automatically
according to lexical similarity links (such as those given by a synonym dictionary). It
is not the result of supervised learning, nor is it a manual, ontological description of
how the lexicon is organized. The next section will break the semantic-space construc-
tion process into steps in presenting the initial data, the granular approach, and the
resulting organization.
2.2 Method
2.2.1 Initial Data. Three databases were used: two synonym databases (one containing
French terms and one containing English terms) and a translation database (French-
English, English-French) that maps each term to similar words in the other language.
The links between an entry and the terms that follow it were not chosen ?by hand.? The
data were taken mainly from published dictionaries and thesauruses.2 It is updated
and supplemented regularly by the addition of new links between words (synonymy
or translation links). The method used to generate the French synonym database (de-
scribed in detail in Ploux (1997) was applied again to generate the English and trans-
lation databases. The first step required creating an intermediate database containing
the set of all links attested in available work in lexicography. In this preliminary
database, a term was deemed similar to another term if at least one lexicographer had
established the link. The final database was obtained through symmetrization of the
links produced in the first step. While maintaining the shifts in meaning that occur
when there is nontransitivity and that, as we shall see, are essential for developing the
model, we created new links to symmetrize any initially one-directional ones.3 Table 1
gives a typical example of the structure of the initial data. Table 2 gives a global eval-
uation of the number of entries and links in the lexical databases. Note that we are
not attempting here to define the term synonymy. We rely on lexicographic publica-
tions, which as Edmonds and Hirst (2002) remarked, ?have always treated synonymy
1 Masson?s (1995) model assigns each concept a basin of attraction in a multidimensional space of
activation. This framework authorizes a certain form of internal variability for the set of patterns
corresponding to a concept. Nevertheless the basins are disjoint and do not overlap as do the nodes in
local semantic networks. Furthermore, this model, built essentially for the purposes of validating
hypotheses and comparing psycholinguistic results, is applicable only to a highly limited vocabulary
and is therefore a poor representative of the natural lexicon.
2 For the French database, we used files compiled by the National Institute for the French Language
(INALF: Institut National de la Langue Franc?aise) from seven different 19th- and 20th-century
synonym dictionaries; for the English and translation databases, we used files obtained from the
French company MEMODATA.
3 Note that symmetrization does not make the semantic spaces of the two terms equivalent.
158
Computational Linguistics Volume 29, Number 2
Table 1
Format of data files.
Headword: Similar1, Similar2, Similar3, . . .
insensible:
(extracted from the
similar English word
database)
apathetic, benumbed, callous, comatose, impassive, impercep-
tible, impercipient, indiscernible, insensitive, pachydermatous,
senseless, thick-skinned, unaffected, unaware, unconscious, un-
detectable, unfeeling, unsympathetic
insensible:
(extracted from the
similar French word
database)
adamantin, anesthe?sie?, apathique, aride, assoupi, blase?, calleux,
calme, cruel, de marbre, desse?che?, dur, de?tache?, endormi, endurci,
engourdi, flegmatique, . . .
insensible:
(extracted from the
French-English
translation
database)
imperceptible, insensitive, numb, unfeeling
Table 2
Number of entries and links in the lexical databases.
Number of entries Mean number of
synonyms per entry
Mean number of terms
proposed by the translation
database
French 54,690 7.5 2.3
English 148,247 6.8 1.9
as near-synonymy.?4 However, having more flexible semantic links does not detract
from the accuracy of the model. No other operations are carried out on the data sets
before application of the model.
2.2.2 Semantic Units. To represent variations in a word?s meaning, each word is asso-
ciated with a spatial form (or space) (Ploux 1997; Ploux amd Victorri 1998). The points
in the space are finer units of meaning than the word itself. In our computational
simulation, the points are represented by cliques. A clique is a set of terms related
to each other by synonymy.5 The conjunction of all terms in the same clique crys-
tallizes and constrains the meaning given to the word. These cliques thus constitute
good candidates for generating the substrate upon which the form will take shape.
The presentation of the results and the features of the model will be illustrated using
examples from the headword good for English and from the headword insensible for
French. The Appendix provides the full results, as well as the definition of the word
insensible taken from a French dictionary. These examples are illustrative of the main
characteristics of the entire data set.
4 Moreover, for the two languages under study here, there are notable differences in how lexicographers
understand and use the concept of synonymy. Synonymy relations in French dictionaries, for example,
are not always symmetrical and are rarely transitive. What is more, the links have a broader scope. For
instance, the words abri (shelter) and even masure (shed) are given as synonyms of maison (house). To
make the databases homogeneous during the matching operation, a new version of the English
database was supplemented with certain hypernym links often given as synonyms in French
dictionaries. The software offers the user the opportunity to see the output obtained using the two
versions of the English database, displayed under the headings standard search and enriched search.
5 By definition, this is a maximal, connected component of the synonym graph. Words are placed at the
nodes of the graph, and arcs between two nodes represent a synonymy link.
159
Ploux and Ji A Model for Matching Semantic Maps
The synonym list contains a heterogeneous set of scrambled terms:
? For the French headword insensible, some of the terms represent a moral
value (dur, sans-coeur, . . . ), others a physical value (inerte, engourdi, . . . ),
and still others a perceptual value (imperceptible, inapparent . . . ).
? The headword good includes many similar terms. As a first
approximation, only the most representative are given here. Some of the
terms represent a generic value (right, sound, . . . ), others refer to a
capability (able, . . . ) or have an affect-related value (benevolent, . . . ), while
still others represent a quality of taste (tasty, . . . ).
The clique list contains the cliques generated from this set of terms. Cliques represent
rather precise units of meaning.6
? Here are some examples of cliques representing the moral value of the
French headword insensible:
20: cruel, dur, impitoyable, implacable, inexorable, inflexible,
inhumain, insensible
21: cruel, dur, impitoyable, implacable, inexorable, inflexible,
insensible, se?ve`re
22: cruel, dur, implacable, inflexible, inhumain, insensible, rigide
23: cruel, dur, implacable, inflexible, insensible, rigide, se?ve`re
Some examples of cliques representing the physical value:
2: anesthe?sie?, insensible
50: endormi, engourdi, inerte, insensible
51: engourdi, froid, inerte, insensible
52: engourdi, immobile, inerte, insensible, paralyse?
And some examples of cliques representing the perceptual value:
69: imperceptible, inapparent, insensible, invisible
70: imperceptible, indiscernable, insaisissable, insensible, invisible
71: imperceptible, indiscernable, insensible, le?ger
? Here are some examples of cliques representing the more prominent
senses of the English headword good:
84: dependable, good, reliable, safe, secure
87: dependable, good, reliable, solid, sound
102: fair, good, honest, honourable, just, right, upright
Some examples of cliques representing a more specific meaning of
aptitude or ability:
6: able, adequate, capable, competent, effective, good
7: able, adroit, clever, dexterous, expert, good, skilful
8: able, capable, clever, expert, good, skilful
6 The cliques are numbered here in the order in which the results are presented on the Web site
(alphabetical order).
160
Computational Linguistics Volume 29, Number 2
And some examples of cliques with affect-related values:
111: friendly, gentle, good, kind, kindly, nice, sweet
112: friendly, good, gracious, kind, kindly, nice, sweet
113: friendly, good, helpful, kind
Note that a given term may belong to several cliques (this characteristic is due to
the nontransitivity of the relation). It appears in each clique with a precise meaning
that is constrained by the presence of its neighbors.
? For example, the following cliques have terms in common; the first has a
stronger moral value than the second:
15: calme, flegmatique, froid, impassible, imperturbable, insensible
18: calme, immobile, inanime?, insensible
? In the same manner, there are shared terms in the next two cliques of
good, the first related to taste, the second to personal qualities:
80: delectable, delicious, good, lovely, savoury, scrumptious, tasty
82: delicious, good, lovely, nice, pleasant
This last point brings us to the study of semantic variations. The following clique
path, in which each clique shares at least one term with the next, moves in a relatively
continuous way from one value to another.
? Transition from a moral value to a physical value:
21: cruel, dur, impitoyable, implacable, inexorable, inflexible,
insensible, se?ve`re
34: dur, froid, impitoyable, implacable, insensible, se?ve`re
35: dur, froid, inaccessible, indiffe?rent, insensible
39: dur, impassible, indiffe?rent, insensible, sto??que
15: calme, flegmatique, froid, impassible, imperturbable, insensible
16: calme, froid, inanime?, insensible
63: froid, inanime?, inerte, insensible
83: inanime?, inerte, insensible, mort
The continuity between the moral and physical values has its
counterpart in their usage. For example, one can use the term engourdi in
French to qualify the disposition of a person who exhibits little moral
reactivity, as in:
Il allait comme dans un songe, l?esprit engourdi, paralyse?, sans chagrin
vibrant, saisi par une sorte d?engourdissement moral qui l?empe?chait de
souffrir, e?prouvant me?me un alle?gement qu?augmentaient les exhalaisons
tie`des e?pandues dans la nuit.7 (Maupassant 1881, page 350)
Moreover, as we shall see later, this type of continuous link between two
values, which acts as a metaphor here, is expressed more explicitly in the
English example below.
7 Although the term engourdi is not specifically translated, to help the reader understand this fine shade
of meaning, here is a translation of the above passage (Maupassant 2002): He walked as if he were in a
dream; his thoughts were paralyzed, although he felt no great grief, for he was in a state of mental torpor that
prevented him from suffering, and he even felt a sense of relief which was increased by the mildness of the night.
161
Ploux and Ji A Model for Matching Semantic Maps
Table 3
Evaluation of clique granularity.
Entry Number of cliques
containing entry
Number of distinc-
tions found in pub-
lished dictionaries
Number of Synsets
in WordNet
de?fendre 44 9?13 ?
distraction 39 3?10 ?
fou 319 10?23 ?
jouer 95 15?46 ?
maison 123 9?42 ?
vert 50 9 ?
blue 54 22?34 26
house 82 11?24 11
good 193 24?50 30
look 104 18?73 13
mind 87 41?68 13
play 240 77?84 47
? Transition from a taste-related value to an affective value:
80: delectable, delicious, good, lovely, savoury, scrumptious, tasty
78: delectable, delicious, excellent, exquisite, good, lovely,
scrumptious
77: delectable, delicious, enjoyable, good, pleasant
79: delectable, delicious, good, lovely, pleasant
82: delicious, good, lovely, nice, pleasant
114: friendly, good, kind, kindly, nice, pleasant, sweet
111: friendly, gentle, good, kind, kindly, nice, sweet
By contrast, for the French headword insensible, there is greater discontinuity between
the perceptual value and the others. At the present stage of our project, clique lists are
in alphabetical order, and the underlying semantic topology has not yet been built.
The geometric model we are now going to present achieves this step. Table 3 contains
an evaluation of the granularity generated by the cliques.
2.2.3 Output Geometry and Organization. To construct the semantic space, a con-
ventional correspondence factorial analysis8 (Benze?cri 1992) was conducted between
the cliques and the synonyms. For each entry, the initial matrix Mij contains nc rows
(where nc stands for the number of cliques) and ns columns (where ns stands for the
number of terms). It is defined by the formula Mij = 1 if clique i contains term j, and 0
if not. The results showed that the ?2 distances9 calculated using this method furnish
a coherent representation of semantic variations. Table 4 presents the configurations
8 Correspondence analysis is a factor analysis method that uses categorical variables (that is,
noncontinuous or discretized ones).
9
d(ci, ck) =
n
?
j=1
x
x.j
( xij
xi.
?
xkj
xk.
)2
where ci and ck are two cliques, n is the number of synonymous terms, xi. the number of terms in ci
(respectively ck), x.j the frequency of term tj and x the sum of the frequencies of all terms (or the total
number of terms in all cliques).
162
Computational Linguistics Volume 29, Number 2
Table 4
Comparison of Euclidean distance and ?2 distance on the principal plane for the above cliques.
Euclidian distance ?2 distance
d(c23, c12) 1.7855 1.7357
d(c17, c23) 0.6306 0.0170
d(c12, c17) 1.2382 1.17213
Figure 1
Two-cluster semantic space for the French headword insensible.
on the principal plane for the Euclidean distance and the ?2 distance, reduced to the
same proportion. The headword fast has many cliques, including
? c12: express, fast, quick, rapid, swift
? c17: fast, fastened, fixed, secure
? c23: fast, firm, lasting, stable, tight
The values obtained using the ?2 distance are more suited to semantic categorization
than those obtained using Euclidean distance; cliques representing the same class
are closer together (even if they do not share a larger number of terms) than ones
representing different meanings.
The dimension of the geometric space is equal to the smaller of the two numbers, ns
or nc. To show the results visually, the projections onto the principal axes are presented
in Figures 1 and 2. (The horizontal axis in the figures is the best representative of the
form delineated by the cluster of points such that the distances between the points are
maintained to the optimal degree; the vertical axis, perpendicular to the first, is the
second best representative, and so on.) Cliques are represented by points, and each
163
Ploux and Ji A Model for Matching Semantic Maps
Figure 2
Three-cluster semantic space for the English headword good.
term by the region in the space delineated by the set of cliques that contains it.10 Using
the examples again, let us review the main characteristics of the resulting organization.
The same type of organization is found in all cases.
2.2.4 Distinguishing Semantic Values. The model plots the different values on the
map. Distinct notions are clearly separate, and gradual variations are maintained.
? In the insensible example (Figure 1), we can see two clusters as a first
approximation, one smaller cluster labeled by the terms imperceptible,
inapparent, indiscernable, ne?gligeable, etc., and representing the perceptual
value of the word, and one larger cluster containing the moral and
physical values. In the center of the second cluster, we find the terms
dur, inhumain, sans-coeur, cruel, etc., which are prototypes of the word?s
moral value. Two branches come out of this center, one that qualifies a
more specific value (re?fractaire, rebelle, impe?ne?trable, etc.), and one that
leads to the physical value.11
? In the good example (Figure 2), the cliques and terms are plotted on the
map in accordance with the proximities of the values and their links. On
the principal plane, the cluster of points extends in two directions: the
first axis represents the capability value, and the second the affective
value. The affective value gradually turns into a taste-related value (tasty,
. . . ). These two main directions are interconnected by the generic value
(right, true, . . . ) located near the origin.
10 An appropriate algorithm generates the envelope (i.e., the set of cliques that contains the term) for a
given term.
11 In all figures in this article, the principal classes are outlined. (A publication about the principles of this
automatic classification model is now in preparation; only the results are given here.)
164
Computational Linguistics Volume 29, Number 2
Table 5
Some examples of spatial interconnections between semantic values.
Entry Value at the origin (labeled by
a prototype)
Examples of off-centered values
(labeled by prototypes)
de?fendre prote?ger 1. excuser 2. interdire, . . .
maison domicile 1. commerce 2. ligne?e, . . .
insensible sans-coeur 1. imperceptible, 2. engourdi, . . .
home abode 1. family, 2. interior, . . .
good right 1. able, 2. delicious, . . .
2.2.5 Spatially Interconnecting the Values. Table 5 shows the hierarchy of the spatial
organization. The middle column contains the generic values (when they exist) that
interconnect the different meanings of the word. Highly specific values are far from
the origin. This organization follows directly from the calculation of the profile matrix,
which assigns more weight to infrequent terms and to cliques containing few elements.
2.3 Matching
As stated above, the breakdown and overlapping of the lexicon varies from one lan-
guage to the next. However, several studies (Illes and Francis 1999; Ikeda 1998) have
found evidence that the two languages of a bilingual person access a common se-
mantic system. To handle the problem of lexical differences in our translation model,
connections link semantic units rather than words. Because they are finer-grained than
words, semantic units are assumed to be less sensitive to the way a given language
?cuts up? the world, and as such, they are better candidates for achieving a closer
fit between the two languages. For a given set of cliques in the source language, the
model constructs the set of cliques to be used for the translation. The two spaces
(one associated with each set of cliques) are then projected onto a map that maintains
the matches. The example of insensible is a good representative of the various pat-
terns that can appear. It has two very different, nearly homonymic semantic values,
as well as some other values whose meanings overlap considerably. For this reason,
we present the results for the matching operation using this example. The four steps
in this construction process are described below.
Step 1. Constructing the source semantic space. In order to build a semantic
space in the target language associated with a term in the source
language, the system starts by generating the set of all cliques containing
the requested word. This step is identical to the one described in
Section 2.2.2.
Step 2. Searching for relevant target language units for translation. For all
initial terms similar to the input word, the translation database furnishes
the corresponding terms in the target language. Some of these terms are
relevant to the initial generic meaning; others are clearly far removed
from that meaning. For example, the synonyms timide and le?ger of the
term insensible can be translated respectively as (. . . , shy, . . . ) for timide
and (. . . , airy, . . . ) for le?ger, neither of which is useful in generating this
headword?s target semantic space. To find the relevant senses, the model
compares the source language cliques to the cliques generated from the
set of terms proposed by the translation database. Target clique relevance
165
Ploux and Ji A Model for Matching Semantic Maps
is calculated as follows: Let S be a clique in the source language
composed of the terms (tsi )i=1???nS , and let C be clique (t
c
j )i=j???nC in the
target language. The model evaluates the relevance of the translation
based on the rank of matrix MSC, composed of zeroes and ones,
calculated using the formula MSC[i][j] = 1, if tcj translates t
s
i , and
MSC[i][j] = 0, otherwise. The rank defines a spreading parameter (in the
model, a rank of zero means that the two cliques are unrelated and the
target clique represents an out-of-range meaning in the translation
operation; a rank of three or more represents a highly cohesive semantic
link).
If this last constraint is imposed on all cliques, the model will output a
relatively small number of terms belonging to the target?s semantic
field.12
Step 3. Constructing the source-point/target-point geometry. The factorial
analysis algorithm (presented in Section 2.2.3) is followed to determine
the correspondences between the source cliques and the target cliques
that were retained in step 2, because they are relevant to at least one
clique in the source language. The correspondences are determined by
taking the product of the following matrices:
Mtr = MScs ? Tsc ? M?Ccs
where MScs is the source-clique/source-term matrix defined as in
monolingual processing (see Section 2), Tsc is the matrix that defines the
translation between the source terms and the target terms (Tsc[i][j] = 1 if
and only if term j translates term i in the initial database), and M?Ccs is the
transposed target-clique/target-term matrix.
For a subset of the French cliques of insensible, the closest three English
cliques are given below for each French clique, along with a table of the
corresponding distances calculated on the principal plane (Table 6). The
maps reproduced in Figures 3?5 summarize the resulting distances for
the headword insensible.
? cf28: cruel, dur, fe?roce, impitoyable, implacable, inexorable,
inhumain, insensible
ce67: cruel, ferocious, fierce, ruthless, savage
ce84: cruel, inhuman, merciless, pitiless, ruthless, savage
ce28: bitter, cruel, fierce, ruthless, savage
? cf40: dur, indiffe?rent, inhumain, insensible, sans-coeur
ce36: callous, hard, hardened
ce33: callous, cruel, hard, hard-hearted, heartless
ce92: difficult, hard, tough
? cf78: imperme?able, insensible, rebelle, re?fractaire, sourd
ce148: insensitive, unmoved
12 Our software proposes two types of lexical access. The first is more restrictive and sets the rank at
three or more; the second supplies a broader vocabulary and sets the rank at two or more.
166
Computational Linguistics Volume 29, Number 2
Table 6
Distances between French and English cliques on the principal plane. (For all cliques, the
distances ranged between 0.0035 and 4.0183.)
cf28 cf40 cf50 cf51 cf68 cf71 cf78
ce17 2.6483 2.1008 0.3486 0.1542 3.2331 3.6239 1.3379
ce28 0.2567 0.3009 2.0498 2.3846 3.1128 3.5984 1.0726
ce33 0.5407 0.0543 1.7672 2.1031 3.0130 3.5002 0.7897
ce36 0.5625 0.0439 1.7467 2.0831 2.9967 3.4839 0.7670
ce40 1.3223 0.7680 1.0502 1.3933 2.6981 3.1721 0.0907
ce67 0.1151 0.4404 2.1912 2.5256 3.1666 3.6503 1.2135
ce84 0.2228 0.3323 2.0854 2.4206 3.1108 3.5959 1.1056
ce87 2.3812 1.8385 0.0813 0.2630 3.2189 3.6326 1.0886
ce89 2.5708 2.0272 0.2656 0.0944 3.2805 3.6799 1.2730
ce92 0.5461 0.0633 1.7609 2.0965 3.0209 3.5081 0.7856
ce97 2.5336 1.9861 0.2365 0.1846 3.1868 3.5866 1.2240
ce98 2.3637 1.8176 0.0676 0.3000 3.1508 3.5641 1.0598
ce100 2.2895 1.7453 0.0164 0.3593 3.1568 3.5761 0.9926
ce112 3.0294 2.7339 2.8600 3.0620 0.3066 0.7473 2.5137
ce114 3.6318 3.3733 3.5037 3.6875 0.4153 0.0788 3.1821
ce129 2.9849 2.6955 2.8534 3.0606 0.3108 0.7718 2.4883
ce130 1.3400 0.7892 0.9756 1.3163 2.8715 3.3439 0.0867
ce137 3.1895 2.9208 3.1005 3.3031 0.0685 0.5290 2.7350
ce148 1.3696 0.8147 0.9837 1.3268 2.7454 3.2172 0.0551
ce149 3.6058 3.3440 3.4678 3.6514 0.3879 0.1143 3.1488
ce152 3.6335 3.3752 3.5061 3.6899 0.4171 0.0765 3.1843
ce130: impassive, indifferent, phlegmatic, stoical
ce40: callous, impassive, insensible, unfeeling
? cf50: engourdi, froid, inerte, insensible
ce100: dull, inanimate, inert, lifeless
ce98: dull, expressionless
ce87: dead, inanimate, inert, lifeless
? cf51: engourdi, immobile, inerte, insensible, paralyse?
ce89: dead, numb, paralytic
ce17: asleep, numb
ce97: dull, dulled
? cf68: imperceptible, insensible, invisible
ce137: imperceptible, indiscernible, invisible
ce112: frivolous, indifferent, insignificant, trifling, unimportant
ce129: impalpable, imperceptible, intangible, invisible
? cf71: imperceptible, insensible, insignifiant, le?ger
ce152: light, slight, trifling, trivial
ce114: frivolous, light, trifling, trivial
ce149: insignificant, slight, trifling, trivial, unimportant
Step 4. Defining the lexical regions. As above, for each language, a term is
represented by the clique region that contains it.
The next section will use examples to illustrate the results obtained. The entire set
of results is available at http://dico.isc.cnrs.fr.
167
Ploux and Ji A Model for Matching Semantic Maps
Figure 3
English-French space matching for the English headword insensible.
3. Results
The advantages of the model presented are (1) access to an extended lexicon and a
broad semantic field and (2) coherence of the matching between the semantic values in
each language. The results for insensible will be used again in this section to illustrate
the second advantage.
3.1 Access to an Extended Semantic Field and Lexicon
The model fulfills two functions: It searches for a suitable lexicon and organizes the
terms found. For each entry, the initial data provides a short list of terms representing
certain prototypes of the word?s translation. Table 1 lists the four English terms pro-
posed as translations for the French word insensible. It can happen that certain semantic
values in the source language are not represented in the translation database. For ex-
ample, insensible has no corresponding French word in our database of English word
translations. However, the model builds the appropriate values in French (Figure 3).
The model builds a much larger vocabulary that includes the initial terms from
the translation database and some semantic neighbors. Table 7 presents an overall
evaluation of the results.
Table 7
Assessment of lexical access spreading to the target language.
Mean number of terms supplied by the
translation database from a sample of 60
terms
Mean number of terms supplied by the
semantic maps of the same sample
14.1 92.9
168
Computational Linguistics Volume 29, Number 2
Figure 4
Two-cluster separation of the French and English spaces for the French headword insensible.
3.2 Coherence of the Semantic Matching
The final step in the model consists of establishing a correspondence between the
semantic values of the cliques and the terms in the two languages. By application
of the above algorithm, the cliques and terms of the two languages are plotted on
the same map. This map thus provides a summary of the semantic proximities in
each language. In order to demonstrate the coherence of the semantic-value matching
after projection onto the target language, the clusters obtained from the French and
English cliques for the term insensible are superimposed on one another. Figures 4 and
5 present the division of the output into two and four clusters. (The French clusters in
these figures are marked by a darker line and set in a darker typeface than the English
ones.) As in the two-cluster semantic space for the French word insensible, Figure 4
separates the perceptual value from the other values.
The three-cluster separation then differentiates the physical-moral value from the
moral value. Figure 5 shows the division within the physical-moral value between
what is more specifically physical and what pertains to emotional insensitivity (emo-
tionless, re?fractaire, etc.) or to the inability to discern that sensitivity (impe?ne?trable, etc.).
Note that although all values initially present in the monolingual space are rep-
resented, a reorganization process still takes place during pairing with the target lan-
guage. In French, the terms (re?fractaire, inacessible, . . . ) were separated from the terms
(inerte, engourdi, . . . ) by the group made up of the terms (dur, sans-coeur, . . . ), but now
they are located close to the center. This layout probably results from (1) the effect
of the greater number of terms like (inert, numb, sluggish, chilly, . . . ), which, in En-
glish, unlike in French, encompass emotional and physical insensitivity and therefore
bring these two values closer together on the map, and (2) the prototypical, cen-
tral nature of this value in English, as expressed by the terms (impassive, insensible,
insensitive, . . . ).
169
Ploux and Ji A Model for Matching Semantic Maps
Figure 5
Four-cluster separation of the French and English spaces for the French headword insensible.
4. Discussion
We have presented a model for matching a semantic space in a source language and a
semantic space in a target language. This model, currently built from lexical similarity
relations (synonymy or near-synonymy and translations), uses several representation
levels: cliques, which represent very precise units of meaning; terms, which are repre-
sented geometrically by a region in the space containing a set of cliques; and clusters,
which are generated from the results of a spatialization process that singles out a term?s
main semantic values. (Again, this last representation level is merely mentioned in the
present article; the method used to generate it and the rationale for its use in semantic
classification will be described in detail in a forthcoming publication.) The matching
between the French and English spaces is achieved by mapping the cliques of the two
languages to each other. The model software allows a user to choose a candidate word
in the target language according to its synonym neighborhood. A map showing each
language?s neighborhoods and separate clusters for each semantic value helps the user
make the choice. This system and its interactive interface is a useful tool appreciated
by researchers, translators, writers, and other users. Although this alone is enough
to justify the model, it would be worthwhile to incorporate it into a more complete
automatic language processing system. We are now working on enhancing the system
by including context relations, and by bringing to bear a word?s argument structure,
qualia structure, and lexical inheritance.
Within the past 10 years, original contributions have been made in the areas of
compositional semantics and lexical context assignment (see Ide and Veronis [1998] for
the state of the art on word sense disambiguation). Most studies have dealt with the
sentence, but some have looked at the discourse and text levels. Based on a generative
framework, Pustejovski (1995) proposed a computational model that adds a represen-
tation of a word?s structures (event structure, argument structure, qualia structure, and
170
Computational Linguistics Volume 29, Number 2
lexical inheritance structure), along with transformation rules for combining units. In
their study, Asher and Lascarides (1995) showed that lexical semantics and discourse
structure may interfere with discourse structure and devised heuristics to disentangle
the effects of these two interacting levels. Other authors (Foltz, Kintsch, and Lan-
dauer 1998; Kintsch 2001; Schu?tze 1998) have developed an approach based solely on
automatic corpus analysis in which co-occurrences and their frequencies are used to
generate the semantic space associated with a given word. Edmonds and Hirst (2002)
proposed a model with two tiers: a fine-grained synonym tier and a coarse conceptual
tier. Unlike Edmonds and Hirst?s approach, which rests on an ontological model and
conceptual representations, our model is capable of detecting semantic distinctions
solely on the basis of similarity links. This feature is one of the model?s assets, but it is
also a limitation, which provides the incentive for the enhancements we are currently
developing. Here is a brief preview of our ongoing projects:
? Certain words are poorly represented in terms of synonymy. This is the
case for words that are essentially nonpolysemous, like computer or daisy,
and thus have very few synonyms. Such entities are better delineated by
an ontological, hierarchical representation and by their qualia structure
than by synonymy links. Grammatical words also have few synonyms,
so they too need to be represented in a formalism more suited to their
own features than the one proposed in this article.
? Usage contexts or domains of application are not currently given for the
different semantic values detected by the model. For example, the
perceptual value of the word insensible is employed to modify external
phenomena, whereas the moral and physical values apply to animate
beings. It would thus be useful, as in a standard dictionary, to specify
the different types of terms the values obtained can modify.
? Our research should help improve map drawing. At the present time,
map neighborhoods rely solely on semantic criteria, which sometimes
leads to the map?s including terms with similar meanings but different
syntactic category memberships than the initial word.
These projects should contribute to furthering research on language and automatic
language processing. As stated in the article?s introduction, we are also working on the
cognitive relevance of our model. We have already conducted an initial study aimed
at determining whether a spatial model is an appropriate way of representing the
structure of the mental lexicon. Our work on this problem draws from a preliminary
study (Rouibah, Ploux, and Ji 2001) which proposes a homomorphism between lexical
distance (the organizing principal of our model) and reaction time (the parameter used
in lexical access experiments). This idea is based on the finding that lexical distance is
subject to the same effects as reaction time.
Appendix
Example of a classification, for the French term insensible (taken from Le Petit Robert
version 1.2). Rough English translations are given in parentheses.
insensible:
? I Qui ne sent pas, ne ressent rien. (Not sensing, feeling nothing.)
171
Ploux and Ji A Model for Matching Semantic Maps
1. Qui n?a pas de sensibilite? physique. inanime?, mort. (Having no
physical sensitivity. inanimate, dead.)
2. Qui n?e?prouve pas les sensations habituelles, normales. (Not
experiencing the usual, normal sensations) (insensible a` la
douleur, au froid, a` la chaleur. (insensitive to pain, to cold, to
heat.)
3. Qui n?a pas de sensibilite? morale; qui n?a pas ou a peu
d?e?motions. (Having no moral sensitivity; having few if any
emotions.) apathique, calme, de?tache?, froid, impassible,
imperturbable, indiffe?rent. cruel, dur, e?go??ste, endurci,
impitoyable, implacable, inexorable. imperme?able, indiffe?rent.
sourd. e?tranger, ferme?, inaccessible; re?fractaire. (apathetic, calm,
detached, cold, impassible, imperturbable, indifferent. cruel,
hard, egotistical, hardened, pitiless, implacable, inexorable.
impervious, indifferent. deaf. foreign, closed, inaccessible;
resistant.)
? II
1. Qu?on ne sent pas, qu?on ne perc?oit pas ou qui est a` peine
sensible, perceptible. imperceptible, le?ger. (Not being sensed, not
being perceived or being just barely sensible, perceptible.
imperceptible, slight.)
2. Graduel, progressif. (Gradual, progressive.)
System output for a request to generate the semantic space associated with the French
headword insensible.
Your query was: insensible. There are 71 synonyms and 93 cliques.
Table 8
Synonym list for the headword insensible (French lexical database).
insensible: adamantin, anesthe?sie?, apathique, aride, assoupi, blase?, calleux, calme,
cruel, de marbre, desse?che?, dur, de?tache?, endormi, endurci, engourdi,
flegmatique, frigide, froid, fe?roce, glacial, glace?, immobile, impassi-
ble, imperceptible, imperme?able, imperturbable, impitoyable, impla-
cable, impe?ne?trable, inabordable, inaccessible, inanime?, inapparent,
indiffe?rent, indiscernable, indolent, indolore, inerte, inexorable, in-
flexible, inhumain, ininflammable, insaisissable, insignifiant, invisi-
ble, invulne?rable, le?ger, le?thargique, mort, neutre, ne?gligeable, obtus,
paralyse?, progressif, rebelle, rigide, re?fractaire, sans coeur, sans en-
trailles, sans coeur, sec, sourd, sto??cien, sto??que, suprasensible, se?ve`re,
timide, e?go??ste, e?tranger, e?troit.
172
Computational Linguistics Volume 29, Number 2
Table 9
Clique list for the headword insensible (French lexical database).
1 : adamantin, dur, insensible
2 : anesthe?sie?, insensible
3 : apathique, endormi, indolent, insensible
4 : apathique, endormi, inerte, insensible
5 : apathique, flegmatique, impassible, imperturbable, indiffe?rent, insensible
6 : apathique, indiffe?rent, indolent, insensible
7 : apathique, inerte, insensible, mort
8 : apathique, insensible, le?thargique
9 : aride, desse?che?, froid, insensible, sec
10 : aride, froid, indiffe?rent, insensible, sec
11 : aride, froid, insensible, sec, se?ve`re
12 : assoupi, endormi, engourdi, insensible
13 : blase?, flegmatique, froid, indiffe?rent, insensible
14 : calleux, dur, endurci, insensible
15 : calme, flegmatique, froid, impassible, imperturbable, insensible
16 : calme, froid, inanime?, insensible
17 : calme, immobile, impassible, insensible
18 : calme, immobile, inanime?, insensible
19 : cruel, dur, fe?roce, impitoyable, implacable, inexorable, inhumain, insensible
20 : cruel, dur, impitoyable, implacable, inexorable, inflexible, inhumain, insensible
21 : cruel, dur, impitoyable, implacable, inexorable, inflexible, insensible, se?ve`re
22 : cruel, dur, implacable, inflexible, inhumain, insensible, rigide
23 : cruel, dur, implacable, inflexible, insensible, rigide, se?ve`re
24 : cruel, dur, indiffe?rent, inhumain, insensible
25 : de marbre, glacial, impassible, insensible
26 : desse?che?, dur, froid, insensible, sec
27 : dur, endurci, impitoyable, implacable, inflexible, insensible
28 : dur, endurci, impitoyable, insensible, sans coeur
29 : dur, endurci, indiffe?rent, insensible, sans coeur, sec
30 : dur, froid, glacial, impassible, insensible
31 : dur, froid, glacial, insensible, sec
32 : dur, froid, impassible, implacable, insensible
33 : dur, froid, impassible, indiffe?rent, insensible
34 : dur, froid, impitoyable, implacable, insensible, se?ve`re
35 : dur, froid, inaccessible, indiffe?rent, insensible
36 : dur, froid, indiffe?rent, insensible, sec
37 : dur, froid, insensible, sec, se?ve`re
38 : dur, impassible, implacable, inflexible, insensible
39 : dur, impassible, indiffe?rent, insensible, sto??que
40 : dur, impitoyable, inhumain, insensible, sans coeur
41 : dur, indiffe?rent, inhumain, insensible, sans coeur
42 : dur, inhumain, insensible, sans coeur
43 : dur, inhumain, insensible, sans entrailles
44 : dur, insensible, invulne?rable
45 : dur, insensible, rigide, sec, se?ve`re
46 : dur, insensible, rigide, sto??que, se?ve`re
47 : de?tache?, flegmatique, imperturbable, indiffe?rent, insensible
48 : de?tache?, indiffe?rent, insensible, e?tranger
49 : endormi, engourdi, indolent, insensible
50 : endormi, engourdi, inerte, insensible
51 : engourdi, froid, inerte, insensible
52 : engourdi, immobile, inerte, insensible, paralyse?
53 : engourdi, insensible, le?thargique
54 : engourdi, insensible, rigide
55 : flegmatique, froid, impassible, imperturbable, indiffe?rent, insensible
56 : frigide, froid, glace?, insensible
57 : froid, glacial, glace?, impassible, insensible
...
173
Ploux and Ji A Model for Matching Semantic Maps
Table 10
Examples of cliques generated in the target language for the headword insensible.
...
3 apathetic, cold, dull, indifferent, languid
4 apathetic, cold, unfeeling
5 apathetic, cool, impassive, indifferent
6 apathetic, cool, indifferent, unconcerned
7 apathetic, dull, languid, sluggish
8 apathetic, impassive, indifferent, languid
9 apathetic, impassive, indifferent, phlegmatic
...
14 apathetic, phlegmatic, sluggish
15 arid, dried, parched
16 arid, dry, parched
17 asleep, numb
18 austere, bare
19 austere, bitter, harsh, severe
20 austere, cold
21 austere, grave, hard, harsh, severe
22 austere, hard, hard-hearted, harsh, stern
23 austere, hard, hard-hearted, heartless, stern
24 austere, hard, harsh, rigid, severe, stern, strict
...
28 bitter, cruel, fierce, ruthless, savage
29 bitter, cruel, harsh, ruthless
30 bitter, cruel, harsh, severe
31 callous, cold, dead, indifferent
32 callous, cold, senseless, unfeeling
33 callous, cruel, hard, hard-hearted, heartless
34 callous, cruel, hard-hearted, heartless, unfeeling
35 callous, cruel, heartless, inhuman
36 callous, hard, hardened
37 callous, hard-hearted, insensitive, unfeeling
38 callous, hardened, insensitive, unfeeling
39 callous, impassive, indifferent
40 callous, impassive, insensible, unfeeling
41 callous, insensible, insensitive, unfeeling
42 callous, insensible, senseless, unfeeling
43 calm, calmness, composure, cool, quiet
44 calm, composed, cool, impassive, imperturbable
45 calm, composed, cool, quiet
...
54 cold, dead, frigid, indifferent
55 cold, dry, dull, frigid, languid
56 cold, dull, frigid, indifferent, languid
57 cold, freezing, frigid, frosty, icy
58 cold, frigid, frosty, frozen, icy
59 cold, frigid, icy, indifferent
60 cold, senseless, unconscious
61 cool, detached, indifferent, unconcerned
62 cool, emotionless, impassive, imperturbable
63 cool, impassive, indifferent, stoical
64 cramped, dry, stiff
174
Computational Linguistics Volume 29, Number 2
65 cramped, stiff, tight
66 crisp, frosty
67 cruel, ferocious, fierce, ruthless, savage
68 cruel, grave, hard, harsh, severe
69 cruel, hard, hard-hearted, harsh, stern
...
77 cruel, heartless, inexorable, pitiless, relentless
78 cruel, heartless, inexorable, relentless, stern
79 cruel, heartless, inhuman, merciless, pitiless, ruthless
80 cruel, heartless, merciless, pitiless, relentless, ruthless, unfeeling
81 cruel, implacable, inexorable, pitiless, relentless
82 cruel, implacable, merciless, pitiless, relentless
83 cruel, inexorable, relentless, severe, stern
84 cruel, inhuman, merciless, pitiless, ruthless, savage
85 dead, extinct, inanimate, lifeless
86 dead, idle, inert
87 dead, inanimate, inert, lifeless
88 dead, indifferent, inert
89 dead, numb, paralytic
90 deaf, indifferent
91 difficult, hard, stiff
92 difficult, hard, tough
93 difficult, obscure
94 dozing, drowsy
95 drowsy, lethargic, sleepy
96 dry, severe, stiff
97 dull, dulled
...
98 dull, expressionless
99 dull, faint, languid
100 dull, inanimate, inert, lifeless
101 dull, indifferent, inert, languid
102 dull, indifferent, inert, neutral
103 dull, inert, languid, lethargic, sluggish
...
111 frivolous, idle, light, trivial
112 frivolous, indifferent, insignificant, trifling, unimportant
113 frivolous, insignificant, trifling, trivial, unimportant
114 frivolous, light, trifling, trivial
115 hard, hardened, tough
116 hard, heartless, relentless, unyielding
117 hard, inflexible, relentless, stern
118 hard, inflexible, relentless, unyielding
119 hard, inflexible, rigid, stern
120 hard, inflexible, rigid, stiff, stubborn, unyielding
121 hard, inflexible, rigid, tough, unyielding
122 hard, rigid, severe, tough
...
128 immobile, inert, motionless
129 impalpable, imperceptible, intangible, invisible
130 impassive, indifferent, phlegmatic, stoical
131 impassive, indifferent, unmoved
132 impenetrable, inaccessible, unapproachable
133 impenetrable, incomprehensible, inscrutable, unfathomable
134 impenetrable, incomprehensible, obscure
135 impenetrable, unapproachable, unfathomable
175
Ploux and Ji A Model for Matching Semantic Maps
136 imperceptible, indiscernible, insensible
137 imperceptible, indiscernible, invisible
138 implacable, inexorable, inflexible, relentless
...
146 inflexible, intractable, stubborn, unyielding
147 insensible, senseless, unconscious
148 insensitive, unmoved
149 insignificant, slight, trifling, trivial, unimportant
150 lethargic, phlegmatic, sluggish
151 lethargic, sleepy, sluggish
152 light, slight, trifling, trivial
...
Table 11
Clique list for the headword good (English standard lexical database).
...
6 : able, adequate, capable, competent, effective, good
7 : able, adroit, clever, dexterous, expert, good, skilful
8 : able, capable, clever, expert, good, skilful
9 : able, capable, competent, effective, efficient, good
10 : absolutely delicious, delectable, delicious, good, gorgeous, lovely, scrumptious,
yummy
11 : adept, expert, good, practiced, proficient, skilful, skilled, skillful
12 : adequate, competent, good, satisfactory, sufficient
13 : adequate, full, good
14 : admirable, commendable, deserving, good, meritorious, worthy
15 : admirable, deserving, estimable, good, meritorious, worthy
...
27 : advantageous, beneficial, good, helpful, salutary
28 : advantageous, beneficial, good, propitious
29 : agreeable, enjoyable, good, pleasant
30 : agreeable, good, good-natured
31 : agreeable, good, lovely, nice, pleasant, sweet
32 : appetising, appetizing, delicious, good, lovely, nice, savory, savoury, tasty
33 : attentive, good, obliging
34 : attentive, good, sweet, well-behaved
35 : auspicious, benign, good, propitious
36 : auspicious, good, promising, propitious
37 : beneficent, benevolent, benign, good, gracious, kind
38 : beneficent, benevolent, generous, good, kind
39 : beneficent, good, helpful, kind
40 : beneficial, benign, good, propitious
41 : beneficial, friendly, good, helpful
42 : beneficial, friendly, good, propitious
...
48 : benevolent, benign, good, gracious, kind, kindly
49 : benevolent, benign, good, gracious, propitious
50 : benevolent, friendly, good, gracious, kind, kindly
...
176
Computational Linguistics Volume 29, Number 2
56 : commendable, creditable, deserving, good, meritorious, worthy
57 : commendable, creditable, good, honorable, honourable, worthy
58 : commendable, creditable, good, honourable, meritorious, worthy
59 : commendable, deserving, exemplary, good
60 : competent, expert, good, skilful, skilled, skillful, versed
61 : considerable, fair, good, respectable
62 : considerable, fair, good, serious, substantial
63 : considerable, fair, good, sound, substantial
...
71 : creditable, estimable, good, honorable, honourable, worthy
72 : creditable, estimable, good, honourable, meritorious, worthy
73 : dear, good, near
74 : dear, good, precious, sweet
75 : dear, good, precious, valuable
76 : decorous, good, respectable
77 : delectable, delicious, enjoyable, good, pleasant
78 : delectable, delicious, excellent, exquisite, good, lovely, scrumptious
79 : delectable, delicious, good, lovely, pleasant
80 : delectable, delicious, good, lovely, savoury, scrumptious, tasty
81 : delectable, delicious, good, lovely, scrumptious, tasty, yummy
82 : delicious, good, lovely, nice, pleasant
83 : dependable, good, honest, reliable, true, trustworthy
84 : dependable, good, reliable, safe, secure
85 : dependable, good, reliable, safe, trustworthy
86 : dependable, good, reliable, secure, solid
...
92 : effective, efficient, good, serviceable
93 : effective, good, in effect, in force
94 : estimable, good, honorable, honourable, respectable, worthy
95 : excellence, good, goodness, merit, virtue, worth
96 : excellent, exemplary, good
97 : excellent, exquisite, fine, good, lovely
98 : excellent, good, noble, worthy
99 : exemplary, good, virtuous
100 : expert, good, practiced, skilful, skilled, skillful, versed, well-versed
101 : exquisite, fine, good, precious
102 : fair, good, honest, honourable, just, right, upright
103 : fair, good, honest, honourable, respectable
104 : fair, good, honest, honourable, righteous, upright
105 : fair, good, honest, serious
...
110 : fine, good, well
111 : friendly, gentle, good, kind, kindly, nice, sweet
112 : friendly, good, gracious, kind, kindly, nice, sweet
113 : friendly, good, helpful, kind
114 : friendly, good, kind, kindly, nice, pleasant, sweet
115 : friendly, good, propitious, well-disposed
116 : full, good, large
...
121 : gentle, good, noble
122 : genuine, good, honest, right, true
123 : genuine, good, real, solid
124 : genuine, good, real, true
125 : genuine, good, right, sound, true
126 : genuine, good, right, sound, valid
...
177
Ploux and Ji A Model for Matching Semantic Maps
134 : good, helpful, kind, obliging
135 : good, holy, righteous, virtuous
136 : good, honest, honorable, honourable, moral, righteous, upright, virtuous
137 : good, honest, honorable, honourable, respectable
138 : good, honest, honourable, just, right, true, upright
139 : good, honest, honourable, just, upright, virtuous
140 : good, honest, honourable, moral, right, upright
141 : good, honorable, honourable, virtuous, worthy
142 : good, honourable, meritorious, virtuous, worthy
...
Acknowledgments We gratefully
acknowledge support of the Agence
Universitaire de la Francophonie and the
FRANCIL network.
References
Abplanalp, Laure. 1998. La pertinence et la
traduction. Travaux du centre de traduction
litte?raire, Lausanne, Switzerland.
Anderson, John R. 1983. The architecture of
cognition. Harvard University Press,
Cambridge.
Asher, Nicolas and Alex Lascarides. 1995.
Lexical disambiguation in a discourse
context. Journal of Semantics, 12(1):9?108.
Benze?cri, Jean-Paul. 1992. Correspondence
Analysis Handbook. Dekker, P, New York.
Chuquet, He?le`ne and Michel Paillard. 1989.
Approches linguistiques des proble`mes de
traduction. Ophrys, Paris.
Collins, Allan M. and Elizabeth F. Loftus.
1975. A spreading-activation theory of
semantic processing. Psychological Review
82:407?428.
Edelman, Shimon. 1998. Representation is
representation of similarities. Behavioral
and Brain Sciences, 21(4):449?498.
Edmonds, Philip and Graeme Hirst. 2002.
Near-synonymy and lexical choice.
Computational Linguistics, 28(2):104?144.
Fellbaum, Christiane. 1998. WordNet: an
Electronic Lexical Database. MIT Press,
Cambridge.
Foltz, Peter W., Walter Kinsch, and Thomas
K. Landauer. 1998. The measurement of
textual coherence with latent semantic
analysis. Discourse Processes, 25:285?307.
Ide, Nancy and Jean Veronis. 1998. Word
sense disambiguation: The state of the art.
Computational Linguistics, 24(1):1?40.
Ikeda, Satoko. 1998. Manual response set in
a stroop-like task involving categorization
of English and Japanese words indicates
a common semantic representation.
Perceptual and Motor Skills, 87(2):467?474.
Illes, Judy and Wendy S. Francis. 1999.
Convergent cortical representation of
semantic processing in bilinguals. Brain
and Language, 70(3):347?363.
Kinsch, Walter. 2001. Predication. Cognitive
Science, 25:173?202.
Masson, Michael. 1995. A distributed
memory model of semantic priming.
Journal of Experimental Psychology: Learning,
Memory, and Cognition, 21(1):3?23.
Maupassant, Guy (de). 1881. Contes et
nouvelles. Gallimard, Bibliothe`que de la
Ple?iade, Paris.
Maupassant, Guy (de). 2002. Original Short
Stories, vol. 2, trans. Albert M. C.
McMaster and L. Quesada Project
Gutenberg Release. http://www2.cs.
cmu.edu/spok/metabook/maupassant.html.
Miller, George A. 1990. WordNet: An
on-line lexical database. International
Journal of Lexicography, 3(4):235?312.
Ploux, Sabine. 1997. Mode?lisation et
traitement informatique de la synonymie.
Linguisticae Investigationes, 21(1):1?28.
Ploux, Sabine and Bernard Victorri. 1998.
Construction d?espaces se?mantiques a`
l?aide de dictionnaires informatise?s des
synonymes. Traitement automatique des
langues, 39(1):161?182.
Pustejovsky, James. 1995. Generative Lexicon.
MIT Press, Cambridge.
Reboul, Anne. 2000. Words, concepts,
mental representations and other
biological categories. In B. Peeters, editor,
The Lexicon-Encyclopedia Interface. Elsevier,
Amsterdam.
178
Computational Linguistics Volume 29, Number 2
Rouibah, A??cha, Sabine Ploux, and
Hyungsuk Ji. 2001. Un mode`le spatial des
repre?sentations lexicales implique?es dans
la reconnaissance des mots e?crits. In
He?le`ne Paugam-Moisy, Vincent Nyckees,
and Josiane Caron-Pargue (editors), La
cognition entre individu et socie?te?.
Herme`s-Science, Paris.
Schu?tze, Hinrich. 1998. Automatic sense
discrimination. Computational Linguistics,
24(1):97?124.
Vinay, Jean-Paul and Jean Darbelnet. 1996.
Stylistique compare?e du franc?ais et de
l?anglais. Didier, Paris.
Vossen, Piek, editor. 1998. EuroWordNet: A
Multilingual Database with Lexical Semantic
Networks. Kluwer Academic, Dordrecht,
the Netherlands.
Using Topic Salience and Connotational Drifts to Detect
Candidates to Semantic Change
Armelle Boussidan
L2C2, Institut des Sciences Cognitives - CNRS, Universit? de Lyon, Bron, France
armelle.boussidan@isc.cnrs.fr
Sabine Ploux
L2C2, Institut des Sciences Cognitives - CNRS, Universit? de Lyon, Bron, France
sploux@isc.cnrs.fr
Abstract
Semantic change has mostly been studied by historical linguists and typically at the scale of centuries.
Here we study semantic change at a finer-grained level, the decade, making use of recent newspaper cor-
pora. We detect semantic change candidates by observing context shifts which can be triggered by topic
salience or may be independent from it. To discriminate these phenomena with accuracy, we combine
variation filters with a series of indices which enable building a coherent and flexible semantic change
detection model. The indices include widely adaptable tools such as frequency counts, co-occurrence
patterns and networks, ranks, as well as model-specific items such as a variability and cohesion mea-
sure and graphical representations. The research uses ACOM, a co-occurrence based geometrical model,
which is an extension of the Semantic Atlas. Compared to other models of semantic representation, it
allows for extremely detailed analysis and provides insight as to how connotational drift processes unfold.
1 Introduction
Semantic change has long been analyzed and theorized upon in historical linguistics. Its abstract and
ungraspable nature made its detection a difficult task for computational semantics, despite the many tools
available from various models of lexical treatment. Most extant theories are based on manual analysis of
century long semantic drifts. From these works we inherit various typologies and repertories of causes
of change (e.g., Bloomfield (1933)). However these types of analyses may not be suited to the large scale
production of text in our societies. Not only has the quantity of produced text rocketed but its diffusion
and speed of transmission has radically increased. In this context, recent studies have yielded promising
results, showing that computational models of semantics can deal with assessed semantic change exam-
ples as well as detect candidates in corpora. Among them, some include topic salience as an index and
others do not, as they rather try to quantify semantic change with reliable measures. In an era of infor-
mation overflow, topic change takes on a new linguistic value, as it may be responsible for extremely
quick paced semantic change, which can be ephemeral or become fixed. Topic salience might as well
be a sociologically induced or press phenomenon with no semantic impact at all. However when both
topic salience and connotational drift take place, a semantic phenomenon may be at stake. Our analysis
is anchored in this process. We shall briefly introduce other approaches, explain our methods and the
structure of our detection prototype (in progress) as well as give preliminary results before concluding
with a discussion.
2 Measuring semantic change : previous work
To measure semantic change, one has to evaluate the semantics of a lexical item at a given point. To
do so, semantic similarity measures in vector spaces or geometrical spaces may be used to compare the
315
item with its own occurrences at later points. This method has been applied in Sagi et al (2009), where
semantic density was calculated as the average angle between vectors in a semantic space. The variabil-
ity of that density was observed for the same lexical item at different points in time. Density measures
were applied to a series of acknowledged semantic change cases, in the Project Gutenberg Corpus, a
historical corpus of English organized by documents. Results mostly include broadening and narrowing
cases. The same method yielded results on the difference between nominal and verbal types of change,
showing that verbs were more likely to change than nouns (Sagi (2010)).
Cook and Stevenson (2010) also used assessed cases from the historical linguistics literature. They
detected changes in the semantic orientation of words (or polarity shifts) namely amelioration and pejo-
ration. They then applied this methodology to detect possible un-assessed candidates. They used three
English corpora as corpus slices, covering approximately a four century time-span.
Volatility has also been assessed by Holz and Teresniak (2010), who adapted a measure from economet-
rics to quantify semantic change in a time sliced corpus. The volatility measure relied on the computation
of the rank series for every co-occurent term and on the coefficient of variation of all co-occurrent terms
(Holz and Teresniak (2010)). The method was applied to search words in modern corpora in German and
English (the Wortschatz and the New York Times). The strong point of this measure is that it is indepen-
dent from word frequency, however it does not provide detailed analysis about the underlying semantic
processes.
3 Methods
Of the three cited works, our approach is closer to that of Holz and Teresniak (2010) in that both
their work and ours are conducted on very recent corpora. We are currently conducting short diachrony
detection, analysis and representation on a modern press corpus in French (the newspapers Le Monde,
1997-2007). We use the ACOM model (Ji et al (2003)) an extension of the Semantic Atlas Model (Ploux
et al (2010)) that uses factor analysis to provide geometrical representations of word co-occurrence in
corpus (both models are freely available on http://dico.isc.cnrs.fr/eng/index.html).
The model relies on cliques, which are organized subsets of co-occurrent words, from which clustering
can be made. To extract co-occurrent words, we apply ACOM on a time-sliced corpus. For each slice
t, a word-association table is constructed using all headwords (see Ploux et al (2010) for a complete
methodological description). Each headword W it (1?i?N , where N is the total number of types in the
corpus slice) has children (cjs) that are arranged in descending order of co-occurrence with W it 1:
W it : c1; c2; . . . ; cn
We apply two factors to filter this table: ? where 0???1 to eliminate the rarely co-occurring children
of W in :
W it : c1; c2; . . . ; ck
where k = n? and n is the original number of children of W it , and ? where ?(0? ? ?1) to cut off rarely
co-occurring of children of cj :
(cmj : g1; g2; . . . ; gl(1?j?k; l = m?))
On the basis of that table, cliques are calculated. The notion of clique is taken from graph theory (on
graph therory see for ex. Golumbic (2004)). Mathematically, cliques are maximum connected sub-
graphs. In our case, the nodes are contexonyms. Then, correspondence factor analysis is applied (Ben-
z?cri (1980)) and the ?2 distance is calculated between pairs of cliques to obtain a multidimensional
space. A hierarchical clustering algorithm clusters cliques in thematic sets at several degrees of detail.
Clusters show broad topic shifts whereas the cliques show fine-grained sub-organisation. Therefore the
model allows for very detailed analysis as well as topical analysis. It also provides a graphic visualization
for the semantics of a word. With the time-sliced corpus, we may extract maps for each subpart of the
1Children with co-occurrences under a 10,000th of the global frequency of the headword W it are removed to reduce noise.
316
corpus and compare the spaces generated for the same word at different points in time, to complete the
analysis.
3.1 Structure of the detection prototype
Currently our model is structured as follows: the corpus is transformed into a time-sliced ACOM
database, with word frequencies and co-occurence frequencies. We apply an adjustable standard de-
viation filter to extract significant frequency and co-occurrence frequency variations as well as co-
occurrence network variations. (The co-occurrence window is adjustable to the sentence, paragraph
or other window sizes). If we only detect frequency variation, there is a suspicion that the headword
might undergo context variation later, but it could also be an ephemeral press or fashion phenomenon
with no semantic impact. However if we detect both significant frequency variations and co-occurrence
variations, there is a higher chance that the context variations are a reflection of semantic variation. At
this stage we apply indices based on rank variation, clique analysis and clique-term variation analysis
(described in Boussidan et al (2010)) as well as manual analysis to determine the nature of the change.
The next step to verify that the item has undergone semantic change is its stabilization over time. This
detection path highlights short diachronic change. We may also detect significant co-occurence varia-
tions with no significant headword frequency variation, in which case we may apply directly the indices
to check whether the context shifts reveal an anchored meaning shift. If the indices highlight a meaning
shift, the former is necessarily much more subtle than the short diachronic change that we detected pre-
viously. It might be the reflection of a longer term process of which the trigger might not be contained
in the given corpus.
4 Preliminary results
4.1 Testing examples
To conceive a detection model, we first conducted experiments using attested examples or using
words that we selected after manually observing that a shift was taking place. By testing these examples,
we could extract data about how the model would render them so as to use it to create detection indices
and parameters. Among these was the French word malbouffe (literally "bad grub" or "junk food"), a
neology selected from a previously established list of new dictionary entries (Martinez (2009)). The
corpus showed how the different spellings of the words alternated before yielding the current one. Anal-
ysis of the co-occurrence networks showed that one of the most important co-occurrent words, Bov?, the
name of a French political actor, had almost the same co-occurrence network as malbouffe. From this
observation and after comparing definitions and previous contexts of use, we could infer that this person
gave the word malbouffe its new meaning, by superimposing political values on it, on top of its dietetic
values. Co-occurrence networks therefore allowed us to analyse the process of meaning shift. The full
analysis of this example may be found in Boussidan et al (2009).
We also tested a more subtle connotational drift with the word mondialisation ("globalization"), which
undergoes clear contextual change in the corpus. The word first appeared in contexts defined by the
political, economical and intellectual positions it brings about, with strong co-occurrents such as d?fi
(?challenge?), progr?s (?progress") or menace (?threat?). It then drifted into a complete network of
words related to one single French political movement of anti-globalization in 2001. Therefore the use
of mondialisation gained a new connotation, whereas its synonym globalisation ("globalization") re-
mained quite neutral politically. The analysis of this example revealed that some terms were used as
pivots, providing linkage between the existing cliques and the new ones. Pivots therefore provided a
good tool to observe meaning re-organisation. The full analysis of this example may be found in Boussi-
dan et al (2010) and the corresponding dynamic representation on http://dico.isc.cnrs.fr/
en/diachro.html.
4.2 Semantic change detection
On the basis of these preliminary examples, we designed a semantic change detection prototype.
Testing examples brought to light the difficulty of discriminating press-related topic salience with no
317
semantic impact from topic salience with a semantic impact. Detection is conducted in three stages. The
first stage relies on frequency variation to extract topic variations of context in the corpus. For instance
by setting the filter to retain words for which the coefficient of variation2 is higher than 0.5, we obtain a
list of words that may be classified into three loose semantic sets and a fourth set grouping all indepen-
dent items. These semantic sets include words related to:
? war, terrorism and violence
? technology
? illness
By adjusting the settings we mayalso include more subtle topic variations if needed or conversely, looser
ones. The second stage involves co-occurrence variation so as to extract the changes in semantic networks
and thus in connation, for a lexical item. For instance, we detected that the word logiciel ("software")
underwent a frequency co-occurrence peak with libre ("free") in January 2001. The expression logiciel
libre stands for "freeware" and has been renamed gratuiciel or graticiel (a blending of gratuit, "free"
with logiciel, "software") in Quebec. We therefore detect a new compositional expression that coins a
French equivalent to the word freeware used until then.
Another example of connotational drift is the word navigation ("navigation") which is only attested
in the TLFI3 and the Dictionnaire Historique de la Langue Fran?aise (Rey et al (1998)), under the mean-
ing relating to transport, firstly on seas and rivers and then via plane or spaceship. However, between
1997 and 2001 the word takes on a new major meaning in internet search, meaning "browsing". This is
aparent when looking at the co-occurrence patterns of navigation with words related to technology and
comparing them with co-occurrences of words related to transport. The technology words show peaks
between 1997 and 2001 and then lower frequencies until 2007, whereas the transport words show stable
use all the way through the corpus. The new use of navigation, however is almost obsolete now in spoken
speech -or at least it has gone out of fashion- but the semantics of navigation have clearly integrated an
additional domain and broadened. A simple search of French results on Google provides 5,500,000 doc-
uments for navigation internet, among which are a lot of recent ones. However the meaning to search the
internet grew from the name of a specific web navigator: the Netscape Navigator which was widespread
in the 1990s but is no longer supported nowadays.
Both previous stages provide us with candidates to semantic change. The last stage is the stabilization
of a connotational drift, whether it is a broadening, a narrowing, a domain shift or other. We are currently
working on this last index. We often find that when a word undergoes semantic change, it goes through
a phase of onomasiological competition in which other possible candidates may in turn become the new
bearers of certain meanings. For navigation for instance, the word surf was a competitor, however both
words now sound obsolete. It may be that none of them wins the competition, in which case the concept
has become so deeply anchored in language and society that it does not need naming any more.
5 Discussion and Future Work
Since semantic phenomena, whether synchronic or diachronic, are very much corpus specific, it is
difficult to conceive of a large scale universal detection method for them. However, tools may be built
to be highly flexible in order to allow users to adjust settings to adapt to the corpus they deal with. This
flexibility may encompass genre and stylistic variations when working with the same language as well
as adaptation to a completely different language. We are considering global evaluations of the corpora?s
stylistics to avoid the detection of corpus specfic phenomena instead of broader language phenomena.
2The coefficient of variation is the ratio of the standard deviation to the mean
3http://atilf.atilf.fr/tlf.htm
318
Ideally the model should also be able to deal with timescale differences.The precise adjustment of these
settings is part of our future research avenues along with incorporating an index for stabilization. This
last filter is particularly difficult to create when dealing with ongoing phenomena. We may sometimes
need to wait a few years to be able to establish whether a semantic change has stabilized.
To summarize, we are currently developing a filtering tool to extract candidates to semantic change on
the basis of topic salience variation in corpus and co-occurrence network variation. Our approach shed
light on the emergence of these phenomena at a very detailed level. Preliminary results showed that the
tool was succesful at extracting those candidates; however it is not yet advanced enough to discriminate
between context changes that affect a word without semantic impact and those that do have a semantic
impact. This aspect constitutes our current research perspective.
6 Acknowledgements
This research is supported by the R?gion Rh?ne-Alpes, via the Cible Project 2009. Many thanks to
Sylvain Lupone, previously engineer at the L2c2 for the tools he developed in this research?s framework.
References
Benz?cri, J.-P. (1980). L?analyse des donn?es : l?analyse des correspondances. Paris: Bordas.
Bloomfield, L. (1933). Language. New York: Allen and Unwin.
Boussidan, A., S. Lupone, and S. Ploux (2009). La malbouffe : un cas de n?ologie et de glissement
s?mantique fulgurants. In "Du th?me au terme, ?mergence et lexicalisation des connaissances",
Toulouse, France. 8 ?me conf?rence internationale Terminologie et Intelligence Artificielle.
Boussidan, A., A.-L. Renon, C. Franco, S. Lupone, and S. Ploux (2010). Vers une m?thode de visualisa-
tion graphique de la diachronie des n?ologies. Tubingen, Germany. Colloque N?ologie s?mantique et
Corpus. in press.
Cook, P. and S. Stevenson (2010). Automatically identifying changes in the semantic orientation of
words. In Proceedings of the Seventh conference on International Language Resources and Evalua-
tion, Valletta,Malta. LREC 2010.
Golumbic, M. (2004). Algorithmic graph theory and perfect graphs. North-Holland.
Holz, F. and S. Teresniak (2010). Towards automatic detection and tracking of topic change. Computa-
tional Linguistics and Intelligent Text Processing, 327?339.
Ji, H., S. Ploux, and E. Wehrli (2003). Lexical knowledge representation with contexonyms. Proceedings
of the 9th Machine Translation Summit, 194?201.
Martinez, C. (2009). L??volution de l?orthographe dans les Petit Larousse et les Petit Robert 1997-2008:
une approche g?n?alogique du texte lexicographique. Ph. D. thesis, Universit? de Cergy-Pontoise.
Ploux, S., A. Boussidan, and H. Ji (2010). The semantic atlas: an interactive model of lexical representa-
tion. In Proceedings of the Seventh conference on International Language Resources and Evaluation,
Valletta, Malta. LREC 2010.
Rey, A., T. Hord?, and L. Robert (1998). Dictionnaire historique de la langue fran?aise : contenant les
mots fran?ais en usage et quelques autres d?laiss?s, avec leur origine proche et lointaine. Paris.
Sagi, E. (2010). Nouns are more stable than verbs: Patterns of semantic change in 19th century english.
Portland, OR. 32nd AnnualConference of the Cognitive Science Society. to be published.
Sagi, E., S. Kaufmann, and B. Clark (2009). Semantic density analysis: Comparing word meaning across
time and phonetic space. In GEMS: GEometrical Models of Natural Language Semantics. EACL.
319
