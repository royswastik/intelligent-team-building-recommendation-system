Proceedings of SIGDIAL 2010: the 11th Annual Meeting of the Special Interest Group on Discourse and Dialogue, pages 67?70,
The University of Tokyo, September 24-25, 2010. c?2010 Association for Computational Linguistics
Negotiating causal implicatures
Luciana Benotti
Universidad Nacional de Co?rdoba
Grupo PLN
Ciudad Universitaria
5000 Co?rdoba, Argentina
luciana.benotti@gmail.com
Patrick Blackburn
INRIA Nancy Grand-Est
Equipe TALARIS
615, rue du Jardin Botanique
54602 Villers le`s Nancy, France
patrick.blackburn@loria.fr
Abstract
In this paper we motivate and describe
a dialogue manager which is able to in-
fer and negotiate causal implicatures. A
causal implicature is a type of Gricean re-
lation implicature, and the ability to infer
them is crucial in situated dialogue. Be-
cause situated dialogue interleaves conver-
sational acts and physical acts, the dia-
logue manager needs to have a grasp on
causal implicatures in order not only to de-
cide what physical acts to do next but also
to generate causally-aware clarifications.
1 Introduction
In conversation, an important part of the content
conveyed is not explicitly said, rather it is impli-
cated. However, Grice (1975)?s classic concept of
conversational implicature (CI) is far from fully
understood. Traditionally CIs have been classified
using the Gricean maxims: there are relation CIs
(also known as relevance CIs), quantity CIs, qual-
ity CIs and manner CIs. In formal pragmatics, the
most studied CIs are quantity CIs, probably be-
cause they are the ones most obviously amenable
to theoretical analysis; see (Geurts, in press) for
a survey of the state of the art. Far less studied
(and traditionally regarded as somewhat obscure)
are relation CIs. Obscure perhaps, but crucial: it
has been argued that they subsume all other types
of CIs (Wilson and Sperber, 2004). This paper is a
first step towards their formalization.
We shall analyze a kind of CI that we call causal
CIs. Causal CIs are relation CIs as defined by
Grice (1975) where the crucial relation is task do-
main causality. Consider the following example:
Mary: The chest is locked, the crown is inside
Bill: Give me the crown
Bill causally implicated: Unlock the chest
In order to carry out the task action required by
Bill (to give him the crown) it is necessary to un-
lock the chest. Hence we say that Bill is implicat-
ing, by trading on the domain causal relations (af-
ter all, the contents of a chest are not accessible un-
less the chest is unlock) that Mary is to unlock the
chest. Now, once Mary has inferred the causal CI,
she may accept this inference silently or negotiate
it. Mary might decide to silently accept it because
she knows how to get the key; in this case we will
say that Mary constructed an internal bridge from
the current task situation (that is, the crown being
inside the locked chest) to the proposal made by
Bill (giving him the crown). If Mary decides she
has insufficient information to construct the inter-
nal bridge (maybe she has no key, or sees that the
lock is rusty) she may start a sub-dialogue that we
will call an external bridge; she might say, for ex-
ample: But how can I unlock the chest? The in-
ternal process of bridging is what in the literature
has been called accommodation (Lewis, 1979) or
bridging (Clark, 1975). The external processes of
bridging constitutes a large part of what we call
conversation.
This paper presents a dialogue system (called
Frolog) which infers and negotiates causal CIs in
the context of situated task-oriented dialogue; the
framework is intended as a proof-of-concept of the
ideas just sketched. We proceed as follows. In
Section 2, we motivate the study of causal CIs in
dialogue. In Section 3 we present Frolog?s dia-
logue manager which infers causal CIs in situated
dialogue. And in Section 4 we illustrate how the
negotiation (external bridging) of causal CIs incre-
mentally grounds a pragmatic goal proposed by
one of the dialogue participants. Section 5 con-
cludes the paper.
2 Causal implicatures and dialogue
The motivation for our work is both theoretical
and practical. On the theoretical side, we believe
67
that it is crucial to explore CIs in the setting of
naturally occurring dialogues. Strangely enough
(after all, Grice did call them conversational im-
plicatures) this view appears to be novel, perhaps
even controversial. In the formal pragmatics lit-
erature, CIs are often simply viewed as inferences
drawn by a hearer on the basis of a speaker?s ut-
terance, contextual information, and the Gricean
maxims. We find this perspective too static. CIs
(especially relations CIs) are better viewed as in-
trinsically interactional inferences that arise from
the dynamics of conversation. As conversations
progress, speakers and hearers switch roles: mean-
ing are negotiated and inference becomes bidirec-
tional (Thomason et al, 2006). Moreover, even
within a single turn, hearers are not restricted to
simply drawing (or failing to draw) ?the? CI: in
fact, choosing between internal and external bridg-
ing is better viewed as part of the process of nego-
tiating what the CI at stake actually is. We be-
lieve that interactive perspectives will be neces-
sary to extend the theory of CIs beyond the rel-
atively narrow domain of quantity CIs. We also
believe that the dialog-centered approach we ad-
vocate may have practical consequences. In par-
ticular, modeling the external process of bridging
is a step towards having a pragmatically incremen-
tal dialogue manager in the spirit of that sketched
in (Bu? and Schlangen, 2010).
This is a broad goal, in this paper we focus on
clausal implicatures. This restriction gives us an
empirical handle of CIs. It is not controversial that
(in non-conversational activities) the causal rela-
tions between acts define the expectations of the
interaction. But also in conversational activities
situated in a physical task causal relations guide
the interaction; we did an empirical study on such
a kind of corpus (Benotti, 2009) and we found that,
in this corpus, most CIs for which there is evidence
(because they are made explicit in a clarification
request) can be explained in terms of causal rela-
tions. For our empirical study, we annotated and
classified the clarification requests (CRs) that ap-
pear in the SCARE corpus (Stoia et al, 2008).
3 Inferring causal implicatures
In order to model the causal CIs that we observed
in the SCARE corpus, and to experiment with dif-
ferent strategies for negotiating these CIs, we de-
signed a system that mimics the instruction giving
setup of the SCARE corpus. In our setup, the DF
is a dialogue system that we will call Frolog. The
human participant that plays the role of the DG we
will call ?the player?.
In a nutshell, Frolog uses an off-the-shelf plan-
ner to compute causal implicatures. That is, it
uses classical planning (a well explored and com-
putationally efficient AI technique) to fill out the
micro-structure of discourse (the bridging infor-
mation required in the next step).1 We do so us-
ing the planner BLACKBOX (Kautz and Selman,
1999). Like all classical planners, BLACKBOX
takes three inputs: the initial state, the goal, and
the available actions. The question of what these
three elements should be raises a number of issues.
In Frolog, two types of information are regis-
tered: complete and accurate information about
the game world in the world KB and a represen-
tation of the common ground in the interaction
KB. Which of these should be used in the initial
state? In fact, we need both: we infer the actions
intended by the player using the information in the
interaction KB but we have to verify this sequence
of actions on the world KB to check if it can actu-
ally be executed.
Let us now define what the goal of the planning
problem should be. Frolog should act to make the
preconditions of the action true with one restric-
tion. The restriction is that it must be possible for
Frolog to manipulate these preconditions. How-
ever, we don?t need to worry about this restric-
tion because the planner should take care of which
propositions are manipulable by Frolog and which
are not, given the current state. So we can just de-
fine the goal as the conjunction of all the precon-
ditions of the command uttered by the player.
To complete the picture, the actions available to
the planner are all the actions in the game action
database. This means that we are assuming that
all the actions that can be executed, are mutually
known to Frolog and the player.
In order to be able to perform bridging to the
mutual information it must be mutually known
what the preconditions and the effects of the ac-
tions involved are. The assumption that the player
and Frolog know the exact specification of all the
actions that can be executed in the game world is
1Thus the work reported here is very different from the
traditional work of (Perrault and Allen, 1980; Allen and
Allen, 1994): classic papers in the plan-based tradition use
plan recognition (a more computationally expensive task) to
interpret utterances by inserting them into the plan the macro-
structure (the global shape) of discourse.
68
a simplifying assumption. We make it because it
enables us to avoid deciding (and implementing)
how differing knowledge about actions get coordi-
nated; dealing with such issues simply too difficult
at present.
4 Negotiating with a dialogue system
In this section we present a worked out example of
how the solutions of the planning problems intro-
duced in the previous section can be used in order
to perform internal bridging and trigger external
bridging when appropriate.
In this example Frolog does not have enough
knowledge yet in order to infer the bridge.2 This
is the case in instruction (37) in Figure 1. In this
instruction the player wants Frolog to open the
chest but Frolog does not know how to do this.
In the screen-shot in the right you can see state of
the interaction KB from turns (37) to (39). In this
model we can see that the player does not have
information about what fits into the chest, in or-
der to unlock it. This is why the planner is not
able to find a plan that achieves the precondition
(unlocked chest1) of the command ?open the
chest? in instruction (37). The instruction in (39)
fails as well making the obstacle explicit. Utter-
ance (40) is an example of a CR caused by a re-
quired and unknown thematic relation filler (the
second most frequent CR in the SCARE corpus).
Player(32): look at the chestFrolog(33): the chest is closed and          locked and woodenPlayer(34): look at FrologFrolog(35): Frolog is aliveFrolog(36): Frolog holds the sword, the worm                   and the golden keyPlayer(37): open the chestFrolog(38): Frolog can't do that!   the chest is not unlockedPlayer(39): unlock the chestFrolog(40): Frolog can't do that!   Frolog doesn't know what fits into the chestPlayer(41): unlock the chest with the golden keyFrolog(42): [Frolog unlocks the chest] Frolog(43): the chest is unlockedPlayer(44): lock the chest with the keyFrolog(45): [Frolog locks the chest] Frolog(46): the chest is lockedPlayer(47): open the chestFrolog(48): Frolog can't do that!   the chest is not unlocked fitsin??????
Figure 1: External bridging in Frolog
Frolog?s behavior continues as expected until
turn (48) in which Frolog again is not able to
bridge the command open the chest. It is to be
expected that the fact that the golden key fits into
2For illustrations of other reasons that trigger negotiation
of CIs see (Benotti, 2010).
the chest is mutual knowledge by now but Frolog
is not reacting accordingly.
In order to overcome this issue there are two
options: (1) either we allow different sources to
update the mutual information loosing uniformity
in the update process or (2) we add actions that
manipulate this kind of information. Here we de-
scribe option (1) that turns out to be the proce-
dural version of ?strict accommodation? (as de-
fined in (Beaver and Geurts, in press)), and when
generalized is of a piece with abduction (Hobbs,
1985). For an discussion of (2) we refer the reader
to (Benotti, 2010).
We could say that the intuition behind the strict
notion of accommodation is that when the speaker
utters a sentence, she is not only trying to achieve
the obvious effects of the utterance, but is also
communicating the ways in which she assumes the
world to be, and on which the success of the utter-
ance depends. Following this intuition it can be
argued that the intention behind the utterance ?un-
lock the chest with the golden key? in turn (41) is
twofold. It is clear that the player wants to achieve
the effects of the action, that is, she wants to have
the chest unlocked. But the player also expects
Frolog to recognize the assumptions she is making
and on which the success of the utterance depends.
In particular, she expects Frolog to recognize that
she is assuming that the golden key fits into the
chest lock (this is why Frolog can coherently ask
why do you think that the golden key will fit?).
This means that, when an action is executed, the
interaction KB will be updated not only with the
effects of the action but also with its preconditions.
And those preconditions that were not in the inter-
action KB before will be verbalized as in turn (9)
in Figure 2.
Player(32): olkth:cse:tse4cFrolog(3): Frolog thecs io sdhsa :::::::::::::::Frklkg:7ke4opc:hokn::::::::::::::::nsac:iuc4duock:cse:tse4cPlayer(92):lkkh:ac:yk Frolog(n): kow hr5 hlv65Frolog(,): kow doli h goli5e m5kPlayer('2): olkth:cse:tse4c:nucs:cse:gkl7eo:heyFrolog(y): 8Frolog welotm' sd5 td5's                 !vsd sd5 goli5e m5k4Frolog(0): sd5 td5's v' welotm5iFrolog(2): cse:hey:iuc4duock:cse:tse4cPlayer(3w2):lkth:cse:tse4cFrolog([[): 8Frolog lotm' sd5 td5's :::::::::::::::::!vsd sd5 goli5e m5k4Frolog([3): sd5 td5's v' lotm5iPlayer(392):lkkh:ac:cse:tse4cFrolog([n): sd5 td5's v' tlo'5i hei          lotm5i hei !ooi5ePlayer(3f2):k1eo:cse:tse4cFrolog([u): 8Frolog welotm' sd5 td5's !vsd sd5 goli5e m5k4Frolog([y): sd5 td5's v' welotm5iFrolog([0): 8Frolog o]5e' sd5 td5's4Frolog([2): sd5 td5's v' o]5eFrolog(3?): sd5 td5's doli h goli5e tro!e
:action?open?:arguments??????(agent??w)?(theme??x)???:precondition?????????(accessible??x)?????????(closed??x)?????????(unlocked??x)?:effect?????????(not(closed??x))?????????(open??x)
:action?unlock?:arguments??????(agent??w)?(theme??x)?(inst??y)??:precondition?????????(accessible??x)?????????(locked??x)?????????(fitsin??y??x)?????????(hold??w??y)????:effect?????????(not(locked??x))?????????(unlocked??x)?????????
Figure 2: External bridging becomes internal
69
The rest of the interaction (from turns (10)
to (15)) show that once the proposition (fitsin
key1 chest1) is added to the interaction KB the
action ?open the chest? can be internally bridged
even when the chest is locked. Because the player
and Frolog mutually know which key fits into the
chest.
5 Discussion
Clearly, our inference framework is limited in
many ways. But we think we?ve made a small
step in the right direction. Dialogue systems are
reaching a development level in which they cannot
elude drawing inferences for much longer. This
paper is a step in this direction.
Causal implicatures are a kind of relation
implicature (historically Grice?s most obscure
and crucial implicature) whose inference?we?ve
argued?is essential in situated dialogue if our di-
alogue systems are not to violate the expectations
of the user. Causal relations have a direct impact
on the coherence structure of situated dialogues
such as those in the SCARE corpus; in the SCARE
corpus most pragmatic clarification requests make
explicit causal implicatures.
We need to have a grasp on causal impli-
catures in order for our dialogue systems not
only to decide what physical acts to do next?
internal bridging?but also to generate causally-
aware clarification requests?external bridging.
Of course the inference framework presented here
has many limitations that we discussed through-
out the paper and probably classical planning is
not the formalism that we will finally want to use
in our dialogue systems (at least not in its present
form). Our model is intended as a proof of con-
cept, and intentionally stays at a level of formal-
ization that is still simple enough so as not to loose
our intuitions. The two intuitions that we don?t
want to loose sight of are (1) utterances are to be
interpreted in a context and need to be connected
to this context (through some kind of relation, be-
ing causality one of the most important ones in
situated dialogue) in order to be grounded (2) the
process of connecting utterances to the context is
a joint process, it is a negotiation that involves de-
cisions of all the dialogue participants.
With the intuitions in place we plan to extend
this work mainly by porting the inference frame-
work into new domains.
There is lot to do yet, but we believe that the
negotiation of causal implicatures is a step towards
an incremental dialogue manager.
References
James Allen and Richard Allen. 1994. Natural lan-
guage understanding. Addison Wesley, 2nd edition.
David Beaver and Bart Geurts. in press. Presup-
position. In Handbook of Semantics. Mouton de
Gruyter.
Luciana Benotti. 2009. Clarification potential of in-
structions. In Proc. of SIGDIAL, pages 196?205,
London, United Kingdom.
Luciana Benotti. 2010. Implicature as an Interactive
Process. Ph.D. thesis, Universite? Henri Poincare?,
INRIA Nancy Grand Est, France. Supervised by
P. Blackburn. Reviewed by N. Asher and B. Geurts.
Okko Bu? and David Schlangen. 2010. Modelling
sub-utterance phenomena in spoken dialogue sys-
tems. In The 2010 Workshop on the Semantics and
Pragmatics of Dialogue, Poznan?, Poland.
Herbert Clark. 1975. Bridging. In Proc. of the Work-
shop on Theoretical issues in natural language pro-
cessing, pages 169?174, Morristown, USA. ACL.
Bart Geurts. in press. Quantity implicatures. Cam-
bridge University Press.
Paul Grice. 1975. Logic and conversation. In P. Cole
and J. Morgan, editors, Syntax and Semantics, vol-
ume 3, pages 41?58. Academic Press, New York.
Jerry Hobbs. 1985. Granularity. In Proceedings of
the 9th International Joint Conference on Artificial
Intelligence, pages 432?435. Morgan Kaufmann.
Henry Kautz and Bart Selman. 1999. Unifying SAT-
based and graph-based planning. In Proceedings of
the 16th International Joint Conference on Artificial
Intelligence, pages 318?325, Stockholm, Sweden.
David Lewis. 1979. Scorekeeping in a language game.
Journal of Philosophical Logic, 8:339?359.
Raymond Perrault and James Allen. 1980. A plan-
based analysis of indirect speech acts. Computa-
tional Linguistics, 6(3-4):167?182.
Laura Stoia, Darla Shockley, Donna Byron, and Eric
Fosler-Lussier. 2008. SCARE: A situated corpus
with annotated referring expressions. In Proc. of
LREC.
Richmond Thomason, Matthew Stone, and David De-
Vault. 2006. Enlightened update: A computa-
tional architecture for presupposition and other prag-
matic phenomena. In Presupposition Accommoda-
tion. Ohio State Pragmatics Initiative.
Deirdre Wilson and Dan Sperber. 2004. Relevance
theory. In Handbook of Pragmatics, pages 607?632.
Blackwell, Oxford.
70
