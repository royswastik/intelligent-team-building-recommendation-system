Poisson Naive Bayes for Text Classification with Feature Weighting
Sang-Bum Kim, Hee-Cheol Seo and Hae-Chang Rim
Dept. of CSE., Korea University
5-ka Anamdong, SungPuk-ku, SEOUL 136-701, KOREA
sbkim,hcseo,rim@nlp.korea.ac.kr
Abstract
In this paper, we investigate the use of
multivariate Poisson model and feature
weighting to learn naive Bayes text clas-
sifier. Our new naive Bayes text classifi-
cation model assumes that a document is
generated by a multivariate Poisson model
while the previous works consider a doc-
ument as a vector of binary term features
based on the presence or absence of each
term. We also explore the use of feature
weighting for the naive Bayes text classifi-
cation rather than feature selection, which
is a quite costly process when a small
number of the new training documents are
continuously provided.
Experimental results on the two test col-
lections indicate that our new model with
the proposed parameter estimation and the
feature weighting technique leads to sub-
stantial improvements compared to the
unigram language model classifiers that
are known to outperform the original pure
naive Bayes text classifiers.
1 Introduction
The naive Bayes classifier has been one of the core
frameworks in the information retrieval research for
many years. Recently, naive Bayes is emerged as a
research topic itself because it sometimes achieves
good performances on various tasks, compared to
more complex learning algorithms, in spite of the
wrong independence assumptions on naive Bayes.
Similarly, naive Bayes is also an attractive ap-
proach in the text classification task because it is
simple enough to be practically implemented even
with a great number of features. This simplicity en-
ables us to integrate the text classification and filter-
ing modules with the existing information retrieval
systems easily. It is because that the frequency re-
lated information stored in the general text retrieval
systems is all the required information in naive
Bayes learning. No further complex generaliza-
tion processes are required unlike the other machine
learning methods such as SVM or boosting. More-
over, incremental adaptation using a small number
of new training documents can be performed by just
adding or updating frequencies.
Several earlier works have extensively studied the
naive Bayes text classification (Lewis, 1992; Lewis,
1998; McCallum and Nigam, 1998). However,
their pure naive Bayes classifiers considered a doc-
ument as a binary feature vector, and so they can?t
utilize the term frequencies in a document, result-
ing the poor performances. For that reason, the
unigram language model classifier (or multinomial
naive Bayes text classifier) has been referred as an
alternative and promising naive Bayes by a num-
ber of researchers(McCallum and Nigam, 1998; Du-
mais et al, 1998; Yang and Liu, 1999; Nigam et
al., 2000). Although the unigram language model
classifiers usually outperform the pure naive Bayes,
they also have given the disappointing results com-
pared to many other statistical learning methods
such as nearest neighbor classifiers(Yang and Chute,
1994), support vector machines(Joachims, 1998),
and boosting(Schapire and Singer, 2000), etc.
In the real world, an operational text classifica-
tion system is usually placed in the environment
where the amount of human-annotated training doc-
uments is small in spite of the hundreds of thousands
classes. Moreover, re-training of the text classifiers
is required since a small number of new training
documents are continuously provided. In this envi-
ronment, naive Bayes is probably the most appropri-
ate model for the practical systems rather than other
complex learning models. Therefore, more inten-
sive studies about the naive Bayes text classification
model are required.
In this paper, we revisit the naive Bayes frame-
work, and propose a Poisson naive Bayes model for
text classification with a statistical feature weight-
ing method. Feature weighting has many advan-
tages compared to the previous feature selection ap-
proaches, especially when the new training exam-
ples are continuously provided. Our new model as-
sumes that a document is generated by a multivari-
ate Poisson model, and their parameters are esti-
mated by weighted averaging of the normalized and
smoothed term frequencies over all the training doc-
uments. Under the assumption, we have tested the
feature weighting approach with three measures: in-
formation gain, -statistic, and newly introduced
probability ratio. With the proposed model and fea-
ture weighting techniques, we can get much better
performance without losing the simplicity and effi-
ciency of the naive Bayes model.
The remainder of this paper is organized as fol-
lows. The next section presents a naive Bayes frame-
work for the text classification briefly. Section 3
describes our new naive Bayes model and the pro-
posed technique, and the experimental results are
presented in Section 4. Finally, we conclude the pa-
per by suggesting possible directions for future work
in Section 5.
2 Naive Bayes Text Classification
A naive Bayes classifier is a well-known and highly
practical probabilistic classifier, and has been em-
ployed in many applications. It assumes that all
attributes of the examples are independent of each
other given the context of the class, that is, an in-
dependent assumption. Several studies show that
naive Bayes performs surprisingly well in many do-
mains(Domingos and Pazzani, 1997) in spite of its
wrong independent assumption.
In the context of text classification, the probabil-
ity of class  given a document 

is calculated by
Bayes? theorem as follows:


 












  









 






   
(1)
Now, if we define a new function 

,


 






(2)
then, Equation (1) can be rewritten as


 



 



   
(3)
Using Equation (3), we can get the posterior prob-
ability 

 by obtaining 

, which is a form of
log ratio similar to the BIM retrieval model(Jones et
al., 2000). It means that the linked independence as-
sumption(Cooper et al, 1992), which explains that
the strong independent assumption can be relaxed
in the BIM model, is sufficient for the use of naive
Bayes text classification model.
With this framework, two representative naive
Bayes text classification approaches are well intro-
duced in (McCallum and Nigam, 1998). They desig-
nated the pure naive Bayes as multivariate Bernoulli
model, and the unigram language model classifier as
multinomial model. Instead, we introduce multivari-
ate Poisson model to improve the pure naive Bayes
text classification in the next section.
3 Poisson Naive Bayes Text Classification
3.1 Overview
The Poisson distribution is most commonly used to
model the number of random occurrences of some
phenomenon in a specified unit of space or time,
for example, the number of phone calls received by
a telephone operator in a 10-minute period. If we
think that the occurrence of each term is a random
occurrence in a fixed unit of space (i.e. a length
of document) the Poisson distribution is intuitively
suitable to model the term frequencies in a given
document. For that reason, the use of Poisson model
is widely investigated in the IR literature, but it is
rarely used for the text classification task(Lewis,
1998). It motivates us to adopt the Poisson model
for learning the naive Bayes text classification.
Our model assumes that 

is generated by multi-
variate Poisson model. In other words, a document


is a random vector which consists of the Poisson
random variables 

, and 

has the value of within-
term-frequency 

for the 	-th term 


. Thus, if we
assume the independence among the terms in 

, a
probability of 

is represented by,


 
 

 

 

 (4)
where,   is a vocabulary size, and each  




 is given by,
 

 

 



	



	
(5)
where,  is the Poisson mean.
As a result, the 

function of Equation (2) is
rewritten using Equations (4) and (5) as follows:



 



 

 


 

 



 








	







	

(6)
where, 

and 

is the Poisson mean for 


in class
 and class , respectively.
The most important issues of this work are as fol-
lows:
 How to decide the frequency 

representing
the characteristic of document 

?
 How to estimate the model parameter 

and 

representing the characteristic of each class?
We propose the possible answers in the next subsec-
tion.
3.2 Parameter Estimation
Since 

is a frequency of a term 	 in a document


with a fixed length according to the definition of
Poisson distribution, we should normalize the actual
term frequencies in the documents with the different
length. In addition, many earlier works in NLP and
IR fields recommend that smoothing term frequen-
cies is necessary in order to build a more accurate
model.
Thus, we estimate 

as the normalized and
smoothed frequency of actual term frequency 

,
represented by,







 


    
  (7)
where  is a laplace smoothing parameter,  is any
huge value which makes all the 


in our model an
integer value1, and 

is the length of 

.
Conceptually, 


can be regarded as the value es-
timated by the following steps : 1) Add  of all  
terms to the document 

, 2) Scale 

up to 

whose
total length is  without changing the proportion of
frequency for each term 


, 3) Count 


in 

.
Then, Poisson mean 

, which represents an aver-
age number of occurrence of 


in the documents be-
longing to class , is estimated using the normalized
and smoothed 


values over the training documents
as follows:












 




(8)
where 

is the set of training documents belonging
to class , and 


2 is the interpolation of the
uniform probability and the probability proportional
to the length of the document, and the interpolation
is calculated as follows:


  




   









(9)
Simple averaging of 


, the case of =1, seems to
be correct to estimate 

. However, the statistics
1Since 

is a value of random variable 

representing
the frequency in our Poisson distribution, we multiply the nor-
malized frequency with some unnatural constant  to make 

integer value. However,  is dropped in the final induced func-
tion.
2We use the notation 

 for the distribution defined
only in the training documents, to distinguish it from the no-
tation 

 used in the Section 2.
from the long documents can be more reliable than
those in the short documents, hence we try to inter-
polate between the two different probabilities with
the parameter  ranging from 0 to 1. Consequently,


is a weighted average over all training documents
belonging to the class , and 

for the class  can be
estimated in the same manner.
3.3 Feature Weighting
Feature selection is often performed as a preprocess-
ing step for the purpose of both reducing the fea-
ture space and improving the classification perfor-
mance. Text classifiers are then trained with various
machine learning algorithms in the resulting feature
space. (Yang and Pedersen, 1997) investigated some
measures to select useful term features including
mutual information(MI), information gain(IG), and


-statistics(CHI), etc. On the contrary, (Joachims,
1998) claimed that there is no useless term features,
and it is preferable to use all term features. It is
clear that learning and classification become very
efficient when the feature space is considerably re-
duced. However, there is no definite conclusion
about the contribution of feature selection to im-
prove overall performances of the text classification
systems. It may considerably depend on the em-
ployed learning algorithm. We believe that proper
external feature selection or weighting is required to
improve the performances of naive Bayes since the
naive Bayes has no framework of the discriminative
optimizing process in itself. Of the two possible ap-
proaches, feature selection is very inefficient in case
that the additional training documents are provided
continuously. It is because the feature set should
be redefined according to the modified term statis-
tics in the new training document set, and classifiers
should be trained again with this new feature set. For
that reason, we prefer to use feature weighting to
improve naive Bayes rather than feature selection.
With the feature weighting method, our 

is rede-
fined as follows:



 




W

 










	


 






	

(10)
where, 

is the weight of feature for the class ,
and W

is the normalization factor, that is,





.
In our work, three measures are used to weight
Table 1: Two-way contingency table
presence of 


absence of 


labeled as  a b
not labeled as  c d
each term feature: information gain, -statistics
and probability ratio. Information gain (or aver-
age mutual information) is an information-theoretic
measure defined by the amount of reduced uncer-
tainty given a piece of information. We use the in-
formation gain value as the weight of each term for
the class , and the value is calculated using a docu-
ment event model as follows:


   KUNLP System in SENSEVAL-3
Hee-Cheol Seo, Hae-Chang Rim
Dept. of Computer Science
and Engineering,
Korea University
1, 5-ka, Anam-dong, Seongbuk-Gu,
Seoul, 136-701, Korea
 hcseo, rim@nlp.korea.ac.kr
Soo-Hong Kim
Dept. of Computer Software Engineering,
College of Engineering,
Sangmyung University,
San 98-20, Anso-Dong,
Chonan, Chungnam, Korea
soohkim@smuc.ac.kr
Abstract
We have participated in both English all words
task and English lexical sample task of SENSEVAL-
3. Our system disambiguates senses of a target
word in a context by selecting a substituent among
WordNet relatives of the target word, such as syn-
onyms, hypernyms, meronyms and so on. The deci-
sion is made based on co-occurrence frequency be-
tween candidate relatives and each of the context
words. Since the co-occurrence frequency is obtain-
able from raw corpus, our method is considered to
be an unsupervised learning algorithm that does not
require a sense-tagged corpus.
1 Introduction
At SENSEVAL-3, we adopted an unsupervised ap-
proach based on WordNet and raw corpus, which
does not require any sense tagged corpus. Word-
Net specifies relationships among the meanings of
words.
Relatives of a word in WordNet are defined as
words that have a relationship with it, e.g. they
are synonyms, antonyms, superordinates (hyper-
nyms), or subordinates (hyponyms). Relatives, es-
pecially those in a synonym class, usually have
related meanings and tend to share similar con-
texts. Hence, some WordNet-based approaches ex-
tract relatives of each sense of a polysemous word
from WordNet, collect example sentences of the rel-
atives from a raw corpus, and learn the senses from
the example sentences for WSD. Yarowsky (1992)
first proposed this approach, but used International
Roget?s Thesaurus as a hierarchical lexical database
instead of WordNet. However, the approach seems
to suffer from examples irrelevant to the senses of
a polysemous word since many of the relatives are
polysemous. Leacock et al (1998) attempted to ex-
clude irrelevant or spurious examples by using only
monosemous relatives in WordNet. However, some
senses do not have short distance monosemous rel-
atives through a relation such as synonym, child,
and parent. A possible alternative of using only
monosemous relatives in the long distance, how-
ever, is problematic because the longer the distance
of two synsets in WordNet, the weaker the relation-
ship between them. In other words, the monose-
mous relatives in the long distance may provide ir-
relevant examples for WSD.
Our approach is somewhat similar to the Word-
Net based approach of Leacock et al (1998) in that
it acquires relatives of a target word from WordNet
and extracts co-occurrence frequencies of the rela-
tives from a raw corpus, but our system uses poly-
semous as well as monosemous relatives. To avoid
a negative effect of polysemous relatives on the co-
occurrence frequency calculation, our system han-
dles the example sentences of each relative sepa-
rately instead of putting together the example sen-
tences of all relatives into a pool. Also we devised
our system to efficiently disambiguate senses of all
words using only co-occurrence frequency between
words.
2 KUNLP system
2.1 Word Sense Disambiguation
We disambiguate senses of a word in a context1
by selecting a substituent word from the WordNet2
relatives of the target word. Figure 1 represents a
flowchart of the proposed approach. Given a target
word and its context, a set of relatives of the target
word is created by searches in WordNet. Next, the
most appropriate relative that can be substituted for
the word in the context is chosen. In this step, co-
occurrence frequency is used. Finally, the sense of
the target word that is related to the selected relative
is determined.
The example in Figure 2 illustrates how the pro-
posed approach disambiguates senses of the tar-
get word chair given the context. The set of rel-
atives  president, professorship, ... of chair is
built by WordNet searches, and the probability,
1In this paper, a context indicates a target word and six
words surrounding the target word in an instance.
2The WordNet version is 1.7.1.
                                             Association for Computational Linguistics
                        for the Semantic Analysis of Text, Barcelona, Spain, July 2004
                 SENSEVAL-3: Third International Workshop on the Evaluation of Systems
Context Target Word
Context
Words
Surrounding
Target Word
Acquire
Set of Relatives
Select
a Relative
Determine
a Sense
WordNet
Co-occurrence
Information
Matrix
Sense
Figure 1: Flowchart of KUNLP System
?  	
,? that a relative can
be substituted for the target word in the given con-
text is estimated by the co-occurrence frequency be-
tween the relative and each of the context words. In
this example, the relative, seat, is selected with the
highest probability and the proper sense, ?a seat for
one person, with a support for the back,? is chosen.
Thus, the second step of our system (i.e. selecting
a relative) has to be carefully implemented to select
the proper relative that can substitute for the target
word in the context, while the first step (i.e. acquir-
ing the set of relatives) and the third step (i.e. deter-
mining a sense) are done simply through searches in
WordNet.
The substituent word of the -th target word 
 
in a context 	 is defined to be the relative of 
 
which has the largest co-occurrence probability with
the words in the context:
  
 
 	
 
 

 
   

 
	 (1)
where  is the substituent word, 
 
is the -th
relative of 
 
, and 
 
is the -th sense related to

 
3
. If  is 2, the 2-nd sense of 
 
is related to

 
. The right hand side of Equation 1 is calculated
with logarithm as follows:


 
   

 
	
 

 
   	

 
   

 

   	
 

 
   	

 
   

 

 

 
    	

 
     

 
 (2)
3
  is a function with two parameters 
 
and 
 
, but it can
be written in brief without parameters.
Instance :
    He should sit in the chair beside the desk.
Target Word :
    'chair'
Context :
    sit in the chair beside the desk
Set of Relatives :
    {professorship, president, chairman,
     electronic chair, death chair, seat,
     office, presiding officer, ...}
Probability of Relative given the Context :
    P( professorship | Context )
    P( president | Context )
    ...
    P( seat | Context )
    ...
Selected Relative :
    'seat' - it is the most likely word occurred
                from the above context among
                the relatives of 'chair'
Determined Sense :
    chair%1:06:00 - "a seat for one person,
                                with a support for the back."
    'seat' - the hypernym of chair%1:06:00.
Figure 2: Example of sense disambiguation proce-
dure for chair
Then Equation 2 may be calculated under the as-
sumption that words in 	 occur independently:


 
    	

 
     

 

 

 
 

 

   



 
     

 
 (3)
where 

is the -th word in 	 and 
 is the number
of words in 	 . In Equation 3, we assume indepen-
dence among words in 	 .
The first probability in Equation 3 is calculated as
follows:
   



 

    


 


   
 


   


   
 

(4)
The second probability in Equation 3 is computed
as follows:
   

 
   

 
   
 
 (5)
where  
 
 is the ratio of the frequency of 
 
to
that of 
 
:
 

 
 
 

 
  	


  	
   
 

where  
 
 is the frequency of 
 
in Word-
Net,  
 
 is the frequency of 
 
in WordNet,
0.5 is a smoothing factor, and 
 is the number of
senses of 
 
.
Applying Equations 4 and 5 to Equation 3, we
have the following equation for acquiring the rela-
tive with the largest co-occurrence probability:


 
   

 
	
 

 

 


   
 


   


   
 

  

 
   
 

 

 

 


   
 



   
 

  

 
   
 

In the case that several relatives have the largest
co-occurrence probability, all senses related to the
relatives are determined as proper senses.
2.2 Co-occurrence Frequency Matrix
In order to select a substituent word for a target
word in a given context, we must calculate the
probabilities of finding relatives, given the con-
text. These probabilities can be estimated based on
the co-occurrence frequency between a relative and
context words as follows:
   
 
 
 
 

	
(6)
   
 


 
   
 
 


   



 
 
 


 


(7)
where  
 
 is the frequency of 
 
, 	 is the
corpus size,    
 
 

 is the probability that 
 
and 

co-occur, and  
 
 

 is the frequency
that 
 
and 

co-occur.
In order to calculate these probabilities, frequen-
cies of words and word pairs are required. For this,
we build a co-occurrence frequency matrix that con-
tains co-occurrence frequencies of words pairs. In
this matrix, an element Word Sense Disambiguation
by Relative Selection
Hee-Cheol Seo1, Hae-Chang Rim2, and Myung-Gil Jang1
1 Knowledge Mining Research Team,
Electronics and Telecommunications Research Institute (ETRI),
Daejeon, Korea
{hcseo, mgjang}@etri.re.kr
2 Dept. of Computer Science and Engineering, Korea University,
1, 5-ka, Anam-dong, Seongbuk-Gu, Seoul, 136-701, Korea
rim@nlp.korea.ac.kr
Abstract. This paper describes a novel method for a word sense disam-
biguation that utilizes relatives (i.e. synonyms, hypernyms, meronyms,
etc in WordNet) of a target word and raw corpora. The method disam-
biguates senses of a target word by selecting a relative that most prob-
ably occurs in a new sentence including the target word. Only one co-
occurrence frequency matrix is utilized to efficiently disambiguate senses
of many target words. Experiments on several English datum present
that our proposed method achieves a good performance.
1 Introduction
With its importance, a word sense disambiguation (WSD) has been known as
a very important field of a natural language processing (NLP) and has been
studied steadily since the advent of NLP in the 1950s. In spite of the long study,
few WSD systems are used for practical NLP applications unlike part-of-speech
(POS) taggers and syntactic parsers. The reason is because most of WSD studies
have focused on only a small number of ambiguous words based on sense tagged
corpus. In other words, the previous WSD systems disambiguate senses of just
a few words, and hence are not helpful for other NLP applications because of its
low coverage.
Why have the studies about WSD stayed on the small number of ambiguous
words? The answer is on sense tagged corpus where a few words are assigned to
correct senses. Since the construction of the sense tagged corpus needs a great
amount of times and cost, most of current sense tagged corpora contain a small
number of words less than 100 and the corresponding senses to the words. The
corpora, which have sense information of all words, have been built recently,
but are not large enough to provide sufficient disambiguation information of
the all words. Therefore, the methods based on the sense tagged corpora have
difficulties in disambiguating senses of all words.
R. Dale et al (Eds.): IJCNLP 2005, LNAI 3651, pp. 920?932, 2005.
c
? Springer-Verlag Berlin Heidelberg 2005
Word Sense Disambiguation by Relative Selection 921
In this paper, we proposed a novel WSD method that requires no sense tagged
corpus1 and that identifies senses of all words in sentences or documents, not
a small number of words. Our proposed method depends on raw corpus, which
is relatively very large, and on WordNet [1], which is a lexical database in a
hierarchical structure.
2 Related Works
There are several works for WSD that do not depend on a sense tagged corpus,
and they can be classified into three approaches according to main resources
used: raw corpus based approach [2], dictionary based approach [3,4] and hier-
archical lexical database approach. The hierarchical lexical database approach
can be reclassified into three groups according to usages of the database: gloss
based method [5], conceptual density based method [6,7] and relative based
method [8,9,10]. Since our method is a kind of the relative based method, this
section describes the related works of the relative based method.
[8] introduced the relative based method using International Roget?s The-
saurus as a hierarchical lexical database. His method is conducted as follows: 1)
Get relatives of each sense of a target word from the Roget?s Thesaurus. 2) Col-
lect example sentences of the relatives, which are representative of each sense. 3)
Identify salient words in the collective context and determine weights for each
word. 4) Use the resulting weights to predict the appropriate sense for the target
word occurring in a novel text. He evaluated the method on 12 English nouns,
and showed over than 90% precision. However, the evaluation was conducted on
just a small part of senses of the words, not on all senses of them.
He indicated that a drawback of his method is on the ambiguous relative: just
one sense of the ambiguous relative is usually related to a target word but the
other senses of the ambiguous relatives are not. Hence, a collection of example
sentences of the ambiguous relative includes the example sentences irrelevant
to the target word, which prevent WSD systems from collecting correct WSD
information. For example, an ambiguous word rail is a relative of a meaning bird
of a target word crane at WordNet, but the word rail means railway for the most
part, not the meaning related to bird. Therefore, most of the example sentences
of rail are not helpful for WSD of crane. His method has another problem in
disambiguating senses of a large number of target words because it requires a
great amount of time and storage space to collect example sentences of relatives
of the target words.
[9] followed the method of [8], but tried to resolve the ambiguous relative
problem by using just unambiguous relatives. That is, the ambiguous relative
rail is not utilized to build a training data of the word crane because the word
rail is ambiguous. Another difference from [8] is on a lexical database: they
utilized WordNet as a lexical database for acquiring relatives of target words
1 Strictly speaking, our method utilizes bias of word senses at WordNet, which is
acquired a sense tagged corpus. However, our method does not access a sense tagged
corpus directly. Hence, our method is a kind of a weakly supervised approach.
922 H.-C. Seo, H.-C. Rim, and M.-G. Jang
instead of International Roget?s Thesaurus. Since WordNet is freely available
for research, various kinds of WSD studies based on WordNet can be compared
with the method of [9]. They evaluated their method on 14 ambiguous nouns
and achieved a good performance comparable to the methods based on the sense
tagged corpus. However, the evaluation was conducted on a small part of senses
of the target words like [8].
However, many senses in WordNet do not have unambiguous relatives
through relationships such as synonyms, direct hypernyms, and direct hy-
ponyms.2 A possible alternative is to use the unambiguous relatives in the long
distance from a target word, but the way is still problematic because the longer
the distance of two senses is, the weaker the relationship between them is. In
other words, the unambiguous relatives in the long distance may provide ir-
relevant examples for WSD like ambiguous relatives. Hence, the method has
difficulties in disambiguating senses of words that do not have unambiguous rel-
atives near the target words in the WordNet. The problem becomes more serious
when verbs, which most of the relatives are ambiguous, are disambiguated. Like
[8], the method also has a difficulty in disambiguating senses of many words
because the method collects the example sentences of relatives of many words.
[10] reimplemented the method of [9] using a web, which may be a very
large corpus, in order to collect example sentences. They built training datum
of all noun words in WordNet whose size is larger than 7GB, but evaluated their
method on a small number of nouns of lexical sample task of SENSEVAL-2 as
[8] and [9].
3 Word Sense Disambiguation by Relative Selection
Our method disambiguates senses of a target word in a sentence by selecting
only a relative among the relatives of the target word that most probably occurs
in the sentence. A flowchart of our method is presented in Figure 1 with an
example3: 1) Given a new sentence including a target word, a set of relatives of
the target word is created by looking up in WordNet. 2) Next, the relative that
most probably occurs in the sentence is chosen from the set. In this step, co-
occurrence frequencies between relatives and words in the sentence are used in
order to calculate the probabilities of relatives. Our method does not depend on
the training data, but on co-occurrence frequency matrix. Hence in our method,
it is not necessary to build the training data, which requires too much time and
space. 3) Finally, a sense of the target word is determined as the sense that is
related to the selected relative. In this example, the relative stork is selected with
the highest probability and the proper sense is determined as crane#1, which is
related to the selected relative stork.
2 In this paper, direct hypernyms and direct hyponyms mean parents and children at
a lexical database, respectively.
3 In WordNet 1.7.1, a word crane contains four senses, but in this paper only two
senses (i.e. bird and device) are described in the convenience of description.
Word Sense Disambiguation by Relative Selection 923
A mother crane soon laid an egg.
stork, ibis, flamingo, 
bird, beak, feather, ...
lifting device, elevator,
davit, derrick, ...
Pr(stork | Context ),  Pr(ibis | Context ) , 
...
Pr(davit | Context), Pr(derrick | Context ) 
stork
crane#1 crane#2
crane#1
Sentence
Collect 
Relatives
Calculate 
Probability
Select a 
Relative
Determine 
Sense
Fig. 1. Flowchart of our proposed method
Our method makes use of ambiguous relatives as well as unambiguous rela-
tives unlike [9] and hence overcomes the shortage problem of relatives and also
reduces the problem of ambiguous relatives in [8] by handling relatives separately
instead of putting example sentences of the relatives together into a pool.
3.1 Relative Selection
The selected relative of the i-th target word twi in a sentence C is defined to be
the relative of twi that has the largest co-occurrence probability with the words
in the sentence:
SR(twi, C)
def
= argmax
rij
P (rij |C)P (Srij )W (rij , twi) (1)
where SR is the selected relative, rij is the j-th relative of twi, Srij is a sense of
twi that is related to the relative rij , and W is a weight of rij . The right hand
side of Eq. 1 is logarithmically calculated by Bayesian rule:
argmax
rij
P (rij |C)P (Srij )W (rij , twi)
= argmax
rij
P (C|rij)P (rij)
P (C)
P (Srij )W (rij , twi)
= argmax
rij
P (C|rij)P (rij)P (Srij )W (rij , twi)
= argmax
rij
{logP (C|rij) + logP (rij)
+logP (Srij) + logW (rij , twi)} (2)
924 H.-C. Seo, H.-C. Rim, and M.-G. Jang
The first probability in Eq. 2 is computed under the assumption that words
in C occur independently as follows:
logP (C|rij) ?
n
?
k=1
logP (wk|rij) (3)
where wk is the k-th word in C and n is the number of words in C. The proba-
bility of wk given rij is calculated:
P (wk|rij) =
P (rij , wk)
P (rij)
(4)
where P (rij , wk) is a joint probability of rij and wk, and P (rij) is a probability
of rij .
Other probabilities in Eq. 2 and 4 are computed as follows:
P (rij , wk) =
freq(rij , wk)
CS
(5)
P (rij) =
freq(rij)
CS
(6)
Pr(Srij ) =
0.5 + WNf(Srij)
n ? 0.5 + WNf(twi)
(7)
where freq(rij , wk) is the frequency that rij and wk co-occur in a raw corpus,
freq(rij) is the frequency of rij in the corpus, and CS is a corpus size, which is
the sum of frequencies of all words in the raw corpus. WNf(Srij ) and WNf(twi)
is the frequency of a sense related to rij and twi in WordNet.4 In Eq. 7, 0.5 is
a smoothing factor and n is the number of senses of twi. Finally, in Eq. 2, the
weights of relatives, W (rij , twi), are described in following Section 3.1.
Relative Weight. WordNet provides relatives of words, but all of them are not
useful for WSD. That is to say, it is clear that most of ambiguous relatives may
bring about a problem by providing example sentences irrelevant to the target
word to WSD system as described in the previous section.
However, WordNet as a lexical database is classified as a fine-grained dictio-
nary, and consequently some words are classified into ambiguous words though
the words represent just one sense in the most occurrences. Such ambiguous rela-
tives may be useful for WSD of target words that are related to the most frequent
senses of the ambiguous relatives. For example, a relative bird of a word crane is
an ambiguous word, but it usually represents one meaning, ?warm-blooded egg-
laying vertebrates characterized by feathers and forelimbs modified as wings?,
4 WordNet provides the frequencies of words and senses in a sense tagged corpus (i.e.
SemCor), and WNf is calculated with the frequencies in WordNet. That represents
bias of word senses in WordNet.
Word Sense Disambiguation by Relative Selection 925
which is closely related to crane. Hence, the word bird can be a useful relative of
the word crane though the word bird is ambiguous. But the ambiguous relative
is not useful for other target words that are related to the least frequent senses
of the relatives: that is, a relative bird is never helpful to disambiguate the senses
of a word birdie, which is related to the least frequent sense of the relative bird.
We employ a weighting scheme for relatives in order to identify useful rel-
atives for WSD. In terms of weights of relatives, our intent is to provide the
useful relative with high weights, but the useless relatives with low weights. For
instance, a relative bird of a word crane has a high weight whereas a relative
bird of a word birdie get a low weight.
For the sake of the weights, we calculate similarities between a target word
and its relatives and determine the weight of each relative based on the degree of
the similarity. Among similarity measures between words, the total divergence
to the mean (TDM) is adopted, which is known as one of the best similarity
measures for word similarity [11].
Since TDM estimates a divergence between vectors, not between words,
words have to be represented by vectors in order to calculate the similarity
between the words based on the TDM. We define vector elements as words that
occur more than 10 in a raw corpus, and build vectors of words by counting
co-occurrence frequencies of the words and vector elements.
TDM does measure the divergence between words, and hence a reciprocal of
the TDM measure is utilized as the similarity measure:
Sim(
?
wi,
?
wj) =
1
TDM(
?
wi,
?
wj)
where Sim(
?
wi,
?
wj) represents a similarity between two word vectors,
?
wi and
?
wj .
A weight of a relative is determined by the similarity of a target word and
its relative as follows:
W (rij , twi) = Sim(
?
rij ,
?
twi)
3.2 Co-occurrence Frequency Matrix
In order to select a relative for a target word in a given sentence, we must
calculate probabilities of relatives given the sentence, as described in previous
section. These probabilities as Eq. 5 and 6 can be estimated based on frequencies
of relatives and co-occurrence frequencies between each relative and each word
in the sentence.
In order to acquire the frequency information for calculating the probabilities,
the previous relative based methods constructed a training data by collecting
example sentences of relatives. However, to construct the training data requires
a great amount of time and storage space. What is worse, it is an awful work
to construct training datum of all ambiguous words, whose number is over than
20,000 in WordNet.
Instead, we build a co-occurrence frequency matrix (CFM) from a raw corpus
that contains frequencies of words and word pairs. A value in the i-th row and
926 H.-C. Seo, H.-C. Rim, and M.-G. Jang
j-th column in the CFM represents the co-occurrence frequency of the i-th word
and j-th word in a vocabulary, and a value in the i-th row and the i-th column
represents the frequency of the i-th word.
The CFM is easily built by counting words and word pairs in a raw corpus.
Furthermore, it is not necessary to make a CFM per each ambiguous word since
a CFM contains frequencies of all words including relatives and word pairs.
Therefore, our proposed method disambiguates senses of all ambiguous words
efficiently by referring to only one CFM.
The frequencies in Eq. 5 and 6 can be obtained through a CFM as follows:
freq(wi) = cfm(i, i) (8)
freq(wi, wj) = cfm(i, j) (9)
where wi is a word, and cfm(i, j) represents the value in the i-th row and j-th
column of the CFM, in other word, the frequency that the i-th word and j-th
word co-occur in a raw corpus.
4 Experiments
4.1 Experimental Environment
Experiments were carried out on several English sense tagged corpora: SemCor
and corpora for both lexical sample task and all words task of both SENSEVAL-
2 & -3.5 SemCor [12]6 is a semantic concordance, where all content words (i.e.
noun, verb, adjective, and adverb) are assigned to WordNet senses. SemCor
consists of three parts: brown1, brown2 and brownv. We used all of the three
parts of the SemCor for evaluation.
In our method, raw corpora are utilized in order to build a CFM and to
calculate similarities between words for the sake of the weights of relatives. We
adopted Wall Street Journal corpus in Penn Treebank II [13] and LATIMES cor-
pus in TREC as raw corpora, which contain about 37 million word occurrences.
Our CFM contains frequencies of content words and content word pairs. In
order to identify the content words from the raw corpus, Tree-Tagger [14], which
is a kind of automatic POS taggers, is employed.
WordNet provides various kinds of relationships between words or synsets.
In our experiments, the relatives in Table 1 are utilized according to POSs of
target words. In the table, hyper3 means 1 to 3 hypernyms (i.e. parents, grand-
parents and great-grandparent) and hypo3 is 1 to 3 hyponyms (i.e. children,
grandchildren and great-grandchildren).
5 We did not evaluate on verbs of lexical sample task of SENSEVAL-3 because the
verbs are assigned to senses of WordSmyth, not WordNet.
6 In this paper, SemCor 1.7.1 is adopted.
Word Sense Disambiguation by Relative Selection 927
Table 1. Used Relative types
POS relatives
noun synonym, hyper3, hypo3, antonym, attribute, holonym, meronym, sibling
adjective synonym, antonym, similar to, alsosee, attribute, particle, pertain
verb synonym, hyper2, tropo2, alsosee, antonym, causal, entail, verbgroup
adverb synonyms, antonyms, derived
4.2 Experimental Results
ComparisonwithOtherRelative Based Methods. We tried to compare our
proposed method with the previous relative based methods. However, both of [8]
and [9] didnot evaluate theirmethods onapublicly available data.We implemented
their methods and compared our method with them on the same evaluation data.
When both of the methods are implemented, it is practically difficult to col-
lect example sentences of all target words in the evaluation data. Instead, we
implemented the previous methods to work with our CFM. WordNet was uti-
lized as a lexical database to acquire relatives of target words and the sense
disambiguation modules were implemented by using on Na??ve Bayesian classi-
fier, which [9] adopted though [8] utilized International Roget?s Thesaurus and
other classifier similar to decision lists. Also the bias of word senses, which is
presented at WordNet, is reflected on the implementation in order to be in a
same condition with our method. Hence, the reimplemented methods in this pa-
per are not exactly same with the previous methods, but the main ideas of the
methods are not corrupted. A correct sense of a target word twi in a sentence
C is determined as follows:
Sense(twi, C)
def
= arg max
sij
P (sij |C)Pwn(sij) (10)
where Sense(twi, C) is a sense of twi in C, sij is the j-th sense of twi. Pwn(sij)
is the WordNet probability of sij . The right hand side of Eq. 10 is calculated
logarithmically under the assumption that words in C occur independently:
arg max
sij
P (sij |C)Pwn(sij)
= argmax
sij
P (C|sij)P (sij)
P (C)
Pwn(sij)
= argmax
sij
P (C|sij)P (sij)Pwn(sij)
= argmax
sij
{logP (C|sij) + logP (sij))
+logPwn(sij)}
? argmax
sij
{
n
?
k=1
logP (wk|sij) + logP (sij))
+logPwn(sij)} (11)
928 H.-C. Seo, H.-C. Rim, and M.-G. Jang
where wk is the k-th word in C and n is the number of words in C. In Eq. 11,
we assume independence among the words in C.
Probabilities in Eq. 11 are calculated as follows:
P (wk|sij) =
P (sij , wk)
P (sij)
=
freq(sij , wk)
freq(sij)
(12)
P (sij) =
freq(sij)
CS
(13)
Pwn(sij) =
0.5 + WNf(sij)
n ? 0.5 + WNf(twi)
(14)
where freq(sij , wk) is the frequency that sij and wk co-occur in a corpus,
freq(sij) is the frequency of sij in a corpus, which is the sum of frequencies
of all relatives related to sij . CS means corpus size, which is the sum of frequen-
cies of all words in a corpus. WNf(sij) and WNf(twi) are the frequencies of a
sij and twi in WordNet, respectively, which represent bias of word senses. Eq.
14 is the same with Eq. 7 in Section 3.
Since the training data are built by collecting example sentences of relatives
in the previous works, the frequencies in Eq. 12 and 13 are calculated with our
matrix as follows:
freq(sij , wk) =
?
rl related to sij
freq(rl, wk)
freq(sij) =
?
rl related to sij
freq(rl)
where rl is a relative related to the sense sij . freq(rl, wk) and freq(rl) are the
co-occurrence frequency between rl and wk and the frequency of rl, respectively,
and both frequencies can be obtained by looking up the matrix since the matrix
contains the frequencies of words and word pairs.
The main difference between [8] and [9] is whether ambiguous relatives are
utilized or not. Considering the difference, we implemented the method of [8] to
include the ambiguous relatives into relatives, but the method of [9] to exclude
the ambiguous relatives.
Word Sense Disambiguation by Relative Selection 929
Table 2. Comparison results with previous relative-based methods
S2 LS S3 LS S2 ALL S3 ALL SemCor
All Relatives 38.86% 42.98% 45.57% 51.20% 53.68%
Unambiguous Relatives 27.40% 24.47% 30.73% 33.61% 30.63%
our method 40.94% 45.12% 45.90% 51.35% 55.58%
Table 3. Comparison results with top 3 systems at SENSEVAL
S2 LS S2 ALL S3 ALL
[15] 40.2% 56.9% .
[16] 29.3% 45.1% .
[5] 24.4% 32.8% .
[17] . . 58.3%
[18] . . 54.8%
[19] . . 48.1%
Our method 40.94% 45.12% 51.35%
Table 2 shows the comparison results.7 In the table, All Relatives and Unam-
biguous Relatives represent the results of the reimplemented methods of [8] and
[9], respectively. It is observed in the table that our proposed method achieves
better performance on all evaluation data than the previous methods though the
improvement is not large. Hence, we may have an idea that our method handles
relatives and in particular ambiguous relatives more effectively than [8] and [9].
Compared with [9], [8] obtains a better performance, and the difference be-
tween the performance of them are totally more than 15 % on all of the evaluation
data. From the comparison results, it is desirable to utilize ambiguous relatives
as well as unambiguous relatives.
[10] evaluated their method on nouns of lexical sample task of SENSEVAL-2.
Their method achieved 49.8% recall. When evaluated on the same nouns of the
lexical sample task, our proposed method achieved 47.26%, and the method of
[8] 45.61%, and the method of [9] 38.03%. Compared with our implementations,
[10] utilized a web as a raw corpus that is much larger than our raw corpus, and
employed various kinds of features such as bigram, trigram, part-of-speeches,
etc.8 Therefore, it can be conjectured that a size of a raw corpus and features
play an important role in the performance. We can observe that in our imple-
mentation of the method of [9], the data sparseness problem is very serious since
unambiguous relatives are usually not frequent in the raw corpus. In the web,
the problem seems to be alleviated. Further studies are required for the effects
of various features.
7 Evaluation measure is a recall, which is utilized for evaluating systems at SENSE-
VAL. In the table, S2 means SENSEVAL-2, LS means lexical sample task, and ALL
represents all words task.
8 [10] also utilized the bias information of word senses at WordNet.
930 H.-C. Seo, H.-C. Rim, and M.-G. Jang
Comparison with Systems Participated in SENSEVAL. We also com-
pared our method with the top systems at SENSEVAL that did not use sense
tagged corpora.9 Table 3 shows the official results of the top 3 participating
systems at SENSEVAL-2 & 3 and experimental performance of our method. In
the table, it is observed that our method is ranked in top 3 systems.
5 Conclusions
We have proposed a simple and novel method that determines senses of all
contents words in sentences by selecting a relative of the target words in Word-
Net. The relative is selected by using a co-occurrence frequency between the
relative and the words surrounding the target word in a given sentence. The co-
occurrence frequencies are obtained from a raw corpus, not from a sense tagged
corpus that is often required by other approaches.
We tested the proposed method on SemCor data and SENSEVAL data, which
are publicly available. The experimental results show that the proposed method
effectively disambiguates many ambiguous words in SemCor and in test data
for SENSEVAL all words task, as well as a small number of ambiguous words
in test data for SENSEVAL lexical sample task. Also our method more cor-
rectly disambiguates senses than [8] and [9]. Furthermore, the proposed method
achieved comparable performance with the top 3 ranked systems at SENSEVAL-
2 & 3.
In consequence, our method has two advantages over the previous methods
([8] and [9]): our method 1) handles the ambiguous relatives and unambiguous
relatives more effectively, and 2) utilizes only one co-occurrence matrix for dis-
ambiguating all contents words instead of collecting training data of the content
words.
However, our method did not achieve good performances. One reason of
the low performance is on the relatives irrelevant to the target words. That is,
investigation of several instances which assign to incorrect senses shows that
relatives irrelevant to the target words are often selected as the most probable
relatives. Hence, we will try to devise a filtering method that filters out the useless
relatives before the relative selection phase. Also we will plan to investigate a
large number of tagged instances in order to find out why our method did not
achieve much better performance than the previous works and to detect how
our method selects the correct relatives more precisely. Finally, we will conduct
experiments with various features such as bigrams, trigrams, POSs, etc, which
[10] considered and examine a relationship of a size of a raw corpus and a system
performance.
9 At SENSEVAL, unsupervised systems include the weakly supervised systems though
there are some debates. In this paper, our methods are compared with the systems
that are classified into the unsupervised approach at SENSEVAL.
Word Sense Disambiguation by Relative Selection 931
References
1. Fellbaum, C.: An WordNet Electronic Lexical Database. The MIT Press (1998)
2. Schu?tze, H.: Automatic word sense discrimination. Computational Linguistics 24
(1998) 97?123
3. Lesk, M.: Automatic sense disambiguation using machine readable dictionaries:
How to tell a pine cone from an ice cream cone. In: Proceedings of the 5th annual
international conference on Systems documentation, Toronto, Ontario, Canada
(1986) 24?26
4. Karov, Y., Edelman, S.: Similarity-based word sense disambiguation. Computa-
tional Linguistics 24 (1998) 41?59
5. Haynes, S.: Semantic tagging using WordNet examples. In: Proceedings of
SENSEVAL-2 Second International Workshop on Evaluating Word Sense Disam-
biguation Systems, Toulouse, France (2001) 79?82
6. Agirre, E., Rigau, G.: Word sense disambiguation using conceptual density. In:
Proceedings of COLING?96, Copenhagen Denmark (1996) 16?22
7. Fernandez-Amoros, D., Gonzalo, J., Verdejo, F.: The role of conceptual relations in
word sense disambiguation. In: Proceedings of the 6th International Workshop on
Applications of Natural Language for Information Systems, Madrid, Spain (2001)
87?98
8. Yarowsky, D.: Word-sense disambiguation using statistical models of Roget?s cat-
egories trained on large corpora. In: Proceedings of COLING-92, Nantes, France
(1992) 454?460
9. Leacock, C., Chodorow, M., Miller, G.A.: Using corpus statistics and WordNet
relations for sense identification. Computational Linguistics 24 (1998) 147?165
10. Agirre, E., Martinez, D.: Unsupervised wsd based on automatically retrieved
examples: The importance of bias. In: Proceedings of the Conference on Em-
pirical Methods in Natural Language Processing (EMNLP), Barcelona, Spain
(2004)
11. Lee, L.: Similarity-Based Approaches to Natural Language Processing. PhD thesis,
Harvard University, Cambridge, MA (1997)
12. Miller, G.A., Leacock, C., Tengi, R., Bunker, R.: A semantic concordance. In:
Proceedings of the 3 DARPA Workshop on Human Language Technology. (1993)
303?308
13. Marcus, M.P., Santorini, B., Marcinkiewicz, M.A.: Building a large annotated
corpus of english: The penn treebank. Computational Linguistics 19 (1994) 313?
330
14. Schmid, H.: Probabilistic part-of-speech tagging using decision trees. In: Proceed-
ings of the Conference on New Methods in Language Processing, Manchester, UK
(1994)
15. Fernandez-Amoros, D., Gonzalo, J., Verdejo, F.: The UNED systems at
SENSEVAL-2. In: Proceedings of SENSEVAL-2 Second International Work-
shop on Evaluating Word Sense Disambiguation Systems, Toulouse, France (2001)
75?78
16. Litkowski, K.: SENSEVAL-2:overview. In: Proceedings of SENSEVAL-2 Sec-
ond International Workshop on Evaluating Word Sense Disambiguation Systems,
Toulouse, France (2001) 107?110
932 H.-C. Seo, H.-C. Rim, and M.-G. Jang
17. Strapparava, C., Gliozzo, A., Giuliano, C.: Pattern abstraction and term similarity
for word sense disambiguation: Irst at senseval-3. In: Proceedings of SENSEVAL-
3: Third International Workshop on the Evaluation of Systems for the Semantic
Analysis of Text, Barcelona, Spain (2004) 229?234
18. Fernandez-Amoros, D.: Wsd based on mutual information and syntactic patterns.
In: Proceedings of SENSEVAL-3: Third International Workshop on the Evalu-
ation of Systems for the Semantic Analysis of Text, Barcelona, Spain (2004)
117?120
19. Buscaldi, D., Rosso, P., Masulli, F.: The upv-unige-ciaosenso wsd system.
In: Proceedings of SENSEVAL-3: Third International Workshop on the Eval-
uation of Systems for the Semantic Analysis of Text, Barcelona, Spain (2004)
77?82
