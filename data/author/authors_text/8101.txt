Context-Free Grammar Rewriting and the Transfer of Packed Linguistic 
Representations 
Marc Dymetman 
Xerox Research Centre Europe 
6, chemin de Maupertuis 
38240 Meylan, France 
dymetman @ xrce.xerox.com 
Fr~dfiric Tendeau 
Lernout & Hauspie 
Koning Albert-I laan 64 
B- 1780 Wemmel, Belgium 
Frederic.Tendeau @ lhs.be 
Abstract 
We propose an algorithm for the trausfer of packed linguistic 
structures, that is, finite collections of labelled graphs which 
share certain subparts. A labelled graph is seen as a word over 
a vocabulary of description elements (nodes, arcs, labels), and 
a collection of graphs as a set of such words, that is, as a hm- 
guage over description elements. A packed representation for 
the collection of graphs is then viewed as a context-free gram- 
mar which generates such a language. We present an algorithm 
that uses a conventional set of transfer ules but is capable of 
rewriting the CFG representing the source packed structure into 
a CFG representing the target packed structure that preserves 
the compaction properties of the source CFG. 
1 Introduction 
There is currently much interest in translation models 
that support some amount of ambiguity preservation be- 
tween source and target exts, so as to minimize disam- 
biguation decisions that the system, or an interactive user, 
has to make during the translation process (Kay et al, 
1994).. 
An important aspect ol' such models is the ability to 
handle, during all the stages of the translation process, 
packed linguistic structures, that is, structures which fac- 
torize in a compact fashion all the different readings of 
a sentence and obviate the need to list and treat all these 
readings in isolation of each other (as is standard in more 
traditional models for machine translation). 
In the case of parsing, and more specifically, parsing 
with unification-based formalisms uch as LFG, tech- 
niques for producing packed structures have been in 
existence for some time (Maxwell and Kaplan, 1991; 
Maxwell and Kaplan, 1993; Maxwell and Kaplan, 1996; 
D6rre, 1997; Dymetman, 1997). More recently, tech- 
niques have been appearing for the generation from 
packed structures (Shemtov, 1997), the transfer between 
packed structures (Emele and Dorna, 1998; Rayner and 
Bouillon, 1995), and the integration of such mechanisms 
into the whole translation process (Kay, 1999; Frank, 
1999). 
This paper focuses on the problem of transfer. The 
method proposed is related to those of (Emele and Dorna, 
1998) and (Kay, 1999). As in these approaches, we view 
packed representations a being descriptions of a finite 
collection of directed labelled graphs (similar to the func- 
tional structures of LFG), each representing a different 
non-ambiguous reading, which share certain subparts. 
The representations of (Emele and Dorna, 1998) and 
(Kay, 1999) arc based on a notion of propositional con- 
texts (see (Maxwell and Kaplan, 1991)), where each 
possible non-ambiguous reading included ill the packed 
source representation is extracted by selecting the value 
(true or false) of a certain number of propositional vari- 
ables that index elements of the labelled source graph. 
Transfer is then seen as a process of rewriting source 
graph elements (e.g, nodes labelled with French lexemes) 
into target graph elements (e.g. nodes labelled with En- 
glish lexemes), while preserving the propositional con- 
texts in which these graph elements were selected. 
In contrast, our approach, following (Dymetman, 
1997), views a packed representation as being a gram- 
mar (more specifically, a context-flee grammar) over the 
vocabulary of graph elements (labelled nodes and edges), 
where each word (in the sense of formal anguage theory) 
generated by the grammar represents one of the possible 
non-ambiguous readings of the packed representation. I  
other terms, the collection of non-ambiguous graphs be- 
longing to the packed representation is seen as a km- 
guage over a vocabulary of graph elements, and a packed 
representation is seen as a grammar which generates such 
a language. Packing comes fi'om the fact that a context- 
free grammar is an cMcicnt representation lbr the lan- 
guage it generates. Another essential feature of such a 
representation is that it is interaction-free, that is, each 
nondeterministic op-down traversal of the grammar suc- 
ceeds without ever backtracking and it results in a certain 
reading, without he need for checking the consistency of 
a set of associated propositional constraints: the repre- 
sentation for the collection of readings is as direct as can 
be while permitting a filctorization of common parts. 
Based on this notion, we present an algorithm for 
transfer which, starting fi'om a finite set of rewriting 
patterns (the transfer lexicon), associates with a given 
context-fi'ee grammar epresenting the source packed 
structure a context-free grammar epresenting the tat'- 
get packed structure. Therefore, the target representa- 
tion remains interaction-fi'ee and transparently encodes 
the target structures; furthermore, under certain natural 
"locality" conditions on the rewriting rules (the graph el- 
ements in their left-hand sides tend be be "close" from 
each other in the source grammar derivations), the target 
grmnmar preserves much of the factorization and com- 
paction properties of the sotu'ce grammar. 
The paper is structtu'ed in the following way. Sec- 
1016 
tion 2 explains how mnbiguous graphs can be seen as 
commutative hmguagcs over graph description elements, 
and how context-free grammars provide concise specili- 
cations for these languages. Section 3 extends the stan- 
dard notion of non-ambiguous transfer to that of am- 
biguous transfer. Section 4 presents the basic hmguagc- 
theoretic formalism needed and introduces ome opera- 
|ors on languages. Section 5 presents Ihe detailed rewrit- 
ing algorithm, which applies these operators not directly 
to hmguages, but to the context-free grammars pecify- 
ing them. Section 6 gives an example of the algorithm in 
operation. 
2 Ambiguous structures as languages 
O: see /sawz  . . . . . . . . . . . . .  - . _ _  
argl~- -'~ ~at 'g2- - - - - .  *nod " "  mod 
1: i 2: l ight z_ ~-Z - -\\- -. \ 
{ J l f  n l ( ) ( \ ] - -  ~ ~ , - -  -- I I lOd  \ 
7: g reen  I / g reen2 err'g2 ~ ~l 
J 
4: h i l l -  m(~d x t 
5 :  w i lh  
ar?,2 \[ 
(~: le lescope  
Figure 1 : An informal graphical representation f the 20 
possible analyses for "I saw the green light on the hill 
with a telescope". 
Let's consider the sentence "I saw the green light on 
the hill with a telescope". In Fig. I, we have repre- 
sented inlbnnally the set of possible analyses for this 
sentence. Labels on the nodes correspond to predicate 
names ('on', 'hill', etc). A slash is used to indicate dif- 
ferent possible readings for a node; for instance, we as- 
sume that the surface form "saw" can correspond to the 
verbs "to see" or "to saw", and that "green" is ambigu- 
ous between the color adjective "green l" and the noun 
"green2" (grassy lawn). Relations between odes are in- 
dicated by labels on the edges joining two nodes: 'argl '  
and 'arg2' for tirst and second argument, 'rood' for mod- 
ilier. The solid edges correspond to relations which are 
satistied in all the readings for |be sentence, dotted edges 
to relations that are satistied only for certain readings. 
Thus, the preprositional phrase "on the hill" can modify 
either "light" or "see/saw", the phrase "with a telescope" 
either "hill", "light", or "see/saw'. The informal picture 
of Fig. 1 does not make explicit exactly which structures 
are actually possible analyses of the sentence. For in- 
stance the two crossing edges modo3 and rood25 (where 
indices are used to denote the origin and destination of 
the edge) cannot appear together in a reading of the given 
sentence. As a consequence only five of the apparent 
2 x 3 prepositional ttachments combinations are possi- 
ble, which multiplied by the four possible lexical variants 
for "saw" and "green" gives 20 possible readings for tim 
sentence .  
Each of these readings is a graph where nodes 0 and 
7 now carry one label, and where one 'rood' edge has 
been selected for the attachment of nodes 3 and 5. One 
way to describe such a graph is by listing a collection of 
"description elenmnts" for it, where each such dement 
is either a labelled node such as scco or a labelled edge 
such as rood27. Using this format, the pragmatically pre- 
ferred analysis for our sentence is the set {SCCo, mglol, 
il, arg202, light2, mod27, gwenlT, mod.23, on3, arg234, 
hill4, modo5, with~,, zug2.~a, tclescope~ }.
If we consider the collection of all possible analyses, 
we then obtain a collection of sets of description ele- 
ments. It is convenient to view such a collection as a 
commutative language over the vocabulary of all possi- 
ble description elements; each word in such a hmguage 
corresponds to one analysis and is a list of description 
elements the order of which is considered irrelevant. 
The main advantage of taking this view of ambiguous 
structures is that fomml language theory provides stan- 
dard tools for representing languages compactly. Thus 
it is well-known in computational lexicography tlmt a 
large list of word strings can be represented efliciently by 
means of a tinite-stale atltoma|on which factorizes com- 
mon subs|rings. Such a representation is both compact 
and "explicit": accessing and using it is as direct as the 
flat list of words would be. 
Although one might think o1' using tinite-statc mod- 
els for representing compaclly the language associated 
with a collection of graphs, they do not seem as relevant 
as context-free models for our purposes. The reason is 
that the source packed representations are typically ob- 
tained as the results of chart-parsing processes. A chart 
used in the parsing of a context-fi'ee grammar can itself 
be viewed as a context-free grammar, which is a spe- 
cialization of the original granllllar l'or the string being 
parsed, and which directly generates tim deriwltion trees 
for this string relative to the ot t,q,," "'o'.aL grammar (Billot and 
Lang, 1989). 1 The generalization of this approach to uni- 
tication grammars (ot' the LFG or DCG type) proposed 
in (Dymemmn, 1997) shows that, in tt, rn, chart-parsing 
with these unilication grammars conducts naturally to 
packed representations for the parse results very close to 
the ones we are about to introduce. 
Let's consider the CFG Go: 
S~ SAW ()r~ Wnlt D3 
Saw -9 I)0 a.'gl01 i, arg2o:~ Lt<irr 
Lit;in' --4" O~H~n Inod27 light2 
Gi~lit~N --+ grcelll7 \[ green27 
O~ -9 on3 arg23a hill4 
W.ll -9 with5 a/g256 telcscope~i 
1)0 -9 seco\] sawo 
I)3 -9 modo3 D30 \[ mod.2a I)32 
D30 -4 modo5 \] mod4~ 
D32 -9 modo5 \] mod.2~ \] mod4~ 
Nontenninals of that grammar arc written in upper- 
case, terminals (which are graph description elements) in 
lowercase. It can be verified that the language generated 
by this grammar is the collection of commutative words 
IThis context-free grammar has polynomial size relative to the 
length of the string. While it is also possible in principle to use a linite- 
stale model for representing lhe sallle sel of derivation trees, it can be 
showll Ihal such at model may be exponential relative to string length 
(remark due to John Maxwell). 
1017 
corresponding precisely to all the possible analyses for 
the sentence. 
The fact that there are 20 such words can be es- 
tablished by a simple bottom-up computation i volving 
multiplications and sums. I1' we call ambiguity degree 
ad(N) of a nonterminal N tim ntunber of words it gen- 
erates, then it is obvious that, for instance, ad(D30) = 2, 
ad(D3) = 2+3, ad(S) = 4.1.1-5 = 20. In fact, it is the mul- 
tiplications which appear in such computations which are 
responsible for the compactness of the grammar as com- 
pared to the direct listing of the words: each time a mul- 
tiplication appears, a factorization is being cashed in. 2 
3 Transfer as language rewriting 
When working with non-ambiguous structures, transfer 
is a rewriting process which takes as input a source- 
language graph and constructs a target-language raph 
by applying transfer ules of the form lhs --4 rhs, where 
lhs and rhs are finite sets of description elements for 
source graph and target graph respectively. In outline, the 
"non-ambiguous" transfer process works in the Mlowing 
way: for each non-overlapping covering of the source 
graph with left-hand sides of transfer ules, the corre- 
sponding right-hand sides are produced and taken to- 
gether epresent a target graph (this is a non-deterministic 
ftmction as there can be several such coverings). 
In the case of ambigt, ous structures, the aim of transfer 
is to take as input a language of source graphs and to pro- 
duce a language of target graphs. The language of target 
graphs hould be equal to the union of all the graphs that 
would have obtained if one had enumerated one-by-one 
the source graphs, applied non-ambiguous transfer, and 
taken the collection of all target graphs obtained. The 
goal of ambiguous transfer is to perform the same task 
on the basis o1' a compact representation for the collec- 
tion of source graphs, yielding a compact representation 
for the collection of target graphs. 
For illustratkm purposes, we will consider the follow- 
ing collection of transfer ules: 
seeo --+ voitb, sawo -+ sciero, 
gl"eenl7 --+ Vel17, green27 -+ gazonT,  
light2, rood27, greenl7 --+ lcu2, rood'27, vcrlT, 
light2 --+ lumi&e2, etc. 
We have only listed a few rules, and have assumed that 
the remaining ones are straighlorward one-to-one corre- 
spondences (11 --+ jet, medea -+ mod'o3 \[we prime la- 
bels such as mod, argl .... in order to have disjointness of 
source and target vocabulary\], etc.)) 
2As the example shows, conlexl-flee representations of ambigu- 
ous slructures have the important properly (related to their inte,'aclion- 
freeness as described in the i,~troduction) of being easily "countable". 
This is to be contrasted with other possible representations forambigu- 
ous structures, uch as ones based on propositional xioms determining 
which desc,'iption elemenls can be jointly p,esent in a given analysis. 
In these representations, the problem of determining whether there ex- 
ists one structure satisfying the specification can be of high complexity, 
let alne the problem of counting such structures. 
3 In practice, real transfer rules are not specialized lbr specific nodes, 
but are panerns containing variables instead of imlnbers; in order to oh- 
4 Formal aspects 
The cotnmutative monoid over an alphabet A is denoted 
by C(~*),  and its words are represented by vectors of 
N A, indexed by ..4 and with entries ill N. For each w E 
N A, the c(mlponent indexed by a C ..4 is denoted by 
w\[,\] and tells how many a's occur in w. The product 
(concatenation) ofwl  and 'w2 in C(.A*) is the vector w E 
N A s.t. Vet C A: w\[,\] = wl \[,\] + "w2\[, 1. A language of 
the commutative monoid is a subset of C(A*). 
The subword relation is denoted by --<. For a language 
L, we write: v--<L iff there exists w E L s.t. v-<w. 
The rewriting is performed from a sourcc language ?s  
over an alphabet Es to a target language/27, over an al- 
Es)  w.r.t, a phabet ET (disjoint fi'om set of rewriting 
rules 7~ C P,s + x P'T* (rules have the form A-+p). We 
assume in the sequel that any a G ES appears at most 
once in any left-hand side of each rule of "R. and also at 
most once in any word of ?s .  This property is preserved 
by all the rewritings that we are going to int,'oduce. 
Let's deline LI tS(A-+p)  = A. For R C ~., we define 
L.,~&,(R) = {a E P's' \[ 3r e 17, s.t. et-e, LHS(, ' )  }. 
Tim rewriting is a l'unction qSre. taking ?,9 and yielding 
L;T, delined as: 
, / ,~(?s)  = {mp, ,  I ~,,  ~ ?s.,~,, = ,x~...%,/~ 
kl - -~'pl  G "J~ A ... A Ap'-q, flp G "R.}. 
5 Algorithm 
In order to implement he function ()n, it is useful to 
introduce rewriting functions q~--+t, and q~?r. They apply 
to any language L over C(E*), where E = Es, tO ET. 
They are detined as: 
~x-+,,(r) = {m" I aw C L} 
O~(L) = {w c L I ~v\[. 1 = 0}. 
The ~x-~p functions are applied so that source sym- 
bols are guaranteed to be removed one by one from ?.s': 
we consider E.s' is totally ordered by < and we write 
E.5' = \[(/,1, a2, ..., aN\], with ai < eti+l ; then consider the 
partition of 7~.: 7Zl, J~2 ..... T~N s.t.R.1 contains all ~. 
rules with al in LHS, "R.2 contains all 7? rules with a9 but 
not al in LHS, etc, "R.N contains all 7Z rules with only aN 
in LHS. Then we deline a third rewriting function q')7?~ : 
~l,,e, (L) = qSv(L) U U,.eT~, 4,.(c). 
Lemma. ?7' can be obtained l;'om ?s by applying the 
T~i iteratively in the following manner: 
~b~/~N ((/)'~N--I ( '" "{J)'\]~l (CS) ?" ")) = j~'\]'" 
PROOF SKETCII. For 1 _< j < N, we deline 
?'J = {p l ' ' 'ppx  \] ~*tJ E J~.S,z E ES*,p > O,w = 
At ' "  .Apa; ,Vk < p Ak-4 Ph. G Oi<_jT~i,Vi ~ j etiT~Z}. 
It is cleat" that ?N = ?T- Furthermore, we have L;1 = 
(/)'\]~1 (?S) ,  and it is easy to show that, for 2 _.5_ n < N, 
?n = ()'1?,~(/3,z-~). From this we have immediately 
CN = ~,~, (~,~_, (.. "~'~1 (Cs)-  . .) ) = Or.  
In order to obtain ?r ,  we will start from ?.s' and ac- 
tually apply the ~bTa~'s not on languages directly but on 
rain g,'otmd, rules, as the ones we are considering, a simple preproces,s ing, 
step is necessary. 
1018 
tim grmnnmrs that deline them. Tiffs computation is per- 
formed by the algorithm that we now present. 
Let/2~, be detined by the CFG Go = ()2, Ale, 7)o, So). 
For A G iV'o, the set o1' all rules having A as I.HS is no- 
tated A--> ~A-~a.<;% (t- This additive notation is a for- 
111111 represenlion of A-~cq I ct2 \] ... ltcnce A-+0 means 
that no rule delines A. 
First ()7,'.1 is @plied on Go, which builds G1 = 
(~l, Af:I, 791, ,91 ), Ihen ?-~= is applied on G1 to produce 
G:, and so forth. Each time, new non-terminals are in- 
troduced: of the form (A)-~,, (A),x-4o or (A)~r, where 
A ~ N' i -~, A G Ns +, p E NT*, and a G S,s. Each one 
is defined by a formal sum as we saw above. 
The order of symbols in the RHSs of grammar ules 
is irrelevant since we consider commutative languages. 
Hence the RHSs ot' grammar rt,les can be denoted by :c/3 
s.t. x ~ C(~*) and/':/ E C(N'*), where iV" is the set o1' 
all non-terminals considered. 
The algorithm consists of the procedure and functions 
described below and uses an agenda which contains Dew 
i~on-terminals to be defined in Gi. The agenda is handled 
with a table: each hen-terminal is treated once. 
procedure main is 
fo r i  G {1 , . . . ,N}  do 
Initialize 79i with 79i_~ ;
if "R,i # 0 then 
Initialize Agenda with (S i_  1 )7,LI ; 
repeat 
remove NonTerm l'ron~ Agenda; 
case NonTerm is 
when (A)7,,,~ : add to 79i 
when (A)x4t, :  add to "l~i 
(A )x -~.~ ~..~->,.:7,, , ,l~x-+~,(,~); 
when (A),: add to "Pi 
end case; 
until Agenda is empty 
Reduce Gi whose axiom is Si = (Si-~)n~ ; 
/:t:I'ClllOVC non-terminals that are non-praductive 
(? (A) = ~) or inaccessihle fi'om Si. */ 
end for; 
end procedure; 
flmction R'7,', (x{4) is// fl = At . . .Ak  
if ~j ~ {1, ..., k} s.t. Va E L,.,,&,('R.i), a-<?(Aj) 
/ / i f  all rewritings in "R.i can only q/.'/bct A.4 
then add (Aj)vv.i to Agenda; 
retnrn xAI"  ? "Aj-1 (Aj)vz~Aj+I ? ? .A~; 
el,;e return ,~(a ' f l )  + y~,,.~x., ~,,. (a'/~); 
end function; 
(1) 
(2) 
f lmction 'I,~(xfl) is//fl = At-.-A~. 
i f~j < {J,..., a:} s.t. a-<Z;(&) 
then/* j  is unique, see below*/add (Aj)~ t() Agenda; 
return :rA~-. "Aj-1 (Aj)~rAj+1-..A~.; (3) 
el,;e if a-qx then return O; 
else return xfl; 
end fimction; 
flmction ff'X-+p(a;fl) i~/ fl = A1. . .Ak 
//A is seamhed within a:AI. ? .-4k 
if ~j < {1, ..., k} s.t. Va-<k, a-<12(Aj) ~~if A falls 
//entirely within ?(  Aj ) then the rewriting applies only to A.i 
then add (Aj)>,--,,p to Agenda; 
return xA~. .  "Aj-1 (Aj), , ,~oAj+I ? - -Ak; (4) 
else//A is searched wilhin several symboLv 
Consider A = y,wa w.2.. "Wk s.t. 
- the longest common subword ot' x and ~ is y, 
-- V(t-d, Wj , (t...~?( A j  ) // wj is Aj contribution to A 
if such decomposition ofA exists//that is, it is 
//entirely covered by x and some Aj 's 
then/* it is mffque: see below */add to Agenda 
all (Aj)wj---}~ S.I. Wj ~ e; l/all those that contribute 
,-et,,,-,,.,./:j (FI,,,~#~ (Aj),~,-~) (Fiw,=, A;)/,;(5) 
//77te rewriting is actually cqqdied: y is deleted.fiom a:; 
//each contributing (i.e. non e) wj is to be deleted 
//(i.e. rewritten to e it, Aj); non-contributing Aj ' s  
//Jvntain tmtoudted; attd p is inserted. 
else//A cannot be pJvdtu'ed by xfl 
return O; ~~No Jvwriting is ~qqdicable 
end fnnctlon; 
Unicity o f j  in ffhr, and unicity of the sequence in ff,),+p: 
consider A-~a:XY7 C 79i-1 ; as each source symbol oc- 
curs at most once in every word of ?(S i -1) ,  the same 
holds for/_2(A) hence the sets of source symbols occur- 
ring in ?(X) an0 ?(Y)  are disioint. 
6 Example  
Consider ~2,s, = \[i~, green It, grccn27, seed .... \[ so that "R. 
is partitioned in ~.1 = {ij ~ je l  }, "R.2 = {green 17-+ VCl't7, 
grccnlr mod.27 light2-~lbu2 rood27 verl7}, etc. Each 
other "R.i contains a single rule. 
The lirst iteration of the algorithm computes the gram- 
mar Gt = ff"R., (Go). The resuh is: 
(So)?,h -+(S,xw)?q ()N Win, 1)3, 
(SAW)'p~, --+DO atglol ar, g2o2 L~,,r,.icl, 
gKillrl" ---)" Orl!,~N mod27 \]ight2, 
GRliI:N -+ gmen17 I gmcn2r, 
On --~ ona mg2a4 hill4, 
Wr,~ -+ with~, ar.g256 tclescopca, etc. 
We see that the only nonterminals which have been rede- 
fined are ,5' = ,5'o and Saw. The computation of (,5'o)~ 
has been done through step (I) in the algorithm. This is 
because the terminals in lefbhand skies of 77q, nmnely 
the single terminal i~, are all "concentrated" on the sin- 
gle nonterminal Saw on the right-hand side of St}. This 
leads in turn to a requirement for a definition of (Saw)hi, 
which is fulfilled by step (5) in the algorithm, at which 
time the rewriting of il intojel is performed. 
For any group of rules "R.i, as long as all terminals in 
the left-hand sides of rules ol"R.i a,'e thus concentrated on
at most one nonterminal in a right-hand side, no expan- 
sion of rules is necessary. It is only when the terminals 
start to be distributed on several RHS terminals or non- 
terminals that an expansion is required. 
This situatien is illustrated by the second iteration 
which maps G1 into (7, 2 = ,I,~,,. e((71). The result is: 
1019 
((S0)7~1)7?2 --+((Saw)rq )7?2 ON W,,'. D3, 
((SAw)~q)g2 -+DO argl01 rag202 (L,?;,r)r?2 jOh 
(L,t;,'r)~ 2 -+(GR,~,{N)~ mod.2r light.>, 
I (G'w.'~N)g,'ee,,tv-+,,e,',7 mod.2r light2, 
\[ (GR,~,~.Je,.ee,,tr-+, feu2 mo~gr vertr, 
(GRI~,!N)~ -+ green27 ON -+ o113 atg2a4 hill4, 
(Gl~l~N)gmenl7"-+ vertr -+ vertr W,,H -+ with~ arg256 telescope6, 
(GlmI{N)greenl7-+ e -+ e, etc. 
This time, the terminals in left-hand sides of T~2 are 
grcen l7, nlod27 and light> We first need to compute 
((S0)~)Tz=. Again, our three terminals are all con- 
centrated on (SAw)Tz~. We thus only have to definc 
((Saw)Tq)g2. Once again, the three terminals are con- 
centrated on L,~;,r,', and we have to define (L~.,)r?~. 
At this point, something interesting happens. It is not 
the case any more that one nonterminal on the right- 
hand side of the rule defining L~H.r concentrates all 
our terminals. In fact, G~H~ only "touches" grcen lT, 
but not the other two terminals. The algorithm then 
has recourse to step (2), which leads it to dctine three 
rules for (L~?;.,)r?=, involving recursive calls to ~I'gr~o,,~ ~ ,  
teenlT--f~ett7, ~} feet ~ , , The fi~st g. , . g ~lTmod271"gl t'2--+ feu2 mod27 vertT " ". 
of these calls involves step (3), the second, step (4), and 
the third, step (5), leading to the three exlmnsions shown 
for (L,?~.'r)Tz~, and eventually to the definitions for the 
three variants of the nonterminal GEN. 
The remaining iterations of the rewriting procedures 
arc of the same type as the first iteration. They lead fi- 
nally to a target grammar of the form: 
S'-+SAw' ON' Win( D3' SAw'-+D0' atgl{i 1 al~2to2 L,{m'/jel 
gIdlrr t -+aR,~*~d II10C~.27 \]tlllli~.rc2 
I GRH{N" I170~27 lumi&'e.2 
I f~lJ2 n\]0C~27 vert7 
Om:N' --+ gazon7 Wrm' ~ aVCC5 argO56 hmette6 
Gm.:I:N" --+ Vel't7 ON' --+ SUI'3 ~11"~'r'~34 colline4 
D30' -+ mo4.5 I mo4.5 D3' -+ ,no4a D30' \] mO4a D32' 
DO' -+ voiro I sciero D32' --+ mo~g~ I mo4~ I meal45 
which is only slightly less compact than the source gram- 
mar. It can be checked that this grammar enumerates 30 
target graphs, the difference of 10 with the source gram- 
mar being due to the addition of the French variant "feu 
vert" along with "lumi~re vcrte" for translating "green 
light". 
7 Conclusion 
We have presented a model and an algorithm for the 
transfer of packed linguistic representations based on 
the view that: (1) packed representations are best seen 
as context-free grammars over graph description ele- 
ments, an approach which permits factorization of com- 
mon parts while maintaining a transparent, easily com- 
putable, relationship to the set of structures represented 
(interaction-freeness, countability) 4, and (2) transfer is 
a rewriting process that takes as input such a context- 
free representation a d that outputs a target context-free 
4properties that we believe are essential to all such representations, 
whether they are made xplicit or not. 
representation which maintains these beneficial proper- 
tics. Although proofs have not been provided here, the 
algorithm can be shown to satisfy our initial formal def- 
inition of transfer as nondcterministic, exhaustive, non- 
overlapping replacement of description elements in the 
source structure by their counterparts as specilied in the 
rewriting rules. Tim method escribed in this paper bears 
some obvious analogy to the classical problem of map- 
ping a context-free language into another context-fi'ee 
language by way of a finite-state transducer (Harrison, 
1978). It would be an interesting research question to 
make this analogy formal, the main difference here be- 
ing the need to work with a commutative concatenation, 
as opposed to the standard non-commutative concatena- 
tion which is more directly connected with the automaton 
view of transductions. 
Acknowledgments 
Thanks to our colleagues Eric de la Clergerie, Max Copper- 
man, Andreas Eisele, Martin Emele, Anette Frank, Pierre Is- 
abelle, Ron Kaplan, Martin Kay, Berna~zl Lang, John Maxwell 
and Hadar Shemtov for extended iscussions and comments at 
various stages in the preparation of this paper. 
References 
S. Billet and B. Lang. 1989. The structure of shared forests in 
ambiguous parsing. In 27 th Meeting of the Association for 
Computational Lhlguistics. 
J. I)6rre. 1997. Efficient construction ofunderspecified seman- 
tics under massive ambiguity. In Prec. ACL, Madrid. 
M. Dymetman. 1997. Interaction-free grammars, chart- 
parsing, and the compact representation of ambiguity. In 
Prec. I.ICAI, Nagoya. 
Martin Emele and Michael l)orna. 1998. Ambiguity p,'eserv- 
ing machine translation using tracked representations. In
Proceedings of Coling-ACL '98, pages 365-371, Montreal, 
August. 
Anette Frank. 1999. From parallel grammar development to- 
wards machine translation. In Proceedings of MT Summit 
VII. MT hl the Great 7)'anslation Et:a, pages 134-142, Kent 
Ridge Digital Labs, Singapore, September. 
Michael A. ltarrison. 1978. hm-oduction to Formal Lcmguage 
Theoty. Addison-Wesley, Reading, MA. 
M. Kay, J.M. Gawron, and R Norvig. 1994. Verbmobih a 
translation system for face to fitce dialog. CSLI. 
Martin Kay. 1999. Chart translation. In Proceedings of MT 
Summit VII. MT in the Great 7)'anslation Era, pages 9-14, 
Kent Ridge Digital Labs, Singapore, September 
John Maxwell and Ronald Kaplan. 1991. A method for dis- 
junctive constraint satisfaction. In Masaru Tomita, editor, 
Current Issues in PatMng Technology. Kluwer, Dordrecht. 
John T. Maxwell and Ronald M. Kaplan. 1993. Tbe interface 
between phrasal and functional constraints. Computational 
Linguistics, 19(4):571-590, l)ecember. 
John T. Maxwell and Ronald M. Kaplan. 
1996. An efficient parser for LFG. In IO'twt 
LFG Colference, Grenoble, France, August. 
ht tp  : / /www-cs l i .  stanford ,  edu/user /mutt / .  
M. Rayner and P. Bouillon. 1995. Hybrid Transfer in an 
English-French Spoken Language Translator In Proceed- 
ings of lA '95, Montpellim, France, Jtme. 
H. Shemtov. 1997. Ambiguity Management hz Natural Lan- 
guage Generation. Ph.D. thesis, Stanford. 
1020 
