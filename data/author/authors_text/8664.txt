Proceedings of NAACL HLT 2007, Companion Volume, pages 189?192,
Rochester, NY, April 2007. c?2007 Association for Computational Linguistics
Modifying SO-PMI for Japanese Weblog Opinion Mining by Using a
Balancing Factor and Detecting Neutral Expressions
Guangwei Wang
Graduate School of Information
Science and Technology
Hokkaido University
Sapporo, Japan 060-0814
wgw@media.eng.hokudai.ac.jp
Kenji Araki
Graduate School of Information
Science and Technology
Hokkaido University
Sapporo, Japan 060-0814
araki@media.eng.hokudai.ac.jp
Abstract
We propose a variation of the SO-PMI al-
gorithm for Japanese, for use in Weblog
Opinion Mining. SO-PMI is an unsuper-
vised approach proposed by Turney that
has been shown to work well for English.
We first used the SO-PMI algorithm on
Japanese in a way very similar to Turney?s
original idea. The result of this trial leaned
heavily toward positive opinions. We then
expanded the reference words to be sets of
words, tried to introduce a balancing fac-
tor and to detect neutral expressions. After
these modifications, we achieved a well-
balanced result: both positive and negative
accuracy exceeded 70%. This shows that
our proposed approach not only adapted
the SO-PMI for Japanese, but also modi-
fied it to analyze Japanese opinions more
effectively.
1 Introduction
Recently, more and more websites add information
in the form of personal opinions to the Web, e.g.
customer reviews of products, forums, discussion
groups, and blogs. Here, we use the term Weblog for
these sites. This type of information is often useful.
However, we have to deal with an enormous amount
of unstructured and/or semi-structured data. These
data are subjective, in free format and mostly tex-
tual, thus using them is difficult and time consum-
ing. Therefore, how to mine the Weblog opinions
automatically more effectively has attracted more
and more attention (Gamon, 2005; Popescu, 2005;
Chaovalit, 2005).
Turney (2002) has presented an unsupervised
opinion classification algorithm called SO-PMI (Se-
mantic Orientation Using Pointwise Mutual Infor-
mation). The main use of SO-PMI is to estimate
the semantic orientation (i.e. positive or negative)
of a phrase by measuring the hits returned from a
search engine of pairs of words or phrases, based on
the mutual information theory. This approach has
previously been successfully used on English. The
average accuracy was 74% when evaluated on 410
reviews from Epinions1.
However, according to our preliminary experi-
ment, directly translating Turney?s original idea into
Japanese gave a very slanted result, with a positive
accuracy of 95% and a negative accuracy of only
8%. We found that the balance between the posi-
tive and negative sides is influenced greatly by the
page hits of reference words/sets, since a search en-
gine is used. Therefore, we introduced a balancing
factor according for the difference in occurrence be-
tween positive and negative words. And then we
added several threshold rules to detect neutral ex-
pressions. The proposed approach is evaluated on
200 positive and 200 negative Japanese opinion sen-
tences and yielded a well-balanced result.
In the remainder of this paper, we review the SO-
PMI Algorithm in Section 2, then adapt the SO-PMI
for Japanese and present the modifications in Sec-
tion 3. In section 4, we evaluate and discuss the
experimental results. Section 5 gives concluding re-
marks.
2 Details of the SO-PMI Algorithm
The SO-PMI algorithm (Turney, 2002) is used to es-
timate the semantic orientation (SO) of a phrase by
1http://www.epinions.com
189
measuring the similarity of pairs of words or phrases
using the following formula:
PMI(word1,word2)=log2
[
p(word1&word2)
p(word1)p(word2)
]
(1)
SO(phrase) = PMI(phrase,?excellent?)
?PMI(phrase,?poor?) (2)
The reference words ?excellent? and ?poor? are
used, thus SO is positive when a phrase is more
strongly associated with ?excellent? and negative
when a phrase is more strongly associated with
?poor?. Let hits(query) be the number of hits re-
turned when using a search engine, the following
estimate of SO can be derived from Formula (2) and
(1) with some minor algebraic manipulation.
SO(phrase) = log2 [A]
A = hits(phrase NEAR?excellent?)?hits(?poor?)hits(phrase NEAR?poor?)?hits(?excellent?) (3)
Turney used AltaVista2 search engine because it
has a NEAR operator. This operator constrains the
search to documents that contain the words within
ten words of one another, in either order. Turney?s
previous work has shown that NEAR performs bet-
ter than AND when measuring the strength of se-
mantic association between words.
3 Our Proposed Approach
The first step of our approach is to extract opin-
ion phrases using word POS (part of speech) tem-
plates based on our analysis of opinions in Japanese
Weblog and the results of related work (Kobayashi,
2003; Taku, 2002; Wang, 2006). The second step is
to estimate the semantic orientation of the extracted
phrases, using the SO-PMI algorithm.
3.1 Adapting SO-PMI for Japanese
Following Turney?s original idea, we first translated
the SO formula to the one shown in Formula (4) for
Japanese.
SO(phrase) = log2 [B] (4)
We used the Google search engine3 to get the
hits(query) even though Google does not have a
NEAR operator. The AltaVista NEAR operator does
not work well for Japanese and Google indexes more
2http://www.altavista.com/sites/search/adv
3http://www.google.co.jp/
pages than AltaVista, thus we used Google and re-
placed the NEAR operator with the AND operator in
the SO formula. ? ? and ? ? were se-
lected because they correspond to the English words
?excellent? and ?poor?.
For testing the performance of this trial, we used
200 positive and 200 negative Japanese opinion sen-
tences which have been labeled by hand. The re-
sults were very slanted. Many phrases, whether pos-
itive or negative in meaning, still received a posi-
tive SO. Some possible causes could be that ?
(poor)? has more hits than ? (excellent)?,
as shown in Table 1, and that the AND operator is
less useful than the NEAR operator.
3.2 Modifying SO-PMI for Japanese
In Japanese, there are many expressions when
people evaluate something. For example, ?
(good)?, ? (good)?, ? (satisfaction)? , ?
(excellent)? are usually used when some-
one wants to convey a positive opinion. Hence
we tried to replace the reference words ?excellent?
and ?poor? with two reference sets: ?p?basic? and
?n?basic?:
SO(phrase) = log2 [C]
C = hits(phrase ANDp?basic)?hits(n?basic)hits(phrase ANDn?basic)?hits(p?basic) (5)
?p?basic? is a set of common strong positive
words in Japanese. ?n?basic? is a set of common
weak negative words. The hit counts of these words
from Google is shown in Table 1 (All data from
2007/01/12). The hits(query) was calculated by
hits(phrase AND (? (good)? OR ? (like)?)
OR ? (good)? OR ...).
Table 1: Frequency of p?basic/n?basic words on the Web
2.57 26,000?????(excellent)
2.81 28,400?????(interesting)
5.89 59,500????(happy)
7.40 74,700??(lovely)
7.48 75,500???(happy)
7.89 79,700???(interesting)
7.98 80,600??(satisfaction)
9.59 96,900??(good)
10.20 103,000??(good)
10.59 107,000???(delightful)
11.39 115,000???(want)
11.39 115,000???(favorite) 
14.85 150,000??(charm)
20.89 211,000??(good)
23.96 242,000??(like)
36.83 372,000??(good)
R(%)Hits (K)p_basic words
1.02 10,300 ???(bad)
1.54 15,600 ???(not good) 
1.64 16,600 ??? (fault)
2.05 20,700 ??(worst)
2.20 22,200 ??(dissatisfaction)
2.58 26,100 ??(dissatisfaction)
2.62 26,500 ??(painful)
2.62 26,500 ??(useless)
3.67 37,100 ??(dislike)
3.75 37,900 ????(not good)
6.44 65,000 ?(dislike)
7.68 77,600 ???(hard)
7.71 77,900 ??(fault)
8.22 83,000 ??(worry)
10.89 110,000 ??(bad)
11.78 119,000 ??(poor)
R(%)Hits (K)n_basic words
We evaluated this modification using the same
190
data as in Section 3.1. We obtained a slightly bet-
ter result. However the SO values were still slanted.
This time many phrases, whether positive or nega-
tive in meaning, still received a negative SO. All of
these test results are shown in detail in Section 4.2.
In the experiments above, we obtained heavily
slanted results. We consider that the large differ-
ence in page hits between the positive and negative
reference words/sets are the main cause for this phe-
nomenon. To mitigate this problem, we decided to
introduce a balancing factor to adjust the balance be-
tween the positive and negative sides. The SO for-
mula was modified from (5) to (6).
SO(phrase) = log2 [C] + f (?) (6)
The balancing factor f(?) was calculated by For-
mula (7).
f (?) = ? ? log2
[hits(p?basic)
hits(n?basic)
]
(7)
The log2 of ?p?basic? and ?n?basic? is a fac-
tor that adjusts the balance of the similarity of
?p?basic?/?n?basic? and phrases automatically by
the hits of ?p?basic?/?n?basic? itself. ? is a weight
value. We evaluated different values of ? from ?0.0?
to ?1.0? on the benchmark dataset, which is shown
in detail in Section 4.2.
From these preliminary trials, we also found that
many neutral phrases often receive positive or neg-
ative SO. Therefore we added detection of neu-
tral expressions. The idea is that if the phrase is
strongly or faintly associated with both ?p?basic?
and ?n?basic?, it is considered a neutral phrase. Be-
cause this means that this phrase has an ambiguous
connection with both ?p?basic? and ?n?basic?. We
use the following rules (Figure 1) to separate neutral
phrases from positive/negative phrases. The thresh-
old values ta, tb and tc are obtained from a small,
hand-labeled corpus.
1. hits( phrase AND p_basic) > ta AND hits( phrase AND n_basic) > ta
2.  hits( phrase AND p_basic) < tb AND  hits( phrase AND n_basic) < tb
3.  | hits( phrase AND p_basic) ? hits( phrase AND n_basic) | < tc
4. SO( phrase ) = 0 
Figure 1: Rules for Detecting Neutral Expressions
4 Experimental Performance Evaluation
4.1 Gold Standard and Evaluation Metrics
As a gold standard, we collected a benchmark
dataset which has 200 positive opinion sentences
and 200 negative opinion sentences from the reviews
about Electronic Dictionary and MP3 Player prod-
ucts that have been labeled as either positive or neg-
ative reviews in ?Kakaku.com?4. ?Kakaku.com? is
the largest Japanese Weblog specializing in product
comparison of consumer goods, including price and
user opinions, etc. Lots of people exchange mis-
cellaneous product information and reviews. These
reviews are classified as questions, positive re-
views, negative reviews, rumors, sale information or
?other? category.
To classify a sentence as positive (P) or negative
(N), the average SO of the phrases in the sentence is
used. If the average SO is P, the sentence is a posi-
tive sentence; otherwise it is a negative sentence. As
evaluation metrics, we measured our proposed ap-
proach?s performance by accuracy. accuracy was
measured as the number of sentences correctly clas-
sified as P/N sentences to the total number of P/N
sentences in the benchmark dataset (200). PA means
positive accuracy, NA means negative accuracy, i.e.
the accuracy on only positive or negative sentences
respectively.
4.2 Experiments and Results
First we did the balancing factor experiment to
determine the value of ???, using the benchmark
dataset. The results are shown in Figure 2. (a)
and (b) show the dashed line indicates average ac-
curacy (74%) on English Data from Turney?s Study
(2002). Turney didn?t evaluate positive and nega-
tive accuracy respectively. The full drawn line indi-
cates the result after translating the original SO-PMI
to Japanese (PA:95%, NA: 8%). PA series (the line
with triangle mark)/NA series (the line with circle
mark) when values of ??? from ?0.0? to ?1.0? were
used.
Changing the ? tends to be a tradeoff, lowering
PA when NA is improved and vice versa. There-
fore, we used Harmonic?Mean by the following
formula to find a proper value of ???.
Harmonic?Mean = 2 ? PA ?NAPA+NA (8)
Figure 2, (c) shows PA, NA and
Harmonic?Mean curves for different values
4http://www.kakaku.com/
191
0.00
0.10
0.20
0.30
0.40
0.50
0.60
0.70
0.80
0.90
1.00
0.0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1.0
?
A
c
c
u
r
a
c
y
Positive Accuracy by Modified SO-PMI (PA)
Positive Accuracy by Original SO-PMI for Japanese
Accuracy on English Data from Turney's Study
0.00
0.10
0.20
0.30
0.40
0.50
0.60
0.70
0.80
0.90
1.00
0.0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1.0
?
A
c
c
u
r
a
c
y
Negative Accuracy by modified SO-PMI (NA)
Negative Accuracy by Original SO-PMI for Japanese
Accuracy on English Data from Turney's Study
0.00
0.10
0.20
0.30
0.40
0.50
0.60
0.70
0.80
0.90
1.00
0.0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1.0
?
A
c
c
u
r
a
c
y
Harmonic_Mean of PA & NA
Positive Accuracy by Modified SO-PMI (PA)
Negative Accuracy by Modified SO-PMI (NA)
(a) Positive Accuracy (PA) (b) Negative Accuracy (NA) (c) Harmonic-Mean of PA/NA
Figure 2: Experiment for ? in Balance Factor
of ???. We selected the ??=0.9? giving the highest
Harmonic?Mean value, thus giving a good
balance between PA (75%) and NA (70%).
The comparative experiment results between the
SO-PMI for Japanese (Test 1), and our modifications
(Test 2, 3, 4) are shown in Table 2.
Table 2: Comparative Experiment Results
7278Test 3 + Modification 3: Neutral Phrase DetectionTest 4
PA: Positive Accuracy         NA: Negative Accuracy 
Test 3
Test 2
Test 1
9912Modification 1: Two Reference Sets
7075Test 2 + Modification 2: Balancing Factor [? =  0.9] 
895Naive translation of Turney?s Approach for Japanese
NA(%)PA(%)Test Content
In Test 1 and 2, we obtained extreme results, lean-
ing to the positive or negative end, whether using the
Turney?s original approach or expanding the refer-
ence word as ?p?basic? and ?n?basic?. In Test 3,
we added a balancing factor as described in section
3.2, and obtained a comparatively well-balanced re-
sult. Finally, after adding the neutral expressions de-
tection, we achieved a PA of 78% and NA of 72%
(Test 4). The balance between positive and negative
sides was quite improved by contrast with Test 1 and
2.
5 Conclusions
This study first proposed a modified unsupervised
approach (SO-PMI) for Japanese Weblog Opinion
Mining. Some parts of Turney?s approach, such as
the NEAR operator, does not work for Japanese,
thus some modifications must be done. In a prelim-
inary experiment, the negative accuracy (8%) was
very poor while the positive accuracy (95%) was
high. To deal with this phenomenon, we presented
three modifications based on the characteristics of
Japanese and the results of related work. The ex-
periment results (positive accuracy: 78%, negative
accuracy: 72%) show that our proposal achieved
a considerably improved performance, comparing
with directly translating the SO-PMI. Hence it
would be expected that the balancing factor and neu-
tral expressions detection would work effectively
also for other reference words or languages. In the
future, we will evaluate different choices of words
for the sets of positive and negative reference words.
We also plan to appraise our proposal on other lan-
guages.
References
Peter D. Turney. 2002. Thumbs up or thumbs down? Semantic
orientation applied to unsupervised classification of reviews.
Proceedings 40th Annual Meeting of the ACL, pp. 417-424.
Popescu, Ana-Maria, and Oren Etzioni. 2005. Extracting Prod-
uct Features and Opinions from Reviews. Proceedings of
HLT-EMNLP.
Michael Gamon, Anthony Aue, Simon Corston-Oliver and Eric
K. Ringger. 2005. Pulse: Mining Customer Opinions from
Free Text. Proceedings of the 2005 Conference on Intelligent
Data Analysis (IDA), pp.121-132.
Pimwadee Chaovalit and Lina Zhou. 2005. Movie Review Min-
ing: a Comparison between Supervised and Unsupervised
Classification Approaches. Proceedings of the 38th Annual
HICSS.
Nozomi Kobayashi, Kentaro Inui, Yuji Matsumoto, Kenji
Tateishi and Toshikazu Fukushima. 2003. Collecting eval-
uative expressions by a text mining technique. IPSJ SIG
NOTE, Vol.154, No.12, In Japanese.
Taku Kudoh and Yuji Matsumoto. 2002. Applying Cascaded
Chunking to Japanese Dependency Structure Analysis. In-
formation Processing Society of Japan (IPSJ)Academic
Journals, Vol 43, No 6, pp. 1834-1842, In Japanese.
Guangwei Wang and Kenji Araki. 2006. A Decision Support
System Using Text Mining Technology. IEICE SIG Notes
WI2-2006-6, pp. 55-56.
192
NAACL HLT Demonstration Program, pages 19?20,
Rochester, New York, USA, April 2007. c?2007 Association for Computational Linguistics
OMS-J: An Opinion Mining System for Japanese Weblog Reviews Using a
Combination of Supervised and Unsupervised Approaches
Guangwei Wang
Graduate School of Information
Science and Technology
Hokkaido University
Sapporo, Japan 060-0814
wgw@media.eng.hokudai.ac.jp
Kenji Araki
Graduate School of Information
Science and Technology
Hokkaido University
Sapporo, Japan 060-0814
araki@media.eng.hokudai.ac.jp
Abstract
We introduce a simple opinion mining
system for analyzing Japanese Weblog re-
views called OMS-J. OMS-J is designed
to provide an intuitive visual GUI of opin-
ion mining graphs for a comparison of
different products of the same type to
help a user make a quick purchase de-
cision. We first use an opinion mining
method using a combination of supervised
(a Naive Bayes Classifier) and unsuper-
vised (an improved SO-PMI: Semantic
Orientation Using Pointwise Mutual In-
formation) learning.
1 Introduction
Nowadays, there are numerous Web sites containing
personal opinions, e.g. customer reviews of prod-
ucts, forums, discussion groups, and blogs. Here,
we use the term Weblog for these sites. How to ex-
tract and analyze these opinions automatically, i.e.
?Opinion Mining?, has seen increasing attention in
recent years.
This paper presents a simple opinion mining sys-
tem (OMS-J) for analyzing Japanese Weblog re-
views automatically. The novelty of OMS-J is two-
fold: First, it provides a GUI using intuitive visual
mining graphs aimed at inexperienced users who
want to check opinions on the Weblog before pur-
chasing something. These graphs can help the user
to make a quick decision on which product is suit-
able. Secondly, this system combines a supervised
and an unsupervised approach to perform opinion
mining. In related work (Chaovalit, 2005; Tur-
ney, 2002), both supervised and unsupervised ap-
proaches have been shown to have their pros and
cons. Based on the merits of these approaches and
the characteristics of Japanese (Kobayashi, 2003),
we proposed an opinion mining method using a
Naive Bayes Classifier (supervised approach) and an
improved SO-PMI method (unsupervised approach)
to perform different parts of the classification task
(Wang, 2006).
OMS-J implements Weblog opinion mining by
the steps shown in Figure 1. In the next section, we
describe the proposed system in detail.
1. Information Search
2. Weblog Content Extraction
3. Opinion Mining
DB
4. Mining Grap s GUI
User
Search Engine (Google), Keyword
Lynx (Text Browser)
Cabocha (Structure Analyzer)
Template content extraction
Feature Classification
Supervised Approach (Na?ve Bayes)
P/N Classification
Unsupervised Approach (SO-PMI)
Figure 1: System Flow
2 Proposed System
2.1 Information Search
The first step is information search. We used the
Google search engine1 to get al the information on
one product category or one specific product in the
Japanese weblog on the Internet. The search key-
word is the product category name or the product
name. The URL range of the search is restricted by
the URL type (e.g. blog, bbs, review).
2.2 Weblog Content Extraction
The Content Extraction step first analyzes the We-
blog content using a dependency structure analyzer
for Japanese, Cabocha2. Based on the syntactic
characteristics of Japanese reviews and the results
1http://www.google.co.jp/
2http://www.chasen.org/?taku/software/cabocha/
19
of related work (Kobayashi, 2003; Taku, 2002), we
designed the following templates to extract opinion
phrases:
< noun + auxiliary word + adj / verb / noun >
< adj + noun / undefined / verb >
< noun + verb >
< noun + symbol + adj / verb / noun >
Except the above < adj >
2.3 Opinion Mining
Opinion mining methods can usually be divided into
two types: supervised and unsupervised approaches.
Supervised approaches are likely to provide more
accurate classification results but need a training cor-
pus. Unsupervised approaches on the other hand re-
quire no training data but tend to produce weaker
results.
We propose a combined opinion mining method
by performing feature classification and P/N classi-
fication (Wang, 2006). The purpose of these classifi-
cations is to know what the opinion expresses about
a certain product?s features. Feature means a prod-
uct?s attribute, i.e. price, design, function or battery
feature. Based on our previous study, it is easy to
create a feature corpus. Therefore feature classifica-
tion is performed by a supervised approach, a Naive
Bayes Classifier. P/N classification classifies repu-
tation expressions into positive or negative meaning
using an unsupervised approach, SO-PMI. The SO-
PMI approach measures the similarity of pairs of
words or phrases based on the mutual information
theory, in our case the closeness of an opinion and
words for ?good? or ?bad?.
No human effort is required when mining a new
product or category. Only inputting the name of the
product or category is needed. It does however re-
quire quite a lot of processing time, since the SO-
PMI approach using a search engine is very time
consuming. Adding new features requires manual
work, since a small hand labeled training corpus is
used. Similar categories of products, for instance
cameras and mp3 players, use the same features
though, so this is not done very often.
2.4 Mining Graphs GUI
Finally, OMS-J provides a GUI with mining graphs
showing the opinion mining data in the database, as
shown in Figure 2. These graphs show the distribu-
tion of positive and negative opinions of each feature
type such as ?design?, and for each product. The
distribution of positive opinions among the different
product choices are shown in a pie chart, as is the
same for negative opinions. This GUI can also show
graphs for a single product?s mining results, show-
ing the positive/negative opinion distribution of each
feature.
Figure 2: OMS-J?s GUI Screenshot for One Product Category
3 Demonstration
During the demonstration, we will show that OMS-
J is an intuitive opinion mining system that can help
people to make a quick decision on purchasing some
product. OMS-J?s trial version has been developed
and tested with three kinds of products: Electronic
Dictionaries, MP3 Players and Notebook PCs. The
experiment results were positive. We will show how
the system works when a user wants to buy a good
MP3 player or wants to get a feel for the general
opinions on a specific Notebook PC etc.
References
Pimwadee Chaovalit and Lina Zhou. 2005. Movie Review Min-
ing: a Comparison between Supervised and Unsupervised
Classification Approaches. Proceedings of the 38th Annual
HICSS.
Peter D. Turney. 2002. Thumbs up or thumbs down? Semantic
orientation applied to unsupervised classification of reviews.
Proceedings 40th Annual Meeting of the ACL, pp. 417-424.
Nozomi Kobayashi, Kentaro Inui, Yuji Matsumoto, Kenji
Tateishi and Toshikazu Fukushima. 2003. Collecting eval-
uative expressions by a text mining technique. IPSJ SIG
NOTE, Vol.154, No.12.
Guangwei Wang and Kenji Araki. 2006. A Decision Support
System Using Text Mining Technology. IEICE SIG Notes
WI2-2006-6, pp. 55-56.
Taku Kudoh and Yuji Matsumoto. 2002. Applying Cascaded
Chunking to Japanese Dependency Structure Analysis. In-
formation Processing Society of Japan (IPSJ)Academic
Journals, Vol 43, No 6, pp. 1834-1842.
20
