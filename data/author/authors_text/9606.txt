Proceedings of the 22nd International Conference on Computational Linguistics (Coling 2008), pages 73?80
Manchester, August 2008
A Classification of Dialogue Actions in Tutorial Dialogue
Mark Buckley and Magdalena Wolska
Dept. of Computational Linguistics
Saarland University
66041 Saarbr?ucken, Germany
{buckley|magda}@coli.uni-sb.de
Abstract
In this paper we present a taxonomy of di-
alogue moves which describe the actions
that students and tutors perform in tutorial
dialogue. We are motivated by the need for
a categorisation of such actions in order to
develop computational models for tutorial
dialogue. As such, we build both on exist-
ing work on dialogue move categorisation
for tutorial dialogue as well as dialogue
taxonomies for general dialogue. Our tax-
onomy has been prepared by analysing a
corpus of tutorial dialogues on mathemati-
cal theorem proving. We also detail an an-
notation experiment in which we apply the
taxonomy and discuss idiosyncrasies in the
data which influence the decisions in the
dialogue move classification.
1 Introduction
The field of Intelligent Tutoring Systems has seen
recent developments moving towards adding natu-
ral language capabilities to computer-based tutor-
ing (Graesser et al, 1999; Zinn, 2004; Litman and
Silliman, 2004), motivated by empirical investiga-
tions which point to the effectiveness of human tu-
tors (Bloom, 1984; Moore, 1993; Graesser et al,
1995). However, to be able to interact with a stu-
dent through the medium of natural language dia-
logue, the system must have a model of how such
tutorial dialogues can progress and what utterances
are licenced. In order to develop such a model
of dialogue, we need to understand and describe
the ?actions? performed with words, i.e. speech
acts (Austin, 1955) or dialogue moves. This in-
volves identifying and categorising the functions
c
? 2008. Licensed under the Creative Commons
Attribution-Noncommercial-Share Alike 3.0 Unported li-
cense (http://creativecommons.org/licenses/by-nc-sa/3.0/).
Some rights reserved.
that utterances may have in dialogue and their re-
lationships to each other.
Researchers in conversation and dialogue the-
ory have proposed various general categorisa-
tions of dialogue moves. DIT++ (Bunt, 2000)
is an example of a comprehensive multidimen-
sional taxonomy of dialogue acts for informa-
tion dialogues based on DAMSL (Allen and Core,
1997), a general-purpose extensible taxonomy pro-
posed as a standard for dialogue annotation. The
DAMSL dialogue act taxonomy characterises utter-
ances along four dimensions which correspond to
four levels of functions utterances may have. The
forward looking function describes the utterance?s
effect on the following interaction, the backward
looking function, its relation to previous dialogue,
the communicative status describes the compre-
hensibility or interpretability of the utterance, and
the information level characterises the content of
the utterance.
Tsovaltzi and Karagjosova (2004) proposed an
extension of the DAMSL classification based on an
analysis of tutorial dialogue corpora. The pro-
posed taxonomy adds a Task dimension which
concentrates on tutor actions in the dialogue.
1
Building on this work, we propose a further ex-
tension to this taxonomy inspired by our analysis
from the point of view of task-related goals. The
classification we present (i) includes modifications
of the DAMSL categorisation motivated by tutorial
dialogue, (ii) accounts for student?s actions, and
(iii) introduces a Task progress dimension whose
purpose is to characterise the completion status of
a generally viewed ?task?, instantiated for the pur-
pose of tutorial dialogue. We validated our dia-
logue act categorisation in a small-scale annotation
experiment whose results we present.
This paper is organised as follows: In Section 2
we introduce our data and taxonomy development
1
This classification has not been, to our knowledge, quan-
titatively evaluated.
73
methodology. In Section 3 we present the taxon-
omy. The results of the annotation experiment and
their discussion are presented in Section 4. Sec-
tion 5 presents related work and Section 6 con-
cludes the paper.
2 The Data and Analysis Methodology
Our work is based on an analysis of two corpora of
tutorial dialogues on mathematical theorem prov-
ing. We use the data to (i) verify the general
dialogue dimensions of the DAMSL taxonomy in
the context of tutorial dialogues, and (ii) extend
the taxonomy by developing the task dimension.
While the specific task-level moves are instanti-
ated for the mathematics tutoring domain, our aim
is to maintain generality that would allow us to
model task-level moves in other tutoring domains
as well as task-oriented dialogues in general. Be-
low we briefly introduce the corpora and outline
our methodology.
Corpora We analysed two corpora of tutorial
dialogues in the domain of mathematical theo-
rem proving collected in Wizard-of-Oz experi-
ments in which a human tutor (wizard) simulated
the system?s behaviour (Benzm?uller et al, 2003;
Benzm?uller et al, 2006a). The domains of mathe-
matics in the first (Corpus-I) and second (Corpus-
II) corpora are naive set theory and binary relations
respectively (Wolska et al, 2004; Benzm?uller et
al., 2006b).
In both experiments the dialogues were con-
ducted in German using the keyboard and a graph-
ical user interface. The tutoring in the experiment
described in (Benzm?uller et al, 2003) was per-
formed under three experimental conditions. The
control group (8 subjects) were tutored according
to the minimal feedback strategy in which the tu-
tor?s reactions were limited to informing the stu-
dent as to the correctness and completeness of their
contributions. In the didactic group (7 subjects)
and socratic group (7 subjects) the tutor?s strategy
focused on disclosing partial solutions to the stu-
dent in case of lack of progress and leading toward
the solution (hinting) respectively. Given the tutor-
ing strategy the verbosity of the minimal feedback
tutors was limited, while in both other conditions
as well as in the other experiment, the subjects and
the tutors were unconstrained in terms of the lin-
guistic realisation of their turns. Table 1 shows the
overview of the size of the corpora in terms of the
number of turns.
Corpus-I Corpus-II
no. subjects 22 37
no. turns 775 1917
no. student turns 332 937
no. tutor turns 443 980
Table 1: Overview of the corpora
Methodology In developing the taxonomy we
pursued the following iterative methodology:
First, in order to build the initial taxonomy, we
analysed 18 dialogues from Corpus-I containing
299 utterances (the development set). The purpose
of this analysis was to (i) verify the general suit-
ability of the DAMSL scheme in the tutoring do-
main,
2
(ii) identify features of dialogues moves rel-
evant in tutoring that were not present in the origi-
nal taxonomy (see the discussion in Section 4), (iii)
identify an initial set of task-level moves. We de-
scriptively defined the move types and wrote draft
annotation guidelines.
Second, we applied the initial taxonomy to 4 di-
alogues (108 utterances) taken from the two cor-
pora in an annotation task performed indepen-
dently by the authors of this paper (a preliminary
test set), after which we extended the taxonomy
and refined the existing category definitions. Fi-
nally, we randomly
3
selected an 64-utterance sub-
set taken from both corpora (validation set) to test
the coverage of the final taxonomy.
3 A Dialogue Move Taxonomy
Our goal in the analysis of the development set
and preliminary test set of the corpus was to deter-
mine a categorisation of the actions that can be per-
formed by students and tutors in tutorial dialogues.
The taxonomy which we have created from this
categorisation contains the dialogue moves which
realise these actions. Now the utterances per-
formed by students and tutors realise actions which
may or may not address or have an effect on the
current task. We thus speak of the task-level func-
tion of an utterance in addition to a general di-
alogue level function which all utterances have.
Task-level vs. general dialogue level function is
therefore the basic split in our taxonomy.
2
We expected this to be suitable because DAMSL is a tax-
onomy with general applicability.
3
We avoided dialogues in which the student?s utterances
contained formulas only.
74
The full definition of the taxonomy is presented
in Table 2. For each dialogue move we give a short
explanation of what function it is intended to cap-
ture as well as a short example. In the following
sections we discuss some of our design decisions.
3.1 The Forward and Backward Dimensions
At the general dialogue level we follow the DAMSL
taxonomy and categorise the functions of utter-
ances according to their relationship with the pre-
vious dialogue and their effect on the dialogue to
follow. For these functions we use a Forward
dimension and a Backward dimension, respec-
tively. In general, we try to accommodate the
DAMSL categories in order to build as much as
possible on existing generally accepted work on
dialogue moves. The forward dimension captures
utterances which are either assertions, requests or
commands. The backward dimension captures ut-
terances which agree or disagree with previous
utterances, address questions, signal the under-
standing status of previous utterances, or stand
in some information relation to previous utter-
ances. The main differences between DAMSL and
our categorisation within these two dimensions are
the following: (i) we combine DAMSL?s Assert
and Re-assert in a single category Assert which
may be optionally marked as repeating informa-
tion, (ii) we combine DAMSL?s Action-directive
and Info-request in a higher-level category of Re-
quests, (iii) in place of DAMSL?s Answer, we in-
troduce a more general Address category in the
backward dimension with subcategories Answer,
Deflect, and Neutral, where Deflect accounts for
avoiding answering and Neutral refers to those ut-
terances which simply address a previous informa-
tion request without answering it or a previous ac-
tion directive without acceding to it. The remain-
ing DAMSL categories were left unchanged; they
are also not presented in Table 2.
3.2 The Task and Task Progress Dimensions
At the task level we have utterances which address
the task at hand. These can mean altering the state
of the task solution, for instance by performing a
step in the solution, or talking about the task solu-
tion without altering it, for instance making state-
ments about previously performed steps. We di-
vide the task related actions in those which address
the task directly and those which address the solu-
tion construction process, and capture these in the
task and task progress dimensions respectively.
The Task dimension contains most of the task
related dialogue moves. We follow Tsovaltzi and
Karagjosova (2004) by splitting the task dimen-
sion into two subdivisions which relate to the par-
allel tasks being carried out and the roles of the
dialogue participants. Since the roles of student
and tutor restrict what actions can be performed
by the speakers, we split the task dimension into
actions which contribute to the solving task and
those which contribute to the teaching task. Ac-
tions in the solving task are typically performed
by the student, actions in the teaching task are typ-
ically performed by the tutor and are pedagogically
motivated. This is important for example to differ-
entiate between requests for task level information
? requests coming from the student are of an in-
formation seeking nature, those that come from the
tutor contribute to diagnostic or pedagogical goals.
Within the solving task, changes or additions to
the solution are captured by Solution-step, which
may be a new step or an extension of an exist-
ing step, and Solution-strategy. Solution-strategy
is divided into stating a strategy which will be fol-
lowed and stating a solution step which will be per-
formed in the future. The difference between these
is that the statement of a future step refers to a sin-
gle step in the solution which the student is com-
mitting to perform, whereas a strategy is a more
abstract concept. A strategy is more like a solution
approach which may consist of a number of steps,
however which actual steps are to be performed is
left open. In the domain of mathematical theorem
proving a strategy may refer to a particular proving
technique, for instance a proof by induction or by
contradiction, which may be realised by an utter-
ance such as ?I will now do a proof by induction?.
Exactly what constitutes a step and a strategy is a
matter of how the domain is modelled.
Request-assistance covers actions which ask for
help with the task. Within the teaching task,
Solution-step-evaluation refers to utterances that
convey the correctness or otherwise of steps. Do-
main relevant requests ask for domain related in-
formation such as definitions. Hint covers direct
hints about how to continue the task, for instance
by giving away a concept which should be used by
the student. The hint category will need to cover
many different kinds of actions depending on the
tutorial strategy which tutors follow ? we have
not subdivided this category and refer to Tsovaltzi
et al (2004) where this is further elaborated.
75
The Task Progress dimension equates in part to
the task management dimension in DAMSL. Here
the dialogue moves related to the current task are
those which start, finish, restart or abandon it. The
student can indicate the status of the solution con-
struction process to be on-track or finished or sig-
nal that he is lost.
In summary, we have prepared our taxonomy of
dialogue moves for tutoring by adding a Task and
Task Progress dimensions to the original DAMSL
taxonomy. We have tried to keep as close to the
DAMSL specification as possible with regard to the
general dialogue level function of dialogue moves,
while at the same time adapting it to capture the
phenomena of tutorial dialogue. Although some
moves will typically by performed by either the
student or the tutor (for example, only the tutor
will realistically give hints) we do not introduce
any constraints which restrict this.
4 Validating the Taxonomy
We used the taxonomy to perform a small-scale
annotation experiment on a validation set taken
from the two corpora introduced in Section 2. The
data had previously been segmented into utter-
ances. The goal of this experiment was to see
whether our categorisation can be reliably applied
to data and to validate the coverage of the taxon-
omy. The annotation was carried out by two an-
notators (the authors of this paper), following the
definitions of the dialogue moves informally pre-
sented above. We did not consider the category
information-relation because no definition is given
by the original DAMSL taxonomy, however we will
return to the question of information relation later
in the discussion.
Results Inter-annotator agreement was calcu-
lated using Cohen?s kappa (Cohen, 1960) and the
results of the experiment are given in the following
table.
Dimension ? value
Forward 0.87
Backward 0.47
Task 0.75
Task Progress 0.91
These results can be considered very good for the
Forward and Task Progress dimensions, good
for the Task dimension, and low for the Back-
ward dimension. Among the categories with the
lowest agreement were Neutral at 0.11 and Step-
augmentation at 0.37. In this preliminary evalua-
tion our strategy was not to use an category ?other?
for utterances which did not appear to belong to
any existing category, but rather to try to fit the an-
notation to the categories as they are. We marked
possibly problematic utterances for further discus-
sion.
Example We give examples of two fully anno-
tated dialogue excerpts in Figure 1. The exam-
ples illustrate some of the types of problematic ut-
terances which the corpora contain. For instance
both utterances ?Really?? and ?Yes?? are ques-
tions and could appear to be information requests,
but in fact act more like prompts to continue, for
which we had no category. Similarly the functions
of the questions in sequence in the second exam-
ple are difficult to abstract. We have tagged these
as Neutral, since they discharge the obligations
introduced by the questions before them, but the
link between consecutive interrogative utterances
is elusive.
Discussion We will now briefly discuss the re-
sults and findings of our annotation experiment
and allude to some of the possible causes of the
difficulties we encountered.
The nature of tutorial dialogue is an underlying
factor which makes it difficult to annotate cate-
gories reliably. Students tend to be very concise,
which makes it difficult to determine how the stu-
dent intended to relate the latest input to the pre-
vious discourse. This is reflected in our agreement
score for the backward dimension, which at 0.47
is much lower than the other dimensions, as well
as in the agreement score of 0.37 for the Solution-
step augmentation category, which is heavily de-
pendent on previous context. This result may even
point to a general characteristic of tutorial dialogue
which makes computational modelling challeng-
ing. In particular the Neutral category resulted in
conflicting annotations because it is often unclear,
as in the examples shown above, whether Requests
are being answered or merely addressed.
We have found that tutors typically perform ut-
terances which contribute to many different goals
? for instance they can simultaneously reject pro-
posed solution steps while giving hints on how to
continue in the task. The purpose of multidimen-
sional dialogue move taxonomies is to handle this
very multifunctionality, and while this is success-
76
Utterance Forward Backward Task
S: It holds that P (C ? (A ?B)) ? P (C) ? . . . assert solution-step:new
T: Really? info-request reject signal-incorrect
S: no it?s not, answer
S: the other way around assert solution-step:new
T: that?s right at last assert accept signal-correct
S: R ? S := {(x,y)| ? z(z ? M ? (x,z) ? R ? . . . assert solution-step:new
T: That?s right! assert accept signal-correct
S: now i want the inverse of that assert state-future-step
T: yes? neutral hint
S: (R ? S)
?1
assert neutral solution-step:new
T: = ? info-request request-clar request-explanation
S: How will the system answer? info-request neutral
T: What?s the question? info-request neutral
S: Can the system conclude (R ? S)
?1
from R ? S info-request neutral
T: yes assert answer
T: But try it yourself! action-dir hint
Figure 1: Annotated example from the corpus
ful to a point, conflicts in the annotation experi-
ment have highlighted some dual functions within
the same category. For instance, utterances simul-
taneously rejecting steps and requesting explana-
tions of the errors in the steps were found a number
of times.
We have found at least three categories that may
need to be added to the current taxonomy to make
it cover tutorial dialogue more completely. As dis-
cussed above, a prompt type in the forward dimen-
sion seems necessary. In addition, we would fore-
see a backward category which corrects a previ-
ous utterance, a category in the solving task which
requests the next step in the solution, and a cate-
gory in the task progress dimension to check if the
current task is being restarted. Similar categories
are proposed by Tsovaltzi and Karagjosova (2004),
and may be taken up.
We can draw attention to the fact that there are
many interrelations between the dimensions which
are not captured by our presentation of the tax-
onomy, and which may for instance be accounted
for by introducing constraints on label combina-
tions. We observe that many utterances stand in
some information relation (a DAMSL category) to
the previous discourse, although we have not fur-
ther specified what this relation might be. Such
utterances are typically step augmentations, and
could be described for instance (in RST terms) as
elaborations.
Finally we have adopted Tsovaltzi and
Karagjosova?s top-level structure, with Task as a
dimension. However, we observe that it would be
equally valid and more in keeping with the original
DAMSL categorisation of utterance functions to
make use of the existing Task sub-category of
the Info-level dimension. Similarly, our Task
progress corresponds to Info-level?s sub-category
Task management. This is a straightforward struc-
tural change which will not affect the annotation
results within these categories.
5 Related Work
The original DAMSL taxonomy was applied to and
evaluated on the TRAINS corpus of problem solv-
ing dialogues (Core and Allen, 1997). In this an-
notation a single label Task was used to mark all
task-related utterances. In the Verbmobil project,
a set of dialogue moves specific to negotiation
was proposed (Alexandersson et al, 1997). These
moves capture only the task-specific functions of
the utterances. Similarly, the HCRC Map Task
coding scheme concentrates on the task functions
of utterances, here specific to instruction-giving
dialogues. This classification is based on con-
versational games approach to dialogue seman-
tics (Houghton, 1986).
The DIT++ taxonomy of dialogue acts (Bunt,
2006) provides a more fine grained categorisation
of general dialogue actions, however there is no
one category or dimension dedicated to task spe-
cific functions. The category closest to (a subset
of) our Task dimension would be Activity-Specific
Functions, which however is defined in terms of
performative verbs or graphical actions. In the tu-
toring domain not all task-related actions are re-
alised by performatives.
There are a number of categorisations of dia-
logue actions specific to tutoring and motivated
by the development of tutorial dialogue systems.
Closely related to our work is a recent study by
77
Porayska-Pomsta et al (2008), who categorise task
related student actions and tutor feedback in a in-
vestigation of student affect. (Dzikovska et al,
2006) propose a flat coding scheme for tutorial di-
alogues on mathematics and relate it to a model of
collaborative problem solving dialogue. A simpler
taxonomy is presented by Marineau et al (2000)
which differs from our approach in that it was de-
veloped with the goal of automatic classification in
an intelligent tutoring system. In a pedagogically
motivated analysis of a corpus of tutorial dialogues
on computer literacy, Graesser et al (1999) cate-
gorise tutors? actions in order to propose a model
of tutorial dialogue structure.
6 Conclusions and Future Work
In this paper we have presented a taxonomy of dia-
logue moves which captures the actions performed
in by students and tutors in a corpus of tutorial dia-
logues. We then detailed an annotation experiment
which applied the taxonomy to a validation data
set and achieved good inter-annotator agreement.
This preliminary study showed that we are able to
cover the data well. We did however find a num-
ber of problematic phenomena in the data, such as
that of relating task level actions to the previous
discourse, which are of particular importance for
classifying tutorial dialogue actions.
In our future work we plan a larger scale anno-
tation of a further test set of our corpus, which we
believe will confirm the tendencies found so far.
We also intend to apply our taxonomy in an an-
notation of tutorial dialogue dealing with differ-
ent task domains, for example, tutorial dialogue
corpora in domains other than mathematics and
general problem-solving dialogues (e.g. TRAINS).
One of the goals of our work is to inform the de-
velopment of models for tutorial dialogue, and so
with a view towards operationalisation of the di-
alogue moves in our taxonomy, we will work on
an axiomatic formalisation of the dialogue moves.
This can form important input into developing a
plan-based model for tutorial dialogue.
References
Alexandersson, Jan, Bianka Buschbeck-Wolf, Tsutomu
Fujinami, Elisabeth Maier, Norbert Reithinger, Birte
Schmitz, and Melanie Siegel. 1997. Dialogue acts
in verbmobil-2. Technical report, DFKI.
Allen, James and Mark Core. 1997. Draft of
DAMSL: Dialogue act markup in several layers.
DRI: Discourse Research Initiative, University of
Pennsylvania. http://www.cs.rochester.
edu/research/cisd/resources/damsl/
RevisedManual/.
Austin, John L. 1955. How to do things with Words.
2005, second edition. William James Lectures.
Benzm?uller, Christoph, Armin Fiedler, Malte Gabsdil,
Helmut Horacek, Ivana Kruijff-Korbayov?a, Manfred
Pinkal, J?org Siekmann, Dimitra Tsovaltzi, Bao Quoc
Vo, and Magdalena Wolska. 2003. A Wizard-of-
Oz experiment for tutorial dialogues in mathemat-
ics. In Aleven, Vincent, Ulrich Hoppe, Judy Kay,
Riichiro Mizoguchi, Helen Pain, Felisa Verdejo,
and Kalina Yacef, editors, AIED2003 Supplementary
Proceedings, volume VIII: Advanced Technologies
for Mathematics Education, pages 471?481, Sydney,
Australia. School of Information Technologies, Uni-
versity of Sydney.
Benzm?uller, Christoph, Helmut Horacek, Ivana Kruijff-
Korbayov?a, Henri Lesourd, Marvin Schiller, and
Magdalena Wolska. 2006a. DiaWozII ? A Tool
for Wizard-of-Oz Experiments in Mathematics. In
Proceedings of the 29th Annual German Conference
on Artificial Intelligence (KI-06), Lecture Notes in
Computer Science, number 4314, pages 159?173,
Bremen, Germany. Springer-Verlag.
Benzm?uller, Christoph, Helmut Horacek, Henri
Lesourd, Ivana Kruijff-Korbayov?a, Marvin Schiller,
and Magdalena Wolska. 2006b. A corpus of tuto-
rial dialogs on theorem proving; the influence of the
presentation of the study-material. In Proceedings
of the 5th International Conference on Language
Resources and Evaluation (LREC-06), pages 1766?
1769, Genoa, Italy. ELDA.
Bloom, B. 1984. The 2 Sigma Problem: The Search for
Methods of Group Instruction as Effective as One-to-
One Tutoring. Educational Researcher, 13(6):4?16.
Bunt, Harry. 2000. Dialogue pragmatics and context
specification. In Bunt, Harry and William Black,
editors, Abduction, Belief and Context in Dialogue.
Studies in Computational Pragmatics, volume 1,
pages 81?150. Benjamins.
Bunt, Harry. 2006. Dimensions in Dialogue Act An-
notation. In Proceedings of the 5th International
Conference on Language Resources and Evaluation
(LREC-06), pages 919?924, Genova, Italy.
Cohen, Jacob. 1960. A coefficient of agreement
for nominal scales. Educational and Psychological
Measurement, 20(1):37?46.
Core, Mark G. and James F. Allen. 1997. Coding
dialogues with the DAMSL annotation scheme. In
Traum, David, editor, Working Notes: AAAI Fall
Symposium on Communicative Action in Humans
and Machines, pages 28?35. AAAI, Menlo Park,
CA, USA.
78
Dzikovska, Myroslava O., Charles B. Callaway,
Matthew Stone, and Johanna D. Moore. 2006. Un-
derstanding student input for tutorial dialogue in pro-
cedural domains. In Schlangen, David and Raquel
Fernandez, editors, Proceedings of Brandial, the
10th Workshop on the Semantics and Pragmatics of
Dialogue, pages 10?17.
Graesser, A. C., N. K. Person, and J. P. Magliano.
1995. Collaborative dialogue patterns in naturalistic
one-on-one tutoring. Applied Cognitive Psychology,
9:495?522.
Graesser, Arthur C., Katja Wiemer-Hastings, Peter
Wiemer-Hastings, and Roger Kreuz. 1999. Auto-
tutor: A simulation of a human tutor. Cognitive Sys-
tems Research, 1:35?51.
Houghton, G. 1986. The Production of Language in
Dialogue: A Computational Model. Ph.D. thesis,
University of Sussex.
Litman, Diane J. and Scott Silliman. 2004. ITSPOKE:
An Intelligent Tutoring Spoken Dialogue System.
In Proceedings of the Human Language Technol-
ogy Conference: 4th Meeting of the North American
Chapter of the Association for Computational Lin-
guistics (HLT/NAACL) (Companion Proceedings),
Boston, MA.
Marineau, Johanna, Peter Wiemer-Hastings, Derek
Harter, Brent Olde, Patrick Chipman, Ashish Kar-
navat, Victoria Pomeroy, Sonya Rajan, and Art
Graesser. 2000. Classification of speech acts in tu-
torial dialogue. In Proceedings of the Workshop on
Modeling Human Teaching Tactics and Strategies,
ITS 2000, pages 65?71.
Moore, Johanna. 1993. What makes human explana-
tions effective? In Proceedings of the 15
th
Meet-
ing of the Cognitive Science Society, pages 131?136,
Hillsdale, NJ.
Porayska-Pomsta, Ka?ska, Manolis Mavrikis, and He-
len Pain. 2008. Diagnosing and acting on student
affect: the tutor?s perspective. User Modeling and
User-Adapted Interaction, 18(1-2):125?173.
Tsovaltzi, Dimitra and Elena Karagjosova. 2004. A
View on Dialogue Move Taxonomies for Tutorial
Dialogues. In Strube, Michael and Candy Sidner,
editors, Proceedings of 5th SIGdial Workshop on
Discourse and Dialogue, pages 35?38, Cambridge,
Massachusetts, USA. Association for Computational
Linguistics.
Tsovaltzi, Dimitra, Armin Fiedler, and Helmut Ho-
racek. 2004. A multi-dimensional taxonomy for au-
tomating hinting. In Lester, James C., Rosa Maria
Vicari, and F?abio Paraguac?u, editors, Intelligent
Tutoring Systems ? 7th International Conference
(ITS-04), number 3220 in LNCS, pages 772?781.
Springer.
Wolska, M., B. Q. Vo, D. Tsovaltzi, I. Kruijff-
Korbayova, E. Karagjosova, H. Horacek, M. Gabs-
dil, A. Fiedler, and C. Benzm?uller. 2004. An an-
notated corpus of tutorial dialogs on mathematical
theorem proving. In Proceedings of the Fourth In-
ternational Conference on Language Resources and
Evaluation (LREC-04), pages 1007?1010, Lisbon.
Zinn, Claus. 2004. Flexible dialogue management
in natural-language enhanced tutoring. In Konvens
2004 Workshop on Advanced Topics in Modeling
Natural Language Dialog, pages 28?35, Vienna,
Austria.
79
Label Explanation Example
Forward Dimension
Assert Makes a claim about the world ?It holds that P ?
Request Introduces an obligation on the hearer to answer
Action-directive The obligation is that an action is performed ?Please show the following ?
Info-request Request for a piece of information ?What is the definition of...??
Open-option Suggestion of future action without obligation ?You could do a proof by induction?
Backward Dimension
Agreement Acceptance or rejection of plans or propositions
Accept Accepts a proposal ?Ok?
Reject Rejects a proposal ?That?s incorrect?
Address Responses to requests
Answer Answers a previously posed info-request ?Yes?/?No?
Deflect Shows inability or unwillingness to answer ?I can?t answer that?
Neutral Addresses without answering or deflecting ?Why do you ask??
Information relation Relation to an antecedent utterance
Understanding related Refers to problems understanding the speaker
Request clarification Asks to clarify a previous utterance ?What do you mean by X??
Request rephrase Asks for a repeat/rephrase of an utterance ?Could you repeat that??
Signal non-understanding Catch-all for signalling understanding problems
Task Dimension: Solving Task
Solution-step Refers to a step to the current solution
Step augmentation Adds to an existing step ?Concluded using Rule X?
New Contributes a new step ?Rewrite formula A to B?
Solution-strategy Refers to a solution strategy
State strategy States a solution strategy which will be used ?I now do a case split?
state future step State a step that will be executed later ?I will use DeMorgan2?
Request assistance Ask for help with the task
Request concept explanation Ask to explain a domain concept ?What does P mean??
Request worked example Ask for an example to be presented ?Could you give me an example??
Request solution strategy Ask what strategy to proceed with ?How should i do this task??
Task Dimension: Teaching Task
Solution-step-evaluation References to evaluations of soln steps
Signal correct Indicates the step was correct ?Correct!?
Signal incorrect Indicates the step was incorrect ?Wrong!?
Hint Give a hint towards solving the task
Give-away-concept Give away a concept to help with the task ?You should use rule X?
Request domain relevant Requests which refer to domain concepts
Explain Ask for an explanation to be given ?T: What is the defn of powerset??
Identify Ask for a concept to be identified ?T: What does ? denote??
Define Ask for a definition ?What is the definition of...??
Task Progress
Start task Starts the solution construction process ?Please prove P = Q?
Finish task Indicates end of the solution construction process ?I?m done?, ?Q.E.D?
Restart task Indicates solution being started again ?Start again?
Give-up task Abandons the current solution attempt ?I give up?
Task solution status References to solution progress
On-track Solution construction is on track ?Am i ok??, ?You?re doing fine?
Lost Indicates speaker is lost in current solution ?I?m lost?
Table 2: The full taxonomy. Each type is given along with an explanation and an example
80
