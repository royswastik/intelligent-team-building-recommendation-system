Proceedings of the Fourth Workshop on Statistical Machine Translation , pages 165?172,
Athens, Greece, 30 March ? 31 March 2009. c?2009 Association for Computational Linguistics
Mining a comparable text corpus for a Vietnamese - French  
statistical machine translation system 
 
 
Thi-Ngoc-Diep Do *,**, Viet-Bac Le *, Brigitte Bigi*,  
Laurent Besacier*, Eric Castelli** 
*LIG Laboratory, CNRS/UMR-5217, Grenoble, France 
** MICA Center, CNRS/UMI-2954, Hanoi, Vietnam 
thi-ngoc-diep.do@imag.fr 
 
 
 
 
Abstract 
This paper presents our first attempt at con-
structing a Vietnamese-French statistical 
machine translation system. Since Vietnam-
ese is an under-resourced language, we con-
centrate on building a large Vietnamese-
French parallel corpus. A document align-
ment method based on publication date, spe-
cial words and sentence alignment result is 
proposed. The paper also presents an appli-
cation of the obtained parallel corpus to the 
construction of a Vietnamese-French statis-
tical machine translation system, where the 
use of different units for Vietnamese (sylla-
bles, words, or their combinations) is dis-
cussed. 
1 Introduction 
Over the past fifty years of development, ma-
chine translation (MT) has obtained good results 
when applied to several pairs of languages such 
as English, French, German, Japanese, etc. How-
ever, for under-resourced languages, it still re-
mains a big gap. For instance, although 
Vietnamese is the 14th widely-used language in 
the world, research on MT for Vietnamese is 
very rare.  
The earliest MT system for Vietnamese is the 
system from the Logos Corporation, developed 
as an English-Vietnamese system for translating 
aircraft manuals during the 1970s (Hutchins, 
2001). Until now, in Vietnam, there are only four 
research groups working on MT for Vietnamese-
English (Ho, 2005). However the results are still 
modest. 
MT research on Vietnamese-French occurs 
even more rarely. Doan (2001) proposed a trans-
lation module for Vietnamese within ITS3, a 
multilingual MT system based on the classical 
analysis-transfer-generation approach. Nguyen 
(2006) worked on Vietnamese language and 
Vietnamese-French text alignment. But no com-
plete MT system for this pair of languages has 
been published so far.  
There are many approaches for MT: rule-based 
(direct translation, interlingua-based, transfer-
based), corpus-based (statistical, example-based) 
as well as hybrid approaches. We focus on build-
ing a Vietnamese-French statistical machine 
translation (SMT) system. Such an approach re-
quires a parallel bilingual corpus for source and 
target languages. Using this corpus, we build a 
statistical translation model for source/target lan-
guages and a statistical language model for target 
language. Then the two models and a search 
module are used to decode the best translation 
(Brown et al, 1993; Koehn et al, 2003). 
Thus, the first task is to build a large parallel 
bilingual text corpus. This corpus can be de-
scribed as a set of bilingual sentence pairs. At the 
moment, such a large parallel corpus for Viet-
namese-French is unavailable. (Nguyen, 2006) 
presents a Vietnamese-French parallel corpus of 
law and economics documents. Our SMT system 
was trained using Vietnamese-French news cor-
pus created by mining a comparable bilingual 
text corpus from the Web.  
Section 2 presents the general methodology of 
mining a comparable text corpus. We present an 
overview of document alignment methods and 
sentence alignment methods, and discuss the 
document alignment method we utilized, which 
is based on publishing date, special words, and 
sentence alignment results. Section 3 describes 
our experiments in automatically mining a multi-
lingual news website to create a Vietnamese-
French parallel text corpus. Section 4 presents 
165
our application to rapidly build Vietnamese-
French SMT systems using the obtained parallel 
corpus, where the use of different units for Viet-
namese (syllables, words, or their combination) is 
discussed. Section 5 concludes and discusses fu-
ture work. 
2 Mining a comparable text corpus  
In (Munteanu and Daniel Marcu, 2006), the au-
thors present a method for extracting parallel 
sub-sentential fragments from comparable bilin-
gual corpora. However this method is in need of 
an initial parallel bilingual corpus, which is not 
available for the pair of language Vietnamese-
French (in the news domain). 
The overall process of mining a bilingual text 
corpus which is used in a SMT system typically 
takes five following steps (Koehn, 2005): raw 
data collection, document alignment, sentence 
splitting, tokenization and sentence alignment. 
This section presents the two main steps: docu-
ment alignment and sentence alignment. We also 
discuss the proposed document alignment 
method. 
2.1 Document alignment 
Let S1 be set of documents in language L1; let S2 
be set of documents in language L2. Extracting 
parallel documents or aligning documents from 
the two sets S1, S2 can be seen as finding the 
translation document D2 (in the set S2) of a 
document D1 (in the set S1). We call this pair of 
documents D1-D2 a parallel document pair 
(PDP). 
For collecting bilingual text data for the two 
sets S1, S2, the Web is an ideal source as it is 
large, free and available (Kilgarriff and Grefen-
stette, 2003). For this kind of data, various meth-
ods to align documents have been proposed. 
Documents can be simply aligned based on the 
anchor link, the clue in URL (Kraaij et al, 2003) 
or the web page structure (Resnik and Smith, 
2003). However, this information is not always 
available or trustworthy. The titles of documents 
D1, D2 can also be used (Yang and Li, 2002), but 
sometimes they are completely different. 
Another useful source of information is invari-
ant words, such as named entities, dates, and 
numbers, which are often common in news data. 
We call these words special words. (Patry and 
Langlais, 2005) used numbers, punctuation, and 
entity names to measure the parallelism between 
two documents. The order of this information in 
document is used as an important criterion. How-
ever, this order is not always respected in a PDP 
(see an example in Table 1). 
 
French document Vietnamese document 
      Selon l'Administration 
nationale du tourisme, les 
voyageurs en provenance de 
l'Asie du Nord-Est (Japon, 
R?publique de Cor?e,...) 
repr?sentent 33%, de l'Eu-
rope, 16%, de l'Am?rique 
du Nord, 13%, d'Australie 
et de Nouvelle-Z?lande, 6%. 
     En outre, depuis le d?but 
de cette ann?e, environ 2,8 
millions de touristes ?tran-
gers ont fait le tour du Viet-
nam, 78% d'eux sont venus 
par avion.  
     Cela t?moigne d'un af-
flux des touristes riches au 
Vietnam.? 
     Trong s? g?n 2,8 tri?u 
l??t kh?ch qu?c t? ??n Vi?t 
Nam t? ??u n?m ??n nay, 
l??ng kh?ch ??n b?ng 
???ng h?ng kh?ng v?n 
chi?m ch? ??o v?i kho?ng 
78%.  
     ?i?u n?y cho th?y, d?ng 
kh?ch du l?ch ch?t l??ng 
cao ??n Vi?t Nam t?ng 
nhanh. 
     Theo th?ng k? th? kh?ch 
qu?c t? v?o Vi?t Nam cho 
th?y kh?ch ??ng B?c ? 
(Nh?t B?n, H?n Qu?c) 
chi?m t?i 33%, ch?u ?u 
chi?m 16%, B?c M? 13%, 
?xtr?ylia v? Niu Dil?n 
chi?m 6%.? 
Table 1. An example of a French-Vietnamese 
parallel document pair in our corpus. 
2.2 Sentence alignment 
From a PDP D1-D2, the sentence alignment 
process identifies parallel sentence pairs (PSPs) 
between two documents D1 and D2. For each 
D1-D2, we have a set SenAlignmentD1-D2 of 
PSPs. 
SenAlignmentD1-D2 = {?sen1-sen2?| sen1 is 
zero/one/many sentence(s) in document D1, 
sen2 is zero/one/many sentence(s) in docu-
ment D2, sen1-sen2 is considered as a 
PSP}. 
We call a PSP sen1-sen2 alignment type m:n 
when sen1 contains m consecutive sentences and 
sen2 contains n consecutive sentences. 
Several automatic sentence alignment ap-
proaches have been proposed based on sentence 
length (Brown et al, 1991) and lexical informa-
tion (Kay and Roscheisen, 1993). A hybrid ap-
proach is presented in (Gale and Church, 1993) 
whose basic hypothesis is that ?longer sentences 
in one language tend to be translated into longer 
sentences in the other language, and shorter sen-
tences tend to be translated into shorter sen-
tences?. Some toolkits such as Hunalign1 and 
Vanilla2 implement these approaches. However, 
they tend to work best when documents D1, D2 
contain few sentence deletions and insertions, 
and mainly contain PSPs of type 1:1. 
                                                          
1
 http://mokk.bme.hu/resources/hunalign 
2
 http://nl.ijs.si/telri/Vanilla/ 
166
Ma (2006) provides an open source software 
called Champollion1 to solve this limitation. 
Champollion permits alignment type m:n (m, n = 
0,1,2,3,4), so the length of sentence does not play 
an important role. Champollion uses also lexical 
information (lexemes, stop words, bilingual dic-
tionary, etc.) to align sentences. Champollion can 
easily be adapted to new pairs of languages. 
Available language pairs in Champollion are 
English-Arabic and English-Chinese (Ma, 2006).  
2.3 Our document alignment method 
Figure 1 describes our methodology for docu-
ment alignment. For each document D1 in the set 
S1, we find the aligned document D2 in the set 
S2.  
We propose to use publishing date, special 
words, and the results of sentence alignment to 
discover PDPs. First, the publishing date is used 
to reduce the number of possible documents D2. 
Then we use a filter based on special words con-
tained in the documents to determine the candi-
date documents D2. Finally, we eliminate 
candidates in D2 based on the combination of 
document length information and lexical infor-
mation, which are extracted from the results of 
sentence alignment. 
 
 
Figure 1. Our document alignment scheme. 
2.3.1 The first filter: publishing date 
We assume that the document D2 is translated 
and published at most n days after the publishing 
date of the original document. We do not know 
whether D1 or D2 is the original document, so 
                                                          
1
 http://champollion.sourceforge.net 
we assume that D2 is published n days before or 
after D1. After filtering by publishing date crite-
rion, we obtain a subset S2? containing possible 
documents D2. 
2.3.2 The second filter: special words  
In our case, the special words are numbers and 
named entities. Not only numbers (0-9) but also 
attached symbols (?$?, ?%?, ???, ?,?, ?.??) are 
extracted from documents, for example: 
?12.000$?; ?13,45?; ?50%?;? Named entities 
are specified by one or several words in which 
the first letter of each word is upper case, e.g. 
?Paris?, ?Nations Unies? in French.  
While named entities in language L1 are usu-
ally translated into the corresponding names in 
language L2, in some cases the named entities in 
L1 (such as personal names or organization 
names) do not change in L2. In particular, many 
Vietnamese personal names are translated into 
other languages by removal of diacritical marks 
(see examples in Table 2). 
 
 French Vietnamese Vietnamese 
-Removed 
diacritic 
Nations 
Unies 
Li?n H?p 
Qu?c 
Lien Hop 
Quoc 
Changed 
France Ph?p Phap 
ASEAN ASEAN ASEAN 
Nong Duc 
Manh 
N?ng ??c 
M?nh 
Nong Duc 
Manh 
Not 
changed 
Dien Bien ?i?n Bi?n Dien Bien 
Table 2. Some examples of named entities in 
French-Vietnamese. 
 
All special words are extracted from document 
D1. This gives a list of special words w1,w2,?wn. 
For each special word, we search in the set S2? 
documents D2 which contain this special word. 
For each word, we obtain a list of documents D2. 
The document D2 which has the biggest number 
of appearance in all lists is chosen. It is the 
document containing the highest number of spe-
cial words. We can find zero, one or several 
documents which are satisfactory. We call this 
set of documents set S2?? (see in Figure 2). 
The way that we use special words is different 
from the way used in (Patry and Langlais, 2005). 
We do not use punctuation as special words. We 
use the attached symbols (?$?, ?%?, ???, ?) with 
the number. Furthermore, in our method, the or-
der of special words in documents is not impor-
tant, and if a special word appears several times 
in a document, it does not affect the result. 
 
S1 S2 
Filter by publishing date  
(?n days) 
S2?
S2??
?S2?  D2 },ent{SenAlignm D2-D1 ?
Filter by special words 
 (numbers+ named entities) 
Align sentences 
Filter SenAlignment 
(use ?, ?) 
sen2}-{sen1D2}-{D1 +
D1 D2
167
  
Figure 2. Using special words to filter documents 
D2. 
2.3.3 The third filter: sentence alignments  
As mentioned in section 2.3.2, for each document 
D1, we discover a set S2??, which contains zero, 
one or several documents D2. When we continue 
to align sentences for each PDP D1-D2, we get a 
lot of low quality PSPs. The results of sentence 
alignment allow us to further filter the documents 
D2. 
After aligning sentences, we have a set of 
PSPs, SenAlignmentD1-D2, for each PDP D1-D2. 
We add two rules to filter documents D2.  
When D1-D2 is not a true PDP, it is hard to 
find out PSPs. So we note the number of PSPs in 
the set SenAlignmentD1-D2 by 
card(SenAlignmentD1-D2). The number of sentence 
pairs which can not find their alignment partner 
(when sen1 or sen2 is ?null?) is noted by 
nbr_omitted(SenAlignmentD1-D2).  
When ?>)ignmentcard(SenAl
)mentd(SenAlignnbr_omitte
D2-D1
D2-D1
 , this 
PDP D1-D2 will be eliminated. 
This first rule also deals with the problem of 
document length, sentence deletions and sentence 
insertions. 
The second rule makes use of lexical informa-
tion. For each PSP, we add two scores xL1 and xL2 
for sen1 and sen2.  
i
i
Li
seninwordsofnumber
seninwordstranslatedofnumber
x
????
?????
=
 
Translated words are words having translation 
equivalents in the other sentence. In this rule, we 
do not take into account the stop words. Table 3 
shows an example for calculating two scores xL1 
and xL2  for a PSP.  
In the second rule, when all PSPs in Se-
nAlignmentD1-D2 have two scores xL1 and xL2 that 
are both smaller than ?, this PDP D1-D2 will be 
eliminated. This rule removes the low quality 
PDP which creates a set of low quality PSPs. 
sen1 (in French) : ils ont ?chang? leurs opinions pour 
parvenir ? la signature de documents constituant la base 
du d?veloppement et de l' intensification de la coop?ra-
tion en ?conomie en commerce et en investissement ainsi 
que celles dans la culture le sport et le tourisme entre les 
deux pays 
sen2 (in Vietnamese) : hai b?n ?? ti?n_h?nh trao_??i ?? 
k?_k?t c?c v?n_b?n l?m c?_s? cho vi?c m?_r?ng v? 
t?ng_c??ng quan_h? h?p_t?c kinh_t? th??ng_m?i 
??u_t? v?n_ho? th?_thao v? du_l?ch gi?a hai n??c 
Translated words :  
??chan-
ger:trao_??i? ;?base:c?_s??,?intensification:t?ng_c??n
g? ;?coop?ration:h?p_t?c?,??conomie:kinh_t?? ; inves-
tissement:??u_t??,?sport:th?_thao? ; ?tou-
risme :du_l?ch? ; ?pays:n??c? 
Number of non-stop words in sen1 19  
Number of non-stop words in sen2 21 
Number of translated words 9 
xL1 = 9/19=0.47 ; xL2 = 9/21=0.43 
Table 3. Example for calculating two scores xL1 
and xL2. 
 
After using three filters based on information 
of publishing date, special words, and the results 
of sentence alignment, we have a corpus of 
PDPs, and also a corpus of corresponding PSPs. 
To ensure the quality of output PSPs, we can 
continue to filter PSPs. For example, we can keep 
only the PSPs whose scores (xL1 and xL2) are 
higher than a threshold. 
3 Experiments 
3.1 Characteristics of Vietnamese 
The basic unit of the Vietnamese language is syl-
lable. In writing, syllables are separated by a 
white space. One word corresponds to one or 
more syllables (Nguyen, 2006). Table 4 presents 
an example of a Vietnamese sentence segmented 
into syllables and words.  
 
Vietnamese sentence: Th?nh ph? hy v?ng s? ??n nh?n 
kho?ng 3 tri?u kh?ch du l?ch n??c ngo?i trong n?m nay 
Segmentation in syllables: Th?nh | ph? | hy | v?ng | s? | 
??n | nh?n | kho?ng | 3 | tri?u | kh?ch | du | l?ch | n??c | 
ngo?i | trong | n?m | nay 
Segmentation in words: Th?nh_ph? | hy_v?ng | s? | 
??n_nh?n | kho?ng | 3 | tri?u | kh?ch_du_l?ch | 
n??c_ngo?i | trong | n?m | nay 
Corresponding English sentence: The city is expected to 
receive 3 million foreign tourists this year 
Table 4. An example of a Vietnamese sentence 
segmented into syllables and words. 
 
In Vietnamese, words do not change their 
form. Instead of conjugation for verb, noun or 
adjective, Vietnamese language uses additional 
words, such as ?nh?ng?, ?c?c? to express the plu-
D1 
Extract  
special words 
w1?wn  
 find w1 in S2?   doc1, doc3, doc5 
 find w2 in S2?   doc3, doc4, doc5 
 find w3 in S2?   doc3, doc5 
 ?                     ? 
doc1: 1 time 
doc3: 3 times 
doc4: 1 time 
doc5: 3 times 
 Count 
Choose 
the max 
S2?? 
{doc3, 
doc5} 
168
ral; ????, ?s?? to express the past tense and the 
future. The syntactic functions are also deter-
mined by the order of words in the sentence 
(Nguyen, 2006).  
3.2 Data collecting  
In order to build a Vietnamese-French parallel 
text corpus, we applied our proposed methodol-
ogy to mine a comparable text corpus from a 
Vietnamese daily news website, the Vietnam 
News Agency1 (VNA). This website contains 
news articles written in four languages (Vietnam-
ese, English, French, and Spanish) and divided in 
9 categories including ?Politics - Diplomacy?, 
?Society - Education?, ?Business - Finance?, 
?Culture - Sports?, ?Science - Technology?, 
?Health?, ?Environment?, ?Asian corner? and 
?World?. However, not all of the Vietnamese 
articles have been translated into the other three 
languages. The distribution of the amount of data 
in four languages is shown in figure 3. 
 
 
Figure 3. Distribution of the amount of data for 
each language on VNA website. 
 
Each document (i.e., article) can be obtained 
via a permanent URL link from VNA. To date, 
we have obtained about 121,000 documents in 
four languages, which are gathered from 12 April 
2006 to 14 August 2008; each document con-
tains, on average, 10 sentences, with around 30 
words per sentence. 
3.3 Data pre-processing 
We splitted the collected data into 2 sets. The 
development set, designated SDEV, contained 
1000 documents, was used to tune the mining 
system parameters. The rest of data, designated 
STRAIN, was used as a training set, where the esti-
mated parameters were applied to build the entire 
corpus. We applied the following pre-process to 
each set SDEV and STRAIN: 
1. Extract contents from documents. 
                                                          
1
 http://www.vnagency.com.vn/ 
2. Classify documents by language (using 
TextCat2, an n-gram based language identi-
fication). 
3. Process and clean both Vietnamese and 
French documents by using the CLIPS-Text-
Tk toolkit (LE et al, 2003): convert html to 
text file, convert character code, segment 
sentence, segment word. The resulting clean 
corpora are S1 (for French) and S2 (for 
Vietnamese). 
3.4  Parameters estimation 
Our proposed document alignment method was 
applied to the sets S1 and S2 extracted from the 
set SDEV. To filter by publishing date, we as-
sumed that n=2.  
The second filter was implemented on the set 
S1 and the new set S2* which was created by re-
moving diacritical marks from the set S2 (in the 
case of Vietnamese).  
The sentence alignment process was imple-
mented by using data from sets S1, S2 and the 
Champollion toolkit. We adapted Champollion to 
Vietnamese-French by changing some parame-
ters: the ratio of French word to Vietnamese 
translation word is set to 1.2, penalty for align-
ment type 1-1 is set to 1, for type 0-1 to 0.8, for 
type 2-1, 1-2 and 2-2 to 0.75, and we did not use 
the other types (see more in (Ma, 2006)). After 
using two filters, the result data is shown in Table 
5. The true PDPs were manually extracted. 
 
SDEV - Number of documents: 1000 
- Number of French documents: 173 
- Number of Vietnamese documents: 348 
- Number of true PDPs: 129 
S2?? - Number of found PDPs: 379 
- Number of hits PDPs: 129 
- Precision = 34.04% , Recall = 100% 
Table 5. Result data after using two filters. 
  
The third filter was applied in which ? was set 
to (0.4, 0.5, 0.6, 0.7) and ? was set to (0.1, 0.15, 
0.2, 0.25, 0.3, 0.35, 0.4). The precision and recall 
were calculated according to our true PDPs and 
the F-measure (F1 score) was estimated. 
F-measure 
    ?   
?  0.1 0.15 0.2 0.25 0.3 0.35 0.4 
0.4 0.69 0.71 0.71 0.60 0.48 0.36 0.21 
0.5 0.76 0.79 0.77 0.65 0.52 0.39 0.23 
0.6 0.77 0.83 0.82 0.70 0.56 0.41 0.26 
0.7 0.75 0.84 0.83 0.73 0.59 0.44 0.27 
Table 6. Filter result with different values of ? 
and ? on the SDEV. 
                                                          
2
 http://www.let.rug.nl/~vannoord/TextCat/ 
169
From the results mentioned in Table 6, we 
chose ?=0.7 and ?=0.15. 
3.5 Mining the entire corpus 
We applied the same methodology with the pa-
rameters estimated in section 3.4 to the set 
STRAIN. The obtained corpus is presented in Table 
7.  
 
STRAIN - Number of documents: 120,218 
- Number of French documents: 20,884 
- Number of Vietnamese documents: 
54,406 
Entire 
corpus 
- Number of PDPs: 12,108 
- Number of PSPs: 50,322 
Table 7. The obtained corpus from STRAIN. 
4 Application: a Vietnamese - French 
statistical machine translation system  
With the obtained parallel corpus, we attempted 
to rapidly build a SMT system for Vietnamese-
French. The system was built using the Moses 
toolkit1. The Moses toolkit contains all of the 
components needed to train both the translation 
model and the language model. It also contains 
tools for tuning these models using minimum 
error rate training and for evaluating the transla-
tion result using the BLEU score (Koehn et al, 
2007). 
4.1 Preparing data 
From the entire corpus, we chose 50 PDPs (351 
PSPs) for developing (Dev), 50 PDPs (384 PSPs) 
for testing (Tst), with the rest PDPs (49,587 
PSPs) reserved for training (Trn).  
Concerning the developing and testing PSPs, 
we manually verified and eliminated low quality 
PSPs, which produced 198 good quality PSPs for 
developing and 210 good quality PSPs for test-
ing. The data used to create the language model 
were extracted from 49,587 PSPs of the training 
set. 
4.2 Baseline system  
We built translation systems in two translation 
directions: French to Vietnamese (FV) and 
Vietnamese to French (VF). The Vietnamese 
data were segmented into either words or sylla-
bles. So we first have four translation systems. 
We removed sentences longer than 100 
words/syllables from the training and develop-
                                                          
1
 http://www.statmt.org/moses/ 
ment sets according to the Moses condition (so 
the number of PSPs used in the training set dif-
fers slightly between systems). All words found 
are implicitly added to the vocabulary. 
 
System Direction Vietnamese is 
segmented into Nbr of PSPs 
S1FV FV 
S1VF VF 
Syllable 
Training: 47,081 
Developing: 198 
Testing:        210 
S2FV FV 
S2VF VF 
Word 
Training: 48,864 
Developing: 198 
Testing:        210 
 
System Set - 
Language 
Nbr. of vocab  
(K) 
Nbr. of running 
words/syllables 
(K) 
Fr 38.6 1783.6 Trn Vn 21.9 2190.2 
Fr 1.8 6.3 Dev Vn 1.2 6.9 
Fr 1.9 6.4 
S1FV 
S1VF 
 
Tst Vn 1.3 7.1 
Fr 39.7 1893 Trn Vn 33.4 1629 
Fr 1.8 6.3 Dev Vn 1.5 4.8 
Fr 1.9 6.3 
S2FV 
S2VF 
 
Tst Vn 1.6 4.9 
Table 8. Our four translation systems. 
 
We obtained the performance results for those 
systems in Table 9. In the case of the systems 
where Vietnamese was segmented into words, 
the Vietnamese sentences were changed back to 
syllable representation before calculating the 
BLEU scores, so that all the BLEU scores evalu-
ated can be compared to each other. 
 
 S1FV S1VF S2FV S2VF 
BLEU  0.40 0.31 0.40 0.30 
Table 9. Evaluation of SMTs on the Tst set. 
 
The BLEU scores for French to Vietnamese 
translation direction are around 0.40 and the 
BLEU scores for Vietnamese to French transla-
tion direction are around 0.31, which is encour-
aging as a first result. Moreover, only one 
reference was used to estimate BLEU scores in 
our experiments. It is also interesting to note that 
segmenting Vietnamese sentences into words or 
syllables does not significantly change the per-
formance for both translation directions. An ex-
ample of translation from four systems is 
presented in Table 10.  
 
 
 
170
Given a pair of parallel sentences 
FR: selon le d?partement de gestion des travailleurs 
? l' ?tranger le qatar est un march? prometteur et 
n?cessite une grande quantit? de travailleurs ?tran-
gers 
VNsyl : theo c?c qu?n l? lao ??ng ngo?i n??c cata 
l? th? tr??ng ??y ti?m n?ng v? c? nhu c?u l?n lao 
??ng n??c ngo?i 
VNword : theo c?c qu?n_l? lao_??ng ngo?i n??c 
cata l? th?_tr??ng ??y ti?m_n?ng v? c? nhu_c?u l?n 
lao_??ng n??c_ngo?i 
S1FV Input: FR              Reference: VNsyl 
Output: theo c?c qu?n l? lao ??ng ? n??c 
ngo?i ph?a cata l? m?t th? tr??ng ??y ti?m 
n?ng v? c?n m?t l??ng l?n lao ??ng n??c 
ngo?i 
S2FR Input: FR              Reference: VNword 
Output: theo th?ng_k? c?a c?c qu?n_l? 
lao_??ng ngo?i n??c cata l? m?t 
th?_tr??ng ??y ti?m_n?ng v? c?n c? s? l?n 
l??ng lao_??ng n??c_ngo?i 
S1VF Input: VNsyl         Reference: FR 
Output: selon le d?partement de gestion 
des travailleurs ?trangers cata ?tait un mar-
ch? plein de potentialit?s et aux besoins 
importants travailleurs ?trangers 
S2VF Input: VNword      Reference: FR 
Output : selon le d?partement de gestion 
des travailleurs ?trangers cata march? plein 
de potentialit?s et la grande travailleurs 
?trangers 
Table 10 : Example of translation from systems. 
4.3 Combining word- and syllable-based 
systems 
We performed another experiment on combining 
syllable and word units on the Vietnamese side. 
We carried out the experiment on the Vietnamese 
to French translation direction only. In fact, the 
Moses toolkit supports the combination of 
phrase-tables. The phrase-tables of the system 
S1VF (Tsyl) and system S2VF (Tword) were used. 
Another phrase-table (Tword*) was created from 
the Tword, in which all words in the phrase table 
were changed back into syllable representation 
(in this latter case, the word segmentation infor-
mation was used during the alignment process 
and the phrase table construction, while the unit 
kept at the end remains the syllable). The combi-
nations of these three phrase-tables were also 
created (by simple concatenation of the phrase 
tables). The Vietnamese input for this experiment 
was either in word or in syllable representation. 
As usual, the developing set was used for tuning 
the log-linear weights and the testing set was 
used to estimate the BLEU score. The obtained 
results are presented in Table 11. Some perform-
ances are marked as X since those combinations 
of input and phrase table do not make sense (for 
instance the combination of input in words and 
syllable-based phrase table). 
 
Input in syllable Input in word Phrase-tables 
used Dev Tst Dev Tst 
Tsyl 0.35 0.31 X X 
Tword X X 0.35 0.30 
Tword* 0.37 0.31 X X 
Tsyl + Tword 0.35 0.31 0.36 0.30 
Tsyl + Tword* 0.38 0.32 X X 
Tword + Tword* 0.37 0.30 0.36 0.30 
Table 11: The BLEU scores obtained from com-
bination of phrase-tables on Dev set and Tst set 
(Vietnamese to French machine translation). 
 
These results show that the performance can 
be improved by combining information from 
word and syllable representations of Vietnamese. 
(BLEU improvement from 0.35 to 0.38 on the 
Dev set and from 0.31 to 0.32 on the Tst set). In 
the future, we will analyze more the combination 
of syllable and word units for Vietnamese MT 
and we will investigate the use of confusion net-
works as an MT input, which have the advantage 
to keep both segmentations (word, syllable) into 
a same structure. 
4.4 Comparing with Google Translate1 
Google Translate system has recently supported 
Vietnamese. In most cases, it uses English as an 
intermediary language. For the first comparative 
evaluation, some simple tests were carried out. 
Two sets of data were used: in domain data set 
(the Tst set in section 4.2) and out of domain data 
set. The latter was obtained from a Vietnamese-
French bilingual website2 which is not a news 
website. After pre-processing and aligning manu-
ally, we obtained 100 PSPs in the out of domain 
data set. In these tests, the Vietnamese data were 
segmented into syllables. Both data sets were 
inputted to our translation systems (S1FV, S1VF) 
and the Google Translate system. The outputs of 
Google Translate system were post-processed 
(lowercased) and then the BLEU scores were 
estimated. Table 12 presents the results of these 
tests. While our system is logically better for in 
domain data set, it is also slightly better than 
Google for out of domain data set.  
 
                                                          
1
 http://translate.google.com 
2
 http://www.ambafrance-vn.org 
171
BLEU score  Direction Our system Google 
FV 0.40  0.25 In domain 
(210 PSPs) VF 0.31  0.16 
FV 0.25 0.24 Out of domain 
(100 PSPs) VF 0.20 0.16 
Table 12: Comparing with Google Translate. 
5 Conclusions and perspectives 
In this paper, we have presented our work on 
mining a comparable Vietnamese-French corpus 
and our first attempts at Vietnamese-French 
SMT. The paper has presented our document 
alignment method, which is based on publication 
date, special words and sentence alignment re-
sult. The proposed method is applied to Vietnam-
ese and French news data collected from VNA. 
For Vietnamese and French data, we obtained 
around 12,100 parallel document pairs and 
50,300 parallel sentence pairs. This is our first 
Vietnamese-French parallel bilingual corpus. We 
have built SMT systems using Moses. The BLEU 
scores for French to Vietnamese translation sys-
tems and Vietnamese to French translation sys-
tems were 0.40 and 0.31 in turn. Moreover, 
combining information from word and syllable 
representations of Vietnamese can be useful to 
improve the performance of Vietnamese MT sys-
tem.  
In the future, we will attempt to increase the 
corpus size (by using unsupervised SMT for in-
stance) and investigate further the use of different 
Vietnamese lexical units (syllable, word) in a MT 
system.  
References  
Brown, Peter F., Jennifer C. Lai and Robert L. Mer-
cer. 1991. Aligning sentences in parallel corpora. 
Proceedings of 47th Annual Meeting of the Asso-
ciation for Computational Linguistics. 
Brown, Peter F., Stephen A. Della Pietra, Vincent J. 
Della Pietra and Robert L. Mercer. 1993. The 
Mathematics of Statistical Machine Translation: 
Parameter Estimation. Computational Linguistics. 
Vol. 19, no. 2. 
Doan, Nguyen Hai. 2001. Generation of Vietnamese 
for French-Vietnamese and English-Vietnamese 
Machine Translation. ACL, Proceedings of the 8th 
European workshop on Natural Language Genera-
tion. 
Gale, William A. and Kenneth W. Church. 1993. A 
program for aligning sentences in bilingual cor-
pora. Proceedings of the 29th annual meeting on 
Association for Computational Linguistics. 
Ho, Tu Bao. 2005. Current Status of Machine Trans-
lation Research in Vietnam Towards Asian wide 
multi language machine translation project. Viet-
namese Language and Speech Processing Work-
shop. 
Hutchins, W.John. 2001. Machine translation over 
fifty years. Histoire, epistemologie, langage: HEL, 
ISSN 0750-8069, Vol. 23, N? 1, 2001 , pages. 7-32.  
Kay, Martin and Martin Roscheisen. 1993. Text - 
translation alignment. Association for Computa-
tional Linguistics. 
Kilgarriff, Adam and Gregory Grefenstette. 2003. 
Introduction to the Special Issue on the Web as 
Corpus. Computational Linguistics, volume 29. 
Koehn, Philipp, Franz Josef Och and Daniel Marcu. 
2003. Statistical phrase-based translation. Confer-
ence of the North American Chapter of the Asso-
ciation for Computational Linguistics on Human 
Language Technology - Volume 1. 
Koehn, Philipp. 2005. Europarl: A Parallel Corpus 
for Statistical Machine Translation. Machine 
Translation Summit.  
Koehn, Philipp, Hieu Hoang, Alexandra Birch, Chris 
Callison-Burch, Richard Zens, Marcello Federico, 
Nicola Bertoldi, Brooke Cowan, Wade Shen and 
Christine Moran. 2007. Moses: Open Source Tool-
kit for Statistical Machine Translation. Proceedings 
of the ACL.  
Kraaij, Wessel, Jian-Yun Nie and Michel Simard. 
2003. Embedding web-based statistical translation 
models in cross-language information retrieval. 
Computational Linguistics,  Volume 29 ,  Issue 3. 
LE, Viet Bac, Brigitte Bigi, Laurent Besacier and Eric 
Castelli. 2003. Using the Web for fast language 
model construction in minority languages. Eu-
rospeech'03. 
Ma, Xiaoyi. 2006. Champollion: A Robust Parallel 
Text Sentence Aligner. LREC: Fifth International 
Conference on Language Resources and Evalua-
tion.  
Munteanu, Dragos Stefan and Daniel Marcu. 2006. 
Extracting parallel sub-sentential fragments from 
non-parallel corpora . 44th annual meeting of the 
Association for Computational Linguistics 
Nguyen, Thi Minh Huyen. 2006. Outils et ressources 
linguistiques pour l'alignement de textes multilin-
gues fran?ais-vietnamiens. Th?se pr?sent?e pour 
l?obtention du titre de Docteur de l?Universit? Hen-
ri Poincar?, Nancy 1 en Informatique.  
Patry, Alexandre and Philippe Langlais. 2005. Para-
docs: un syst?me d?identification automatique de 
documents parall?les. 12e Conference sur le Trai-
tement Automatique des Langues Naturelles. 
Dourdan, France.  
Resnik, Philip and Noah A. Smith. 2003. The Web as 
a Parallel Corpus. Computational Linguistics.  
Yang, Christopher C. and Kar Wing Li. 2002. Mining 
English/Chinese Parallel Documents from the 
World Wide Web. Proceedings of the 11th Interna-
tional World Wide Web Conference, Honolulu, 
USA.  
172
